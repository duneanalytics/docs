[["0",{"pageContent":"[View code on GitHub](https://dune.com/README.md)\n\n# Dune Docs\n\nThe Dune Docs is an open-source crypto analytics tool built by and for the community. This guide provides technical documentation for the Dune Docs app. The guide is built with Material for MkDocs, and contributions are welcome, from spelling mistakes to entire guides on the Ethereum Virtual Machine (EVM).\n\n## Chatgpt Integration\n\nThis section explains how to use the chatgpt integration to ask questions in a CLI. To use the chatgpt integration, you need to follow the autodoc setup guide. Autodoc requires Node v18.0.0 or greater, and v19.0.0 or greater is recommended. You can check the version of Node you are running by typing `node -v` in the terminal. If you don't have the proper version, you need to install it. \n\nAfter installing the proper version of Node, you need to install the Autodoc CLI tool as a global NPM module by typing `npm install -g @context-labs/autodoc` in the terminal. Then, you need to set or export your OpenAI API key. Once you have done that, you can clone the repo and run `doc q` in the repo to ask questions. \n\n## Install Dune Docs Locally\n\nThis section explains how to install Dune Docs locally. To run the docs locally, you need to set up your local Python 3 environment, e.g., with Miniconda. After setting up your local Python 3 environment, you need to install the Python libraries by typing `pip install -r requirements.txt` in the terminal. Finally, you can run the docs locally by typing `mkdocs serve` in the terminal.\n\n## Notes\n\nThis section provides a reminder to use relative paths to markdown files for internal links. If you don't use relative paths, the mkdocs compiler will not detect broken internal links. \n\n## Translations\n\nThis section explains that Dune Docs are translated by members of the community and are currently available in English and Chinese. Each translation is run as a separate `mkdocs-material` project. For example, with the Chinese docs, you can navigate to `zh` and run `mkdocs serve`. The build process automatically merges together translations into a single docs site with a language switcher. If you want to propose a new language, you can open an issue or reach out to the Dune Docs team on Discord.\n\n## Upgrades\n\nThis section explains how to upgrade `mkdocs-material`. To upgrade `mkdocs-material`, you need to pin a new version of `mkdocs-material` and update the hard-coded value for stylesheets in `overrides/main.html`. You can update the `requirements.txt` file with the new version of `mkdocs-material`, upgrade your local environment, find the auto-generated stylesheet file name, update it in `overrides/main.html`, and do the same for the `mkdocs-material-insiders`. Finally, you can update the `mkdocs-material` version on Vercel.\n## Questions: \n 1. What is the purpose of Dune Docs?\n- Dune Docs is a crypto analytics tool built for the community.\n\n2. What are the requirements for using the chatgpt integration?\n- The chatgpt integration requires Node v18.0.0 or greater, and the Autodoc CLI tool must be installed as a global NPM module.\n\n3. How are translations handled in Dune Docs?\n- Translations are run as separate `mkdocs-material` projects, and the build process automatically merges translations into a single docs site with a language switcher. Currently, Dune Docs is available in English and Chinese.","metadata":{"source":".autodoc/docs/markdown/README.md"}}],["1",{"pageContent":"[View code on GitHub](https://dune.com/docs/analytics_guidelines.md)\n\n# Web3 Analytics Resources\n\nThis technical guide provides end-to-end tutorials on how to analyze specific protocols in web3. It highlights the challenges of analyzing protocols in web3, which include the ever-expanding data battlefield as new protocols, tokens, and wallets join the fray and add to the chaos. The guide provides tips on scoping your work and finding what to analyze. It also emphasizes the importance of metrics-driven analysis and provides two great end-to-end video series guides for metrics analysis. \n\nThe guide explains that protocol metrics are usually dependent on different token and wallet segments. For example, Uniswap allows you to create pairs of two tokens at a time to add liquidity and swap through. However, the USDC-WETH pair will have very different behaviors from SHIB-WETH. To understand token trends and contexts, the guide recommends checking out the ERC20 dashboard and the NFT dashboard. To understand wallet/user segments, you'll need to leverage labels to enhance your analysis.\n\nThe guide also emphasizes the importance of sharing your work with the community. When you're done, be sure to share your work in the Discord `#📺︱show-your-work` channel and on Twitter tagging @duneanalytics. The guide provides more community guides and resources to help you get started with querying on Dune Analytics.\n\nThe guide also includes a section on the OurNetwork Course, which is based on Dune's V1 engine. The course teaches 30 people web3 data analytics in 30 days and covers all of the important topics you'll need to know to effectively analyze blockchain data and become a full-fledged Dune Wizard. The guide provides a link to the course materials and encourages readers to consider buying an edition of the Mirror post to support the teachers of this course.\n## Questions: \n 1. What is the purpose of the Dune Docs app and how does it relate to blockchain data analysis?\n    \n    The Dune Docs app provides end-to-end tutorials on how to analyze specific protocols in web3 using SQL and blockchain concepts. It is designed to help blockchain SQL analysts build their reputation as expert wizards by staying centered on what they want to analyze and what metrics they want to present.\n\n2. What are some of the challenges that blockchain SQL analysts might face when analyzing protocols in web3?\n    \n    Blockchain SQL analysts might face challenges when analyzing protocols in web3 due to the ever-expanding data battlefield as new protocols, tokens, and wallets join the fray and add to the chaos. They will need to understand the contract architecture and context, as well as the mix of onchain events happening, to build metrics-driven analysis.\n\n3. What resources are available for blockchain SQL analysts to learn how to use Dune Analytics and analyze blockchain data?\n    \n    There are several resources available for blockchain SQL analysts to learn how to use Dune Analytics and analyze blockchain data, including the Dune official guides, the OurNetwork course, and various guides and tutorials created by members of the Dune community. Additionally, there are several dashboards available for understanding token trends and contexts, as well as wallet/user segments.","metadata":{"source":".autodoc/docs/markdown/docs/analytics_guidelines.md"}}],["2",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/FAQ/TOS.md)\n\n# Dune API TOS\n\nThis section of the app technical guide covers the Dune API Terms of Service (TOS). The TOS outlines the rules and guidelines for using the Dune API. It is important for developers to understand and comply with these terms in order to use the API effectively and avoid any legal issues.\n\nThe header provides a link to the actual API TOS document, which is hosted on the Dune website. Developers should review this document thoroughly before using the API.\n\nExample:\n\n```\n// Make a request to the Dune API\nfetch('https://api.dune.com/data')\n  .then(response => {\n    // Handle response\n  })\n  .catch(error => {\n    // Handle error\n  });\n```\n\n# Authentication\n\nThis section covers the authentication process for accessing the Dune API. Developers must obtain an API key in order to access the API. The header provides an overview of the authentication process and links to additional resources for obtaining an API key.\n\nExample:\n\n```\n// Set API key as authorization header\nconst headers = {\n  'Authorization': 'Bearer YOUR_API_KEY_HERE'\n};\n\n// Make a request to the Dune API with headers\nfetch('https://api.dune.com/data', { headers })\n  .then(response => {\n    // Handle response\n  })\n  .catch(error => {\n    // Handle error\n  });\n```\n\n# Rate Limiting\n\nThis section covers the rate limiting policy for the Dune API. The API has a limit on the number of requests that can be made within a certain time period. The header provides an overview of the rate limiting policy and links to additional resources for understanding and managing rate limits.\n\nExample:\n\n```\n// Check if rate limit has been reached\nif (response.headers.get('X-RateLimit-Remaining') === '0') {\n  // Handle rate limit reached error\n}\n```\n\nOverall, this app technical guide provides important information for developers using the Dune API. It covers the API TOS, authentication process, and rate limiting policy, which are all crucial aspects of using the API effectively and responsibly.\n## Questions: \n 1. What specific APIs does Dune Docs offer and what are their respective terms of service?\n- The app technical guide only provides a link to the API terms of service page, so a blockchain SQL analyst may want to know more about the specific APIs offered by Dune Docs and their corresponding terms of service.\n\n2. Does Dune Docs have any restrictions or limitations on the usage of their APIs?\n- The app technical guide does not provide any information on restrictions or limitations on API usage, so a blockchain SQL analyst may want to know if there are any such restrictions in place.\n\n3. Is there any documentation available on how to integrate Dune Docs APIs into a blockchain SQL project?\n- The app technical guide only provides a link to the API terms of service page, so a blockchain SQL analyst may want to know if there is any additional documentation available on how to integrate Dune Docs APIs into their project.","metadata":{"source":".autodoc/docs/markdown/docs/api/FAQ/TOS.md"}}],["3",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/FAQ/billing-pricing.md)\n\n# Dune API Billing & Pricing\n\nThis technical guide provides information about Dune's API billing and pricing. It covers the following topics:\n\n## FAQ: Billing & Pricing\n\nThis section provides answers to frequently asked questions about Dune's API billing and pricing.\n\n### How will API Billing work with the new Team plans?\n\nThis question addresses the upcoming support for API keys on a team level in the first few months of 2023. The answer explains that any usage associated with a team API key will be billed to their respective team.\n\n### What’s a datapoint?\n\nThis question defines a datapoint as rows multiplied by columns with an additional limit of 50 average bytes per cell in a set of results. The formula for calculating datapoints is also provided.\n\n### Do I get charged datapoints for every execution?\n\nThis question clarifies that Dune charges datapoints for the first read result of every distinct query execution and every subsequent 100th read per billing cycle.\n\nOverall, this technical guide provides important information about Dune's API billing and pricing. It is particularly useful for developers who are building applications that use Dune's API and need to understand how they will be charged for their usage. The guide is concise and easy to understand, with clear explanations and examples where appropriate.\n## Questions: \n 1. What is the pricing model for Dune API and how is it calculated?\nA blockchain SQL analyst might want to know more about the pricing model for Dune API and how it is calculated based on the usage of datapoints and query executions.\n\n2. How does Dune handle billing for multiple API keys associated with a team?\nA blockchain SQL analyst might want to know how Dune handles billing for multiple API keys associated with a team and if there are any limitations or restrictions.\n\n3. Is there a limit on the number of datapoints that can be used in a single query execution?\nA blockchain SQL analyst might want to know if there is a limit on the number of datapoints that can be used in a single query execution and if there are any additional charges for exceeding that limit.","metadata":{"source":".autodoc/docs/markdown/docs/api/FAQ/billing-pricing.md"}}],["4",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/FAQ/functionality.md)\n\n# Dune API Functionality\n\nThis technical guide provides answers to frequently asked questions about how the Dune API works. The guide is divided into different sections based on the feature of the project app that the file is focused on. \n\n## General\n\nThis section provides general information about the Dune API.\n\n### Requests Per Minute\n\nThe API is currently set to a rate limit of 60 requests per minute. However, this will soon be set to match the rate limits specified in the varying API plan tiers.\n\n### SLAs\n\nSLAs will be available in the future on Enterprise pricing plans.\n\n## Executing Queries\n\nThis section provides information on how to execute queries using the Dune API.\n\n### Query ID\n\nTo find a query ID, navigate to a query, and it's the first number after \"/queries/\" in the URL. An example is provided in the guide.\n\n### Query Parameters\n\nThe API supports query parameters. For Dune Queries that include parameters, you can pass parameter data as part of the Execute Query ID endpoint. The guide provides links to learn more about building Dune Queries with parameters and how to pass parameter data using cURL and Python.\n\n### Performance and Differences\n\nThere are no major performance differences or differences in what can be accessed between the Dune API and the Dune web app if both are using the same app plan tier. The Dune API gives you programmatic access to the capabilities and data sets that can already be accessed from the Dune web app.\n\n### Execution Timeout Limit\n\nThe query execution timeout limit matches the Dune web app, which is 30 minutes.\n\n### Query Engine\n\nThe guide recommends using the API with v2 Dune SQL as the old v1 engine and v2 Spark SQL are slowly being deprecated.\n\n## Check Execution Status\n\nThis section provides information on how to check the execution status of a query.\n\n### States\n\nPending means the execution is waiting for an available execution connection slot, while executing means the query is currently executing against the database.\n\n## Reading Results Data\n\nThis section provides information on how to read results data from a query.\n\n### Direct Connection to the Database\n\nCurrently, it's not possible to ingest data by getting a direct connection to the database. In the interim, the guide recommends periodically fetching from \"max(latestBlockNumber) - 2\" to \"lastFetchedBlockNumber\" in regular intervals.\n\n### Query Results Data\n\nQuery results data is saved for faster retrieval.\n\n### Results Data Storage\n\nThe results data from an execution is currently stored for two years, but this may be reduced to something closer to 90 days in the future. This is visible on the API response on the \"expires_at\" field in the execution status and results body.\n\n### Retrieving Data\n\nThere is currently a 250MB limit on how much data can be retrieved in a single API result call. However, there is a chance this may increase for certain paid plans. The API does not currently return an explicit error upon hitting this limit but will instead fail (timeout) when attempting to retrieve the results.\n## Questions: \n 1. What is the rate limit for the Dune API and will it change in the future?\n- The API is currently set to a rate limit of 60 requests per minute, but it will soon be set to match the rate limits specified in the varying API plan tiers.\n\n2. What is the execution timeout limit for queries and can it be extended?\n- The query execution timeout limit matches the Dune web app, which is 30 minutes. It is not mentioned whether it can be extended.\n\n3. Is there a limit to how much data can be retrieved in a single API result call?\n- Yes, there is currently a 250MB limit, but there is a chance it may be increased for certain paid plans. The API does not currently return an explicit error upon hitting this limit but will instead fail (timeout) when attempting to retrieve the results.","metadata":{"source":".autodoc/docs/markdown/docs/api/FAQ/functionality.md"}}],["5",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/FAQ/other.md)\n\n# Dune API Other FAQs\n\nThis section of the Dune Docs app technical guide provides answers to frequently asked questions about how the Dune API works. The purpose of this guide is to provide additional information and clarification on the Dune API beyond what is covered in the main API documentation.\n\nThe guide starts by providing contact information for users who have additional questions or feedback about the Dune API. Users can reach out to api-feedback@dune.com or join the #dune-api channel on Discord for assistance.\n\nThe guide then proceeds to answer various questions about the Dune API, such as how to authenticate requests, how to handle rate limiting, and how to handle errors. Each question is addressed in a separate section, with clear and concise explanations provided.\n\nFor example, the section on authentication explains the different authentication methods supported by the Dune API, such as API keys and OAuth 2.0. It also provides examples of how to authenticate requests using each method.\n\nOverall, this guide serves as a helpful resource for users who want to learn more about the Dune API and how to use it effectively. By providing clear and concise answers to common questions, it helps users avoid common pitfalls and get the most out of the API.\n## Questions: \n 1. What specific functionalities does the Dune API offer for blockchain data analysis?\n- This information is not provided in the app technical guide and would require further research or communication with the Dune team.\n\n2. Are there any limitations or restrictions on the amount or type of data that can be accessed through the Dune API?\n- This information is not provided in the app technical guide and would require further research or communication with the Dune team.\n\n3. How does the Dune API handle data privacy and security for blockchain data analysis?\n- This information is not provided in the app technical guide and would require further research or communication with the Dune team.","metadata":{"source":".autodoc/docs/markdown/docs/api/FAQ/other.md"}}],["6",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/FAQ)\n\nThe `docs/api/FAQ` folder contains a collection of technical guides that provide detailed information and answers to frequently asked questions about the Dune API. These guides are essential for developers who are building applications using the Dune API and need to understand various aspects of the API, such as authentication, rate limiting, billing, pricing, and functionality.\n\nThe `TOS.md` file covers the Dune API Terms of Service (TOS), which outlines the rules and guidelines for using the API. Developers must understand and comply with these terms to use the API effectively and avoid legal issues. The guide also provides examples of how to authenticate requests and handle rate limiting.\n\nThe `billing-pricing.md` file provides information about Dune's API billing and pricing, including answers to frequently asked questions. This guide is particularly useful for developers who need to understand how they will be charged for their API usage. For example, the guide explains what a datapoint is and how it is calculated, as well as how API billing will work with the new Team plans.\n\nThe `functionality.md` file answers frequently asked questions about how the Dune API works, such as the rate limits, SLAs, executing queries, query parameters, performance differences, execution timeout limits, and query engines. This guide is essential for developers who want to learn more about the API's capabilities and limitations. For instance, the guide explains how to find a query ID, pass query parameters, and check the execution status of a query.\n\nThe `other.md` file provides additional information and clarification on the Dune API beyond what is covered in the main API documentation. This guide addresses various questions about authentication, rate limiting, and error handling. For example, it explains the different authentication methods supported by the Dune API and how to authenticate requests using each method.\n\nOverall, the guides in this folder are crucial for developers working with the Dune API, as they provide in-depth information on various aspects of the API. By understanding the contents of these guides, developers can avoid common pitfalls and get the most out of the API, ensuring that their applications work seamlessly with the Dune platform.","metadata":{"source":".autodoc/docs/markdown/docs/api/FAQ/summary.md"}}],["7",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/api-reference/authentication.md)\n\nThe app technical guide titled \"Authentication\" provides instructions on how to authenticate API requests in the Dune app. The guide emphasizes the importance of API keys in determining the permissions of private queries and billing for requests. It warns against sharing secret API keys in publicly accessible areas to ensure security.\n\nThe guide provides a specific method for authenticating requests, which involves adding an \"x-dune-api-key\" property to the request header. This property is required for all request types. The guide includes an example of how to do this with an Execute POST API request using the curl command:\n\n```\ncurl -X POST -H x-dune-api-key:{{api_key}} \"https://api.dune.com/api/v1/query/{{query_id}}/execute\"\n```\n\nOverall, this guide is essential for developers working on the Dune app who need to authenticate API requests. It provides clear instructions on how to do so and emphasizes the importance of keeping API keys secure.\n## Questions: \n 1. What type of authentication does the Dune API use?\n- The Dune API uses API keys to authenticate requests.\n\n2. What is the purpose of the \"x-dune-api-key\" property in the request header?\n- The \"x-dune-api-key\" property is used for authentication with the API and is needed on all request types.\n\n3. What is the recommended practice for handling secret API keys?\n- The recommended practice is to not share secret API keys in publicly accessible areas such as GitHub or client-side code.","metadata":{"source":".autodoc/docs/markdown/docs/api/api-reference/authentication.md"}}],["8",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/api-reference/cancel-execution.md)\n\n# Explanation of the App Technical Guide\n\nThe app technical guide is a documentation for the Dune API execution requests cancellation feature. The guide is divided into several sections that provide information on how to cancel an API execution request. \n\nThe first section is the title, which is \"Cancel Execution\". This section provides a brief overview of what the guide is about. The description section follows, which explains how to cancel Dune API execution requests. \n\nThe next section is the POST Cancel Execution header. This section provides information on how to cancel an API execution request. It explains that the user needs to pass the `execution_id` obtained from making an Execute Query ID POST request to complete a Cancel Execution API request. \n\nThe Arguments section follows, which explains that there are no arguments required to cancel an API execution request. The Returns section explains that the API returns a boolean for whether the execution is successfully canceled. \n\nThe Example Request section provides an example of how to cancel an API execution request using the `execution_id`. The section provides a URL and a cURL command that can be used to cancel an API execution request. \n\nThe Example Response section provides an example of the response that the user will receive after canceling an API execution request. The response is delivered in JSON format and contains a boolean value that indicates whether the request to cancel the query execution was made successfully. \n\nIn summary, the app technical guide provides a step-by-step guide on how to cancel Dune API execution requests. It explains the arguments required, the returns, and provides examples of how to make a request and the response that the user will receive.\n## Questions: \n 1. What is the purpose of the Dune API and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the Dune API or its relation to blockchain technology.\n\n2. Can the Cancel Execution API request be used to cancel multiple execution requests at once?\n- The app technical guide does not provide information on whether the Cancel Execution API request can be used to cancel multiple execution requests at once.\n\n3. Is there a limit to the number of execution requests that can be canceled using the Cancel Execution API request?\n- The app technical guide does not provide information on whether there is a limit to the number of execution requests that can be canceled using the Cancel Execution API request.","metadata":{"source":".autodoc/docs/markdown/docs/api/api-reference/cancel-execution.md"}}],["9",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/api-reference/errors.md)\n\nThis app technical guide covers how to handle errors that may come up when working with the Dune API. The guide is divided into two main sections: \"Invalid API Key\" and \"An Internal Error Occurred\". Each section provides a response object and a list of checks to help users troubleshoot the error. \n\nThe \"Invalid API Key\" section provides a response object of `{'error': 'invalid API Key'}` and two checks to help users resolve the error. The first check is to ensure that the API key is being passed to the endpoint in a header, as described in the Authentication section of the API reference. The second check is to ensure that the API key is correctly entered. \n\nThe \"An Internal Error Occurred\" section provides a response object of `{'error': 'An internal error occurred'}` and two checks to help users resolve the error. The first check is to ensure that the `query_id` entered for GET endpoints is correct, while the second check is to ensure that the `execution_id` obtained from a GET endpoint is correctly passed on to a POST endpoint. \n\nThe guide also includes a note that if users find the guide too technical or confusing, they can reach out to the Dune API team on the #dune-api Discord channel for support. \n\nOverall, this guide is a helpful resource for users of the Dune API who may encounter errors while working with the API. The guide provides clear response objects and actionable steps to help users troubleshoot and resolve errors.\n## Questions: \n 1. What is the Dune API and how does it relate to blockchain technology?\n- The app technical guide does not provide information on what the Dune API is or how it relates to blockchain technology.\n\n2. Are there any specific error codes related to blockchain transactions or smart contracts?\n- The app technical guide does not provide information on specific error codes related to blockchain transactions or smart contracts.\n\n3. Is there any information on how to troubleshoot errors related to data retrieval from the blockchain?\n- The app technical guide provides some information on how to troubleshoot errors related to data retrieval from the Dune API, but it is not clear if this data is specifically related to the blockchain.","metadata":{"source":".autodoc/docs/markdown/docs/api/api-reference/errors.md"}}],["10",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/api-reference/execute-query-id.md)\n\n# Explanation of the Dune Docs App Technical Guide\n\n## Execute Query ID\n\nThis section of the guide explains how to execute a query with or without parameters to retrieve data. The guide is focused on the `query` folder of the project. \n\n### [POST] Execute Query ID\n\nThis header explains that the method to execute a query is a POST request. \n\n### Arguments\n\nThis section explains that no arguments are required to execute a query. However, it is possible to add query parameters to the request. An example of how to add query parameters is provided in the guide. \n\n### Returns\n\nThis section explains that the API returns an `execution_id` for the specified request. \n\n### Example Request\n\nThis section provides an example of how to make a request to execute a query. The example shows the URL to use for the request. \n\n#### cURL\n\nThis section provides an example of how to make a request using cURL. The example shows the command to use for the request. \n\n#### cURL with Parameters\n\nThis section provides an example of how to make a request with query parameters using cURL. The example shows the command to use for the request. \n\n### Example Response\n\nThis section provides an example of the response that the API returns when a query is executed. The response is delivered in JSON format and contains an `execution_id` and a `state`. The `execution_id` is a unique ID that is generated every time the API is called. The `state` is the current state of the query's execution. \n\nOverall, this guide provides a step-by-step explanation of how to execute a query with or without parameters to retrieve data. It also provides examples of how to make requests and what responses to expect.\n## Questions: \n 1. What is the purpose of the `execution_id` returned by the API?\n   \n   The `execution_id` is a unique ID generated every time the API is called, which can be saved and passed on to other API endpoints.\n\n2. Can this API be used to execute queries on a blockchain database?\n   \n   The technical guide does not provide information on whether this API can be used to execute queries on a blockchain database or not.\n\n3. Are there any limitations on the size or complexity of the queries that can be executed using this API?\n   \n   The technical guide does not provide information on any limitations on the size or complexity of the queries that can be executed using this API.","metadata":{"source":".autodoc/docs/markdown/docs/api/api-reference/execute-query-id.md"}}],["11",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/api-reference/execution-results.md)\n\nThis technical guide provides information on how to obtain the results data of an execution request in the Dune Docs project. The guide is focused on the Execution Results API feature of the app. The guide provides details on how to make a GET request to the API endpoint to retrieve the status, metadata, and query results from a query execution. \n\nThe guide provides an example request that requires passing the `execution_id` obtained from making an Execute Query ID POST request. The guide also provides an example cURL request. The guide further provides an example response in JSON format, which includes details such as the execution ID, query ID, state, submitted time, execution start and end times, and the actual rows of data being returned. The metadata of the queried data being returned is also included in the response. The metadata includes details such as the names of the columns in the data returned, the size of the returned data, the number of rows in the data, the total number of datapoints returned, the time it took to assign a slot in the server for the request, and the time it took for the actual execution of the query with the request. \n\nThe guide also provides an example of how to get the results in CSV format by appending \"/csv\" to the URL pattern. The guide advises against using the API key as a parameter in public documents where the API key can be viewed and compromised. \n\nFinally, the guide provides a FAQ section that answers questions such as whether data can be ingested by getting a direct connection to the database, whether query results data are saved for faster retrieval, how long the results data from an execution are stored for, and how much data can be retrieved in a single API result call. \n\nIn summary, this technical guide provides developers with a detailed explanation of how to obtain the results data of an execution request in the Dune Docs project. The guide provides examples of requests and responses, as well as a FAQ section that answers common questions.\n## Questions: \n 1. What is the purpose of the Dune Docs app and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the overall purpose of the Dune Docs app, so a blockchain SQL analyst may need to seek additional documentation or context to understand how it relates to blockchain technology.\n\n2. How does the Dune Docs app handle security and authentication for API requests?\n- The app technical guide does not provide information on security and authentication measures for API requests, so a blockchain SQL analyst may need to seek additional documentation or context to understand how the app handles these aspects.\n\n3. What is the pricing model for using the Dune Docs app and how does it compare to other blockchain data analysis tools?\n- The app technical guide does not provide information on the pricing model for using the Dune Docs app, so a blockchain SQL analyst may need to seek additional documentation or context to understand the costs associated with using the app and how it compares to other blockchain data analysis tools.","metadata":{"source":".autodoc/docs/markdown/docs/api/api-reference/execution-results.md"}}],["12",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/api-reference/execution-status.md)\n\n# Explanation of Execution Status App Technical Guide\n\nThe Execution Status technical guide is a part of the Dune Docs project and provides information on how to check the status of an execution request. The guide is located in the app folder of the project and is focused on the app feature that allows users to execute queries and check their status. \n\nThe guide provides a detailed explanation of how to use the GET Execution Status API request to check the status of a query execution. It includes information on the arguments and returns of the API request, as well as an example request and response. \n\nThe Arguments section of the guide explains that there are no arguments required for the Execution Status API request. The Returns section explains that the API request returns the status of a query execution along with relevant metadata of the results if the execution is completed. \n\nThe Example Request section provides an example of how to pass the execution_id obtained from making an Execute Query ID POST request to complete an Execution Status API request. It includes both a URL and cURL example. \n\nThe Example Response section provides two examples of JSON responses that can be returned by the Execution Status API request. The first example shows the response when the query is still executing, while the second example shows the response when the execution is complete. The section also provides a detailed explanation of the different properties of the response data, such as execution_id, query_id, state, submitted_at, expires_at, execution_started_at, execution_ended_at, and result_metadata. \n\nFinally, the Check Execution Status FAQ section provides answers to common questions about the different states of query execution, such as \"Executing\" and \"Pending\". It also provides a list of all status codes for reference. \n\nOverall, the Execution Status technical guide provides a comprehensive explanation of how to check the status of a query execution using the Execution Status API request. It is a useful resource for developers working on the Dune Docs project who need to understand how to use this feature of the app.\n## Questions: \n 1. What is the purpose of this API and how does it relate to blockchain technology?\n   - This API is used to check the status of a query execution request. It is not directly related to blockchain technology, but it may be used in conjunction with blockchain data analysis.\n2. What authentication is required to make requests to this API?\n   - The cURL example shows that an API key is required to make requests to this API. A blockchain SQL analyst may want to know how to obtain an API key and what level of access it provides.\n3. What is the maximum size of the response data that can be generated with this request?\n   - The `result_set_bytes` property in the `result_metadata` object indicates the size of the response data in bytes, but it does not specify a maximum size. A blockchain SQL analyst may want to know if there are any limitations on the amount of data that can be returned by this API.","metadata":{"source":".autodoc/docs/markdown/docs/api/api-reference/execution-status.md"}}],["13",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/api-reference/index.md)\n\n# API Reference\n\nThis section of the Dune Docs project covers the API endpoints and common errors that may occur when using them. The purpose of this guide is to provide developers with a comprehensive understanding of the API and how to use it effectively.\n\nThe guide is divided into several sections, each covering a specific aspect of the API. These sections include:\n\n- **Authentication**: This section covers the authentication process for accessing the API. It provides information on how to obtain an API key and how to use it to authenticate requests.\n\n- **Execute Query ID**: This section covers the endpoint for executing a query by ID. It provides information on the parameters required for this endpoint and the expected response.\n\n- **Execution Status**: This section covers the endpoint for checking the status of a query execution. It provides information on the parameters required for this endpoint and the expected response.\n\n- **Execution Results**: This section covers the endpoint for retrieving the results of a query execution. It provides information on the parameters required for this endpoint and the expected response.\n\n- **Cancel Execution**: This section covers the endpoint for canceling a query execution. It provides information on the parameters required for this endpoint and the expected response.\n\n- **Error Codes**: This section covers the error codes that may be returned by the API. It provides information on what each error code means and how to handle it.\n\nEach section provides a detailed explanation of the endpoint or error code, including any required parameters and expected responses. The guide also includes links to the relevant files for each section.\n\nFor example, the **Authentication** section links to the `authentication.md` file in the `api-reference` folder, which provides more detailed information on the authentication process.\n\nOverall, this API Reference guide is an essential resource for developers working with the Dune Docs API. It provides a comprehensive understanding of the API endpoints and common errors, helping developers to use the API effectively and troubleshoot any issues that may arise.\n## Questions: \n 1. What type of data is being accessed through the API endpoints listed in this technical guide?\n- The technical guide does not provide information on the type of data being accessed through the API endpoints listed. \n\n2. Are there any security measures in place to protect the data being accessed through the API endpoints?\n- The technical guide does not provide information on security measures in place to protect the data being accessed through the API endpoints. \n\n3. Is there any information on how the API endpoints interact with a blockchain or SQL database?\n- The technical guide does not provide information on how the API endpoints interact with a blockchain or SQL database.","metadata":{"source":".autodoc/docs/markdown/docs/api/api-reference/index.md"}}],["14",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/api-reference)\n\nThe `docs/api/api-reference` folder contains a collection of technical guides that provide comprehensive information on various aspects of the Dune API. These guides are essential for developers working with the Dune Docs project, as they offer detailed explanations, examples, and troubleshooting tips for using the API effectively.\n\nThe **Authentication** guide (`authentication.md`) focuses on the process of authenticating API requests in the Dune app. It highlights the importance of API keys and provides a method for adding the \"x-dune-api-key\" property to the request header. This guide is crucial for developers who need to authenticate API requests and ensure the security of their API keys.\n\nThe **Cancel Execution** guide (`cancel-execution.md`) explains how to cancel Dune API execution requests. It provides information on passing the `execution_id` and the expected response when canceling an execution. This guide is useful for developers who need to manage and cancel API execution requests.\n\nThe **Errors** guide (`errors.md`) covers handling errors that may occur when working with the Dune API. It provides response objects and troubleshooting steps for common errors, such as \"Invalid API Key\" and \"An Internal Error Occurred\". This guide is a valuable resource for users who encounter errors while working with the API.\n\nThe **Execute Query ID** guide (`execute-query-id.md`) explains how to execute a query with or without parameters to retrieve data. It provides examples of making requests and the expected responses, making it a helpful resource for developers who need to execute queries using the Dune API.\n\nThe **Execution Results** guide (`execution-results.md`) provides information on obtaining the results data of an execution request. It offers details on making a GET request to the API endpoint and the expected response, including metadata and query results. This guide is essential for developers who need to retrieve execution results from the Dune API.\n\nThe **Execution Status** guide (`execution-status.md`) focuses on checking the status of an execution request. It explains how to use the GET Execution Status API request and provides examples of requests and responses. This guide is useful for developers who need to monitor the progress of their query executions.\n\nFinally, the **Index** guide (`index.md`) serves as an overview of the API Reference, covering the API endpoints and common errors. It provides a concise summary of each section in the API Reference, making it a helpful starting point for developers exploring the Dune API.\n\nOverall, the guides in this folder are essential resources for developers working with the Dune Docs API. They provide a comprehensive understanding of the API endpoints, common errors, and best practices, helping developers use the API effectively and troubleshoot any issues that may arise.","metadata":{"source":".autodoc/docs/markdown/docs/api/api-reference/summary.md"}}],["15",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/index.md)\n\n# Dune API Technical Guide\n\nThis technical guide is focused on the API feature of the Dune project. The API provides users with access to queries and data available on the Dune website. The guide provides an overview of the API, how it works, and how to get started with it.\n\n## Overview\n\nThe guide starts with an introduction to the Dune API, which provides users with full access to public and private queries. The API allows users to execute queries, check the status of an execution, and get the results of an execution. The guide also notes that the results of API executions are stored separately from the Dune website and are not currently reflected on the website.\n\n## Getting Started\n\nThe guide provides instructions on how to get started with the API. Users need to purchase an app plan and API package to obtain an API key, which can be found in the settings page. The guide also notes that users can consume the API in the language of their choice, but provides quick start guides for Python and Node.js. Additionally, the guide provides links to community clients available for the API.\n\n## Important Links\n\nThe guide provides links to important resources related to the Dune API, including the API documentation, the Dune API Discord channel, and a community-sourced API client.\n\nOverall, this technical guide provides a high-level overview of the Dune API, how it works, and how to get started with it. It is a useful resource for developers who want to use the Dune API in their projects.\n## Questions: \n 1. What kind of data can be queried using the Dune API?\n- The Dune API gives access to both public and personal private queries that a user's Dune account has access to.\n\n2. Are the results from API executions reflected on Dune's website?\n- No, the results from API executions are currently stored separately and are not reflected on Dune's website.\n\n3. What programming languages can be used to consume the Dune API?\n- The Dune API can be consumed in any programming language, but there are quick start guides available for Python and Node.js. Additionally, there are community clients available for use.","metadata":{"source":".autodoc/docs/markdown/docs/api/index.md"}}],["16",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/quick-start/api-js.md)\n\nThis app technical guide provides a step-by-step guide on how to access the Dune API via JavaScript. The guide is not yet comprehensive, but it provides a starting point for developers who want to use the Dune API. The guide assumes that the reader has some level of familiarity with Node.js, Node Package Manager (NPM), and Node Version Manager (NVM). \n\nThe guide starts by showing one of the several ways the API can be consumed via JavaScript, using the `node-fetch` package. The guide also mentions that developers can use the native fetch functionality available in the newest LTS version of node, node 18. The guide provides an example of how to set up the environment and install the necessary packages. \n\nThe guide then provides an example of how to call the Dune API using a simple query that fetches a small set of data. The example query has the `query_id`, `1258228`. The guide shows how to replace `#! YOUR_API_KEY` with the Dune API key and add it to the `main.js` file in the project. The guide also provides an example of how to call a parameterized query that takes in a wallet address as a parameter. The example query has the `query_id`, `1258228`, and the guide shows how to pass an example address as a value to the `wallet_address` parameter. \n\nThe guide concludes by showing how to run the script from the command line and how to edit the Query URL to fetch data from any other Queries. The guide also provides a link to a Github repository where developers can find some code from the tutorial. \n\nOverall, this guide provides a useful starting point for developers who want to use the Dune API via JavaScript. The guide is easy to follow and provides clear examples of how to call the API using simple and parameterized queries.\n## Questions: \n 1. What is the Dune API and how does it relate to blockchain technology?\n- The app technical guide explains how to access the Dune API via JavaScript, but it does not provide information on what the Dune API is or how it relates to blockchain technology.\n\n2. Are there any security measures in place to protect user data when using the Dune API?\n- The app technical guide does not mention any security measures in place to protect user data when using the Dune API, which may be a concern for a blockchain SQL analyst.\n\n3. Are there any limitations or restrictions on the types of queries that can be executed using the Dune API?\n- The app technical guide provides examples of simple and parameterized queries that can be executed using the Dune API, but it does not mention any limitations or restrictions on the types of queries that can be executed.","metadata":{"source":".autodoc/docs/markdown/docs/api/quick-start/api-js.md"}}],["17",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/quick-start/api-py.md)\n\nThis app technical guide covers how to access the Dune API using Python. It provides a step-by-step guide to set up the environment, install necessary libraries, and create functions to interact with the Dune API. The guide assumes prior experience with Python and covers the following topics:\n\n1. **Getting Set Up**: Installing the `requests`, `pandas`, and `jupyter notebook` libraries using `pip`.\n2. **Importing Libraries**: Importing the `requests` and `pandas` libraries.\n3. **API Keys**: Setting up the API key and header for making API calls.\n4. **Simplifying URL Generation**: Creating a function to generate URLs for different API endpoints.\n5. **Wrapping API Endpoints in Functions**: Defining functions to execute queries, get query status, get query results, and cancel query execution.\n6. **Using the Dune API**: Demonstrating how to execute a query, get query execution status, get query results, and cancel query execution.\n7. **Parameterized Queries**: Defining a function to execute queries with parameters and demonstrating its usage.\n\nThe guide includes examples of function calls and their expected outputs, making it easy for users to follow along and interact with the Dune API using Python.\n## Questions: \n 1. **How do I pass my API key to the Dune API?**\n\n   You need to pass your API key in the header of your API calls. In the provided code, you can set your API key in the `API_KEY` variable and the header is set in the `HEADER` variable as `{\"x-dune-api-key\" : API_KEY}`.\n\n2. **How can I execute a parameterized query using the provided functions?**\n\n   You can use the `execute_query_with_params` function to execute a parameterized query. You need to pass the `query_id` and a dictionary containing the parameter values as arguments to this function.\n\n3. **How can I cancel the execution of a running query?**\n\n   You can use the `cancel_query_execution` function to cancel the execution of a running query. You need to pass the `execution_id` of the running query as an argument to this function.","metadata":{"source":".autodoc/docs/markdown/docs/api/quick-start/api-py.md"}}],["18",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/quick-start/api-ready-queries.md)\n\n# API Ready Queries\n\nThis technical guide provides a list of queries that are ready for API use in the Dune Docs project. The guide contains four queries, each with a unique query ID that can be used in any of the API guides or can be forked and modified to create a new query ID for use in the API. \n\n## Get the ERC20 balances for a given address\n\nThis query provides the ERC20 token balances for a given address. The query ID is 1616880, and it requires the following parameters:\n\n- `address`: The address that you would like to get balances for. It must be a valid EVM address.\n- `blocknumber`: The cutoff block for checking balances. Use 0 if you want the most recent block, otherwise any block number that has been processed will work (~3 minute/15 block delay).\n- `chain`: The EVM chain you'd like to check balances for. Valid choices include `ethereum`, `polygon`, `bnb`, `optimism`, `arbitrum`, `avalanche_c`, and `gnosis`.\n- `dust`: Keep or remove dust tokens (worth less than $0.01). Valid choices are `keep` or `remove`.\n\nThe output columns include:\n\n- `symbol`: The token symbol, if available.\n- `notional_value`: The notional amount of tokens held, rounded to 5 decimals.\n- `total_value`: The $USD value of tokens held, rounded to 3 decimals.\n- `token_price`: The $USD price of the token.\n\n## Get all the holders and their balances for a given ERC20 address\n\nThis query provides all the holders and their balances for a given ERC20 address. The query ID is 1618116, and it requires the following parameters:\n\n- `address`: The ERC20 token address you would like to get holders of. It must be a valid EVM address.\n- `blocknumber`: The cutoff block for checking balances. Use 0 if you want the most recent block, otherwise any block number that has been processed will work (~3 minute/15 block delay).\n- `chain`: The EVM chain you'd like to check balances for. Valid choices include `ethereum`, `polygon`, `bnb`, `optimism`, `arbitrum`, `avalanche_c`, and `gnosis`.\n\nThe output columns include:\n\n- `holder`: The address of the holder.\n- `holder_ens`: The ENS of the holder address, if any.\n- `notional_value`: The notional amount of tokens held, rounded to 5 decimals.\n- `total_value`: The $USD value of tokens held, rounded to 3 decimals.\n- `token_price`: The $USD price of the token.\n\n## Get the NFT balances for a given address\n\nThis query provides the NFT balances for a given address. The query ID is 1617158, and it requires the following parameters:\n\n- `address`: The address that you would like to get balances for. It must be a valid EVM address.\n- `blocknumber`: The cutoff block for checking balances. Use 0 if you want the most recent block, otherwise any block number that has been processed will work (~3 minute/15 block delay).\n- `chain`: The EVM chain you'd like to check balances for. Valid choices include `ethereum`, `polygon`, `bnb`, `optimism`, `arbitrum`, `avalanche_c`, and `gnosis`.\n\nThe output columns include:\n\n- `symbol`: The symbol of the NFT, if available.\n- `name`: The name of the NFT, if available.\n- `category`: The category of the NFT, if available.\n- `token_id`: The token ID of the NFT.\n- `contract_address`: The contract address of the NFT.\n- `acquired_how`: Whether the NFT was `minted` or `transferred/bought`.\n- `acquired_on_block_number`: The block number that the NFT was received on.\n\n## Get all the holders and their balances for a given NFT address\n\nThis query provides all the holders and their balances for a given NFT address. The query ID is 1618122, and it requires the following parameters:\n\n- `address`: The NFT address that you would like to get holders of. It must be a valid EVM address.\n- `blocknumber`: The cutoff block for checking balances. Use 0 if you want the most recent block, otherwise any block number that has been processed will work (~3 minute/15 block delay).\n- `chain`: The EVM chain you'd like to check balances for. Valid choices include `ethereum`, `polygon`, `bnb`, `optimism`, `arbitrum`, `avalanche_c`, and `gnosis`.\n\nThe output columns include:\n\n- `holder`: The address of the holder.\n- `holder_ens`: The ENS of the holder address, if any.\n- `tokens_held`: The number of NFTs from this contract held.\n- `token_ids`: An array of all the token IDs held.\n## Questions: \n 1. What are the valid choices for the `chain` parameter in each of the queries?\n- Valid choices for the `chain` parameter in each of the queries are `ethereum`, `polygon`, `bnb`, `optimism`, `arbitrum`, `avalanche_c`, and `gnosis`.\n\n2. What is the delay between block processing and when the `blocknumber` parameter can be used in each of the queries?\n- The delay between block processing and when the `blocknumber` parameter can be used in each of the queries is approximately 3 minutes or 15 blocks.\n\n3. What is the difference between the `notional_value` and `total_value` output columns in each of the queries?\n- The `notional_value` output column in each of the queries represents the notional amount of tokens or NFTs held, rounded to 5 decimals. The `total_value` output column represents the $USD value of tokens or NFTs held, rounded to 3 decimals.","metadata":{"source":".autodoc/docs/markdown/docs/api/quick-start/api-ready-queries.md"}}],["19",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/quick-start/community-clients.md)\n\n# Community Clients\n\nThis section of the Dune Docs project provides a list of Dune API clients built by the community. The purpose of this guide is to showcase the work of the community and provide information on how to use these clients. \n\nThe guide starts with a warning disclaimer that the clients listed are not directly maintained by the Dune team. This is important information for users to be aware of before using any of the clients listed. \n\nThe guide then proceeds to list the API clients built by the community. Each client is described in detail, including the name of the client, the person or team who built it, and where it can be found. \n\nFor example, the Cow Protocol Python Client was built by [@bh2smith](https://dune.com/bh2smith) and the team at [Cow Protocol](https://dune.com/cowprotocol). It can be found on [PyPi](https://pypi.org/project/dune-client/). The guide provides a simple pip install command to get started quickly and a link to the client's GitHub page for more information. \n\nSimilarly, the Cow Protocol Typescript Client was also built by [@bh2smith](https://dune.com/bh2smith) and can be found on [npm](https://www.npmjs.com/package/@cowprotocol/ts-dune-client). The guide provides an example of how to install it using yarn. \n\nThe guide also lists a Go client built by Dune team member [@theedgeofrage](https://dune.com/theedgeofrage) and a Ruby client built by [@shellandbull](https://github.com/shellandbull). \n\nOverall, this guide provides valuable information for users who want to use Dune API clients built by the community. It showcases the work of the community and provides instructions on how to use these clients.\n## Questions: \n 1. What is the purpose of the Dune API clients listed in this technical guide?\n- The purpose of the Dune API clients is not explicitly stated in the technical guide, but it appears that they are built by the community to interact with the Dune API.\n\n2. Who maintains the Dune API clients listed in this technical guide?\n- The Dune team does not directly maintain the API clients listed in this technical guide. \n\n3. What programming languages are the Dune API clients built in?\n- The Dune API clients listed in this technical guide are built in Python, TypeScript, Go, and Ruby.","metadata":{"source":".autodoc/docs/markdown/docs/api/quick-start/community-clients.md"}}],["20",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/quick-start/index.md)\n\n# API Quick Start Guide\n\nThe API Quick Start Guide is a part of the Dune Docs project and provides a quick and easy way to get started with the Dune Analytics API. The guide is designed to help users who are new to the API and want to quickly learn how to use it. \n\nThe guide covers the following topics:\n\n## Endpoints\n\nThe guide provides example queries for NFT or ERC20 balances or holders. Users can check out these endpoints to get started with the API.\n\n## Ingestion Pipeline\n\nThe guide provides a link to a Python and Celery-based ingestion pipeline for users who are setting up an ingestion pipeline. This pipeline can be used to extract, transform, and load data from the API.\n\n## Quick Start Guides\n\nThe guide provides quick start guides for Python, Javascript, and Community Clients. These guides provide step-by-step instructions on how to get started with the API using these programming languages. \n\nFor example, the Python guide provides instructions on how to install the Dune Analytics Python client, authenticate with the API, and make queries. \n\nOverall, the API Quick Start Guide is a useful resource for users who want to quickly get started with the Dune Analytics API. It provides clear and concise instructions on how to use the API and is a great starting point for users who are new to the API.\n## Questions: \n 1. What type of data does this API handle?\n- The API provides example queries for NFT or ERC20 balances or holders, which may be of interest to a blockchain SQL analyst.\n\n2. Are there any specific programming languages or tools recommended for working with this API?\n- The API offers quick start guides for Python and Javascript, as well as a community clients guide, which may be helpful for a blockchain SQL analyst looking to integrate with the API.\n\n3. Is there any information on how the API handles data ingestion and transformation?\n- The guide includes a link to a Python and Celery-based ingestion pipeline, which may be of interest to a blockchain SQL analyst looking to work with the API's data.","metadata":{"source":".autodoc/docs/markdown/docs/api/quick-start/index.md"}}],["21",{"pageContent":"[View code on GitHub](https://dune.com/docs/api/quick-start)\n\nThe `docs/api/quick-start` folder contains a collection of app technical guides that focus on helping users get started with the Dune Analytics API. These guides cover various programming languages and provide step-by-step instructions on how to interact with the API, making it easy for users to fetch data and integrate it into their projects.\n\nFor example, the `api-js.md` guide provides a detailed walkthrough on how to access the Dune API using JavaScript. It assumes the reader has some familiarity with Node.js, NPM, and NVM. The guide demonstrates how to set up the environment, install necessary packages, and call the Dune API using simple and parameterized queries. This guide is particularly useful for developers who want to use the Dune API in their JavaScript projects.\n\nSimilarly, the `api-py.md` guide covers how to access the Dune API using Python. It provides instructions on setting up the environment, installing required libraries, and creating functions to interact with the Dune API. This guide is beneficial for users who prefer working with Python and want to fetch data from the Dune API for their projects.\n\nThe `api-ready-queries.md` guide offers a list of ready-to-use queries that can be consumed by the API. These queries cover various use cases, such as fetching ERC20 or NFT balances for a given address or retrieving all holders and their balances for a specific ERC20 or NFT address. Users can utilize these queries as a starting point and modify them according to their needs.\n\nThe `community-clients.md` guide showcases Dune API clients built by the community. It lists clients for different programming languages, such as Python, TypeScript, Go, and Ruby, along with their creators and installation instructions. This guide is valuable for users who want to use community-built clients to interact with the Dune API.\n\nLastly, the `index.md` guide serves as an API Quick Start Guide, providing an overview of the available guides and resources for users who are new to the Dune Analytics API. It directs users to the appropriate guides based on their preferred programming language and use case.\n\nOverall, the guides in this folder are designed to help users quickly get started with the Dune Analytics API, regardless of their programming language preference. They provide clear instructions, examples, and resources to make it easy for users to fetch data from the API and integrate it into their projects.","metadata":{"source":".autodoc/docs/markdown/docs/api/quick-start/summary.md"}}],["22",{"pageContent":"[View code on GitHub](https://dune.com/docs/api)\n\nThe `docs/api` folder contains a comprehensive set of technical guides and resources for developers working with the Dune Analytics API. These guides cover various aspects of the API, such as authentication, rate limiting, billing, pricing, and functionality, as well as provide quick-start guides for different programming languages.\n\nFor example, the `index.md` file in this folder serves as a high-level overview of the Dune API, explaining its purpose, how it works, and how to get started with it. This guide is particularly useful for developers who are new to the Dune API and want to understand its capabilities and limitations.\n\nThe `FAQ` subfolder contains a collection of technical guides that provide detailed information and answers to frequently asked questions about the Dune API. These guides are essential for developers who are building applications using the Dune API and need to understand various aspects of the API, such as authentication, rate limiting, billing, pricing, and functionality. For instance, the `TOS.md` file covers the Dune API Terms of Service (TOS), which outlines the rules and guidelines for using the API. Developers must understand and comply with these terms to use the API effectively and avoid legal issues.\n\nThe `api-reference` subfolder contains a collection of technical guides that provide comprehensive information on various aspects of the Dune API. These guides are essential for developers working with the Dune Docs project, as they offer detailed explanations, examples, and troubleshooting tips for using the API effectively. For example, the **Authentication** guide (`authentication.md`) focuses on the process of authenticating API requests in the Dune app, highlighting the importance of API keys and providing a method for adding the \"x-dune-api-key\" property to the request header.\n\nThe `quick-start` subfolder contains a collection of app technical guides that focus on helping users get started with the Dune Analytics API. These guides cover various programming languages and provide step-by-step instructions on how to interact with the API, making it easy for users to fetch data and integrate it into their projects. For example, the `api-js.md` guide provides a detailed walkthrough on how to access the Dune API using JavaScript, demonstrating how to set up the environment, install necessary packages, and call the Dune API using simple and parameterized queries.\n\nOverall, the guides and resources in the `docs/api` folder are essential for developers working with the Dune Analytics API. They provide a comprehensive understanding of the API endpoints, common errors, and best practices, helping developers use the API effectively and troubleshoot any issues that may arise.","metadata":{"source":".autodoc/docs/markdown/docs/api/summary.md"}}],["23",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/dashboards/dashboards.md)\n\n# How To Create a Dashboard\n\nThis technical guide covers the process of creating a dashboard on Dune, which is where the app's content lives and gets discovered. Dashboards consist of widgets, which can either be visualizations or text boxes. It is also possible to embed images or GIFs inside of the text box. The guide explains how to create a dashboard, add visualizations, add text boxes, and arrange the layout of the dashboard.\n\nTo create a new dashboard, navigate to the \"Discover\" page and click on the \"new Dashboard\" button on the right. The initial name that you give to your dashboard will also be the URL slug. You can't change the URL slug afterwards, so be mindful of the name you choose. Changing the dashboard's display name is always possible though.\n\nVisualizations can be added to the dashboard by going into the editor mode and clicking on the corresponding button. To go into editor mode, first open one of your own dashboards and click on the edit button on the top right.\n\nText boxes can be added to the dashboard by going into editor mode and clicking on \"add text widget\". This will open a simple text editor window. Text boxes support a subset of markdown, which is explained in the guide. You can manipulate text and embed images and GIFs.\n\nThe guide also explains how to embed images and GIFs into the dashboard. Since images cannot be stored locally on Dune's servers, you need to upload your images somewhere else or find the raw file somewhere on the internet. The syntax for embedding images is also explained in the guide.\n\nFinally, the guide explains how to arrange the different widgets on the dashboard in whatever way you like. Widgets will always try to move upwards, so if you want to create a visual divider section in your dashboard, it is advised to create a big text box as a divider.\n\nOverall, this guide provides a comprehensive overview of how to create a dashboard on Dune, including adding visualizations, text boxes, and images/GIFs, as well as arranging the layout of the dashboard. The guide is accompanied by examples and screenshots to make the process easier to understand.\n## Questions: \n 1. What is the purpose of Dune Docs and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of Dune Docs or its relation to blockchain technology, so a blockchain SQL analyst may have this question.\n\n2. Can Dune Docs integrate with blockchain databases or APIs?\n- The app technical guide does not provide information on whether Dune Docs can integrate with blockchain databases or APIs, so a blockchain SQL analyst may have this question.\n\n3. Are there any security measures in place to protect sensitive data on Dune Docs dashboards?\n- The app technical guide does not provide information on security measures in place to protect sensitive data on Dune Docs dashboards, so a blockchain SQL analyst may have this question.","metadata":{"source":".autodoc/docs/markdown/docs/app/dashboards/dashboards.md"}}],["24",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/dashboards/ecosystem-dashboards.md)\n\n# Ecosystem Dashboards\n\nThis technical guide covers the Ecosystem Dashboards feature of the Dune app. The purpose of this feature is to provide users with a way to explore and discover general ecosystem-level metrics related to blockchain data. \n\nThe first section of the guide focuses on Gas Prices, which is a dashboard created by @kroeger0x. This dashboard provides data on average gas spent per transaction, gas limit, gas spent in total in a block, and more. The dashboard is designed to be easy to view and understand, and it is accessible through Dune. Two screenshots of the dashboard are provided as examples.\n\nThe second section of the guide focuses on DeFi Adoption, which is a dashboard created by @rchen8. This dashboard compiles user numbers from all important DeFi protocols into one place. The purpose of this dashboard is to provide users with a way to easily track DeFi adoption over time. A screenshot of the dashboard is provided as an example.\n\nOverall, the Ecosystem Dashboards feature of the Dune app is designed to provide users with a way to explore and discover general ecosystem-level metrics related to blockchain data. The Gas Prices and DeFi Adoption dashboards are two examples of the types of metrics that can be explored using this feature.\n## Questions: \n 1. What blockchain data is available in Dune and how is it organized? \n2. Can Dune be used to analyze specific blockchain transactions or only general ecosystem-level metrics? \n3. Are there any limitations or potential biases in the data presented in the Gas Prices and DeFi Adoption dashboards?","metadata":{"source":".autodoc/docs/markdown/docs/app/dashboards/ecosystem-dashboards.md"}}],["25",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/dashboards/index.md)\n\n# Use Cases\n\nThe app technical guide for Dune Docs covers the use cases of the Dune platform, which is a blockchain data analytics platform. The guide explains that Dune serves three different groups: Dune Spectators, Dune Wizards, and Dune Patrons. Dune Spectators can view on-chain data via dashboards on Dune.com. Dune Wizards take the raw data and use it to tell stories via dashboards, visualizations, and queries. Dune Patrons leverage Dune's powers to solve problems and share insights within their organizations.\n\nThe guide goes on to explain that nearly the entire world of blockchain data analytics can be explored with Dune, and there aren't many limitations to what you can query and visualize with Dune. However, to help users get a clearer picture of the type of problems they can explore and solve with Dune, the guide establishes a few broad use cases: Project Dashboards, Sector Dashboards, and Ecosystem Dashboards.\n\nThe guide also provides a link to Dune's Twitter account, where users can follow and see how people are currently using Dune. \n\nOverall, this guide provides an overview of the Dune platform and its capabilities. It explains the different groups that can benefit from using Dune and the types of problems that can be explored and solved with Dune. The guide is useful for anyone who wants to understand the potential of the Dune platform and how it can be used to generate insights for themselves, their projects, or their organizations.\n## Questions: \n 1. What type of blockchain data does Dune ingest and analyze?\n- The app technical guide does not provide specific information on the type of blockchain data that Dune ingests and analyzes.\n\n2. Can Dune be integrated with SQL databases?\n- The app technical guide does not mention any integration with SQL databases.\n\n3. Are there any limitations to the size of data that can be queried and visualized with Dune?\n- The app technical guide states that there aren't many limitations to what can be queried and visualized with Dune, but it does not provide any specific information on size limitations.","metadata":{"source":".autodoc/docs/markdown/docs/app/dashboards/index.md"}}],["26",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/dashboards/project-dashboards.md)\n\n# Project Dashboards\n\nThe Project Dashboards technical guide explains how to use this feature to track the metrics of a project. The guide is focused on the app folder of the Dune Docs project. \n\nThe guide starts by explaining that Project Dashboards allow users to easily assemble data on their favorite project in one place without having to maintain infrastructure or overhead. Users can query for the data they desire and assemble it on a Dashboard to make a Datahub for their project reality. \n\nThe guide then provides an example of a Project Dashboard for Tornado.Cash by @poma. The Dashboard shows important metrics for the protocol, such as total deposits and unique users, in an easy-to-understand format. The Dashboard also includes historical data points that show the growth in users and volume. \n\nThe guide concludes by directing users to the Dune Projects Page, where they can find many other great Dashboards. \n\nOverall, this technical guide provides a high-level overview of how to use Project Dashboards to track project metrics. It also provides a concrete example of how to use this feature in practice.\n## Questions: \n 1. What kind of data sources does this app support for assembling project dashboards?\n- The app technical guide mentions that users can \"simply query for the data you desire\" without having to maintain infrastructure or overhead, but it does not specify what kind of data sources are supported.\n\n2. Can this app be integrated with blockchain data sources?\n- The app technical guide does not mention anything about blockchain data sources specifically, so a blockchain SQL analyst might wonder if this app can be integrated with blockchain data sources.\n\n3. Are there any limitations to the types of metrics that can be tracked on a project dashboard?\n- The app technical guide does not mention any limitations to the types of metrics that can be tracked on a project dashboard, but a blockchain SQL analyst might want to know if there are any restrictions or limitations to the types of data that can be displayed on a dashboard.","metadata":{"source":".autodoc/docs/markdown/docs/app/dashboards/project-dashboards.md"}}],["27",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/dashboards/sector-dashboards.md)\n\n# Sector Dashboards\n\nThe Sector Dashboards feature of the Dune Docs project allows users to get an overview of an entire sector of the crypto economy and analyze what's happening in real-time. This guide provides an overview of the Sector Dashboards feature and how it can be used to evaluate different sectors of the crypto economy.\n\nThe guide provides examples of different sector-based Dune Dashboards, including Dex Metrics, Indices, and Lending. Each of these dashboards provides an overview of the entire state of a sector in one glance, making it easy to compare different products and projects with ease.\n\nThe Dex Metrics dashboard, for example, provides metrics like Dex Volume, Market Share, and Total Volume across all exchanges, along with many more stats. All of these stats and charts update in real-time and are maintained by the community. If a new DEX wants to be added to this Dashboard, all they have to do is submit their code to the public GitHub.\n\nSimilarly, the Indices dashboard allows users to evaluate the entire state of a sector in one glance to compare different products and projects with ease. The Lending dashboard provides an overview of the state of lending protocols, making it easy to compare protocol performance.\n\nOverall, the Sector Dashboards feature of the Dune Docs project provides users with a powerful tool for evaluating different sectors of the crypto economy. By providing an overview of the entire state of a sector in one glance, users can easily compare different products and projects with ease.\n## Questions: \n 1. What data sources does Dune Docs use to gather information for the Sector Dashboards?\n- This information is not provided in the app technical guide, so a blockchain SQL analyst may need to investigate further or reach out to the Dune Docs team for clarification.\n\n2. How frequently are the stats and charts on the Sector Dashboards updated?\n- The app technical guide states that the stats and charts update in real time, but a blockchain SQL analyst may want to confirm the frequency of updates to ensure the data is up-to-date.\n\n3. Can new sectors be added to the Sector Dashboards, or are they limited to the ones currently available?\n- The app technical guide mentions that new DEXes can be added to the Dex Metrics Dashboard, but it is unclear if new sectors can be added as well. A blockchain SQL analyst may want to investigate further or reach out to the Dune Docs team for more information.","metadata":{"source":".autodoc/docs/markdown/docs/app/dashboards/sector-dashboards.md"}}],["28",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/dashboards)\n\nThe `docs/app/dashboards` folder contains technical guides that focus on the dashboard features of the Dune Docs project. Dashboards are an essential part of the Dune platform, as they allow users to visualize and analyze blockchain data in a comprehensive and easy-to-understand manner. The guides in this folder cover various aspects of creating and using dashboards, as well as exploring different types of dashboards available on the platform.\n\nThe `dashboards.md` guide provides a step-by-step process on how to create a dashboard on Dune, including adding visualizations, text boxes, and images/GIFs, as well as arranging the layout of the dashboard. This guide is particularly useful for users who are new to the platform and want to create their own custom dashboards to analyze specific data.\n\nThe `ecosystem-dashboards.md` guide covers the Ecosystem Dashboards feature, which provides users with a way to explore and discover general ecosystem-level metrics related to blockchain data. This guide highlights two examples of Ecosystem Dashboards: Gas Prices and DeFi Adoption. Users interested in gaining insights into the broader blockchain ecosystem can benefit from this guide.\n\nThe `index.md` guide serves as an overview of the Dune platform and its capabilities, explaining the different groups that can benefit from using Dune and the types of problems that can be explored and solved with Dune. This guide is useful for anyone who wants to understand the potential of the Dune platform and how it can be used to generate insights for themselves, their projects, or their organizations.\n\nThe `project-dashboards.md` guide focuses on using Project Dashboards to track project metrics. It provides an example of a Project Dashboard for Tornado.Cash and directs users to the Dune Projects Page to find more dashboards. This guide is helpful for users who want to monitor the performance of specific projects in the crypto space.\n\nLastly, the `sector-dashboards.md` guide explains how to use Sector Dashboards to evaluate different sectors of the crypto economy. It provides examples of sector-based Dune Dashboards, such as Dex Metrics, Indices, and Lending. Users interested in comparing and analyzing various sectors within the crypto economy can find this guide valuable.\n\nOverall, the guides in the `docs/app/dashboards` folder provide a comprehensive understanding of the dashboard features available on the Dune platform. These guides are essential for users who want to leverage the power of Dune's dashboards to analyze and visualize blockchain data effectively.","metadata":{"source":".autodoc/docs/markdown/docs/app/dashboards/summary.md"}}],["29",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/decoding-contracts.md)\n\n# Decoding Contracts\n\nThis technical guide provides a comprehensive overview of Decoded Contracts in Dune, including how to submit them for decoding. Decoded Contracts are human-readable tables for each event and function defined in the smart contract's ABI. The guide explains how to submit a new contract for decoding, track submissions, and provides answers to frequently asked questions.\n\nThe guide starts by explaining how Decoding works and what Decoded tables are available. It then goes on to explain how to submit a new contract for decoding. Contracts can be submitted through the New contract form, the My Creations > Contracts Tab, or within the dataset explorer in the Query editor's sidebar. The contract submission form consists of two steps: Blockchain and address, and Contract details. The guide provides examples of how to submit a contract, including an example of submitting the USDT contract in Optimism.\n\nThe guide also explains advanced options for submitting contracts, such as indexing multiple contract addresses under the same submission. It provides two strategies for detecting other contracts for decoding: bytecode match and factory instances. The guide warns that these options should only be used if the user is extremely familiar with the project's architecture and deployment hierarchy.\n\nThe guide also explains how to track submissions and their processing status. Users can view their submissions at any time by navigating to My Creations > Contracts. The guide also provides answers to frequently asked questions, such as how to submit contract information manually, how to submit a Proxy contract, how to re-submit a contract, and how to submit Diamond Proxy contracts.\n\nOverall, this guide provides a detailed explanation of how to submit contracts for decoding in Dune, including advanced options and frequently asked questions. It is a valuable resource for anyone looking to submit contracts for decoding in Dune.\n## Questions: \n 1. What is the purpose of submitting contracts for decoding in Dune Docs?\n- Contracts are decoded into human-readable tables for each event and function defined in the smart contract's ABI, making it easier to work with raw transaction, log, and trace data.\n\n2. How can Dune Docs automatically detect and index multiple contract addresses under the same submission?\n- Dune Docs has two strategies for detecting other contracts for decoding: bytecode match and factory instances.\n\n3. What should be done if a submission gets rejected in Dune Docs?\n- To avoid rejection, accurate contract information should be submitted. If a submission gets rejected, users can head over to the #decoding Discord channel for assistance.","metadata":{"source":".autodoc/docs/markdown/docs/app/decoding-contracts.md"}}],["30",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/index.md)\n\n# App Overview\n\nThe App Overview section of the Dune Docs project provides an introduction to the Dune.com app and its features. The section is aimed at users who are already familiar with the basics of the app and are looking for more in-depth explanations and how-to guides for leveraging the Dune app interface.\n\nThe section is divided into five subsections, each of which focuses on a specific feature of the app:\n\n- **Queries**: This subsection provides guides and explanations for data explorer and query creation questions. Users can learn how to create custom queries and explore data using the Dune app interface. Example queries are provided to help users get started.\n\n- **Visualizations**: This subsection provides guides and explanations for visualization creation, formatting, and embedding questions. Users can learn how to create custom visualizations and embed them in their own websites or applications. Example visualizations are provided to help users get started.\n\n- **Dashboards**: This subsection is a collection of example dashboard how-to's and use cases to generate inspiration from! Users can learn how to create custom dashboards and use them to monitor data and track key metrics. Example dashboards are provided to help users get started.\n\n- **Decoding**: This subsection explains the process for submitting a contract for decoding on EVM chains. Users can learn how to decode smart contracts and explore their functionality using the Dune app interface. Example contracts are provided to help users get started.\n\n- **Teams**: This subsection explains how organizations can use the Teams feature to form a combined profile for wizards to contribute and work together under. Users can learn how to create and manage teams using the Dune app interface. Example teams are provided to help users get started.\n\nOverall, the App Overview section of the Dune Docs project provides a comprehensive introduction to the Dune.com app and its features. It is a valuable resource for users who are looking to get the most out of the app and explore its full potential.\n## Questions: \n 1. What blockchain data does the dune.com app work with?\n- The app technical guide does not provide specific information on the type of blockchain data that the dune.com app works with.\n\n2. Is there any integration with SQL databases in the app?\n- The app technical guide does not mention any integration with SQL databases.\n\n3. Are there any security measures in place to protect user data?\n- The app technical guide does not provide information on security measures in place to protect user data.","metadata":{"source":".autodoc/docs/markdown/docs/app/index.md"}}],["31",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/queries/data-explorer.md)\n\n# The Data Explorer\n\nThis technical guide covers the Data Explorer feature of the Dune app. The Data Explorer allows users to search for blockchain and other data to use in their Queries. The guide explains how to use the Data Explorer to find the data you need. \n\nThe guide starts by explaining how to select the database you want to search in and how to enter keywords, protocol names, contract names, or event names into the search bar to bring up a list of Tables containing blockchain data that can be used in Queries. \n\nThe guide then goes on to explain how to perform advanced searches in Dune V2 and V1. The V2 section explains how to search for data in the Dune V2 database, which contains all data accessible in one data lake. The V1 section explains how to search for data in the Dune V1 Engine, which has separate databases for each blockchain. \n\nThe guide provides examples of how to search for data using keywords, how to find specific schemas, events, calls, or contracts, and how to find specific contract data. It also explains how to add references to the Query Window. \n\nThe guide includes screenshots and GIFs to illustrate how to use the Data Explorer and how to perform advanced searches. It also provides warnings and notes to alert users to the fact that the V2 Data Explorer is still in beta and that the V2 explorer is not case sensitive. \n\nOverall, this guide provides a comprehensive overview of the Data Explorer feature of the Dune app and explains how to use it to find the data you need for your Queries.\n## Questions: \n 1. What databases can be searched using the Data Explorer?\n- The Data Explorer allows searching for blockchain and other data to use in Queries, and users can select which database they want to search in from the dropdown list.\n2. What is the difference between the V1 and V2 versions of the Data Explorer?\n- One of the biggest changes in Dune V2 lies in its data structure, where everything is accessible in one data lake, and users can incorporate data from multiple chains in one SQL query. In contrast, V1 allows users to search for specific schemas, events, calls, or contracts.\n3. How can users add references to the Query Window?\n- To add references to the contract tables, users can click the `>>` next to the Table name, and to reference specific data within a Table, they can click its name.","metadata":{"source":".autodoc/docs/markdown/docs/app/queries/data-explorer.md"}}],["32",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/queries/explorer-labels.md)\n\n# Data Explorer Labels\n\nThis technical guide covers the various labels encountered while using the Data Explorer in the Dune Docs project. The guide is divided into four sections: Blockchain Icons, Dataset Icons, Dataset Labels, and Data Type Labels.\n\nThe Blockchain Icons section provides a table of icons and their descriptions for each blockchain available in the data sets. For instance, the Ethereum blockchain icon represents raw data, decoded project, or spell for Ethereum blockchain. \n\nThe Dataset Icons section provides a table of icons and their descriptions for each dataset. For example, the table icon represents data table (raw data, spell, or smart contract event or function), while the decoded project icon represents a decoded project (protocol or protocol version, e.g., \"opensea\" or \"aave_v2\").\n\nThe Dataset Labels section provides a table of labels and their descriptions for each dataset. For instance, the project label represents a spell set for a specific project, e.g., `aave`, while the sector label represents a spell set for a sector, e.g., `dex`.\n\nThe Data Type Labels section provides a table of labels and their descriptions for each data type. For example, the string label represents character sequences of any length greater or equal to 0, while the long label represents 8-byte signed integer numbers.\n\nOverall, this technical guide provides a comprehensive understanding of the various labels encountered while using the Data Explorer in the Dune Docs project. \n\nExample: \n\nIf a user encounters the Ethereum blockchain icon while using the Data Explorer, they can understand that the data set contains raw data, decoded project, or spell for the Ethereum blockchain. Similarly, if a user encounters the project label, they can understand that the data set represents a spell set for a specific project, such as `aave`.\n## Questions: \n 1. What is the purpose of the Data Explorer in relation to blockchain data?\n- The Data Explorer is used to explore and analyze blockchain data from various blockchains, including Ethereum, Gnosis Chain, Polygon, Optimism, BNB Chain, Solana, Arbitrum, Avalanche, and Fantom.\n\n2. What types of data sets are available in the Data Explorer?\n- The Data Explorer includes data sets for raw data, decoded projects, spells, and community data, as well as smart contract event and function datasets.\n\n3. What data types are supported in the Data Explorer?\n- The Data Explorer supports various data types, including string, long, integer, double, boolean, date, timestamp, decimal, and arrays of different data types.","metadata":{"source":".autodoc/docs/markdown/docs/app/queries/explorer-labels.md"}}],["33",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/queries/index.md)\n\n# Queries\n\nThe Queries section of the Dune Docs app technical guide provides an overview of the Query Editor feature in Dune. The Query Editor is a tool that allows users to input SQL code and run it to retrieve data from the blockchain and other sources. The guide is broken down into several sub-sections, each of which covers a different aspect of the Query Editor.\n\nThe first sub-section, The Data Explorer, is focused on helping users search for blockchain and other data to use in their Queries. This feature allows users to explore the data available in Dune and select the data they want to use in their Queries.\n\nThe second sub-section, The Query Window, is where users input their SQL code and run it. This section provides an overview of how to use the Query Window and includes examples of SQL code that can be used to retrieve data from the blockchain.\n\nThe third sub-section, Query Results, is where users can view the data their Query returns after they run it. This section provides an overview of how to interpret the Query Results and includes examples of how to use the data in other parts of the Dune app.\n\nThe fourth sub-section, Parameters, is a specialized feature of Dune that allows users to implement variables in certain parts of their Query code. This section provides an overview of how to use Parameters and includes examples of how to implement them in SQL code.\n\nThe final sub-section, Query Tips, is a collection of tips to help users master Query creation with Dune. This section provides best practices for creating Queries and includes examples of how to optimize Query performance.\n\nOverall, the Queries section of the Dune Docs app technical guide is a comprehensive guide to using the Query Editor feature in Dune. It provides users with the information they need to create effective Queries and retrieve data from the blockchain and other sources.\n## Questions: \n 1. What type of blockchain data can be searched for using the Data Explorer?\n- The app technical guide does not provide information on the specific types of blockchain data that can be searched for using the Data Explorer.\n\n2. Can the Query Window handle complex SQL queries?\n- The app technical guide does not provide information on the limitations or capabilities of the Query Window in handling complex SQL queries.\n\n3. How are Parameters implemented in Dune's Query Editor?\n- The app technical guide briefly mentions Parameters as a specialized feature of Dune, but does not provide detailed information on how they are implemented in the Query Editor.","metadata":{"source":".autodoc/docs/markdown/docs/app/queries/index.md"}}],["34",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/queries/parameters.md)\n\n# Parameters\n\nThis technical guide covers the use of parameters in the Dune app. Parameters are a feature that allows users to implement variables in certain parts of their Query code. This variable can be changed from dashboards, making it possible to create interactive dashboards. Parameters are defined in the Query code as `{{parametername}}` and will appear below the Query and in any dashboards in which a Query Visualization with parameters is used in. \n\nThe guide explains how to use parameters in Queries and dashboards. It also provides an example Query that returns the running total of Gas Paid in USD. The Query Author has included a parameter for `wallet address`, `start date`, and `end date`. The guide also provides examples of dashboards that use parameters. \n\nThe guide explains how to add a parameter to Queries by writing `{{parametername}}` or using the button below the Query. Users can edit the properties of single parameters by clicking on the gear wheel next to the parameter in the Query editor. This allows them to set a default value, define a list of possible parameters, or change the type of the parameter. If users want to share parameters between different Queries on a dashboard, they must ensure that they exactly match in regards to name, type, and default value.\n\nParameters allow users to make a certain part of their SQL query dynamic and thereby offer them to make Queries and dashboards interactive. That way, they can easily display detailed data on their dashboard since it allows the viewer to customize the dashboard for their needs. Parameters are like filters, but the possibilities of using this feature go beyond that.\n\nIn summary, this guide covers the use of parameters in the Dune app. It explains what parameters are, how to use them in Queries and dashboards, and provides examples of Queries and dashboards that use parameters.\n## Questions: \n 1. What is the purpose of Parameters in Dune Docs?\n- Parameters are a feature in Dune Docs that allow for the implementation of variables in certain parts of Query code, which can be changed from dashboards and allow for an interactive dashboard.\n\n2. How do you use Parameters in Dune Docs?\n- Parameters can be added to Queries by writing `{{parametername}}` or using the button below the Query. The properties of single parameters can be edited by clicking on the gear wheel next to the parameter in the Query editor.\n\n3. Can Parameters be shared between different Queries in a Dashboard?\n- Yes, Parameters in a Dashboard can be shared between different Queries, as long as they have the same name, type, and default value.","metadata":{"source":".autodoc/docs/markdown/docs/app/queries/parameters.md"}}],["35",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/queries/query-results.md)\n\n# Query Results\n\nThe Query Results section of the Dune Docs app is where users can view the data their Query returns after running it. The guide explains how to get the results of a Query by clicking the \"Run\" button in the orange box below the Query Window. After a short time, the Query Results will appear as a table. The guide also warns users that queries run on the database they've currently selected in the Data Explorer dropdown. If a user runs a Query that uses Dune V1 Ethereum data, it will fail to run if they select another V1 Blockchain dataset or Dune V2.\n\nThe guide explains the elements above the Results table, which include the \"Query Results\" tab, the \"New Visualization\" button, \"Last run\" and \"Last run took\" times, and the \"Run\" button. The \"New Visualization\" button lets users make Visualizations out of their Query data. The guide also explains how to save a Query, and after running a Query at least once, the \"Save\" button appears above the Query Window. Users can give their Query a name and make it private if they're a Dune Premium user. \n\nThe guide also explains how to re-run a Query, format Results tables, and make Visualizations out of Query Results. Users can change the formatting and appearance of their Query Results tables with the options below the table. The guide explains the different column settings, including Title, Align, Format, Hide column, Colored positive values, and Colored negative values. The guide also provides a table that shows the different column number formatting options. \n\nOverall, the Query Results guide provides a detailed explanation of how to use the Query Results section of the Dune Docs app. It covers everything from running a Query to formatting Results tables and making Visualizations out of Query Results. The guide is a useful resource for users who want to get the most out of the Query Results section.\n## Questions: \n 1. What is the purpose of the Query Results section in Dune Docs?\n    \n    The Query Results section is where you can see the data your Query returns after running it.\n\n2. How can you save your Query in Dune Docs?\n    \n    After running your Query at least once, you'll see the Save button appear above the Query Window. Click it to see a pop-up that asks you to give your Query a name, with the option to make this Query private.\n\n3. How can you change the formatting and appearance of your Query Results tables in Dune Docs?\n    \n    You can change the formatting and appearance of your Query Results tables with the options below the table. The options include changing the table's title, settings for each of your columns, and adding the table to a dashboard.","metadata":{"source":".autodoc/docs/markdown/docs/app/queries/query-results.md"}}],["36",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/queries/query-window.md)\n\n# The Query Window\n\nThis technical guide covers the Query window in the Dune Docs project. The Query window is where users can input SQL code and run it. The guide provides information on how to use the Query window effectively.\n\n## Autocomplete\n\nThe guide explains how to enable or disable the autocomplete function of the Query editor using the gear wheel in the top right corner. The autocomplete feature brings up PostgreSQL keywords, tables, and aliases that have already been included in the Query. The guide provides an example of how to turn on autocomplete and how it works in the Query editor.\n\n## Run Selection\n\nThe guide explains how to save time while testing and debugging Queries by running just a part of the Query. Users can highlight a part of the Query, and the <span class=\"fk-btn-1\">Run</span> button will turn into a <span class=\"fk-btn-1\">Run selection</span> button. The guide provides an example of how to run a selection and what happens when a user highlights an incorrect piece of SQL.\n\n## Shortcuts\n\nThe guide provides a list of shortcuts that users can use to make crafting Queries faster. The shortcuts include executing the Query, commenting out selected code, bringing up a list of keywords, undoing and redoing changes, and searching for and replacing keywords. The guide notes that these shortcuts work on US/UK keyboards and may vary based on the language setting on the user's machine.\n\nOverall, this technical guide provides a comprehensive overview of the Query window in the Dune Docs project. It explains how to use the Query window effectively and provides examples of how to use its features.\n## Questions: \n 1. What is the purpose of the Dune app and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the Dune app or its relation to blockchain technology.\n\n2. What version of PostgreSQL does the Query editor support?\n- The app technical guide does not provide information on the version of PostgreSQL supported by the Query editor.\n\n3. Are there any security features in place to protect sensitive SQL code entered into the Query window?\n- The app technical guide does not provide information on any security features in place to protect sensitive SQL code entered into the Query window.","metadata":{"source":".autodoc/docs/markdown/docs/app/queries/query-window.md"}}],["37",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/queries)\n\nThe `docs/app/queries` folder contains technical guides that focus on the Queries feature of the Dune app. These guides provide comprehensive information on how to use the Query Editor, Data Explorer, and other related features to create effective queries and retrieve data from the blockchain and other sources.\n\nFor example, the `data-explorer.md` guide covers the Data Explorer feature, which allows users to search for blockchain and other data to use in their queries. It explains how to select the database, enter keywords, and perform advanced searches in Dune V2 and V1. This guide is useful for users who want to find specific data for their queries and understand the differences between Dune V2 and V1 databases.\n\nThe `explorer-labels.md` guide provides a detailed understanding of the various labels encountered while using the Data Explorer. It covers Blockchain Icons, Dataset Icons, Dataset Labels, and Data Type Labels. This guide helps users to quickly identify and understand the data sets they encounter while using the Data Explorer.\n\nThe `index.md` guide serves as an overview of the Query Editor feature in Dune. It is broken down into several sub-sections, each covering a different aspect of the Query Editor, such as The Data Explorer, The Query Window, Query Results, Parameters, and Query Tips. This guide is a comprehensive resource for users who want to learn how to create effective queries and retrieve data from the blockchain and other sources.\n\nThe `parameters.md` guide covers the use of parameters in the Dune app. Parameters allow users to implement variables in certain parts of their Query code, making it possible to create interactive dashboards. This guide explains how to use parameters in Queries and dashboards and provides examples of Queries and dashboards that use parameters.\n\nThe `query-results.md` guide focuses on the Query Results section of the Dune Docs app, where users can view the data their Query returns after running it. It covers how to run a Query, format Results tables, and make Visualizations out of Query Results. This guide is useful for users who want to get the most out of the Query Results section.\n\nThe `query-window.md` guide provides a comprehensive overview of the Query window in the Dune Docs project. It explains how to use the Query window effectively, including enabling or disabling the autocomplete function, running a selection of the Query, and using shortcuts.\n\nFinally, the `tips.md` guide offers useful tips for using queries in the Dune app, covering topics such as using Spells, formatting Ethereum addresses, quoting column and table names, removing decimals, getting time with `date_trunc`, getting USD price, using token symbols, and filtering queries and dashboards with parameters.\n\nOverall, the guides in the `docs/app/queries` folder provide valuable information and resources for users who want to become more proficient in using the Queries feature of the Dune app.","metadata":{"source":".autodoc/docs/markdown/docs/app/queries/summary.md"}}],["38",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/queries/tips.md)\n\n# Query Tips\n\nThis technical guide provides tips for using queries in the Dune app. It covers various topics such as using Spells, formatting Ethereum addresses, quoting column and table names, removing decimals, getting time with `date_trunc`, getting USD price, using token symbols, and filtering queries and dashboards with parameters.\n\nThe guide starts with an introduction to Spells, which are well-organized tables that contain cleaned data and metadata that make them easy to query. The guide then explains how to format Ethereum addresses in Dune V1 engine, which uses PostgreSQL byte arrays encoded with the `\\x` prefix. The guide also provides a warning that column and table names are case sensitive in PostgreSQL and that double quotes are reserved for tables and columns, whereas single quotes are reserved for values.\n\nThe guide then explains how to remove decimals from Ether transfers and ERC-20 tokens, which have 18 decimal places, making them difficult to read. The guide suggests using the `erc20.tokens` table and dividing the token's `transfer_value` by 10. The guide also provides examples of how to use `date_trunc` function to get time and how to get USD price by joining the smart contract event with the `prices.usd` on the `minute` for a given `asset`.\n\nThe guide also explains how to use token symbols instead of token addresses to group results by token address. To do this, the guide suggests joining the `erc20.tokens` table with the event table where `asset` = `{{token_address}}`. The guide also provides examples of how to filter queries and dashboards with parameters, which can turn a Query or Dashboard into an app for blockchain data.\n\nOverall, this technical guide provides useful tips for using queries in the Dune app. It is a valuable resource for anyone looking to become a more powerful user of Dune.\n## Questions: \n 1. What is the purpose of the Dune V1 engine and what features are only available in it?\n- The Dune V1 engine is mentioned in several sections of the technical guide, and a blockchain SQL analyst might want to know what it is and what features are exclusive to it. The guide states that the V1 engine is required for certain features such as inline Ethereum address formatting and camelCase table and column name references.\n\n2. How can token symbols be used instead of token addresses in queries?\n- The guide explains that token symbols can be more user-friendly than token addresses, but also warns that the erc20.tokens table only contains popular tokens and may exclude more obscure ones. A blockchain SQL analyst might want to know how to join the erc20.tokens table with their event table to select symbols instead of addresses.\n\n3. How can parameters be used to filter queries and dashboards?\n- The guide explains how parameters can be used to turn queries and dashboards into blockchain data apps, and provides an example of how to add a parameter for token symbol or holder address. A blockchain SQL analyst might want to know how to use parameters in their queries and how to format addresses to save users from having to input the `\\x` prefix.","metadata":{"source":".autodoc/docs/markdown/docs/app/queries/tips.md"}}],["39",{"pageContent":"[View code on GitHub](https://dune.com/docs/app)\n\nThe `docs/app` folder contains technical guides and documentation focused on the Dune app and its various features. These guides are essential for users who want to leverage the full potential of the Dune app, as they provide in-depth explanations and how-to guides for each feature.\n\nFor example, the `decoding-contracts.md` guide offers a comprehensive overview of Decoded Contracts in Dune, including how to submit them for decoding. This guide is valuable for users who want to decode smart contracts and explore their functionality using the Dune app interface. It covers advanced options for submitting contracts, tracking submissions, and answers frequently asked questions.\n\nThe `index.md` guide serves as an introduction to the Dune.com app and its features, such as Queries, Visualizations, Dashboards, Decoding, and Teams. This guide is aimed at users who are already familiar with the basics of the app and are looking for more in-depth explanations and how-to guides for leveraging the Dune app interface.\n\nThe `teams.md` guide covers the Teams feature of the Dune app, which allows Wizards to collaborate within shared workspaces. This guide is a comprehensive resource for anyone looking to use the Teams feature, providing step-by-step instructions for creating a Team, adding users, and transferring content to a Team.\n\nThe subfolders in this folder dive deeper into specific features of the Dune app:\n\n- `dashboards`: This folder contains guides that focus on the dashboard features of the Dune Docs project. Users can learn how to create custom dashboards, explore Ecosystem Dashboards, and monitor the performance of specific projects with Project Dashboards.\n\n- `queries`: This folder contains guides that focus on the Queries feature of the Dune app. Users can learn how to use the Query Editor, Data Explorer, and other related features to create effective queries and retrieve data from the blockchain and other sources.\n\n- `visualizations`: This folder contains guides focused on creating and customizing visualizations using the Dune app. Users can learn how to create various types of visualizations, including charts, graphs, tables, counters, and embeds, and share them across different web platforms.\n\nOverall, the guides in the `docs/app` folder provide a comprehensive understanding of the Dune app and its features. These guides are essential for users who want to leverage the power of the Dune app to analyze and visualize blockchain data effectively.","metadata":{"source":".autodoc/docs/markdown/docs/app/summary.md"}}],["40",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/teams.md)\n\n# Teams\n\nThis technical guide covers the Teams feature of the Dune app. Teams are shared workspaces for Wizards to collaborate within. The guide explains the benefits of creating a Team, such as collaborating on the same content, having a separate workspace for each Team, and showcasing all of a Team's work in one place. It also explains the different user roles available for Team members, including Viewer, Editor, and Admin.\n\nThe guide provides step-by-step instructions for creating a Team, adding users, and transferring content to a Team. It also explains how to find a Team's content and filter it by owner. Additionally, the guide includes an FAQ section that addresses common questions, such as whether private content is supported in Teams and how to edit a user's role.\n\nOverall, this guide is a comprehensive resource for anyone looking to use the Teams feature of the Dune app. It provides clear explanations and helpful visuals to guide users through the process of creating and managing Teams. For example, the guide includes screenshots of the Teams settings page and the My Creations page to help users navigate the app.\n## Questions: \n 1. What is the purpose of Dune Teams in the context of blockchain and SQL analysis?\n- This app technical guide does not provide information on the specific use of Dune Teams in the context of blockchain and SQL analysis. Further research or documentation may be necessary to answer this question.\n\n2. Can Dune Teams support collaboration on blockchain and SQL analysis projects?\n- Yes, Dune Teams are designed to support collaboration on shared Queries and Dashboards, which could include blockchain and SQL analysis projects.\n\n3. Is there a way to restrict access to private content within Dune Teams?\n- The app technical guide states that support for private content in Teams is planned for later in the year, but it is not currently available.","metadata":{"source":".autodoc/docs/markdown/docs/app/teams.md"}}],["41",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/visualizations/charts-graphs.md)\n\n# Charts & Graphs\n\nThis technical guide is focused on the Charts & Graphs feature of the Dune app. The guide provides an overview of the different types of graphs that can be created with Dune, including bar charts, area charts, scatter charts, line charts, pie charts, and mixed graphs. Each graph type is accompanied by an example image. \n\nThe guide also covers the common set of editing options that all graph visualizations share. These options include chart options, result data, x-axis options, y-axis options, and series options. Each option is explained in detail, with accompanying images to illustrate the different configurations. \n\nThe guide also includes a section on pie options, which allows users to define the tick format of the data labels in their pie chart. Finally, the guide provides a table of tick and label formats that can be used to format numeric values and axis labels in graphs. \n\nOverall, this technical guide provides a comprehensive overview of the Charts & Graphs feature of the Dune app, including the different types of graphs that can be created and the editing options available to users. The guide is a valuable resource for anyone looking to create visualizations of their data using Dune.\n## Questions: \n 1. What types of data can be visualized with Dune Docs' graphs?\n- Dune Docs' graphs can visualize bar charts, area charts, scatter charts, line charts, pie charts, and mixed graphs.\n\n2. What editing options are available for all graph visualizations?\n- All graph visualizations share a common set of editing options, which include chart options, result data, x-axis options, y-axis options, and series options.\n\n3. How can tick formats be used to change how numeric values and axis labels are displayed?\n- Tick formats can be used to display numeric values and axis labels in different formats, such as displaying only the integer, displaying the number with a certain number of decimal places, or adding a currency symbol.","metadata":{"source":".autodoc/docs/markdown/docs/app/visualizations/charts-graphs.md"}}],["42",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/visualizations/embeds.md)\n\n# Embeds\n\nThis guide covers the use of Embeds in the Dune app. Embeds allow users to share live Dune charts across different web platforms. The guide explains how to generate embed links and how to use them on different platforms such as Twitter, Discord, web pages, and Mirror.xyz. \n\nThe guide starts by highlighting the benefits of using Embeds over screenshots. It then explains how to generate embed links by clicking on any query title and selecting the embed function in the top right corner. The guide also notes that the embed button works as a stand-alone link and as a way to embed live graphs into websites/apps. If a Query has no Visualizations, the link will be to the Query Results table. If you have multiple Visualizations, the link will be for whichever Visualization you've selected when you clicked the Embed button. \n\nThe guide then provides examples of how to use Embeds on different platforms. For instance, on Twitter, users can paste their embed link, and Twitter will automatically render and update Dune Visualizations. On Discord, users can drop the embed link in the chat, and the corresponding Visualization will be displayed. The guide also provides a code snippet example of how to use Dune's embed links to add live Visualizations to any web page using an `iframe`. \n\nThe guide also explains how to embed Dune Visualizations into articles on Mirror.xyz. Users can generate an embed link and postfix it with `?display=iframe`. The guide notes that Embeds do not work in a couple of popular web platforms, including Substack, Medium, and GitBook. \n\nFinally, the guide explains how to use parameterized Embeds. The embed links work with parameterized Queries, but users need to manually prefix the parameter link with the parameters. The guide provides an example of how to do this. \n\nOverall, this guide provides a comprehensive overview of how to use Embeds in the Dune app. It explains how to generate embed links and how to use them on different platforms. The guide also provides examples and code snippets to help users get started with Embeds.\n## Questions: \n 1. What is the purpose of the Dune Docs app and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the Dune Docs app or its relation to blockchain technology.\n\n2. How does the app handle data security and privacy?\n- The app technical guide does not provide information on how the app handles data security and privacy.\n\n3. Can the app be integrated with blockchain databases or SQL servers?\n- The app technical guide does not provide information on whether the app can be integrated with blockchain databases or SQL servers.","metadata":{"source":".autodoc/docs/markdown/docs/app/visualizations/embeds.md"}}],["43",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/visualizations/index.md)\n\n# Visualizations\n\nThe purpose of this section of the app technical guide is to provide information on how to create visualizations using Dune. The guide is divided into two main sections: Charts & Graphs and Other Visualizations.\n\n## Charts & Graphs\n\nThis section explains and provides examples on how to create popular visualizations using Dune. The guide covers various types of charts and graphs such as line charts, bar charts, pie charts, and scatter plots. It also explains how to customize these visualizations by changing colors, labels, and other properties.\n\nExample: If a user wants to create a line chart to display the trend of sales over time, they can refer to this section of the guide to learn how to create the chart and customize it to their needs.\n\n## Other Visualizations\n\nThis section covers a few more unique visualizations that can be created using Dune. It includes examples of heat maps, word clouds, and network graphs. The guide explains how to create these visualizations and provides tips on how to effectively use them.\n\nExample: If a user wants to create a word cloud to display the most commonly used words in a document, they can refer to this section of the guide to learn how to create the visualization and adjust the settings to display the desired information.\n\nOverall, this section of the app technical guide is a helpful resource for users who want to create visualizations using Dune. It provides clear explanations and examples on how to create various types of visualizations and customize them to meet specific needs.\n## Questions: \n 1. What type of data does this app visualize?\n- The app technical guide does not provide information on the type of data that is visualized.\n\n2. Does this app use any specific SQL queries or databases to generate visualizations?\n- The app technical guide does not mention the use of SQL queries or databases to generate visualizations.\n\n3. Are there any limitations or restrictions on the size or complexity of the data that can be visualized with this app?\n- The app technical guide does not provide information on any limitations or restrictions on the size or complexity of the data that can be visualized.","metadata":{"source":".autodoc/docs/markdown/docs/app/visualizations/index.md"}}],["44",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/visualizations/other-visualizations.md)\n\n# Other Visualizations\n\nThis guide covers non-graph visualizations that can be created using Dune. The guide is divided into two sections: Tables and Counters.\n\n## Tables\n\nTables are the default visualization that appears when a query is run. The guide explains how to create additional tables and customize them. The following options can be configured for each column in a table:\n\n- Title: The title that appears at the top of the column. If left blank, the column title will be the same as its Dune database name.\n- Align: The text alignment for the column data and title.\n- Format: The numerical format of the data.\n- Hide Column: Hides the column from the table.\n\nNumerical columns have additional options:\n\n- Type: Displays the column's numerical data or shows it with a progress bar visual.\n- Colored Values: Colors positive values green and negative values red.\n\n## Counters\n\nCounters are a way to display \"on a glance\" stats. The guide explains how to configure counters and adjust how numerical data is displayed. The following options can be configured for counters:\n\n- Title: The title that appears at the top of the counter. If left blank, the query name will be the only thing displayed.\n- Column: The column the counter should show.\n- Row: The row of the underlying data table to be displayed.\n- Prefix: A prefix for the counter value.\n- Suffix: A suffix for the counter value.\n- Label: A label for the counter value.\n- Decimals: The number of decimal places to be displayed.\n\nThe guide provides examples and screenshots to illustrate how to configure tables and counters.\n## Questions: \n 1. What is the purpose of Dune Docs and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of Dune Docs or its relation to blockchain technology, so a blockchain SQL analyst may need to seek additional documentation or context.\n2. Can Dune Docs visualize data from blockchain databases?\n- The app technical guide does not specify which types of databases Dune Docs can visualize, so a blockchain SQL analyst may need to investigate further to determine if it is compatible with blockchain databases.\n3. Are there any limitations to the numerical data formatting options for Counters?\n- The app technical guide states that the number of decimal places is currently limited to 3, but it does not provide information on any other limitations or restrictions, so a blockchain SQL analyst may need to test the app or consult with the development team to determine any other limitations.","metadata":{"source":".autodoc/docs/markdown/docs/app/visualizations/other-visualizations.md"}}],["45",{"pageContent":"[View code on GitHub](https://dune.com/docs/app/visualizations)\n\nThe `docs/app/visualizations` folder contains a collection of technical guides focused on creating and customizing visualizations using the Dune app. These guides cover various types of visualizations, including charts, graphs, tables, counters, and embeds. The folder is organized into four main files: `charts-graphs.md`, `embeds.md`, `index.md`, and `other-visualizations.md`.\n\nThe `charts-graphs.md` guide provides a comprehensive overview of the Charts & Graphs feature of the Dune app. It covers different types of graphs, such as bar charts, area charts, scatter charts, line charts, pie charts, and mixed graphs, along with examples and editing options for each graph type. This guide is useful for users who want to create visually appealing and informative graphs to represent their data.\n\nThe `embeds.md` guide focuses on the use of Embeds in the Dune app, which allows users to share live Dune charts across different web platforms like Twitter, Discord, web pages, and Mirror.xyz. This guide explains how to generate embed links and use them on various platforms, providing examples and code snippets to help users get started with Embeds. This guide is beneficial for users who want to share their visualizations with a wider audience.\n\nThe `index.md` guide serves as an introduction to the Visualizations section of the app technical guide. It provides a brief overview of the two main sections: Charts & Graphs and Other Visualizations. This guide is helpful for users who are new to Dune and want to understand the different types of visualizations available and how to create them.\n\nThe `other-visualizations.md` guide covers non-graph visualizations, such as tables and counters. It explains how to create and customize tables, which are the default visualization when a query is run, and counters, which display \"at a glance\" stats. This guide is useful for users who want to create simple yet informative visualizations to represent their data.\n\nOverall, the guides in the `docs/app/visualizations` folder provide valuable information for users who want to create and customize visualizations using the Dune app. These guides cover various types of visualizations and provide examples and editing options to help users create visually appealing and informative representations of their data.","metadata":{"source":".autodoc/docs/markdown/docs/app/visualizations/summary.md"}}],["46",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/flashbots/arbitrages.md)\n\n# Dune Docs App Technical Guide: Arbitrages\n\nThe `arbitrages` section of the Dune Docs project is focused on providing additional information about each arbitrage trade. The `flashbots.arbitrages` table contains records with details such as block number, account address, time of record creation, available amount before and after the arbitrage, profit amount, profit token address, protocols involved in the transaction, transaction hash, and timestamp of the latest update of the file.\n\nThe purpose of this technical guide is to provide a clear understanding of the `arbitrages` section of the Dune Docs project. The guide explains the structure of the `flashbots.arbitrages` table, including the column names, data types, and descriptions. It also provides query examples that can be used to retrieve information from the table.\n\nFor instance, the `Total Arb Protocols` query example provided in the guide can be used to retrieve the total number of arbitrage protocols involved in the transaction. This query can be accessed through the link provided in the guide.\n\nOverall, this technical guide serves as a reference for developers and users who want to understand the `arbitrages` section of the Dune Docs project. It provides a clear and concise explanation of the table structure and query examples that can be used to retrieve information from the table.\n## Questions: \n 1. What is the purpose of the `flashbots.arbitrages` table in the context of blockchain technology?\n- The `flashbots.arbitrages` table contains records with additional information about each arbitrage trade in the blockchain, which can be useful for analyzing trading patterns and identifying potential opportunities for profit.\n\n2. How can a blockchain SQL analyst use the query examples provided in the technical guide?\n- The query examples provided in the technical guide can be used by a blockchain SQL analyst to retrieve specific data from the `flashbots.arbitrages` table, such as information about the protocols involved in a transaction or the profit amount after an arbitrage.\n\n3. Are there any limitations or potential issues with using SQL to analyze blockchain data?\n- While SQL can be a powerful tool for analyzing blockchain data, there are some limitations and potential issues to be aware of, such as the need to handle large amounts of data and the possibility of inaccuracies due to the decentralized nature of the blockchain.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/flashbots/arbitrages.md"}}],["47",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/flashbots/index.md)\n\n# Flashbots\n\nThis section of the app technical guide covers the Flashbots project, a research and development organization focused on ensuring that MEV (Miner Extractable Value) incentives do not become opaque and undemocratic. MEV refers to the profit that miners can extract from reordering, censoring, or including transactions in a block. \n\nThe guide notes that Flashbots' open source engine for generating MEV data, mev-inspect-py, powers dashboards such as mev-explore and Dune's Flashbots integration. The section encourages researchers and developers to report any bugs or implement new features to improve the engine. \n\nThe guide provides links to the Flashbots documentation and Discord server for more information and updates on their data and mev-inspect. \n\nExample: If a developer is working on integrating Flashbots into their project, they can refer to the documentation and join the Discord server to stay up-to-date on any changes or improvements to the engine. They can also report any bugs they encounter to help improve the engine for the community.\n## Questions: \n 1. What is the purpose of Flashbots and how does it relate to MEV incentives?\n- Flashbots is a research and development organization that aims to prevent MEV incentives from becoming opaque and undemocratic. MEV-inspect-py, their open source engine for generating MEV data, powers dashboards such as mev-explore and Dune's Flashbots integration.\n\n2. How can blockchain SQL analysts contribute to improving Flashbots' open source engine?\n- Flashbots encourages researchers and developers to report and help correct any found bugs, or implement any new features. They can consult the documentation and join the Flashbots discord for more information and updates on their data and mev-inspect.\n\n3. What resources are available for developers and researchers interested in using Flashbots?\n- Flashbots provides documentation on their website and a Discord server for more information and updates on their data and mev-inspect. They also encourage community contributions to improve their open source engine.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/flashbots/index.md"}}],["48",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/flashbots/liquidations.md)\n\n# Liquidations\n\nThe `liquidations` section of the Dune Docs project focuses on providing details related to executed liquidations. The `flashbots.liquidations` table contains information about liquidations executed using the MEV strategy. The table includes details such as the time of record creation, transaction hash, trace pattern related to the position of the transaction in the chain of all transactions related to the MEV trade, underlying token address of the debt to pay, amount received from the liquidation, protocol name, address of the liquidated user, address of the liquidator user, address of the received asset, block number, amount of purchased debt, and timestamp of the latest update of the file.\n\nThe purpose of this guide is to provide a detailed explanation of the `flashbots.liquidations` table and its columns. The guide also includes a link to query examples for liquidations by protocol. This information is useful for developers who want to understand how liquidations work and how to access the data related to executed liquidations.\n\nAn example of a query that can be run using the `flashbots.liquidations` table is the `Liquidations by Protocol` query, which can be found at [https://dune.com/queries/625715/1166880](https://dune.com/queries/625715/1166880). This query provides information about liquidations executed by protocol, including the protocol name, number of liquidations, total received amount, and average received amount.\n\nOverall, the `liquidations` section of the Dune Docs project provides valuable information for developers who want to understand how liquidations work and how to access the data related to executed liquidations using the MEV strategy.\n## Questions: \n 1. What is the purpose of the `flashbots.liquidations` table in the context of blockchain and how is it related to MEV (Miner Extractable Value)? \n- The `flashbots.liquidations` table contains details related to executed liquidations, which is another MEV strategy. It is related to MEV because it involves extracting value from transactions before they are included in a block.\n\n2. Can you provide more information on the `trace_address` column and how it relates to the position of the transaction in the chain of all transactions related to the MEV trade? \n- The `trace_address` column contains a trace pattern related to the position of the transaction in the chain of all transactions related to the MEV trade. This can be useful for analyzing the flow of transactions and identifying potential bottlenecks or inefficiencies.\n\n3. Are there any limitations or considerations to keep in mind when using the `debt_purchase_amount` column for analysis? \n- It may be important to consider the specific context and protocol being used when analyzing the `debt_purchase_amount` column, as the amount of purchased debt may vary depending on the protocol and other factors. Additionally, it may be useful to compare this column to other relevant metrics to gain a more complete understanding of the data.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/flashbots/liquidations.md"}}],["49",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/flashbots/mev_summary.md)\n\n# mev_summary\n\nThe `mev_summary` section of the Dune Docs project is focused on providing a summary of all the classified transactions. The `flashbots.mev_summary` table contains information on the various transactions that have taken place, including the block timestamp, block number, base fee per gas, direct transfer to miner's address, error (if any), gas price, amount of gas spent, amount of gas used, total profit from the transaction in USD, address of the miner, payment received by the miner in USD, main interacted protocol, list of protocols involved in the transaction, hash of the transaction, type of the MEV (e.g. arbitrage), and timestamp of the latest update of the file.\n\nThis section of the app technical guide provides a detailed description of the various columns in the `flashbots.mev_summary` table, including their data type and description. For example, the `block_timestamp` column contains a timestamp of the block, while the `gas_price` column contains the price of the gas. The guide also provides a query example that can be used to retrieve information from the `flashbots.mev_summary` table.\n\nOverall, the `mev_summary` section of the Dune Docs project is an important resource for anyone looking to understand the various transactions that have taken place on the platform. By providing detailed information on each transaction, including the type of MEV and the protocols involved, this section of the app technical guide helps users gain a better understanding of how the platform works and how they can use it to their advantage.\n## Questions: \n 1. What is the purpose of the `mev_summary` table in the context of blockchain and SQL analysis?\n- The `mev_summary` table contains a summary of all classified transactions, which could be useful for analyzing miner revenue and profit in the context of MEV (miner-extractable value) strategies.\n\n2. Are there any limitations or potential issues with using this table for blockchain and SQL analysis?\n- The technical guide does not provide information on any limitations or potential issues with using this table, so a blockchain SQL analyst may need to investigate further to ensure the data is accurate and complete.\n\n3. Are there any additional resources or documentation available for using the `mev_summary` table in Dune Docs?\n- The technical guide provides a link to query examples, but it is unclear if there are any additional resources or documentation available for using this table in Dune Docs. A blockchain SQL analyst may need to reach out to the Dune Docs team or community for more information.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/flashbots/mev_summary.md"}}],["50",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/flashbots/sandwiched-swaps.md)\n\n# Sandwiched Swaps\n\nThe Sandwiched Swaps section of the Dune Docs project focuses on the `flashbots.sandwiched_swaps` table, which contains additional data about one or more swaps that were sandwiched with a corresponding sandwich in the database. This section provides a detailed explanation of the columns in the table and their respective data types.\n\nThe `created_at` column contains the time of the record's creation, while the `block_number` column contains the block number of the transaction. The `sandwich_id` column contains the internal ID of the sandwiched swap, and the `trace_address` column contains the trace pattern related to the position of the swap in the chain of all swaps related to the arbitrage trade. Finally, the `transaction_hash` column contains the transaction hash, and the `timestamp` column contains the timestamp of the latest update of the file.\n\nThis section also provides query examples for the `flashbots.sandwiched_swaps` table, which can be used as a reference for developers working on the Dune Docs project. The query examples include the column name, data type, and description of each column in the table.\n\nOverall, the Sandwiched Swaps section of the Dune Docs project provides a comprehensive guide to the `flashbots.sandwiched_swaps` table, including its purpose, columns, and query examples. This information is essential for developers working on the Dune Docs project to understand the structure and functionality of the table and to use it effectively in their work.\n## Questions: \n 1. What is the purpose of the sandwiched_swaps table in the context of blockchain and SQL analysis?\n- A blockchain SQL analyst might want to know how the sandwiched_swaps table fits into the overall data schema and how it can be used to analyze arbitrage trades involving swaps.\n\n2. Are there any limitations or constraints on the data that can be queried from the sandwiched_swaps table?\n- A blockchain SQL analyst might want to know if there are any restrictions on the types of queries that can be run on the sandwiched_swaps table, such as limitations on the time range or block numbers that can be queried.\n\n3. How frequently is the sandwiched_swaps table updated and what triggers these updates?\n- A blockchain SQL analyst might want to know how often the sandwiched_swaps table is updated and what events trigger these updates, such as new blocks being added to the blockchain or new transactions being processed.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/flashbots/sandwiched-swaps.md"}}],["51",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/flashbots/sandwiches.md)\n\n# Sandwiches Table\n\nThe `sandwiches` table is a part of the Dune Docs project and contains detailed information about executed sandwiches. The table consists of the following columns:\n\n- `created_at`: This column contains the time of the record's creation.\n- `block_number`: This column contains the block number.\n- `backrun_swap_trace_address`: This column contains the address of the swap in the backrun transaction.\n- `backrun_swap_transaction_hash`: This column contains the transaction hash of the backrun transaction of the specified sandwich.\n- `frontrun_swap_trace_address`: This column contains the address of the swap in the frontrun transaction.\n- `frontrun_swap_transaction_hash`: This column contains the transaction hash of the frontrun transaction of the specified sandwich.\n- `id`: This column contains the internal id of the sandwich.\n- `profit_amount`: This column contains the profit amount after the arbitrage.\n- `profit_token_address`: This column contains the address of the profit asset.\n- `sandwicher_address`: This column contains the address of the sandwicher.\n- `timestamp`: This column contains the timestamp of the latest update of the file.\n\nThe `sandwiches` table is used to keep track of executed sandwiches and their details. For example, it can be used to analyze the performance of the sandwicher and the profitability of the arbitrage. \n\nHere is an example of how the `sandwiches` table can be queried:\n\n```\nSELECT *\nFROM sandwiches\nWHERE sandwicher_address = '0x1234567890abcdef'\n```\n\nThis query will return all the sandwiches executed by the sandwicher with the address `0x1234567890abcdef`.\n## Questions: \n 1. What is the purpose of the \"sandwiches\" table in the Dune Docs app?\n- The \"sandwiches\" table contains detailed information about executed sandwiches, including the time of record creation, block number, swap addresses and transaction hashes, profit amount and token address, sandwicher address, and timestamp of the latest update of the file.\n\n2. How is the data in the \"sandwiches\" table stored and accessed?\n- The data in the \"sandwiches\" table is stored in columns with corresponding data types and descriptions, and can be accessed through SQL queries.\n\n3. Are there any limitations or potential issues with using SQL to analyze the data in the \"sandwiches\" table?\n- It is unclear from the provided technical guide whether there are any limitations or potential issues with using SQL to analyze the data in the \"sandwiches\" table. A blockchain SQL analyst may need to consult additional documentation or perform further testing to determine any such limitations or issues.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/flashbots/sandwiches.md"}}],["52",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/flashbots)\n\nThe Flashbots folder in the Dune Docs project focuses on providing comprehensive information and guides related to the Flashbots project, which is a research and development organization aimed at ensuring that MEV (Miner Extractable Value) incentives remain transparent and democratic. This folder contains various files that cover different aspects of the Flashbots project, such as arbitrages, liquidations, mev_summary, sandwiched swaps, and sandwiches.\n\nFor instance, the `arbitrages.md` file provides a detailed explanation of the `flashbots.arbitrages` table, which contains records with information about each arbitrage trade. Developers can use this guide to understand the table structure and retrieve information using query examples provided in the guide, such as the `Total Arb Protocols` query.\n\nThe `liquidations.md` file focuses on the `flashbots.liquidations` table, which contains information about liquidations executed using the MEV strategy. Developers can use this guide to understand the table structure and access data related to executed liquidations using query examples provided in the guide, such as the `Liquidations by Protocol` query.\n\nThe `mev_summary.md` file covers the `flashbots.mev_summary` table, which provides a summary of all classified transactions. This guide helps users understand the various transactions that have taken place on the platform, including the type of MEV and the protocols involved. The guide also provides a query example that can be used to retrieve information from the `flashbots.mev_summary` table.\n\nThe `sandwiched-swaps.md` file focuses on the `flashbots.sandwiched_swaps` table, which contains additional data about one or more swaps that were sandwiched with a corresponding sandwich in the database. This guide provides a detailed explanation of the columns in the table and their respective data types, as well as query examples for developers working on the Dune Docs project.\n\nLastly, the `sandwiches.md` file provides a comprehensive guide to the `flashbots.sandwiches` table, which contains detailed information about executed sandwiches. This guide is essential for developers working on the Dune Docs project to understand the structure and functionality of the table and to use it effectively in their work.\n\nOverall, the Flashbots folder in the Dune Docs project serves as a valuable resource for developers and users who want to understand the Flashbots project and its various aspects. The guides provided in this folder offer clear and concise explanations of the table structures, column descriptions, and query examples that can be used to retrieve information from the tables.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/flashbots/summary.md"}}],["53",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/index.md)\n\n# Dune Docs App Technical Guide: Community\n\nThis section of the Dune Docs project contains data that has been submitted and hosted on Dune by third-party data providers. The purpose of this guide is to provide an overview of the Community section and its features.\n\n## Availability\n\nThe Community section is only available on the V2 Engine. It is important to note that this section is still under development, and the infrastructure is being built to support more datasets.\n\n## Purpose\n\nWhile blockchain data is interesting on its own, sometimes off-chain data or augmented on-chain data is needed as well. The Community section is designed to partner with selected organizations that stream their data directly to Dune. This allows for a more comprehensive view of the data and can provide additional insights.\n\n## Data Providers\n\nThe Community section currently features two data providers: Flashbots and Reservoir. Each provider has its own page with more detailed information about the data they provide.\n\n### Flashbots\n\nFlashbots is a research and development organization that focuses on miner-extractable value (MEV) and the fair distribution of this value. Their page on the Community section provides data related to MEV and other metrics.\n\n### Reservoir\n\nReservoir is a data provider that focuses on Ethereum data. Their page on the Community section provides data related to Ethereum transactions, including gas usage and transaction volume.\n\nIt is important to note that these are just two examples of data providers that may be featured in the Community section. As the infrastructure is built out, more providers may be added.\n\nOverall, the Community section of the Dune Docs project is designed to provide additional data insights through partnerships with third-party data providers. While still under development, this section has the potential to provide valuable information to users of the Dune platform.\n## Questions: \n 1. What is the V2 Engine and why is it necessary for accessing the Community section?\n- The V2 Engine is required for accessing the Community section, but the guide does not provide information on what it is or why it is necessary.\n\n2. What types of off-chain or augmented on-chain data are being provided by the selected organizations?\n- The guide mentions that selected organizations are streaming their data directly to Dune, but does not provide any information on the types of data being provided.\n\n3. Is there a timeline for when more datasets will be supported in the Community section?\n- The guide mentions that the infrastructure for the Community section is still being built out and that more datasets cannot be supported at the current moment, but does not provide any information on when this may change.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/index.md"}}],["54",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/reservoir/ask-events.md)\n\n# Ask Events\n\nThis section of the app technical guide covers the `reservoir.ask_events` table, which contains records with information about each ask change. The table includes various columns such as `id`, `kind`, `contract`, `token_id`, `order_id`, `maker`, `price`, `quantity_remaining`, `valid_from`, `valid_until`, `source`, `tx_hash`, `tx_timestamp`, and `created_at`. \n\nThe `id` column represents the internal event ID, while the `kind` column represents the type of event (e.g. new-order, expiry, sale, cancel, balance-change, approval-change, bootstrap, revalidation, reprice). The `contract` column contains the contract address, and the `token_id` column contains the ID of the token in the collection. The `order_id` column represents the associated ask ID, and the `maker` column contains the associated ask maker wallet address. The `price` column represents the associated ask price in native currency, and the `quantity_remaining` column represents the associated ask tokens remaining. The `valid_from` and `valid_until` columns represent the associated ask validity start and expiration, respectively. The `source` column contains the source of the order (e.g. opensea.io), while the `tx_hash` and `tx_timestamp` columns represent the associated transaction hash and timestamp, respectively. Finally, the `created_at` column represents the timestamp the event was recorded.\n\nThis section also includes query examples that can be found at the specified URLs. These queries can be used to retrieve information from the `reservoir.ask_events` table. \n\nOverall, this section of the app technical guide provides a detailed overview of the `reservoir.ask_events` table and its various columns. It also includes query examples that can be used to retrieve information from the table.\n## Questions: \n 1. What is the purpose of the `reservoir.ask_events` table in the Dune Docs app?\n- The `reservoir.ask_events` table contains records with information about each ask change in the app.\n\n2. What are some examples of query options available for the `reservoir.ask_events` table?\n- Query examples for the `reservoir.ask_events` table can be found at the following links: [https://dune.com/queries/1302858/2232178](https://dune.com/queries/1302858/2232178) and [https://dune.com/queries/1302863/2232189](https://dune.com/queries/1302863/2232189).\n\n3. What types of events are included in the `kind` column of the `reservoir.ask_events` table?\n- The `kind` column in the `reservoir.ask_events` table includes various event types such as new-order, expiry, sale, cancel, balance-change, approval-change, bootstrap, revalidation, and reprice.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/reservoir/ask-events.md"}}],["55",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/reservoir/asks.md)\n\n## Reservoir.asks\n\nThis section of the app technical guide covers the `reservoir.asks` table, which contains records with information about each listing. The table includes various columns such as `id`, `kind`, `status`, `contract`, `token_id`, `maker`, `taker`, `price`, `start_price`, `end_price`, `currency_address`, `currency_symbol`, `currency_price`, `dynamic`, `quantity`, `quantity_filled`, `quantity_remaining`, `valid_from`, `valid_until`, `nonce`, `source`, `fee_bps`, `expiration`, `raw_data`, `created_at`, and `updated_at`. Each column is described in detail, including its data type and a brief explanation of its purpose.\n\nThe purpose of this guide is to provide developers with a clear understanding of the `reservoir.asks` table and its columns, as well as how to query the table. The guide includes two query examples that can be found at the provided links. Developers can use this information to build applications that interact with the `reservoir.asks` table, such as a marketplace or trading platform.\n\nFor example, a developer building a trading platform could use the `price` column to display the current price of a listing, the `quantity` column to show the amount of tokens available for purchase, and the `valid_from` and `valid_until` columns to display the start and end times of the listing. The `maker` and `taker` columns could be used to identify the parties involved in the transaction, and the `fee_bps` column could be used to calculate the listing fee.\n\nOverall, this section of the app technical guide provides a comprehensive overview of the `reservoir.asks` table and its columns, as well as practical examples of how to use the information to build applications that interact with the table.\n## Questions: \n 1. What is the purpose of the `reservoir.asks` table in the Dune Docs app?\n- The `reservoir.asks` table contains records with information about each listing in the app.\n\n2. What kind of data is stored in the `price` column of the `reservoir.asks` table?\n- The `price` column stores the current price of the listing in native currency.\n\n3. Is there any information in the `reservoir.asks` table about the transaction history of a listing?\n- No, there is no information in the `reservoir.asks` table about the transaction history of a listing.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/reservoir/asks.md"}}],["56",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/reservoir/attribute-keys.md)\n\n## Attribute Keys\n\nThe `attribute_keys` section of the app technical guide provides information about the `reservoir.attribute_keys` table. This table contains records with information about each attribute key. The table has seven columns: `id`, `collection_id`, `key`, `kind`, `rank`, `created_at`, and `updated_at`. \n\n- `id`: This is the internal attribute key id.\n- `collection_id`: This is the associated collection id.\n- `key`: This is the name of the attribute.\n- `kind`: This is the value type, which can be string, number, date, or range.\n- `rank`: This is the sort order.\n- `created_at`: This is the timestamp the attribute key was created.\n- `updated_at`: This is the timestamp the attribute key was updated.\n\nThe guide also provides a link to query examples for the `reservoir.attribute_keys` table. The link leads to a page on the Dune website that provides examples of queries that can be run on the table. \n\nOverall, this section of the guide is useful for developers who need to work with the `reservoir.attribute_keys` table in the Dune app. It provides a clear understanding of the table's structure and contents, as well as examples of how to query the table.\n## Questions: \n 1. What is the purpose of the `reservoir.attribute_keys` table in the context of the dune docs app? \n   - The `reservoir.attribute_keys` table contains information about each attribute key in the app, including its name, type, and associated collection.\n2. How are attribute keys sorted in the `reservoir.attribute_keys` table? \n   - Attribute keys are sorted by their `rank` column in the `reservoir.attribute_keys` table.\n3. Are there any examples of queries that can be run using the `reservoir.attribute_keys` table? \n   - Yes, query examples can be found at the URL provided in the app technical guide: [https://dune.com/queries/1302930/2232305](https://dune.com/queries/1302930/2232305).","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/reservoir/attribute-keys.md"}}],["57",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/reservoir/attributes.md)\n\n# Attributes\n\nThe `reservoir.attributes` table contains records with information about each attribute. This section of the app technical guide provides a detailed description of the columns in this table, including their data types and descriptions. \n\nThe `id` column is an internal attribute ID, while the `attribute_key_id` column is an internal attribute key ID. The `value` column contains the attribute value, and the `token_count` column indicates the number of tokens that have the attribute. The `on_sale_count` column indicates the number of tokens that have the attribute and are currently on sale. \n\nThe `floor_sell_value` column contains the current floor ask price, while the `sell_updated_at` column indicates the timestamp of the last update to the floor sale. The `collection_id` column contains the associated collection ID, and the `kind` column indicates the value type (string, number, date, range). The `key` column contains the associated key name. \n\nFinally, the `created_at` and `updated_at` columns indicate the timestamps of when the attribute was created and last updated, respectively. \n\nThis section also provides two query examples for the `reservoir.attributes` table, which can be found at the provided links. These examples can be used as a reference for querying the table in the app.\n## Questions: \n 1. What is the purpose of the `reservoir.attributes` table in the context of the Dune Docs project? \n   - The `reservoir.attributes` table contains records with information about each attribute in the Dune Docs project.\n2. How is the `token_count` column calculated and what does it represent? \n   - The `token_count` column represents the amount of tokens that have the attribute, but it is unclear how it is calculated based on the information provided in the technical guide.\n3. Are there any limitations or constraints on the data types that can be stored in the `value` column? \n   - The technical guide does not provide information on any limitations or constraints on the data types that can be stored in the `value` column.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/reservoir/attributes.md"}}],["58",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/reservoir/bid-events.md)\n\n# Bid Events\n\nThe `bid_events` table is a part of the Dune Docs project and contains records with information about each bid change. This table is located in the `data-tables` folder of the project.\n\nThe table has several columns that provide information about the bid event, including the event ID, event type, event status, contract address, token set ID, associated bid ID, bid maker wallet address, bid price, bid value, bid tokens remaining, bid validity start and expiration, source of the order, associated transaction hash, and timestamp the event was recorded.\n\nThe purpose of this table is to provide a record of all bid changes that occur within the system. This information can be used to track the progress of bids, monitor the performance of the system, and identify any issues that may arise.\n\nQuery examples for this table are not yet available, but they will be added to the project in the future.\n\nOverall, the `bid_events` table is an important component of the Dune Docs project, providing valuable information about the bidding process within the system.\n## Questions: \n 1. What is the purpose of the `reservoir.bid_events` table in the context of the Dune Docs project?\n- The `reservoir.bid_events` table contains records with information about each bid change in the project.\n\n2. What are the different types of events that can be found in the `kind` column of the `reservoir.bid_events` table?\n- The different types of events that can be found in the `kind` column of the `reservoir.bid_events` table include new-order, expiry, sale, cancel, balance-change, approval-change, bootstrap, revalidation, and reprice.\n\n3. How is the value of a bid represented in the `reservoir.bid_events` table?\n- The value of a bid is represented in the `reservoir.bid_events` table as the associated bid value in native currency.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/reservoir/bid-events.md"}}],["59",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/reservoir/bids.md)\n\n# Bids\n\n## Reservoir.bids\n\nThis section of the app technical guide covers the `reservoir.bids` table, which contains records with information about each bid. The table includes various columns such as `id`, `kind`, `status`, `contract`, `token_set_id`, `maker`, `taker`, `price`, `value`, `currency_address`, `currency_symbol`, `currency_price`, `quantity`, `quantity_filled`, `quantity_remaining`, `valid_from`, `valid_until`, `nonce`, `source`, `fee_bps`, `expiration`, `raw_data`, `created_at`, and `updated_at`.\n\nThe `id` column represents the internal order id, while the `kind` column represents the protocol name (e.g. seaport). The `status` column represents the order status (active, inactive), and the `contract` column represents the contract address. The `token_set_id` column represents the id of the token set, while the `maker` and `taker` columns represent the maker and taker wallet addresses, respectively.\n\nThe `price` column represents the current price in native currency, while the `value` column represents the current value in native currency. The `currency_address` column represents the currency address, and the `currency_symbol` column represents the currency symbol. The `currency_price` column represents the currency price.\n\nThe `quantity` column represents the amount of tokens that is listed, while the `quantity_filled` column represents the amount of tokens that was filled. The `quantity_remaining` column represents the amount of tokens remaining, and the `valid_from` and `valid_until` columns represent the listing start and end times, respectively.\n\nThe `nonce` column represents the order nonce of the maker, while the `source` column represents the source of the listing (e.g. opensea.io). The `fee_bps` column represents the listing fee, and the `expiration` column represents the associated transaction hash. The `raw_data` column represents the raw order data (format will vary per source).\n\nFinally, the `created_at` and `updated_at` columns represent the timestamps the listing was created and updated, respectively.\n\nQuery examples for this table can be found at the link provided in the guide.\n## Questions: \n 1. What is the purpose of the dune docs project and how does this table fit into it?\n- This app technical guide only provides information about the `reservoir.bids` table and does not give context about the overall purpose of the dune docs project.\n\n2. How is the data in this table being collected and updated?\n- The app technical guide does not provide information about the data collection and update process for this table.\n\n3. Are there any constraints or limitations on the data types or values that can be stored in this table?\n- The app technical guide does not mention any constraints or limitations on the data types or values that can be stored in this table.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/reservoir/bids.md"}}],["60",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/reservoir/collection-floor-ask-events.md)\n\n# Collection Floor Ask Events\n\nThis section of the app technical guide covers the `reservoir.collection_floor_ask_events` table, which contains records with information about each collection floor ask change. The table includes columns such as `id`, `kind`, `collection_id`, `contract`, `token_id`, `order_id`, `maker`, `price`, `previous_price`, `valid_until`, `source`, `tx_hash`, `tx_timestamp`, and `created_at`.\n\nThe `id` column is an internal event ID, while the `kind` column specifies the type of event (e.g. new-order, expiry, sale, cancel, balance-change, approval-change, bootstrap, revalidation, reprice). The `collection_id` column contains the ID of the collection, and the `contract` column contains the contract address. The `token_id` column specifies the ID of the token in the collection, and the `order_id` column contains the associated ask ID. The `maker` column contains the wallet address of the associated ask maker, and the `price` column contains the associated ask price in native currency. The `previous_price` column contains the previous floor ask price in native currency, and the `valid_until` column specifies the expiration of the associated ask. The `source` column contains the source of the order (e.g. opensea.io), while the `tx_hash` column contains the associated transaction hash. The `tx_timestamp` column specifies the timestamp of the associated transaction, and the `created_at` column contains the timestamp the event was recorded.\n\nThis section also includes query examples for the `reservoir.collection_floor_ask_events` table, which can be found at the following links:\n\n- [https://dune.com/queries/1302799/2232083](https://dune.com/queries/1302799/2232083)\n- [https://dune.com/queries/1302841/2232151](https://dune.com/queries/1302841/2232151)\n\nOverall, this section of the app technical guide provides a detailed overview of the `reservoir.collection_floor_ask_events` table and its columns, as well as query examples for working with the table.\n## Questions: \n 1. What is the purpose of the `reservoir.collection_floor_ask_events` table in the context of the Dune Docs project? \n   - The `reservoir.collection_floor_ask_events` table contains records with information about each collection floor ask change.\n2. What kind of events are included in the `kind` column of the table? \n   - The `kind` column includes event types such as new-order, expiry, sale, cancel, balance-change, approval-change, bootstrap, revalidation, and reprice.\n3. Are there any limitations or restrictions on the data that can be queried from this table? \n   - The app technical guide does not provide information on any limitations or restrictions on the data that can be queried from this table.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/reservoir/collection-floor-ask-events.md"}}],["61",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/reservoir/collection-top-bid-events.md)\n\n# Collection Top Bid Events\n\nThe `collection_top_bid_events` table is a part of the Dune Docs project and contains records with information about each collection top bid change. This table is located in the `data-tables` folder of the project.\n\nThe table has several columns, including `id`, `kind`, `collection_id`, `contract`, `token_id`, `order_id`, `maker`, `price`, `previous_price`, `valid_until`, `source`, `tx_hash`, `tx_timestamp`, and `created_at`. Each column has a specific data type and description.\n\nThe `id` column is an internal event ID, while the `kind` column specifies the type of event, such as `new-order`, `expiry`, `sale`, `cancel`, `balance-change`, `approval-change`, `bootstrap`, `revalidation`, or `reprice`. The `collection_id` column contains the ID of the collection, and the `contract` column contains the contract address. The `token_id` column contains the ID of the token in the collection, and the `order_id` column contains the associated bid ID. The `maker` column contains the associated bid maker wallet address, and the `price` column contains the associated bid price in native currency.\n\nThe `previous_price` column contains the previous top bid price in native currency, and the `valid_until` column contains the associated bid validity expiration. The `source` column specifies the source of the order, such as `opensea.io`, and the `tx_hash` column contains the associated transaction hash. The `tx_timestamp` column contains the associated transaction timestamp, and the `created_at` column contains the timestamp the event was recorded.\n\nThe `collection_top_bid_events` table can be queried using SQL. Query examples can be found in the project, but the link is currently TBD. This table is useful for tracking changes in top bids for collections and analyzing bidding behavior.\n## Questions: \n 1. What is the purpose of the `reservoir.collection_top_bid_events` table in the context of the dune docs project?\n- The `reservoir.collection_top_bid_events` table contains records with information about each collection top bid change in the dune docs project.\n\n2. What are the different event types that can be found in the `kind` column of the `reservoir.collection_top_bid_events` table?\n- The `kind` column in the `reservoir.collection_top_bid_events` table contains different event types such as new-order, expiry, sale, cancel, balance-change, approval-change, bootstrap, revalidation, and reprice.\n\n3. How are the bid prices represented in the `price` and `previous_price` columns of the `reservoir.collection_top_bid_events` table?\n- The `price` and `previous_price` columns in the `reservoir.collection_top_bid_events` table represent the associated bid price and previous top bid price in native currency, respectively.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/reservoir/collection-top-bid-events.md"}}],["62",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/reservoir/collections.md)\n\n# Collections\n\nThis section of the app technical guide focuses on the `reservoir.collections` table, which contains records with information about each NFT collection. The table includes various columns such as `id`, `slug`, `name`, `description`, `token_count`, `contract`, `day1_rank`, `day7_rank`, `day30_rank`, `all_time_rank`, `day1_volume`, `day7_volume`, `day30_volume`, `all_time_volume`, `day1_volume_change`, `day7_volume_change`, `day30_volume_change`, `floor_ask_value`, `day1_floor_sale_value`, `day7_floor_sale_value`, `day30_floor_sale_value`, `day1_floor_sale_change`, `day7_floor_sale_change`, `day30_floor_sale_change`, `created_at`, and `updated_at`.\n\nThe purpose of this guide is to provide developers with information on how to query the `reservoir.collections` table and understand the meaning of each column. The guide includes two query examples that can be found at the provided links. \n\nDevelopers can use this information to build features that utilize NFT collections, such as displaying information about a specific collection or analyzing trends in NFT trading volume and floor sale prices. For example, a developer could use the `day1_volume` column to display the trading volume of a specific collection over the past day, or use the `floor_ask_value` column to display the current floor sale price of a collection in its native currency.\n\nOverall, this section of the app technical guide provides valuable information for developers looking to work with NFT collections in the Dune Docs project.\n## Questions: \n 1. What is the purpose of the `reservoir.collections` table in the Dune Docs app?\n- The `reservoir.collections` table contains records with information about each NFT collection.\n\n2. What type of data is stored in the `day1_rank`, `day7_rank`, `day30_rank`, and `all_time_rank` columns?\n- The `day1_rank`, `day7_rank`, `day30_rank`, and `all_time_rank` columns store ranking information for the NFT collections.\n\n3. What is the format of the query examples provided in the app technical guide?\n- The query examples provided in the app technical guide are in the form of links to Dune.com queries.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/reservoir/collections.md"}}],["63",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/reservoir/index.md)\n\n# Reservoir\n\nThe Reservoir section of the Dune Docs project focuses on enabling the next generation of NFT products and liquidity sources through open-source, on-chain NFT order aggregation. This header provides links to the Reservoir dashboard, documentation, and Discord channel for further information and support.\n\n## Dashboard\n\nThe Reservoir dashboard link provided in this section directs users to the Reservoir0x dashboard on Dune.com. This dashboard provides a visual representation of Reservoir's on-chain NFT order aggregation, allowing users to view and analyze data related to NFT trades and liquidity sources.\n\n## Docs\n\nThe Reservoir documentation link provided in this section directs users to the Reservoir.tools documentation page. This page provides detailed information on how to use Reservoir's open-source, on-chain NFT order aggregation platform. The documentation covers topics such as installation, configuration, and usage of the Reservoir platform.\n\n## Discord\n\nThe Reservoir Discord link provided in this section directs users to the Reservoir Discord channel. This channel provides a community forum for Reservoir users to ask questions, share information, and collaborate on the development of the Reservoir platform.\n\nOverall, the Reservoir section of the Dune Docs project provides users with the resources they need to understand and utilize Reservoir's on-chain NFT order aggregation platform. The dashboard, documentation, and Discord channel all work together to provide a comprehensive support system for Reservoir users.\n## Questions: \n 1. What is the purpose of Reservoir in the blockchain ecosystem?\n- Reservoir is enabling the next generation of NFT products and liquidity sources through open-source, on-chain NFT order aggregation.\n\n2. What kind of data can be accessed through the Reservoir dashboard?\n- The Reservoir dashboard provides access to data related to the Reservoir project, such as order aggregation.\n\n3. Are there any additional resources available for developers looking to integrate Reservoir into their projects?\n- Yes, the Reservoir documentation provides additional resources for developers looking to integrate Reservoir into their projects.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/reservoir/index.md"}}],["64",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/reservoir/sales.md)\n\n# Sales\n\nThis section of the app technical guide covers the `reservoir.sales` table, which contains records with information about each sale. The table includes various columns such as `id`, `contract`, `token_id`, `order_id`, `order_kind`, `order_side`, `order_source`, `from`, `to`, `price`, `usd_price`, `currency_address`, `currency_symbol`, `currency_price`, `amount`, `fill_source`, `aggregator_source`, `wash_trading_score`, `is_primary`, `tx_hash`, `tx_log_index`, `tx_batch_index`, `tx_timestamp`, `created_at`, and `updated_at`.\n\nThe purpose of this guide is to provide an overview of the `reservoir.sales` table and its columns, as well as query examples that can be used to retrieve data from the table. The guide also includes a description of each column, its data type, and its purpose.\n\nFor example, the `id` column contains the internal sale id, while the `contract` column contains the contract address. The `price` column contains the sale price in the native currency, while the `usd_price` column contains the sale price in USD. The `amount` column contains the amount of tokens sold, while the `is_primary` column indicates whether the sale is a paid mint.\n\nThe guide also includes query examples that can be used to retrieve data from the `reservoir.sales` table. These examples demonstrate how to use the `SELECT` statement to retrieve specific columns from the table, as well as how to use the `WHERE` clause to filter the results based on specific criteria.\n\nOverall, this section of the app technical guide provides a comprehensive overview of the `reservoir.sales` table and its columns, as well as query examples that can be used to retrieve data from the table.\n## Questions: \n 1. What is the purpose of the `reservoir.sales` table in the context of blockchain? \n- The `reservoir.sales` table contains records with information about each sale in the blockchain context.\n\n2. What is the significance of the `currency_address` and `currency_symbol` columns in the `reservoir.sales` table? \n- The `currency_address` and `currency_symbol` columns in the `reservoir.sales` table indicate the currency used for a particular sale in the blockchain context.\n\n3. How is the `wash_trading_score` column calculated in the `reservoir.sales` table? \n- The `wash_trading_score` column in the `reservoir.sales` table is calculated based on past sales and indicates the internal wash trading score in the blockchain context.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/reservoir/sales.md"}}],["65",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/reservoir)\n\nThe `docs/data-tables/community/reservoir` folder contains a comprehensive app technical guide for the Reservoir project, which focuses on enabling the next generation of NFT products and liquidity sources through open-source, on-chain NFT order aggregation. The guide is organized into different sections, each covering a specific aspect of the project, such as token attributes, sales, collections, and various events related to bids and asks.\n\nFor example, the `asks.md` section provides an in-depth overview of the `reservoir.asks` table, which contains records with information about each listing. Developers can use this information to build applications that interact with the `reservoir.asks` table, such as a marketplace or trading platform. The guide also includes query examples that can be used to retrieve data from the table.\n\nAnother example is the `attributes.md` section, which covers the `reservoir.attributes` table containing records with information about each attribute. This section provides a detailed description of the columns in this table and includes query examples that can be used as a reference for querying the table in the app.\n\nThe `tokens.md` section covers the `reservoir.tokens` table, which contains records with information about each NFT token. This section provides a detailed overview of the table and its various columns, as well as query examples that can be used to retrieve information from the table.\n\nOverall, this app technical guide serves as a valuable resource for developers and users who want to learn more about the different features and functionalities of the Reservoir project. The guide provides detailed information on each aspect of the project, including tables, queries, and other important components. By using this guide, developers and users can gain a better understanding of how the project works and how to use it effectively.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/reservoir/summary.md"}}],["66",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/reservoir/token-attributes.md)\n\n# Explanation of the App Technical Guide for Dune Docs\n\nThe app technical guide for Dune Docs is a documentation resource that provides information on the different features and functionalities of the Dune Docs project. The guide is organized into different sections, each of which covers a specific aspect of the project. \n\nThe first section of the guide is focused on token attributes. The `reservoir.token_attributes` table contains records with information about each NFT token attribute. The table includes columns such as `id`, `contract`, `token_id`, `attribute_id`, `collection_id`, `key`, `value`, `created_at`, and `updated_at`. These columns provide information about the internal token attribute ID, contract address, token ID, attribute ID, collection ID, attribute name, attribute value, and timestamps for when the attribute was created and updated. \n\nThe guide also includes query examples for the `reservoir.token_attributes` table, which can be found at the provided URL. These examples demonstrate how to query the table to retrieve specific information about token attributes. \n\nOverall, the app technical guide for Dune Docs is a valuable resource for developers and users who want to learn more about the different features and functionalities of the project. The guide provides detailed information on each aspect of the project, including tables, queries, and other important components. By using this guide, developers and users can gain a better understanding of how the project works and how to use it effectively.\n## Questions: \n 1. What is the purpose of the `reservoir.token_attributes` table in the context of a blockchain application? \n- The `reservoir.token_attributes` table contains information about each NFT token attribute, which may be relevant for tracking ownership or other metadata associated with the tokens.\n\n2. How are the `contract` and `collection_id` fields used in this table? \n- The `contract` field contains the address of the contract associated with the token, while the `collection_id` field contains the internal ID of the collection to which the token belongs. These fields may be used to link token attributes to specific contracts or collections.\n\n3. Are there any limitations or constraints on the types of data that can be stored in the `value` field? \n- The app technical guide does not provide information on any limitations or constraints on the types of data that can be stored in the `value` field. A blockchain SQL analyst may need to consult additional documentation or perform testing to determine any such limitations.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/reservoir/token-attributes.md"}}],["67",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/reservoir/token-floor-ask-events.md)\n\n# Token Floor Ask Events\n\nThis section of the app technical guide covers the `reservoir.token_floor_ask_events` table, which contains records with information about each NFT token floor ask change. The table includes various columns such as `id`, `kind`, `contract`, `token_id`, `order_id`, `maker`, `price`, `previous_price`, `nonce`, `valid_from`, `valid_until`, `source`, `tx_hash`, `tx_timestamp`, and `created_at`.\n\nThe `kind` column specifies the type of event, which can be one of the following: `new-order`, `expiry`, `sale`, `cancel`, `balance-change`, `approval-change`, `bootstrap`, `revalidation`, or `reprice`. The `contract` column specifies the address of the contract associated with the event, while the `token_id` column specifies the ID of the token in the collection. The `order_id` column specifies the associated ask ID, and the `maker` column specifies the wallet address of the ask maker.\n\nThe `price` column specifies the associated ask price in native currency, while the `previous_price` column specifies the previous ask price in native currency. The `nonce` column specifies the order nonce of the maker, and the `valid_from` and `valid_until` columns specify the validity start and expiration of the ask. The `source` column specifies the source of the order, such as `opensea.io`. The `tx_hash` column specifies the associated transaction hash, and the `tx_timestamp` column specifies the associated transaction timestamp. Finally, the `created_at` column specifies the timestamp the event was recorded.\n\nThis section also includes two query examples that can be found at the specified URLs. These queries can be used to retrieve information from the `reservoir.token_floor_ask_events` table.\n## Questions: \n 1. What is the purpose of this table in the context of the dune docs project?\n- As a technical guide documentation expert, it is not clear from this table alone what the overall purpose of the dune docs project is, so a blockchain SQL analyst might have this question.\n\n2. What is the meaning of the \"kind\" column and what are the possible values?\n- The \"kind\" column is described as an event type, but it is not clear what each possible value represents, so a blockchain SQL analyst might have this question.\n\n3. Are there any other tables or data sources that are related to this one and can be used to gain a more complete understanding of NFT token floor asks?\n- This table provides information about NFT token floor ask changes, but it is possible that there are other tables or data sources that are related to this one and can provide additional context or insights, so a blockchain SQL analyst might have this question.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/reservoir/token-floor-ask-events.md"}}],["68",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community/reservoir/tokens.md)\n\n# App Technical Guide: Tokens\n\n## Reservoir.tokens\n\nThis section of the app technical guide covers the `reservoir.tokens` table, which contains records with information about each NFT token. The table includes various columns such as `id`, `contract`, `token_id`, `name`, `description`, `collection_id`, `owner`, `floor_ask_id`, `floor_ask_value`, `floor_ask_maker`, `floor_ask_valid_from`, `floor_ask_valid_to`, `floor_ask_source`, `last_sale_value`, `last_sale_timestamp`, `created_at`, and `updated_at`.\n\nThe `id` column represents the internal token ID, while the `contract` column contains the contract address. The `token_id` column represents the ID of the token in the collection, and the `name` and `description` columns contain the name and description of the NFT, respectively. The `collection_id` column represents the associated collection ID, and the `owner` column contains the wallet address of the owner.\n\nThe `floor_ask_id`, `floor_ask_value`, `floor_ask_maker`, `floor_ask_valid_from`, `floor_ask_valid_to`, and `floor_ask_source` columns represent the floor ask details, such as the ID, value, maker wallet address, listing start and end times, and source (e.g. opensea.io). The `last_sale_value` and `last_sale_timestamp` columns represent the associated transaction timestamp.\n\nFinally, the `created_at` and `updated_at` columns represent the timestamps when the token was created and updated, respectively.\n\nThis section also includes query examples that can be found at the specified URLs. These examples can be used to retrieve information from the `reservoir.tokens` table.\n\nOverall, this section of the app technical guide provides a detailed overview of the `reservoir.tokens` table and its various columns, as well as query examples that can be used to retrieve information from the table.\n## Questions: \n 1. What is the purpose of the `reservoir.tokens` table in the context of blockchain? \n- The `reservoir.tokens` table contains records with information about each NFT token, which can be useful for tracking ownership and transaction history.\n\n2. Are there any limitations or restrictions on the types of queries that can be run on this table? \n- The app technical guide does not provide information on any limitations or restrictions on queries that can be run on this table. \n\n3. How frequently is the `reservoir.tokens` table updated with new token information? \n- The app technical guide does not provide information on the frequency of updates to the `reservoir.tokens` table.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/reservoir/tokens.md"}}],["69",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/community)\n\nThe `docs/data-tables/community` folder contains a comprehensive app technical guide for the Community section of the Dune Docs project. This section focuses on providing additional data insights through partnerships with third-party data providers, such as Flashbots and Reservoir. The guide is organized into different sections, each covering a specific aspect of the project, such as availability, purpose, and data providers.\n\nFor example, the `index.md` file provides an overview of the Community section, its availability on the V2 Engine, and its purpose in providing off-chain data or augmented on-chain data. This guide helps users understand the importance of the Community section and how it can provide additional insights through partnerships with selected organizations.\n\nThe guide also covers two data providers currently featured in the Community section: Flashbots and Reservoir. Each provider has its own subfolder with more detailed information about the data they provide. For instance, the `flashbots` subfolder contains various files that cover different aspects of the Flashbots project, such as arbitrages, liquidations, mev_summary, sandwiched swaps, and sandwiches. These guides provide clear and concise explanations of the table structures, column descriptions, and query examples that can be used to retrieve information from the tables.\n\nSimilarly, the `reservoir` subfolder contains a comprehensive app technical guide for the Reservoir project, which focuses on enabling the next generation of NFT products and liquidity sources through open-source, on-chain NFT order aggregation. The guide is organized into different sections, each covering a specific aspect of the project, such as token attributes, sales, collections, and various events related to bids and asks.\n\nOverall, the Community section of the Dune Docs project serves as a valuable resource for developers and users who want to access additional data insights through partnerships with third-party data providers. The guides provided in this folder offer clear and concise explanations of the table structures, column descriptions, and query examples that can be used to retrieve information from the tables. By using this guide, developers and users can gain a better understanding of how the Community section works and how to use it effectively in their work.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/community/summary.md"}}],["70",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/decoded/call-tables.md)\n\n# Call Tables\n\nThis technical guide explains how Dune parses all message calls and transactions made to smart contracts in their own tables. The guide provides information on how the tables are named and how they are created on an individual contract level or a class of contracts. \n\nThe guide also explains how Dune records transactions in the table when a smart contract is called by an externally owned account (EOA) or another smart contract. The guide provides an example of how Dune records a transaction when a Uniswap v3 pool gets created via the Uniswap v3 factory function `createPool`. \n\nThe guide also explains how Dune decodes all calls to all instances of a smart contract into one table when multiple instances of a contract exist. The guide provides an example of how Dune collects data in the table when there is a transaction calling the `swap` function of any instance of a Uniswap v3 pair contract. \n\nThe guide also highlights a common misconception that web3.js, web3.py, and all other methods of locally calling a `pure`, `read`, or `constant` function do not broadcast or publish anything on the blockchain and are therefore not recorded in Dune. However, if one of these functions is invoked by another smart contract in the context of a transaction, this will be broadcast on the chain and therefore accessible in Dune. \n\nThe guide concludes by providing further reading materials on the difference between a transaction and a call, Soliditylang.org documentation, and how Calldata is encoded. \n\nOverall, this technical guide provides a comprehensive understanding of how Dune parses all message calls and transactions made to smart contracts in their own tables. It is a useful resource for developers who want to understand how Dune records transactions and how to access the data recorded in Dune.\n## Questions: \n 1. What specific blockchain networks does Dune Docs support for parsing message calls and transactions? \n- The app technical guide does not provide information on the specific blockchain networks supported by Dune Docs for parsing message calls and transactions.\n\n2. Can Dune Docs record message calls made by smart contracts to external systems or APIs? \n- The app technical guide does not provide information on whether Dune Docs can record message calls made by smart contracts to external systems or APIs.\n\n3. How does Dune Docs handle state data stored in the memory of a smart contract? \n- The app technical guide states that state data stored in the memory of a smart contract is not available on Dune, but it does not provide information on how Dune Docs handles this type of data.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/decoded/call-tables.md"}}],["71",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/decoded/event-logs.md)\n\n# Event Logs\n\nThis technical guide covers the concept of event logs in smart contracts. Smart contracts emit event logs when certain predefined actions are completed. The structure published in these logs is predefined by the developer of the smart contract, and the content is dynamically created during the transaction. \n\nThe guide explains that logs are useful for monitoring, alerting, and keeping track of what happens inside a smart contract. Logs are also useful for data analysis since they reliably present data that is intended to be analyzed post factum. The guide provides an example of how to search for the keyword `emit` in the source code of a smart contract to see which logs can be emitted by a smart contract.\n\nThe guide also explains how event logs for smart contracts are decoded into tables named accordingly to a specific schema. The schema is different for the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL). The guide provides examples of how to name tables for each engine.\n\nThe guide provides an example of how to look at the event logs of a transaction in Etherscan. The example is in the context of the uniswap v3 factory, and the event that gets emitted upon the creation of a new pool. The event is called `PoolCreated`, and it gives information like the tokens in the pool, the fee tier of this pool, and the tick spacing. The guide provides examples of how to name tables for each engine.\n\nThe guide explains that if there are multiple instances of a contract, all event logs across all instances of this smart contract are collected in one table. The guide provides an example of how all uniswap v3 pool `swap` events (on ethereum) are stored in a table.\n\nFinally, the guide provides further reading resources on understanding event logs on the Ethereum blockchain and everything you ever wanted to know about events and logs on Ethereum. \n\nOverall, this guide provides a comprehensive explanation of event logs in smart contracts and how they are decoded into tables. It also provides examples of how to name tables for each engine and how to look at event logs of a transaction in Etherscan.\n## Questions: \n 1. What is the purpose of the Dune Docs app and how does it relate to blockchain SQL analysis?\n   \n   The Dune Docs app provides technical documentation for decoding event logs emitted by smart contracts on the blockchain. This information is useful for blockchain SQL analysts who want to monitor, alert, and keep track of what happens inside a smart contract.\n\n2. How are event logs stored in Dune Docs and what is the naming convention for the tables?\n\n   Event logs for smart contracts are decoded into tables named according to the schema `[projectname_blockchain].[contractName]_evt_[eventName]` for the V2 Engine (Spark SQL) and `[projectname].\"[contractName]_evt_[eventName]\"` for the V1 Engine (PostgreSQL). For example, the event log for the Uniswap V3 pool creation event is stored in the table `uniswap_v3_ethereum.Factory_evt_PoolCreated` for the V2 Engine and `uniswap_v3.\"Factory_evt_PoolCreated\"` for the V1 Engine.\n\n3. How are event logs from multiple instances of a contract handled in Dune Docs?\n\n   Event logs from multiple instances of a contract are collected in one table. For example, all Uniswap V3 pool swap events on Ethereum are stored in the table `uniswap_v3_ethereum.Pair_evt_Swap` for the V2 Engine and `uniswap_v3.\"Pair_evt_Swap\"` for the V1 Engine. The `contract_address` column indicates which smart contract emitted the event.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/decoded/event-logs.md"}}],["72",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/decoded/index.md)\n\nThe Decoded Tables guide covers the process of decoding smart contract activity into human-readable tables on the Dune platform. It explains how Dune uses the ABI (Application Binary Interface) for smart contracts and the interface standard for standardized token smart contracts (ERC20, ERC721, etc.) to create tables for each event and function defined in the smart contract's ABI. \n\nThe guide provides examples of how to access decoded data for specific events and function calls using the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL). It also explains how to check if contracts are already decoded by querying the `[blockchain].contracts` tables or using a dashboard.\n\nThe guide further explains how decoding works, using the ABI to call a smart contract or interpret the data it emits. It provides an example of decoding an ERC20 transfer event log and how to understand decoded data.\n\nThe guide also discusses which tables to use (events or calls) and provides queries to explore decoded contracts, such as seeing all projects with decoded data or checking for multiple instances of a contract.\n## Questions: \n 1. **How can I check if a specific contract has already been decoded in the Dune database?**\n\nYou can check if a contract has been decoded by querying the `[blockchain].contracts` tables through the database or by using the provided dashboard links for V2 Engine (Spark SQL) and V1 Engine (PostgreSQL) in the app technical guide.\n\n2. **How long does it take to decode a smart contract once it has been submitted?**\n\nIt usually takes about 24 hours to initially decode a smart contract. You can check the status of your contract's decoding process using the \"Is my Contract decoded yet?\" dashboard link provided in the app technical guide.\n\n3. **How can I submit multiple contracts for decoding at the same time?**\n\nTo submit a batch of contracts for decoding, use the provided CSV template in the app technical guide and fill it in with the appropriate information for the contracts you want to decode. Then, send the completed CSV file to decoding@dune.com.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/decoded/index.md"}}],["73",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/decoded)\n\nThe Decoded Tables guide in the `docs/data-tables/decoded` folder focuses on decoding smart contract activity into human-readable tables on the Dune platform. This guide is essential for analysts and developers who want to understand and access the decoded data of smart contracts, events, and function calls on the Dune platform.\n\nThe guide covers the following topics:\n\n1. **Call Tables**: This section explains how Dune parses all message calls and transactions made to smart contracts in their own tables. It provides information on how the tables are named and how they are created on an individual contract level or a class of contracts. It also highlights a common misconception about `pure`, `read`, or `constant` functions not being recorded in Dune.\n\n2. **Event Logs**: This section covers the concept of event logs in smart contracts and how they are decoded into tables named according to a specific schema. It provides examples of how to name tables for the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL) and how to look at event logs of a transaction in Etherscan.\n\n3. **Decoding Process**: This section explains how Dune uses the ABI (Application Binary Interface) for smart contracts and the interface standard for standardized token smart contracts (ERC20, ERC721, etc.) to create tables for each event and function defined in the smart contract's ABI. It provides an example of decoding an ERC20 transfer event log and how to understand decoded data.\n\n4. **Accessing Decoded Data**: This section provides examples of how to access decoded data for specific events and function calls using the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL). It also explains how to check if contracts are already decoded by querying the `[blockchain].contracts` tables or using a dashboard.\n\n5. **Which Tables to Use**: This section discusses which tables to use (events or calls) and provides queries to explore decoded contracts, such as seeing all projects with decoded data or checking for multiple instances of a contract.\n\nThis guide is useful for analysts who want to access and analyze decoded data from smart contracts, events, and function calls on the Dune platform. For example, an analyst might use this guide to understand how to access decoded data for a specific ERC20 token transfer event or how to explore all projects with decoded data on the platform. By understanding the decoding process and how to access the decoded data, analysts can gain valuable insights into smart contract activity and interactions on the Dune platform.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/decoded/summary.md"}}],["74",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/index.md)\n\n# Tables and Chains Overview\n\nThis technical guide provides an overview of the tables and chains available in the Dune app. The guide is divided into two main sections: The Four Kinds of Tables and Available Chains.\n\nThe Four Kinds of Tables section explains how Dune ingests data from node providers to create raw tables, which are then decoded using contract ABIs to provide easier to work with decoded tables. Abstracted tables are then created to standardize and aggregate the data, giving users the easiest to work with spell tables. The section also provides links to the raw data, decoded data, spellbook, and community tables.\n\nThe Available Chains section provides a list of the chains available to query in Dune. For each chain, the section provides a brief overview of the chain, its history, and its technical details. The section also includes links to the chain's documentation and other resources.\n\nFor example, the Ethereum Mainnet section provides a brief history of Ethereum, its updates, and its decentralized platform. The section also includes a link to the Ethereum Developer Docs. Similarly, the BNB Chain (BSC) section explains how BNB Chain follows most of the rules of Ethereum Mainnet but has not implemented EIP1559. The section also includes a link to the BNB Chain Documentation.\n\nOverall, this technical guide provides a comprehensive overview of the tables and chains available in the Dune app. It is a useful resource for users who want to understand how Dune ingests data and creates tables, as well as for users who want to query specific chains and understand their technical details.\n## Questions: \n 1. What kind of data can be queried from the Dune Docs app for each available chain?\n- The app ingests data from node providers to fill raw tables, which are then decoded using contract ABIs to provide decoded tables. Abstracted tables are then created to standardize and aggregate the data, giving users the easiest to work with spell tables. \n\n2. How does the gas calculation differ for transactions on Optimism and Arbitrum compared to Ethereum Mainnet?\n- Optimism processes transactions outside of Ethereum Mainnet, reducing congestion on the base layer and improving scalability. Arbitrum is an optimistic rollup that settles its transactions on Ethereum Mainnet, but its execution environment differs from the Mainnet EVM implementation in its calculation of gas costs. \n\n3. What is the difference between BNB Chain and Ethereum Mainnet in terms of gas fees and fee burning?\n- BNB Chain follows most of the rules of Ethereum Mainnet, but has not implemented EIP1559. Instead, it relies on BEP-95 to burn fees that accrue during usage of the platform. Furthermore, the gas limit per block is set to 100 million, enabling more transactions to be processed in a given block. Transactions fees are paid in BNB instead of ETH.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/index.md"}}],["75",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw/bitcoin/blocks.md)\n\nThe Blocks section of the app technical guide covers the `bitcoin.blocks` feature of the project. This feature provides information about Bitcoin blocks, including their time, height, date, hash, transaction count, size, and various other details. \n\nThe guide provides a table with a detailed breakdown of each column in the `bitcoin.blocks` feature, including the column name, column type, and a description of what each column represents. For example, the `time` column represents the block time, while the `height` column represents the block number. \n\nThis information is useful for developers who are working with Bitcoin blocks and need to access specific details about them. For example, a developer building a Bitcoin wallet app might use this feature to display information about recent Bitcoin blocks to their users. \n\nOverall, the Blocks section of the app technical guide provides a comprehensive overview of the `bitcoin.blocks` feature, making it easier for developers to understand and use this feature in their projects.\n## Questions: \n 1. What is the purpose of the `bitcoin.blocks` table in this app? \n- The `bitcoin.blocks` table contains information about individual blocks in the Bitcoin blockchain, including their height, hash, transaction count, and various other metrics.\n\n2. How is the `total_reward` column calculated? \n- The `total_reward` column represents the static reward given to the miner and is calculated as the sum of the outputs in the coinbase transaction (the first transaction).\n\n3. What is the significance of the `difficulty` column? \n- The `difficulty` column represents the estimated amount of work done to find this block relative to the estimated amount of work done to find block 0. It is a measure of the level of difficulty in mining the block and is used to adjust the mining difficulty level of the network.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/bitcoin/blocks.md"}}],["76",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw/bitcoin/index.md)\n\n# App Technical Guide: Bitcoin\n\nThis guide provides information on how to work with Bitcoin data in the Dune Docs project. Bitcoin is a non-EVM chain, and its raw data looks different from other chains. The guide covers the available data and how to access it.\n\n## Data Available\n\nThis section lists the types of Bitcoin data available in the Dune Docs project. The data is organized into four categories:\n\n- Blocks: This page provides information on Bitcoin blocks, including their height, hash, and timestamp. It also includes data on the number of transactions and the total fees.\n- Transactions: This page provides information on Bitcoin transactions, including their hash, size, and fee. It also includes data on the number of inputs and outputs.\n- Outputs: This page provides information on Bitcoin outputs, including their value and script.\n- Inputs: This page provides information on Bitcoin inputs, including their previous output and script.\n\nEach page provides detailed information on the data available, as well as examples of how to query the data using the Dune Analytics platform.\n\n## Additional Resources\n\nThis guide also includes a link to a full written guide on getting started with Bitcoin data analysis. The guide provides additional information on how to analyze Bitcoin data using the Dune Analytics platform.\n\nOverall, this guide is a useful resource for anyone looking to work with Bitcoin data in the Dune Docs project. It provides a clear overview of the available data and how to access it, as well as additional resources for further learning.\n## Questions: \n 1. What kind of data is available for analysis in this app?\n- The app technical guide lists blocks, transactions, outputs, and inputs as available data for analysis.\n\n2. Is this app specifically designed for analyzing Bitcoin data or can it be used for other blockchain data as well?\n- The title and description of the app technical guide suggest that it is specifically designed for analyzing Bitcoin data.\n\n3. Are there any specific tools or programming languages required to use this app?\n- The app technical guide does not mention any specific tools or programming languages required to use this app.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/bitcoin/index.md"}}],["77",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw/bitcoin/inputs.md)\n\n# Inputs\n\nThe `Inputs` section of the app technical guide covers the `bitcoin.inputs` feature of the project. This feature provides a table with detailed information about the inputs of a Bitcoin transaction. The table includes columns such as `block_time`, `block_date`, `block_height`, `index`, `tx_id`, `spent_block_height`, `spent_tx_id`, `spent_output_number`, `value`, `address`, `type`, `coinbase`, `is_coinbase`, `script_asm`, `script_hex`, `script_desc`, `script_signature_asm`, `script_signature_hex`, `sequence`, and `witness_data`.\n\nEach column is described in detail, including its data type and a brief explanation of its purpose. For example, the `block_time` column contains a timestamp of when the block was mined, while the `value` column contains the number of Satoshis attached to the input. The `address` column contains the address that owned or owns the output used as input, and the `type` column contains the address type of the input.\n\nThe `Inputs` section is useful for developers who need to access detailed information about Bitcoin transactions. For example, a developer building a Bitcoin wallet app might use this feature to display transaction details to the user. \n\nExample usage:\n```python\nimport dune_docs\n\ninputs_table = dune_docs.bitcoin.inputs\nprint(inputs_table.head())\n```\nThis code imports the `dune_docs` module and accesses the `bitcoin.inputs` feature. It then prints the first few rows of the table using the `head()` method.\n## Questions: \n 1. What is the purpose of this app and how does it relate to blockchain technology?\n- The app is not explicitly stated in the provided technical guide, so a blockchain SQL analyst might need more information on the context and use case of the app to understand its relevance to blockchain technology.\n\n2. How is the data in the `bitcoin.inputs` table sourced and updated?\n- The technical guide does not provide information on the data source or update frequency of the `bitcoin.inputs` table, which could be important for a blockchain SQL analyst to understand the reliability and timeliness of the data.\n\n3. Are there any limitations or known issues with the app's handling of bitcoin input data?\n- The technical guide does not mention any potential issues or limitations with the app's handling of bitcoin input data, but a blockchain SQL analyst might want to know if there are any known bugs or edge cases that could affect the accuracy or completeness of the data.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/bitcoin/inputs.md"}}],["78",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw/bitcoin/outputs.md)\n\nThe Outputs section of the app technical guide for the Dune Docs project provides a detailed description of the `bitcoin.outputs` table. This table contains information about the outputs of Bitcoin transactions, including the block time, block date, block height, block hash, transaction ID, output index, value, script ASM, script hex, address, and address type. \n\nThe purpose of this section is to provide developers with a clear understanding of the data contained in the `bitcoin.outputs` table and how it can be used in the Dune Docs app. For example, developers can use this table to track the movement of Bitcoin between addresses, analyze transaction patterns, and identify potential fraud or money laundering activities.\n\nEach column in the table is described in detail, including the data type, description, and any relevant examples. For instance, the `value` column contains the number of Satoshis attached to each output, which can be used to calculate the total value of a transaction. The `address` column contains the address that owns each output, which can be used to track the movement of Bitcoin between addresses.\n\nOverall, the Outputs section of the app technical guide provides developers with a comprehensive overview of the `bitcoin.outputs` table and its role in the Dune Docs app. By understanding the data contained in this table, developers can build more powerful and effective tools for analyzing Bitcoin transactions.\n## Questions: \n 1. What data source does this app technical guide pull from to populate the `bitcoin.outputs` table? \n   - This information is not provided in the app technical guide and would require further investigation or clarification from the developers.\n2. Can this app technical guide be used to track outputs for other cryptocurrencies besides Bitcoin? \n   - Again, this information is not provided in the app technical guide and would require further investigation or clarification from the developers.\n3. Are there any limitations or known issues with the data provided in the `bitcoin.outputs` table? \n   - This information is not provided in the app technical guide and would require further investigation or clarification from the developers.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/bitcoin/outputs.md"}}],["79",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw/bitcoin)\n\nThe `docs/data-tables/raw/bitcoin` folder in the Dune Docs project focuses on providing comprehensive guides for working with raw Bitcoin data. This data is organized into four main categories: Blocks, Transactions, Outputs, and Inputs. Each category has a dedicated markdown file that explains the respective feature in detail, including the available data, data types, and how to access and use the data in the Dune Docs app.\n\nFor example, the `blocks.md` file covers the `bitcoin.blocks` feature, which provides information about Bitcoin blocks, such as their time, height, date, hash, transaction count, and size. Developers working with Bitcoin blocks can use this feature to display information about recent Bitcoin blocks in their applications, such as a Bitcoin wallet app.\n\nSimilarly, the `transactions.md` file provides a detailed guide on the `bitcoin.transactions` feature, which contains information about Bitcoin transactions, including their hash, size, fee, and the number of inputs and outputs. The guide also explains how to work with nested hierarchical data types, such as `input` and `output` fields, which can be useful for developers analyzing transaction patterns or tracking the movement of Bitcoin between addresses.\n\nThe `outputs.md` file focuses on the `bitcoin.outputs` table, which contains information about the outputs of Bitcoin transactions. This table can be used to analyze transaction patterns, track the movement of Bitcoin between addresses, and identify potential fraud or money laundering activities.\n\nLastly, the `inputs.md` file covers the `bitcoin.inputs` feature, which provides a table with detailed information about the inputs of a Bitcoin transaction. Developers can use this feature to display transaction details to users in applications like a Bitcoin wallet app.\n\nOverall, the guides in this folder provide a clear understanding of the raw Bitcoin data available in the Dune Docs project and how to access and use it effectively. By following these guides, developers can build powerful tools for analyzing Bitcoin transactions and blocks, which can be useful in various applications and projects.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/bitcoin/summary.md"}}],["80",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw/bitcoin/transactions.md)\n\n# Transactions\n\nThe Transactions section of the Dune Docs project provides a detailed guide on the `bitcoin.transactions` feature. The guide contains a table with column names, types, and descriptions of the data that can be accessed through this feature. The table includes information such as the block time, block date, block height, block hash, index, ID, input value, output value, fee, input count, output count, size, virtual size, whether the transaction is a coinbase transaction, and the transaction encoded as hexadecimal.\n\nThe guide also provides definitions for the `input`, `input.script_signature`, `input.script_pub_key`, `output`, and `output.script_pub_key` fields. These fields are of type `STRUCT` and allow for representing nested hierarchical data with key-value pairs. The `input` field contains information about transaction inputs, such as the number of Satoshis attached to the output, the height of the output, the transaction ID of the output, the number of the output in the transaction's outputs, and the script signature and public key. The `output` field contains information about transaction outputs, such as the number of Satoshis attached to the output, the public key, and the index of the output within a transaction.\n\nThe guide notes that the `input` field is an `array(row(map))` type, and provides examples of how to work with the columns using syntax such as `input[1].witness_data[2]` or `input[3].script_pub_key.address`, depending on the lengths of arrays within each value.\n\nOverall, the Transactions section of the Dune Docs project provides a comprehensive guide to the `bitcoin.transactions` feature, including detailed information on the data that can be accessed and how to work with the nested hierarchical data types.\n## Questions: \n 1. What data source does this app technical guide pull from to populate the `bitcoin.transactions` table?\n- The app technical guide does not provide information on the data source used to populate the `bitcoin.transactions` table.\n\n2. Can this app technical guide be used to query transactions from other cryptocurrencies besides Bitcoin?\n- The app technical guide does not provide information on whether it can be used to query transactions from other cryptocurrencies besides Bitcoin.\n\n3. How can the `input` and `output` fields be used to track the flow of funds in a Bitcoin transaction?\n- The `input` and `output` fields can be used to track the flow of funds in a Bitcoin transaction by providing information on the value, height, transaction ID, output number, coinbase data, sequence number, witness data, script signature, and script public key for each input and output.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/bitcoin/transactions.md"}}],["81",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw/blocks.md)\n\n# Blocks\n\nThis section of the app technical guide covers the concept of blocks in blockchains and rollups. A block is a collection of transactions that incrementally alter the state of an EVM system. Transactions within a block can only be executed one after the other, not in parallel. The purpose of this section is to provide an understanding of how blocks work in the context of the Dune Docs project.\n\n## Tables\n\nThis section provides tables that are useful for identifying block activity and transaction changes over time. There are two tables provided, one for the V2 Engine (Spark SQL) and one for the V1 Engine (PostgreSQL). Each table contains information about the chains, tables, and notes for each chain. For example, the Ethereum Mainnet chain has a table called `ethereum.blocks` that contains information about blocks on the Ethereum Mainnet.\n\n## Column Data\n\nThis section provides a description of the data contained in each column of the block tables. The table contains columns such as `time`, `number`, `hash`, `parent hash`, `gas limit`, `gas used`, `miner`, `difficulty`, `total difficulty`, `nonce`, `size`, and `base_fee_per_gas`. Each column is described in detail, including its data type and a brief description of its purpose.\n\n### Example\n\nThis section provides an example of the data contained in the block tables. The example is in the form of a video that demonstrates how to use the block tables to identify block activity and transaction changes over time.\n\nOverall, this app technical guide provides a comprehensive understanding of blocks in the context of the Dune Docs project. It covers the tables and column data that are useful for identifying block activity and transaction changes over time. The guide is useful for developers who are working on the Dune Docs project and need to understand how blocks work in the context of the project.\n## Questions: \n 1. What is the purpose of the Dune Docs app and how does it relate to blockchain SQL analysis?\n    \n    The app technical guide describes the tables and column data related to blocks in various blockchain chains. A blockchain SQL analyst might want to know how this information can be used in their analysis and what specific insights they can gain from it.\n\n2. Are there any limitations or gaps in the data provided by the Dune Docs app that might impact blockchain SQL analysis?\n\n    The tables provided in the app technical guide do not contain certain information such as `nonce`, `miner`, `difficulty`, `total_difficulty`, `size`, and `base_fee_per_gas` for some chains. A blockchain SQL analyst might want to know how these limitations might impact their analysis and if there are any workarounds.\n\n3. How does the Dune Docs app handle rollups and how can this information be used in blockchain SQL analysis?\n\n    The app technical guide mentions that blocks are the building blocks of rollups, but it does not provide specific information on how rollups are handled in the app. A blockchain SQL analyst might want to know how rollups are represented in the app and how this information can be used in their analysis.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/blocks.md"}}],["82",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw/event-logs.md)\n\n# Event Logs\n\nThis guide covers the `Event Logs` tables that store all logs data generated by smart contracts. The logs are an elegant way to store tiny amounts of data on EVM blockchains for a small amount of gas. Specifically, event logs are useful to let other people know something has happened without them having to query contracts individually. The guide provides a list of tables for the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL) for different chains. \n\nThe `Tables` section of the guide provides a list of tables for the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL) for different chains. The tables are named after the chain they belong to and contain logs data generated by smart contracts. The tables are useful for querying contracts that are not yet decoded or are not able to be decoded since the code of the smart contract is not public. \n\nThe `Column Data` section of the guide provides a description of the columns in the `Event Logs` tables. The columns include `contract_address`, `topic1`, `topic2`, `topic3`, `topic4`, `data`, `tx_hash`, `block_hash`, `block_number`, `block_time`, `index`, and `tx_index`. The columns contain information such as the address of the contract that emitted the log, keccak256 hash of a flattened event declaration string, unindexed data containing further information on the event, the transaction hash of the transaction that produced this log, and the time when the block was mined that includes this log. \n\nFor more information on this topic, the guide provides a link to an article on understanding event logs on the Ethereum blockchain. \n\nExample:\n```\n|   Chain           |   Table             | Notes |\n| ----------------  | ------------------- | ----- |\n| Ethereum Mainnet  | `ethereum.logs`     |       |\n| Gnosis Chain      | `gnosis.logs`       |       |\n| Polygon           | `polygon.logs`      |       |\n| Optimism          | `optimism.logs`     |       |\n| Optimism (legacy) | `optimism_legacy_ovm1.logs` |       |\n| BNB Chain         | `bnb.logs`          |       |\n| Arbitrum          | `arbitrum.logs`     |       |\n| Avalanche C-Chain  | `avalanche_c.logs` |       |\n```\nThe above example shows the tables for the V2 Engine (Spark SQL) for different chains. \n\n```\n|   Chain              |   Table         | Notes |\n| -------------------  | --------------- | ----- |\n| Ethereum Mainnet     | `ethereum.logs` |       |\n| Gnosis Chain (xDai)  | `xdai.logs`     |       |\n| Polygon              | `polygon.logs`  |       |\n| Optimism (OVM 1 & 2) | `optimism.logs` |       |\n| BNB Chain (BSC)      | `bsc.logs`      |       |\n```\nThe above example shows the tables for the V1 Engine (PostgreSQL) for different chains. \n\n### Column Data\n\n|   Column name      |   Data type     |    Description   |\n| ------------------ | :------------: | -------------------------------------------------------------- |\n| `contract_address` | _bytea_        | The address of the contract that emitted the log               |\n| `topic1`           | _bytea_        | keccak256 hash of a flattened event declaration string         |\n| `topic2`           | _bytea_        | Second indexed `topic` of the event                            |\n| `topic3`           | _bytea_        | Third indexed `topic` of the event                             |\n| `topic4`           | _bytea_        | Fourth indexed `topic` of the event                            |\n| `data`             | _bytea_        | Unindexed data containing further information on the event     |\n| `tx_hash`          | _bytea_        | The transaction hash of the transaction that produced this log |\n| `block_hash`       | _bytea_        | A unique identifier for that block                             |\n| `block_number`     | _int8_         | The length of the blockchain in blocks                         |\n| `block_time`       | _timestamptz_  | The time when the block was mined that includes this log       |\n| `index`            | _numeric_      | This logs index position in the block (cumulative amount of logs ordered by execution) |\n| `tx_index`         | _numeric_      | The index position of the transaction in this block (cumulative amount of transactions ordered by execution) |\n\nThe above example shows the columns in the `Event Logs` tables.\n## Questions: \n 1. What is the purpose of the Event Logs tables in this app and how are they useful for blockchain analysis?\n   \n   The Event Logs tables store all logs data generated by smart contracts and can be useful for querying contracts that are not yet decoded or are not able to be decoded since the code of the smart contract is not public. They are also useful for letting other people know something has happened without them having to query contracts individually.\n\n2. What engines are used to store the data in the tables and what chains are supported by each engine?\n   \n   The V2 Engine (Spark SQL) is used to store data in the tables and supports Ethereum Mainnet, Gnosis Chain, Polygon, Optimism, Optimism (legacy), BNB Chain, and Avalanche C-Chain. The V1 Engine (PostgreSQL) is also used and supports Ethereum Mainnet, Gnosis Chain (xDai), Polygon, Optimism (OVM 1 & 2), and BNB Chain (BSC).\n\n3. What are the different column data types and what information do they contain?\n   \n   The different column data types include contract_address, topic1, topic2, topic3, topic4, data, tx_hash, block_hash, block_number, block_time, index, and tx_index. They contain information such as the address of the contract that emitted the log, keccak256 hash of a flattened event declaration string, unindexed data containing further information on the event, the transaction hash of the transaction that produced this log, and the time when the block was mined that includes this log.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/event-logs.md"}}],["83",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw/index.md)\n\n# Raw Tables\n\nThe Raw Tables section of the Dune Docs project provides users with raw, unfiltered, and unedited data. This allows users to query for any transaction, block, event log, or trace across the blockchains that Dune supports. Raw data tables are particularly useful for obtaining meta information about the blockchain, a transaction, traces, or certain events.\n\nHowever, queries that have been written using raw data tables are notoriously hard to understand and audit due to the nature of the encoded data commonly found in these tables. Furthermore, the raw data tables have a very large number of rows and hence can be slow to query. Most of the time, users are better off submitting contracts for decoding and working with decoded data.\n\n## EVM Raw Table Data\n\nEthereum Virtual Machine (EVM) powers all chains in Dune except Solana and Bitcoin, meaning they share the base structure for underlying data. The following are the different types of EVM raw table data available in the Dune Docs project:\n\n- **Blocks**: Blocks are the building blocks of blockchains and rollups.\n- **Event Logs**: Event Logs are data that gets generated by smart contracts.\n- **Traces**: Traces contain information about the execution of smaller atomic actions generated by transactions.\n- **Transactions**: Transactions are cryptographically signed instructions from accounts.\n\nOverall, the Raw Tables section of the Dune Docs project provides users with a comprehensive guide on how to work with raw data tables. It also highlights the limitations of using raw data tables and suggests alternative methods for working with blockchain data. The section on EVM Raw Table Data provides users with a detailed explanation of the different types of raw data tables available for Ethereum Virtual Machine (EVM) and how they can be used.\n## Questions: \n 1. What types of blockchain data can be queried using raw tables in Dune Docs?\n- Raw tables in Dune Docs allow for querying of any transaction, block, event log, or trace across the blockchains that Dune supports.\n\n2. What are some challenges associated with using raw data tables for queries?\n- Queries written using raw data tables can be difficult to understand and audit due to the encoded data commonly found in these tables. Additionally, raw data tables can have a large number of rows and be slow to query.\n\n3. Which blockchains in Dune Docs are powered by the Ethereum Virtual Machine (EVM)?\n- All chains in Dune Docs except for Solana and Bitcoin are powered by the Ethereum Virtual Machine (EVM).","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/index.md"}}],["84",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw/solana/account-activity.md)\n\n# Account Activity\n\nThis section of the app technical guide covers the `Solana.account_activity` table, which contains information from the transactions table focused on account usage. Each row in the table contains all information about an account's usage in a transaction. The purpose of this table is to provide a detailed view of how an account is being used in the Solana blockchain.\n\nThe table contains several columns, each with a specific purpose. The `block_slot` column contains the slot of the block in which the transaction occurred. The `block_hash` column contains the hash of the block in which the transaction occurred. The `block_time` column contains the timestamp of when the account usage occurred. The `block_date` column contains the date of when the account usage occurred. The `address` column contains the address of the account, also referred to as the public key. The `tx_index` column contains the index of the transaction in the block. The `tx_id` column contains the ID of the transaction in which the account usage occurred. The `tx_success` column indicates whether the transaction succeeded and was committed. The `signed` column indicates whether this account signed the transaction. The `writeable` column indicates whether this account was granted read-write access in the transaction. The `pre_balance` column contains the balance of the account before the transaction was processed. The `pre_token_balance` column contains the token balance before the transaction was processed. The `post_balance` column contains the balance of the account after the transaction was processed. The `post_token_balance` column contains the token balance after the transaction was processed. The `balance_change` column contains the balance change that occurred as part of the transaction. The `token_balance_change` column contains the token balance change that occurred as part of the transaction. The `token_mint_address` column contains the address the associated token address is minting from (i.e. the actual token address). The `token_owner_address` column contains the address that owns this token address.\n\nAn example use case for this table would be to track the usage of a specific account over time. By analyzing the data in this table, developers can gain insights into how an account is being used and make informed decisions about how to optimize their application. For example, if an account is being used frequently and experiencing high traffic, developers may want to consider optimizing the account to handle the increased load.\n## Questions: \n 1. What blockchain platform is this app technical guide for?\n- The app technical guide is for the Solana blockchain platform.\n\n2. What specific account information is included in the Solana.account_activity table?\n- The Solana.account_activity table contains information about an account's usage in a transaction, including the account's address, pre- and post-transaction balances, and token balances.\n\n3. What is the purpose of the token_mint_address and token_owner_address columns?\n- The token_mint_address column indicates the address from which the associated token is being minted, while the token_owner_address column indicates the address that owns the token address. This information can be useful for tracking token ownership and usage.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/solana/account-activity.md"}}],["85",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw/solana/blocks.md)\n\n# Blocks\n\n## Solana.blocks\n\nThis section of the app technical guide covers the `Solana.blocks` table, which contains block data within Solana's blockchain. The purpose of this table is to identify block activity and transaction changes over time. The table includes several columns such as `hash`, `height`, `slot`, `time`, `date`, `parent_slot`, `previous_block___hash`, `total_transactions`, `successful_transactions`, and `failed_transactions`. Each column has a specific data type and description, which is explained in the table.\n\nFor example, the `hash` column is a string that represents the hash of the block, base-58 encoded. The `height` column is a bigint that represents the number of blocks beneath this block. The `time` column is a timestamp that represents the estimated time this block was produced. The `total_transactions` column is a bigint that represents the total number of transactions in this block. The `successful_transactions` column is a bigint that represents the number of successful transactions in this block. The `failed_transactions` column is a bigint that represents the number of failed transactions in this block.\n\nThe guide also provides two Solana Query examples that can be used with the `Solana.blocks` table. The first example is \"Solana blocks over time,\" which can be found at [https://dune.xyz/queries/389979](https://dune.xyz/queries/389979). This query shows the number of blocks produced over time. The second example is \"Transactions per day,\" which can be found at [https://dune.xyz/queries/390045](https://dune.xyz/queries/390045). This query shows the number of transactions produced per day.\n\nOverall, this section of the app technical guide provides a detailed explanation of the `Solana.blocks` table and its columns. It also provides useful examples of Solana Queries that can be used with this table.\n## Questions: \n 1. What is the purpose of the `hash` column in the `Solana.blocks` table?\n- The `hash` column in the `Solana.blocks` table contains the hash of each block in Solana's blockchain, encoded in base-58. A blockchain SQL analyst might want to know how this hash is generated and how it is used within the blockchain.\n\n2. How can the `Solana.blocks` table be used to analyze transaction activity over time?\n- The `Solana.blocks` table can be used to identify block activity and transaction changes over time. A blockchain SQL analyst might want to know how to join this table with other tables in order to analyze transaction activity in more detail.\n\n3. Are there any limitations to the data provided in the `Solana.blocks` table?\n- The `Solana.blocks` table provides information on the number of successful and failed transactions in each block, but it does not provide details on the specific transactions themselves. A blockchain SQL analyst might want to know if there are any other limitations to the data provided in this table, and if there are other tables or data sources that can be used to supplement this information.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/solana/blocks.md"}}],["86",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw/solana/index.md)\n\n# Solana Technical Guide\n\nThis technical guide provides information on Solana's raw data and how it differs from other chains. The guide is divided into two main sections: Data Available and Changelog.\n\n## Data Available\n\nThis section provides a list of tables available in Solana's data. The tables are:\n\n- Account Activity: This table contains information from the transactions table focused on account usage.\n- Blocks: Blocks are the building blocks of blockchains and rollups.\n- Rewards: This table contains data about rewards paid out on Solana.\n- Transactions: Transactions are cryptographically signed instructions from accounts.\n- Vote Transactions: This table contains the full set of vote transactions that are submitted by validators to vote on a block.\n\n## Changelog\n\nThis section provides a list of changes made to Solana's data. The changes are:\n\n### 2022-03-25\n\nThe `solana.account_activity` table has been updated to a new version. The new version of the table contains additional information around token activity. The following columns were added to the table:\n\n- `pre_token_balances`: The token balance before the transaction was processed.\n- `post_token_balances`: The token balance after the transaction was processed.\n- `token_balance_changes`: The balance change that occurred as part of the transaction.\n\n### 2022-03-18\n\nThe `solana.account_activity` table was released. The table contains all of the information about an account’s usage in a transaction. The table is optimized to run with ‘WHERE address = …’ queries.\n\n### 2022-03-01\n\nThe `solana.transactions` table has been upgraded to a new version. The new version of the table uses cleaner array structs to make it easier to extract useful information. The vote transactions have also been split into their own table `solana.vote_transactions`, so queries using `solana.transactions` will have better performance. Unfortunately, the table change also means that some existing queries will now break and need to be changed.\n\nThe changes made to the `solana.transactions` table are:\n\n- You won't need to check if a transaction is a vote transaction, which has typically been done with `WHERE ARRAY_CONTAINS(account_keys, \"Vote111111111111111111111111111111111111111\") = false`.\n- The `error_index` and `error_message` columns have been removed, and have been merged into the `error` column (which is a struct). So now instead of `WHERE error_index is not null`, a query should do `WHERE error is not null`.\n- Structs containing indexes to `account_keys` now include the account address directly, so there is no need to use the `account_keys` column to look up the account addresses.\n- The `pre_token_balances` and `post_token_balances` columns have changed. The token balance is now included in the field `amount`. And as mentioned above, the struct in the array now has a field `account`, which is the account of the token balance.\n- The `instructions` column has changed. As mentioned above, the struct in the array now has a field `executing_account`, which is the account executing the instruction.\n- The `inner_instructions` column is removed, and inner instructions have been moved into the `instructions` column.\n\nIn summary, this technical guide provides information on Solana's raw data and the available tables. It also highlights the changes made to the `solana.account_activity` and `solana.transactions` tables. The guide is useful for developers who want to work with Solana's data and need to understand the changes made to the tables.\n## Questions: \n 1. What is Solana and how does it differ from other chains?\n- Solana is a non-EVM chain and its raw data looks different from other chains. \n\n2. What data is available in Solana and what information does each table contain?\n- Solana has several tables available, including account activity, blocks, rewards, transactions, and vote transactions. Each table contains specific data related to its name.\n\n3. What changes were made to the Solana tables in the latest update and how might this affect existing queries?\n- The latest update added new columns to the `solana.account_activity` table and split vote transactions into their own table. Existing queries may need to be updated to reflect changes in column names and structures.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/solana/index.md"}}],["87",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw/solana/rewards.md)\n\n# Rewards\n\nThis section of the app technical guide covers the `Solana.rewards` table, which contains data about rewards paid out on Solana. The table is structured such that each row corresponds to one reward, and one block may contain zero or more rewards. The purpose of this table is to provide information about rewards paid out on the Solana blockchain, which can be useful for analyzing trends and patterns in reward distribution.\n\nThe table contains several columns, each with a specific purpose. The `block_slot` column contains the block's slot index in the ledger, while the `block_hash` column contains the hash of the block, base-58 encoded. The `block_time` column contains the estimated time the block was produced, and the `block_date` column contains the date of the event. The `commission` column contains the vote account commission when the reward was credited, only present for voting and staking rewards. The `lamports` column contains the number of reward lamports credited or debited by the account, while the `pre_balance` column contains the account balance in lamports before the reward was applied. The `post_balance` column contains the account balance in lamports after the reward was applied, and the `recipient` column contains the public key, as a base-58 encoded string, of the account that received the reward. Finally, the `reward_type` column contains the type of reward, which can be \"fee\", \"rent\", \"voting\", or \"staking\".\n\nAn example query for this table is provided in the guide, which shows how to retrieve the Solana rewards fee per day. This query can be useful for analyzing the distribution of rewards over time and identifying any trends or patterns in reward distribution.\n\nOverall, this section of the app technical guide provides a detailed overview of the `Solana.rewards` table, including its purpose, structure, and columns. It also provides an example query to demonstrate how the table can be used to analyze reward distribution on the Solana blockchain.\n## Questions: \n 1. What is the purpose of the Solana.rewards table?\n    \n    The Solana.rewards table contains data about rewards paid out on Solana, with each row corresponding to one reward. It includes information such as the block slot, block hash, block time, commission, lamports, pre and post balance, recipient, and reward type.\n\n2. What types of rewards are included in the reward_type column?\n    \n    The reward_type column includes four types of rewards: \"fee\", \"rent\", \"voting\", and \"staking\". The commission column is also present for voting and staking rewards.\n\n3. Are there any limitations or restrictions on the data included in the Solana.rewards table?\n    \n    The app technical guide does not provide information on any limitations or restrictions on the data included in the Solana.rewards table. It is possible that a blockchain SQL analyst may have additional questions or concerns about the accuracy or completeness of the data.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/solana/rewards.md"}}],["88",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw/solana)\n\nThe `docs/data-tables/raw/solana` folder contains a comprehensive technical guide for working with Solana's raw data tables. These tables provide valuable insights into various aspects of the Solana blockchain, such as account activity, blocks, rewards, transactions, and vote transactions. This guide is essential for developers and analysts who want to work with Solana's data and understand the structure and contents of these tables.\n\nThe `account-activity.md` file covers the `Solana.account_activity` table, which contains information about account usage in transactions. This table can be used to track the usage of a specific account over time and optimize applications based on account activity patterns.\n\nThe `blocks.md` file provides information on the `Solana.blocks` table, which contains block data within Solana's blockchain. This table can be used to identify block activity and transaction changes over time. The guide also provides Solana Query examples that can be used with the `Solana.blocks` table.\n\nThe `index.md` file serves as an overview of the Solana Technical Guide, providing information on Solana's raw data and how it differs from other chains. It also highlights the changes made to the `solana.account_activity` and `solana.transactions` tables, making it useful for developers who need to understand the updates made to these tables.\n\nThe `rewards.md` file covers the `Solana.rewards` table, which contains data about rewards paid out on Solana. This table can be used to analyze trends and patterns in reward distribution, providing valuable insights into the Solana blockchain's reward system.\n\nThe `transactions.md` file provides a technical guide for the `Solana.transactions` table, which contains transaction data within Solana's blockchain. The guide includes detailed descriptions of each column and struct type, as well as query examples that demonstrate how to extract data from the table.\n\nFinally, the `vote-transactions.md` file focuses on the `Solana.vote_transactions` table, which contains the full set of vote transactions submitted by validators to vote on a block. This table can be joined with the non-vote transactions table to get a full breakdown of all transactions, providing a comprehensive view of validator voting activity on the Solana blockchain.\n\nOverall, the guide in this folder offers a detailed understanding of Solana's raw data tables and their usage. It is an invaluable resource for developers and analysts working with Solana data, providing examples and explanations that can help them make informed decisions and optimize their applications based on the insights gained from these tables.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/solana/summary.md"}}],["89",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw/solana/transactions.md)\n\n# Transactions\n\nThe Transactions section of the Dune Docs project provides a technical guide for the Solana.transactions table, which contains transaction data within Solana's blockchain. The table includes relevant data related to account, protocol, and program activity. The guide provides a detailed description of each column in the table, including the column name, column type, and description. \n\nThe guide also includes query examples that demonstrate how to extract data from the table. For example, the guide provides a query that shows NFT transactions of popular programs in the past seven days and an overview of the drift-protocol. \n\nThe guide also includes definitions for several data types used in the table, including STRUCT, which allows for representing nested hierarchical data and has key-value pairs. The guide provides examples of how to use these data types to extract data from the table. \n\nThe guide also includes definitions for several struct types used in the table, including token_balance, instructions, inner_instructions, and error. Each struct type includes a field, data type, and description. \n\nOverall, the Transactions section of the Dune Docs project provides a comprehensive technical guide for the Solana.transactions table, including detailed descriptions of each column and struct type, as well as query examples that demonstrate how to extract data from the table.\n## Questions: \n 1. What is the purpose of the Solana.transactions table?\n   \n   The Solana.transactions table contains transaction data within Solana's blockchain, including relevant data related to account, protocol, and program activity.\n\n2. What is the data type of the token_balance field in the Struct definitions?\n   \n   The data type of the token_balance field in the Struct definitions is Decimal.\n\n3. How can the STRUCT data type be used to group fields together?\n   \n   The STRUCT data type can be used to group fields together to make them more accessible, similar to a dictionary in Python.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/solana/transactions.md"}}],["90",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw/solana/vote-transactions.md)\n\n# Vote Transactions\n\nThe Vote Transactions section of the Dune Docs project focuses on the Solana.vote_transactions table, which contains the full set of vote transactions submitted by validators to vote on a block. This table can be joined with the non-vote transactions table to get a full breakdown of all transactions. The schema of the Solana.vote_transactions table is the same as the main transactions table.\n\nThe guide provides a detailed description of each column in the Solana.vote_transactions table, including the column name, column type, and description. Some of the columns include block_slot, which is the block's slot index in the ledger, block_time, which is the estimated time the block was produced, and fee, which is the fee charged for the transaction. The guide also includes examples of queries that can be run on the Solana.vote_transactions table, such as the Solana transactions past 30 days query available on Dune.xyz.\n\nOverall, the Vote Transactions section of the Dune Docs project provides a comprehensive guide to the Solana.vote_transactions table, including its schema and how it can be used to analyze vote transactions submitted by validators. This information is useful for developers and analysts working with Solana.vote_transactions and looking to gain a deeper understanding of its structure and contents.\n## Questions: \n 1. What is the purpose of the dune docs app and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the dune docs app, so a blockchain SQL analyst may need to seek additional documentation or context. \n\n2. How does the Solana.vote_transactions table differ from the non-vote transactions table mentioned in the guide?\n- The guide mentions that the Solana.vote_transactions table contains only vote transactions submitted by validators to vote on a block, while the non-vote transactions table contains a full breakdown of all transactions. A blockchain SQL analyst may want to know more about the schema and contents of the non-vote transactions table.\n\n3. Can the instructions column in the Solana.vote_transactions table be used to track specific actions taken by validators during the voting process?\n- The guide mentions that the instructions column contains a list of instructions to execute in order, but it does not provide information on what those instructions may be. A blockchain SQL analyst may want to know if the instructions can be used to track specific actions taken by validators during the voting process.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/solana/vote-transactions.md"}}],["91",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw)\n\nThe `docs/data-tables/raw` folder in the Dune Docs project focuses on providing comprehensive guides for working with raw, unfiltered, and unedited data from various blockchains, including Ethereum, Bitcoin, and Solana. This raw data is organized into different categories such as Blocks, Transactions, Event Logs, and Traces. Each category has a dedicated markdown file that explains the respective feature in detail, including the available data, data types, and how to access and use the data in the Dune Docs app.\n\nFor example, the `blocks.md` file covers the concept of blocks in blockchains and rollups, providing tables and column data that are useful for identifying block activity and transaction changes over time. Developers working with blockchain data can use this guide to understand how blocks work in the context of the Dune Docs project and extract valuable insights from the data.\n\nSimilarly, the `event-logs.md` file provides a detailed guide on the `Event Logs` tables that store all logs data generated by smart contracts. This guide is essential for developers who want to work with event logs and understand the structure and contents of these tables.\n\nThe `traces.md` file focuses on the Traces tables, which contain information about the execution of smaller atomic actions generated by transactions. This guide is useful for developers analyzing transaction patterns or tracking the movement of assets between addresses.\n\nLastly, the `transactions.md` file covers transactions in the Ethereum network, including tables and column data. This guide is essential for developers who want to work with transaction data and understand the structure and contents of these tables.\n\nIn addition to the Ethereum-focused guides, this folder also contains subfolders for Bitcoin and Solana, providing detailed guides for working with raw data from these blockchains.\n\nOverall, the guides in this folder provide a clear understanding of the raw data available in the Dune Docs project and how to access and use it effectively. By following these guides, developers can build powerful tools for analyzing blockchain transactions and blocks, which can be useful in various applications and projects.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/summary.md"}}],["92",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw/traces.md)\n\n# Traces\n\nThe Traces tables contain information about the execution of smaller atomic actions generated by transactions. Transactions can trigger smaller atomic actions that modify the internal state of an Ethereum Virtual Machine. Information about the execution of these actions is logged and can be found stored as an EVM execution trace, or just a trace. In Etherscan, these are referred to as \"internal transactions\". The guide provides information on the tables and column data of the traces.\n\n## Tables\n\nThe tables are divided into two engines, V1 and V2. The V2 engine uses Spark SQL, while the V1 engine uses PostgreSQL. The tables are divided by chain and contain information such as the value measured in wei, gas, gas used, block hash, success, tx index, sub-traces, error, tx success, tx hash, from, to, trace address, type, address, code, call type, input, and output. \n\n## Column Data\n\nThe column data provides a detailed description of the data types and their descriptions. For instance, the `block_time` column is of type `timestamptz` and represents the time when the block was mined. The `value` column is of type `numeric` and represents the amount of `[chain_gas_token]` sent in this transaction. The `gas` column is of type `numeric` and represents the gas provided with the message call. The `gas_used` column is of type `numeric` and represents the gas consumed by the transaction in wei. The `success` column is of type `boolean` and represents a true/false value that shows if the trace action succeeded. \n\n## Gas used in `.traces`\n\nThe `gas_used` column in the `.traces` tables is a bit hard to understand. The `gas_used` of a trace will always include the gas consumed by the trace and all its subtraces. The `gas_used` of the initial call will not contain the cost of making the call in the first place. You need to add 21000 gas units + the cost of sending zero + non-zero bytes to the `gas_used` value of the top trace to arrive at the \"true\" `gas_used` value. \n\n## Creation Traces\n\nThe creation traces table contains information about the creation of a smart contract and the transfer of ether to it. The table is divided by chain and contains information such as block time, block number, tx hash, address, from, and code. \n\nThe guide provides examples of the tables and column data. For instance, the guide provides an example of the V2 engine (Spark SQL) table for Ethereum Mainnet. The guide also provides an example of the creation traces table for Ethereum Mainnet. \n\nOverall, the guide provides a detailed explanation of the Traces tables and column data. It also provides examples of the tables and column data.\n## Questions: \n 1. What is the purpose of the `traces` tables in the different chains listed in the guide?\n- The `traces` tables contain information about the execution of smaller atomic actions generated by transactions in different chains listed in the guide.\n\n2. What is the difference between the V1 and V2 engines in terms of the PostgreSQL database used?\n- The V1 engine uses PostgreSQL while the V2 engine uses Spark SQL.\n\n3. What is the `gas_used` column in the `.traces` tables and how is it calculated?\n- The `gas_used` column in the `.traces` tables includes the gas consumed by the trace and all its subtraces, but not the cost of making the call in the first place. To arrive at the \"true\" `gas_used` value, 21000 gas units plus the cost of sending zero and non-zero bytes should be added to the `gas_used` value of the top trace.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/traces.md"}}],["93",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/raw/transactions.md)\n\n# Transactions\n\nThis section of the app technical guide covers transactions in the Ethereum network. Transactions are cryptographically signed instructions from accounts that initiate a transaction to update the state of the Ethereum network. Transactions always originate from externally owned accounts, and a smart contract cannot initiate a transaction. Transactions need to be broadcast to the whole network, and any node can broadcast a request for a transaction to be executed on the EVM. After this happens, a miner will execute the transaction and propagate the resulting state change to the rest of the network. \n\nThe official Ethereum documentation provides more information on transactions [here](https://ethereum.org/en/developers/docs/transactions).\n\n## Tables\n\nThis section of the app technical guide provides a table of the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL) for different chains. The table lists the chain, table, and notes. \n\n### Example\n\nAn example of the table is shown below:\n\n|   Chain           |   Table               | Notes |\n| ----------------  | --------------------- | ----- |\n| Ethereum Mainnet  | `ethereum.transactions`     |  |\n| Gnosis Chain      | `gnosis.transactions`       |  |\n| Polygon           | `polygon.transactions`      |  |\n| Optimism          | `optimism.transactions`     | No EIP1559 so does not contain  `access_list`, `max_fee_per_gas`,`max_priority_fee_per_gas`, `priority_fee_per_gas` and `type` is always `Legacy` |\n| Optimism (legacy) | `optimism_legacy_ovm1.transactions` | No EIP1559 so does not contain  `access_list`, `max_fee_per_gas`,`max_priority_fee_per_gas`, `priority_fee_per_gas` and `type` is always `Legacy` |\n| BNB Chain         | `bnb.transactions`          | No EIP1559 so does not contain  `access_list`, `max_fee_per_gas`,`max_priority_fee_per_gas`, `priority_fee_per_gas` and `type` is always `Legacy` |\n| Arbitrum          | `arbitrum.transactions`     | No EIP1559 so does not contain  `access_list`, `max_fee_per_gas`,`max_priority_fee_per_gas`, `priority_fee_per_gas` and `type` is always `Legacy`. Gas is measured in `ArbGas` instead of `wei` |\n| Avalanche C-Chain  | `avalanche_c.transactions` | Does not contain. Gas is measured in `nanoavax` instead of `wei` |\n\n## Column Data\n\nThis section of the app technical guide provides a table of column data for transactions. The table lists the column, data type, and description. \n\n### Example\n\nAn example of the table is shown below:\n\n|  Column  **            |  Data type   |  Description                                                   |\n| -------------------------- | :-----------: | ---------------------------------------------------------------- |\n| `block_time`               | _timestamptz_ | The time when the block was mined that includes this transaction |\n| `block_number`             | _int8_        | The length of the blockchain in blocks                     |\n| `value`                      | _numeric_     | The amount of `[chain_gas_token]` sent in this transaction in `wei`. Note that ERC20 tokens do not show up here |\n| `gas_limit`                | _numeric_     | The gas limit in `wei` (ArbGas for Arbitrum) |\n| `gas_price`                | _numeric_     | The gas price in `wei`                                    |\n| `gas_used`                 | _numeric_     | The gas consumed by the transaction in `wei`              |\n| `max_fee_per_gas`          | _numeric_     | The maximum fee per gas the transaction sender is willing to pay total (introduced by [EIP1559](https://eips.ethereum.org/EIPS/eip-1559)) |\n| `max_priority_fee_per_gas` | _numeric_     | Maximum fee per gas the transaction sender is willing to give to miners to incentivize them to include their transaction (introduced by [EIP1559](https://eips.ethereum.org/EIPS/eip-1559)) |\n| `priority_fee_per_gas`     | _numeric_     | The priority fee paid out to the miner for this transaction (introduced by [EIP1559](https://eips.ethereum.org/EIPS/eip-1559)) |\n| `nonce`                    | _numeric_     | The transaction nonce, unique to that wallet               |\n| `index`                    | _numeric_     | The transactions index position in the block               |\n| `success`                  | _boolean_     | A true/false value that shows if the transaction succeeded |\n| `from`                     | _bytea_       | Address of the sender                                      |\n| `to`                       | _bytea_       | Address of the receiver. `null` when its a contract creation transaction |\n| `block_hash`               | _bytea_       | A unique identifier for that block                         |\n| `data`                     | _bytea_       | Can either be empty, a hex encoded message or instructions for a smart contract call |\n| `hash`                     | _bytea_       | The hash of the transaction                                |\n| `type`                     | _text_        | The type of the transaction: `Legacy`, `AccessList`, or `DynamicFee` |\n| `access_list`              | _jsonb_       | A list of addresses and storage keys the transaction intends to access. See [EIP2930](https://eips.ethereum.org/EIPS/eip-2930). Applicable if the transaction is of type `AccessList` or `DynamicFee` |\n| `effective_gas_price` | _numeric_      | [Arbitrum and Avalanche C-Chain only] The gas price this transaction paid in `wei` (Arbitrum) or `nanoavax` (Avalanche) |\n| `gas_used_for_l1` | _numeric_ | [Arbitrum only] The gas consumed by the L1 resources used for this transaction in ArbGas |\n| `l1_gas_used` | _numeric_ | [Optimism only] The costs to send the input `calldata` to L1 |\n| `l1_gas_price` | _numeric_ | [Optimism only] The gas price on L1 |\n| `l1_fee` | _numeric_ | [Optimism only] The amount in wei paid on L1  |\n| `l1_fee_scalar` | _numeric_ | [Optimism only] Variable parameter that makes sure that gas costs on L1 get covered + profits |\n| `l1_block_number` | _numeric_ | [Optimism only] The block_number of the block in which this transaction got batch settled on L1 |\n| `l1_timestamp` | _numeric_ | [Optimism only] The timestamp of the block in which this transaction got batch settled on L1 |\n| `l1_tx_origin` | _numeric_ | [Optimism only] ?? |\n\nThis table provides a detailed description of the column data for transactions. It lists the column name, data type, and description. The column data includes information such as the time when the block was mined that includes this transaction, the length of the blockchain in blocks, the amount of `[chain_gas_token]` sent in this transaction in `wei`, the gas limit in `wei` (ArbGas for Arbitrum), the gas price in `wei`, the gas consumed by the transaction in `wei`, the maximum fee per gas the transaction sender is willing to pay total (introduced by EIP1559), the maximum fee per gas the transaction sender is willing to give to miners to incentivize them to include their transaction (introduced by EIP1559), the priority fee paid out to the miner for this transaction (introduced by EIP1559), the transaction nonce, unique to that wallet, the transactions index position in the block, a true/false value that shows if the transaction succeeded, the address of the sender, the address of the receiver (null when it's a contract creation transaction), a unique identifier for that block, and more.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/transactions.md"}}],["94",{"pageContent":"Overall, this section of the app technical guide provides a detailed description of transactions in the Ethereum network, including tables and column data.\n## Questions: \n 1. What is the purpose of the Transactions table in this app and what data does it contain?\n- The Transactions table contains data on transactions from various blockchain networks, including Ethereum Mainnet, Polygon, and BNB Chain, among others. It includes information such as the block time, block number, gas limit, gas price, gas used, and transaction hash, among others.\n2. Does this app support EIP1559 and how is it reflected in the Transactions table?\n- The app supports EIP1559, but not all blockchain networks included in the Transactions table have implemented it. For networks that have implemented it, the Transactions table includes columns for `max_fee_per_gas`, `max_priority_fee_per_gas`, and `priority_fee_per_gas`.\n3. How does this app handle gas measurement for different blockchain networks?\n- Gas measurement varies across different blockchain networks, and the Transactions table reflects this by using different units of measurement such as `wei`, `ArbGas`, and `nanoavax`. The table also includes columns such as `effective_gas_price` and `gas_used_for_l1` to account for gas measurement differences in specific networks like Arbitrum.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/raw/transactions.md"}}],["95",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/contributing/Adding A Spell/1-do-some-prerequisites and-set-up-Spellbook-dbt.md)\n\nThis technical guide provides instructions on how to set up Spellbook dbt on a local computer. The guide is divided into two main sections: prerequisites and setting up Spellbook dbt. \n\nThe prerequisites section outlines the software and tools required to set up Spellbook dbt. These include VSCode, Python 3.9, pip, pipenv, git, and GitHub. The guide provides links to download and install each of these tools. Additionally, the guide instructs users to fork the Spellbook repository, clone it locally, and add an upstream. The guide also includes a video tutorial on how to fork the Spellbook repo.\n\nThe second section of the guide focuses on setting up Spellbook dbt. Once the user has a local copy of their Spellbook fork, they need to install the necessary packages by running `pipenv install` in the terminal. The guide then instructs users to activate their virtual environment by running `pipenv shell` and initialize dbt by running `dbt init`. The guide provides a list of prompts that users should enter when initializing dbt. The guide also instructs users to run `dbt deps` to install dependencies and `dbt compile` to compile the project. Finally, the guide instructs users to create a new branch called \"workshop\" and push it to their remote GitHub repository.\n\nOverall, this guide provides detailed instructions on how to set up Spellbook dbt on a local computer. The guide is well-structured and includes links to relevant resources and a video tutorial. The guide is intended for users who are new to Spellbook dbt and provides step-by-step instructions to ensure that users can set up Spellbook dbt without any issues.\n## Questions: \n 1. What is the purpose of Spellbook and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of Spellbook or its relation to blockchain technology.\n\n2. Are there any specific SQL databases that Spellbook dbt is compatible with?\n- The app technical guide does not provide information on the specific SQL databases that Spellbook dbt is compatible with.\n\n3. Is there any guidance on how to integrate Spellbook with a blockchain network or smart contract?\n- The app technical guide does not provide information on how to integrate Spellbook with a blockchain network or smart contract.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/contributing/Adding A Spell/1-do-some-prerequisites and-set-up-Spellbook-dbt.md"}}],["96",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/contributing/Adding A Spell/2-decide-on-a-Spell-to-cast.md)\n\nThis app technical guide covers the process of deciding on a Spell to cast in the Dune app. The guide provides three ways to decide on a Spell, including having an idea based on previous experience with Dune, checking out Spellbook bounties in Dework, or asking for suggestions in the #spellbook Discord channel. \n\nThe guide then provides an example of creating a migration Spell, specifically translating the Keep3r network `view_job_log` abstraction from Dune's v1 database into a V2 Spell. The guide directs the user to find the `view_job_log.sql` file in the `deprecated-dune-v1-abstractions` folder within VSCode. \n\nThe guide also includes a note that Dune V1 Abstractions have been moved to a new repository and provides a link to access the code for migrating a V1 Abstraction to a Spell. The guide concludes by instructing the user to set up the file structure for the Spell's SQL schema and source files.\n\nOverall, this guide provides a clear and concise explanation of how to decide on a Spell and create a migration Spell in the Dune app. The example provided helps to illustrate the process and make it more accessible to users.\n## Questions: \n 1. What is the purpose of the Dune Docs app and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the Dune Docs app or its relation to blockchain technology.\n\n2. What is the significance of the migration Spell mentioned in the guide?\n- The migration Spell mentioned in the guide is for translating the Keep3r network `view_job_log` abstraction from Dune’s v1 database into a V2 Spell.\n\n3. How does the Spellbook bounties in Dework relate to blockchain SQL analysis?\n- The Spellbook bounties in Dework provide a way for users to suggest and work on Spells, which may involve SQL analysis related to blockchain technology.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/contributing/Adding A Spell/2-decide-on-a-Spell-to-cast.md"}}],["97",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/contributing/Adding A Spell/3-set-up-your-file-structure-for-SQL-schema-and-source-files.md)\n\nThis app technical guide provides instructions on how to set up the file structure for SQL, schema, and source files in the Dune Docs project. The guide explains that all Spells are stored in the `/spellbook/models` directory by project name, then blockchain network. The folder names are all lowercase, and words are separated by underscores. The guide provides an example of the folder structure for the Keep3r network, where the folder is `/spellbook/models/keep3r_network/ethereum`. \n\nThe guide explains that if the project folder exists but a Spell is being created for a new blockchain, a folder for the new blockchain should be created. The guide then explains that three files need to be created: a `.sql` file for the Spell's logic, a `_schema.yml` file to define the Spell's purpose and add generic tests, descriptions, metadata, etc., and a `_sources.yml` file with any project-specific table dependencies. The guide provides an example of the file structure for a Spell folder.\n\nThe guide also explains the naming convention for Spell files. Schema files are named `[project_name]_[blockchain]_schema.yml`, sources files are named `[project_name]_[blockchain]_sources.yml`, and SQL files for Spells are named `[project_name]_[blockchain]_[spell_name].sql`. \n\nThe guide then provides an example of a specific v1 migration example where three additional `.sql` files are needed for a Spell called `keep3r_network_ethereum_view_job_log.sql`. The guide explains that these files are needed because the original `view_job_log.sql` V1 Abstraction has two `FROM` statements that reference two other files that are also abstractions that need to be converted into Spells. The guide also explains that a recursive check needs to be done to see if those abstractions depend on any other abstractions that have yet to be migrated to Spells. \n\nOverall, this app technical guide provides a detailed explanation of how to set up the file structure for Spells in the Dune Docs project and provides examples to help users understand the process.\n## Questions: \n 1. What is the purpose of the dune docs app and how does it relate to blockchain SQL analysis?\n- The app technical guide does not provide information on the purpose of the dune docs app or its relation to blockchain SQL analysis.\n\n2. What is the file structure for storing Spells in the dune docs app?\n- Spells are stored in the `/spellbook/models` directory by project name, then blockchain network. Names are all lower case and words are separated by `_`. The app requires the creation of three files: a `.sql` file for the Spell's logic, a `_schema.yml` file for defining the spell's purpose and adding metadata, and a `_sources.yml` file for project-specific table dependencies.\n\n3. How does the app handle dependencies between Spells and abstractions in the migration process?\n- The app requires a recursive check to see if abstractions depend on any other abstractions that have yet to be migrated to Spells. The app also requires the creation of additional `.sql` files for Spells that depend on other abstractions, and these dependencies are identified by searching for `FROM` statements in the original abstractions.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/contributing/Adding A Spell/3-set-up-your-file-structure-for-SQL-schema-and-source-files.md"}}],["98",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/contributing/Adding A Spell/4-identify-and-define-sources.md)\n\n# App Technical Guide: Identify and Define Sources\n\nThis guide is focused on the `app` folder of the Dune Docs project and covers the process of identifying and defining sources in the `_sources.yml` file. The purpose of this file is to provide a structured way of defining the sources of data that will be used in the project. \n\nThe guide provides an example of how to format the `_sources.yml` file, which includes a version number and a list of sources. Each source is defined by a name, a one-line description, and a list of tables. The guide also explains how to identify the sources that need to be named by searching for `FROM` statements in the V1 abstractions that are being migrated. \n\nThe example provided in the guide is for the Keep3r Network Ethereum sources. The name of the source is `keep3r_network_ethereum`, and the description provides an overview of the Keep3r Network and its purpose. The list of tables includes the names of the tables that will be used as sources of data for the project. \n\nOverall, this guide is a useful resource for developers who are working on the Dune Docs project and need to identify and define sources of data. By following the guidelines provided in this guide, developers can ensure that the sources of data are properly defined and structured, which will make it easier to work with the data in the project.\n## Questions: \n 1. What is the purpose of the `_sources.yml` file in the Dune Docs project?\n    \n    The `_sources.yml` file in the Dune Docs project is used to define sources, including their names, descriptions, and tables.\n\n2. How are the sources formatted in the `_sources.yml` file?\n    \n    The sources in the `_sources.yml` file are formatted using YAML syntax, with a version number and a list of sources that include a name, description, and tables.\n\n3. How does one determine which tables to include in the `_sources.yml` file?\n    \n    To determine which tables to include in the `_sources.yml` file, one should search for `FROM` statements in the V1 abstractions being migrated and include all tables mentioned that are not abstractions.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/contributing/Adding A Spell/4-identify-and-define-sources.md"}}],["99",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/contributing/Adding A Spell/6-write-your-spell-as-SELECT-statement.md)\n\nThis technical guide covers the process of writing a Spell as a SELECT statement in the Dune Docs project. The guide is focused on the app folder of the project. The guide starts by explaining that the endpoint is `_view_job_log.sql`, but the process should start with `_view_job_migrations.sql` because it is the lowest-level dependency. The guide then explains how to migrate from V1 abstraction to V2 Spell by copying the contents of the V1 file to the `keep3r_network_ethereum_view_job_migrations.sql` file. The guide explains that the `CREATE` or `REPLACE` definition statement is not needed, and everything from the first `SELECT` to the last `TRUE` is required. The guide then explains how to replace hard-coded references with JINJA templating. \n\nThe guide provides examples of SQL code and explains how to modify the syntax to V2/Spark SQL. The guide also explains how to replace hard-coded references with JINJA templating. The guide provides examples of how to format references to sources and models using JINJA. The guide emphasizes the need to test the SQL code in dune.com and fix any errors. The guide also provides tips on how to fix errors by googling or asking for help in the community's Discord channel. \n\nIn summary, this technical guide provides a step-by-step process of writing a Spell as a SELECT statement in the Dune Docs project. The guide covers how to migrate from V1 abstraction to V2 Spell, how to replace hard-coded references with JINJA templating, and how to test the SQL code and fix errors.\n## Questions: \n 1. What is the purpose of the dune docs app?\n- The app technical guide does not provide information on the purpose of the dune docs app.\n\n2. What programming languages or technologies are used in this app?\n- The app technical guide mentions the use of SQL, PostgreSQL, Spark SQL, and JINJA templating.\n\n3. What is the process for migrating from V1 abstraction to V2 Spell style?\n- The app technical guide provides a detailed process for migrating from V1 abstraction to V2 Spell style, including modifying syntax to Spark SQL, replacing hard-coded references with JINJA templating, and testing individual SQL files in dune.com.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/contributing/Adding A Spell/6-write-your-spell-as-SELECT-statement.md"}}],["100",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/contributing/Adding A Spell/7-configure-alias-and-materialization-strategy.md)\n\nThis app technical guide covers the configuration of aliases and materialization strategies in the Spellbook project. The guide explains that materialization strategies are used to persist data in the data lake house and there are four materialization strategies in dbt: table, ephemeral, view, and incremental. Spellbook uses view and incremental strategies. \n\nThe guide explains that view Spells are rebuilt each time they are run, meaning every time someone queries a view Spell, the SQL is run, and fresh data is gathered according to the Spell’s SQL logic. On the other hand, incremental Spells allow dbt to insert or update records in a table according to the logic defined. The guide provides an example of how to create an incremental Spell by including a statement of which column to join new data to the existing data each time the Spell is incremented.\n\nThe guide also explains how to configure aliases and materialization. To configure a Spell’s alias and materialization, the configuration is added to the top of each SQL file. The configuration includes creating an alias for the Spell file that will appear in the dune.com UI, defining how the file is stored and categorized in the UI, and naming the contributors. The guide provides an example of how to configure a Spell’s alias and materialization using a view materialization strategy.\n\nFinally, the guide explains how to add new models to the dbt_project.yml file in the Spellbook root folder. The guide provides an example of how to specify the project name, schema, and materialization strategy for the project as a whole as well as the specific blockchain(s) that Spells have been created for. \n\nOverall, this guide provides a detailed explanation of how to configure aliases and materialization strategies in the Spellbook project. It is a useful resource for developers working on the project who need to configure aliases and materialization strategies for their Spells.\n## Questions: \n 1. What are the available materialization strategies in dbt and which ones does Spellbook use?\n- The available materialization strategies in dbt are `table`, `ephemeral`, `view`, and `incremental`. Spellbook uses `view` and `incremental`.\n\n2. How does the `incremental` materialization strategy work and what configuration is needed to implement it?\n- The `incremental` materialization strategy allows dbt to insert or update records in a table according to the logic defined. To implement it, the configuration section of the file needs to include a statement of which column to join new data to existing data, specify that it is an incremental Spell, and provide an instruction for how dbt should combine new/old data using `merge`. Additionally, `if` statements need to be added to any `FROM` for which data needs to be incremented.\n\n3. How do you configure a Spell's alias and materialization and where is this configuration added?\n- To configure a Spell's alias and materialization, the configuration is added to the top of each SQL file. The configuration includes creating an alias for the Spell file that will appear in the UI, defining how the file is stored and categorized in the UI, and specifying whether it is a Spell for a specific project or a whole sector. This configuration assumes the use of a `view` materialization strategy.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/contributing/Adding A Spell/7-configure-alias-and-materialization-strategy.md"}}],["101",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/contributing/Adding A Spell/8-make-a-pull-request-get-merged-become-an-archwizard.md)\n\nThis section of the app technical guide covers the process of making a pull request to the official Spellbook in the Dune Docs project. The guide provides step-by-step instructions on how to submit a pull request after committing local changes to the Spellbook GitHub fork. The guide also emphasizes the importance of giving an appropriate message when submitting a pull request and waiting for comments from the team. \n\nThe guide includes an example of the \"Open pull request button\" and encourages users to address any comments from the team before their Spell is approved. The ultimate goal of this section is to guide users towards becoming a Dune Archwizard by having their Spell approved. \n\nOverall, this section of the guide is focused on the app feature of contributing to the official Spellbook and becoming a part of the select few Dune Archwizards. It provides clear instructions and encourages users to take the necessary steps to ensure their pull request is approved.\n## Questions: \n 1. What is the purpose of the Dune Docs project and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the Dune Docs project or its relation to blockchain technology.\n\n2. What programming languages or frameworks are used in the development of this app?\n- The app technical guide does not provide information on the programming languages or frameworks used in the development of this app.\n\n3. Are there any security measures in place to protect user data or prevent unauthorized access?\n- The app technical guide does not provide information on any security measures in place to protect user data or prevent unauthorized access.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/contributing/Adding A Spell/8-make-a-pull-request-get-merged-become-an-archwizard.md"}}],["102",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/contributing/Adding A Spell/index.md)\n\nThe app technical guide provides a comprehensive explanation of Spellbook, an open-source dbt repository for creating and maintaining high-level blockchain data tables using SQL and Jinja templating. The guide explains how Spellbook enables the community to build towards a standardized way to transform data into meaningful abstraction layers. The guide also highlights the importance of Spellbook in making blockchain data more transparent, accessible, and meaningful together. \n\nThe guide provides a step-by-step process of how to cast a Spell, which includes setting up Spellbook dbt, deciding on a Spell to cast, setting up a file structure for SQL, schema, and source files, identifying and defining sources, defining expectations with schema and tests, writing a Spell as a SELECT statement, configuring alias and materialization strategy, and making a pull request to become an Archwizard. \n\nThe guide also provides examples of how to use Spellbook to aggregate and organize raw data from multiple sources to make it much easier to query. For instance, the nft.trades Spell enables users to see industry-wide stats like total volume by # of txs and $USD, 24-hr volume, 24-hour and 7-day growth, market share by marketplace, volume by marketplace, and transaction count by marketplace. \n\nOverall, the app technical guide provides a detailed explanation of Spellbook and how to cast a Spell, making it easier for users to create and maintain high-level blockchain data tables using SQL and Jinja templating.\n## Questions: \n 1. What is Spellbook and how does it relate to blockchain data analytics?\n- Spellbook is an open-source dbt repository for creating and maintaining high-level blockchain data tables using SQL and Jinja templating. It enables the community to build toward a standardized way to transform data into meaningful abstraction layers, making it much easier to query blockchain data.\n\n2. How does Spellbook save time and effort in blockchain data analysis?\n- Spellbook allows users to create abstracted data sets, like dex.trades and nft.trades, which aggregate and organize raw data from multiple sources. This saves time and effort in data analysis as users can skip the manual abstraction work and get straight to the insights.\n\n3. How can a blockchain SQL analyst contribute to Spellbook?\n- A blockchain SQL analyst can contribute to Spellbook by doing the data engineering for a new marketplace, submitting a Pull Request to Spellbook, and having the entire community benefit from their work. They can also follow the 8 steps outlined in the app technical guide to create and maintain high-level blockchain data tables using SQL and Jinja templating.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/contributing/Adding A Spell/index.md"}}],["103",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/contributing/Adding A Spell)\n\nThis folder in the Dune Docs project focuses on the process of contributing a new Spell to the Spellbook, which is an open-source dbt repository for creating and maintaining high-level blockchain data tables using SQL and Jinja templating. The guides in this folder provide detailed instructions on how to set up Spellbook dbt, decide on a Spell to cast, set up a file structure for SQL, schema, and source files, identify and define sources, define expectations with schema and tests, write a Spell as a SELECT statement, configure alias and materialization strategy, and make a pull request to become an Archwizard.\n\nFor example, the guide \"2-decide-on-a-Spell-to-cast.md\" helps users decide on a Spell to cast by providing three ways to decide on a Spell, including having an idea based on previous experience with Dune, checking out Spellbook bounties in Dework, or asking for suggestions in the #spellbook Discord channel. The guide also provides an example of creating a migration Spell, specifically translating the Keep3r network `view_job_log` abstraction from Dune's v1 database into a V2 Spell.\n\nAnother example is the guide \"6-write-your-spell-as-SELECT-statement.md\", which covers the process of writing a Spell as a SELECT statement in the Dune Docs project. The guide provides a step-by-step process of migrating from V1 abstraction to V2 Spell, replacing hard-coded references with JINJA templating, and testing the SQL code and fixing errors.\n\nThese guides are useful for analysts and developers who want to contribute to the Spellbook project by creating and maintaining high-level blockchain data tables. By following the instructions provided in these guides, users can ensure that their Spells are properly structured, tested, and integrated into the Spellbook project. This will ultimately help make blockchain data more transparent, accessible, and meaningful for the entire community.\n\nOverall, the guides in this folder provide a comprehensive explanation of how to contribute a new Spell to the Spellbook project, making it easier for users to create and maintain high-level blockchain data tables using SQL and Jinja templating. The guides are well-structured and include examples to help users understand the process and contribute effectively to the project.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/contributing/Adding A Spell/summary.md"}}],["104",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/contributing/examples/daily-aggregation.md)\n\n# Daily Aggregation\n\nThis section of the app technical guide covers the daily aggregation feature of the Dune Docs project. The purpose of this feature is to sum all transfers for the day. The table is materialized as an incrementally loaded table updated every 15 minutes because the next step includes a slower `[window](https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-window.html)` function to capture a rolling sum.\n\nThe guide explains the novel components that make this Spell incremental. The `<div data-gb-custom-block data-tag=\"if\"> </div>` JINJA block allows the addition of an arbitrary filter when running in “incremental” mode. Incremental mode is default and a full refresh is denoted by a command line arg to completely recreate the table. The block is used to filter for all data timestamped in the last two days. The model runs every fifteen minutes, but a look back of 2 days is allowed to account for data arriving late from the blockchain.\n\nTo avoid duplicates, a “`merge`” incremental\\_strategy is used. Merge strategies require a unique key and deduplicate the table upon each update. The guide shows that a unique key is created by coalescing several transfer features together that are utilized here.\n\nThe guide also introduces the first use of “refs” in this spellset. A ref, like `{{ ref('tokens_ethereum_erc20') }}` is simply a reference to another model in the DBT project. The ref references the name of the file itself. That means, duplicate file names cannot exist.\n\nThe guide provides an example of the `transfers_ethereum_erc20_agg_day.sql` file, which contains the SQL code for the daily aggregation feature. The code includes a configuration block that specifies the alias, materialized, file format, incremental strategy, and unique key. The SQL code also includes a select statement that retrieves the required data and a group by statement that groups the data by the required fields.\n\nThe guide also provides an example of the `transfers_ethereum_schema.yml` file, which contains the schema for the Ethereum transfers. The schema includes the name of the transfer, the blockchain, the sector, the project, the contributors, the tags, and the columns. The columns include the blockchain, the hour, the wallet address, the token address, the symbol, the amount raw, and the amount USD.\n\nIn summary, this section of the app technical guide provides a detailed explanation of the daily aggregation feature of the Dune Docs project. It explains the novel components that make this Spell incremental, provides examples of the SQL code and schema files, and introduces the concept of refs.\n## Questions: \n 1. What is the purpose of the Daily Aggregation table in the Dune Docs app?\n- The Daily Aggregation table sums all transfers for the day and is materialized as an incrementally loaded table updated every 15 minutes.\n\n2. How does the app handle duplicates in the Daily Aggregation table?\n- The app uses a \"merge\" incremental strategy that requires a unique key and deduplicates the table upon each update.\n\n3. What is a ref in the Dune Docs app and how is it used?\n- A ref is a reference to another model in the DBT project and is used to reference the name of the file itself. It cannot have duplicate file names.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/contributing/examples/daily-aggregation.md"}}],["105",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/contributing/examples/final-day-balance.md)\n\n# Final Daily Balance\n\nThis technical guide covers the Final Daily Balance feature of the Dune Docs project. The feature is located in the `app` folder of the project. \n\nThe Final Daily Balance feature is an Ethereum ERC20 token balances spell that expands the Spell to cover all days, not just the days with transfer activity. The feature adds price data, removes known rebase tokens, and any tokens that resulted in large negative balances. \n\nThe `balances_ethereum_erc20_day.sql` file contains the SQL code for the feature. It uses the `transfers_ethereum_erc20_rolling_day` table to derive the `balances_ethereum_erc20_noncompliant` table, which looks for unique token addresses with larger negative balances that indicate the contract may not be compliant with ERC20. The `balances_ethereum_erc20_day` table then removes rebase tokens from balances and likely non-compliant tokens due to negative balances. \n\nThe `transfers_ethereum_schema.yml` file contains the schema for the `balances_ethereum_erc20_day` table. The table provides daily token balances of ERC20 Ethereum tokens per wallet and contract address pair. The table depends on `erc20_ethereum_transfers`. \n\nOverall, the Final Daily Balance feature provides a comprehensive view of daily Ethereum ERC20 token balances, including price data and compliance checks.\n## Questions: \n 1. What is the purpose of the `transfers_ethereum_erc20_rolling_day` table and how is it used in the `balances_ethereum_erc20_day` SQL query?\n   \n   The blockchain SQL analyst might want to know more about the `transfers_ethereum_erc20_rolling_day` table and how it is used in the `balances_ethereum_erc20_day` SQL query to understand how the daily token balances are calculated.\n\n2. How are rebase tokens and non-compliant tokens identified and removed from the final daily balances?\n\n   The blockchain SQL analyst might want to know more about how rebase tokens and non-compliant tokens are identified and removed from the final daily balances to understand the accuracy and reliability of the data.\n\n3. What is the significance of the `prices` table and how is it used in the `balances_ethereum_erc20_day` SQL query?\n\n   The blockchain SQL analyst might want to know more about the `prices` table and how it is used in the `balances_ethereum_erc20_day` SQL query to understand how the daily token balances are converted to USD.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/contributing/examples/final-day-balance.md"}}],["106",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/contributing/examples/index.md)\n\nThe app technical guide titled \"Spellbook Examples\" provides an overview of how to track daily balances for ERC-20 tokens using the Dune app. The guide starts by introducing ERC-20 tokens and their contract standard set by the Ethereum Foundation. The main focus of the guide is to identify transfers and track daily balances using the Dune app.\n\nThe guide provides a modular series of spells that can be used to track daily balances. The first spell is \"Reformatted transfers\" which reformats the data from the `erc20_ethereum.evt_Transfer` table. The second spell is \"Daily aggregation\" which aggregates the daily transfers. The third spell is \"Rolling sum\" which calculates the rolling sum of daily transfers. The final spell is \"Final daily balances\" which calculates the final daily balances for Ethereum ERC20 tokens.\n\nThe guide also includes a video that demonstrates how to find the `erc20_ethereum.evt_Transfer` table using the data explorer. The guide is focused on the app folder of the Dune app and provides examples of how to use the app to track daily balances for ERC-20 tokens.\n## Questions: \n 1. What is the purpose of the Dune table `erc20_ethereum.evt_Transfer` and how does it relate to blockchain data analysis?\n   \n   A blockchain SQL analyst might want to know more about the structure and contents of the `erc20_ethereum.evt_Transfer` table, as well as how it can be used to track daily balances of ERC-20 tokens. They may also want to know how this table is populated and updated over time.\n\n2. How do the modular spells in this app technical guide work together to provide a comprehensive analysis of ERC-20 token transfers?\n\n   A blockchain SQL analyst might be interested in understanding how the different spells in this guide fit together to provide a complete picture of daily balances for ERC-20 tokens. They may also want to know how these spells can be customized or adapted for different use cases.\n\n3. Are there any limitations or potential issues with using this app technical guide for blockchain data analysis?\n\n   A blockchain SQL analyst might want to know about any potential limitations or issues with using this app technical guide, such as data quality or accuracy concerns, or any assumptions or simplifications made in the analysis. They may also want to know about any potential performance or scalability issues when working with large datasets.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/contributing/examples/index.md"}}],["107",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/contributing/examples/reformatted.md)\n\n# Reformatted Transfers\n\nThis technical guide is focused on the `app` folder of the Dune Docs project and covers the reformatted transfers feature. The purpose of this feature is to make it easier to sum up transfers by munging the base table into a union of sent transactions and received transactions. \n\nThe guide explains that WETH requires special handling due to the additional functions of deposit and withdrawal. Therefore, `zeroex_ethereum.weth9_evt_deposit` is added as a source. The model is defined in a YAML file where the description, tests, and metadata are defined. Contributors are also tracked in this file. \n\nThe JINJA config block is used to define the alias for this view as `erc20`. Without this alias, the table name would default to the file name. The schema name for this view is defined in the `dbt_project.yml` file in the root of the Spellbook project. Schema’s are defined there by the directory structure. The name of this view would be `transfers_ethereum.erc20` given the current structure.\n\nThe guide provides an SQL example of the `transfers_ethereum_erc20.sql` file, which includes four CTEs: `sent_transfers`, `received_transfers`, `deposited_weth`, and `withdrawn_weth`. These CTEs are used to select unique transaction IDs, wallet addresses, token addresses, event block times, and raw amounts for each transfer type. The `unique_tx_id`, `blockchain`, `wallet_address`, `token_address`, `evt_block_time`, and `amount_raw` columns are then selected from each CTE and unioned together to create the final table.\n\nThe `transfers_ethereum_schema.yml` file is also provided as an example. This file includes metadata such as the blockchain, sector, project, contributors, tags, and description for the `transfers_ethereum_erc20` model. The `dbt_project.yml` file is also included as an example, which defines the schema and materialized view for the `transfers` and `ethereum` folders.\n\nOverall, this technical guide provides a detailed explanation of the reformatted transfers feature in the Dune Docs app. It covers the purpose of the feature, how it works, and provides examples of the SQL, YAML, and `dbt_project.yml` files used to implement it.\n## Questions: \n 1. What is the purpose of the dune docs app and how does it relate to blockchain SQL analysis?\n   \n   The app is a documentation platform for spells used in Dune Analytics, which is a platform for blockchain SQL analysis. Blockchain SQL analysts may use this app to understand the data models and schemas used in Dune Analytics.\n\n2. What is the purpose of the `transfers_ethereum_erc20` model and how is it defined?\n   \n   The `transfers_ethereum_erc20` model is used to track ERC20 token transfers on the Ethereum blockchain. It is defined in a YAML file and a SQL file, where the SQL file defines the logic for the model and the YAML file defines metadata such as the description, tests, and contributors.\n\n3. How does the app handle WETH deposits and withdrawals?\n   \n   The app handles WETH deposits and withdrawals by adding `zeroex_ethereum.weth9_evt_deposit` as a source and defining two SQL queries to handle deposited and withdrawn WETH. These queries are then combined with queries for sent and received transfers to create a union of all transfer types.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/contributing/examples/reformatted.md"}}],["108",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/contributing/examples/rolling-sum.md)\n\n# Rolling Sum of Daily Transfers\n\nThis section of the app technical guide covers the rolling sum window function applied to each daily transfer sum. The purpose of this query is to calculate the rolling sum of raw amounts of ERC20 tokens held after taking into account token decimals. The query is contained in the `transfers_ethereum_erc20_rolling_day.sql` file located in the `app` folder of the project. \n\nThe query selects the blockchain, day, wallet address, token address, symbol, last updated timestamp, recency index, and the rolling sum of the raw amount of ERC20 tokens held. The `transfers_ethereum_erc20_agg_day` reference is used to partition the data by token address and wallet address and order it by day. \n\nThe `transfers_ethereum_erc20_schema.yml` file in the `app` folder of the project contains the schema for the `transfers_ethereum_erc20_rolling_hour` table. The table includes columns for blockchain, hour, wallet address, token address, symbol, amount raw, amount, amount USD, updated at, and recency index. \n\nOverall, this section of the app technical guide provides information on how to calculate the rolling sum of raw amounts of ERC20 tokens held using a window function. It also includes the schema for the table that stores the results of this calculation.\n## Questions: \n 1. What is the purpose of the `rolling sum window function` in this app technical guide?\n    \n    The purpose of the `rolling sum window function` is to apply it to each daily transfer sum in order to calculate the rolling sum of raw amount of ERC20 token held.\n\n2. What is the significance of the `recency_index` column in the `transfers_ethereum_erc20_schema.yml` file?\n    \n    The `recency_index` column is an index of the most recent balance ascending, where `recency_index=1` is the wallet/contract pair's most recent balance.\n\n3. How does the `transfers_ethereum_erc20_rolling_hour` table differ from the `transfers_ethereum_erc20_agg_day` table?\n    \n    The `transfers_ethereum_erc20_rolling_hour` table calculates the rolling sum of raw amount of ERC20 token held after taking into account token decimals, while the `transfers_ethereum_erc20_agg_day` table does not.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/contributing/examples/rolling-sum.md"}}],["109",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/contributing/examples)\n\nThis folder contains a series of technical guides focused on the `app` folder of the Dune Docs project, specifically covering the process of tracking daily balances for Ethereum ERC-20 tokens. The guides provide detailed explanations of various features and functionalities, including reformatted transfers, daily aggregation, rolling sum, and final daily balances. These guides are essential for analysts who want to understand the inner workings of the Dune Docs project and how to use it effectively.\n\nThe `reformatted.md` guide explains the reformatted transfers feature, which simplifies the process of summing up transfers by creating a union of sent and received transactions. It covers the handling of WETH, the use of JINJA config blocks, and provides examples of the `transfers_ethereum_erc20.sql` and `transfers_ethereum_schema.yml` files.\n\nThe `daily-aggregation.md` guide covers the daily aggregation feature, which sums all transfers for the day. It explains the incremental nature of the feature, the use of merge strategies, and the concept of refs. The guide also provides examples of the `transfers_ethereum_erc20_agg_day.sql` file and the `transfers_ethereum_schema.yml` file.\n\nThe `rolling-sum.md` guide focuses on the rolling sum window function applied to each daily transfer sum. It explains how to calculate the rolling sum of raw amounts of ERC20 tokens held, using the `transfers_ethereum_erc20_rolling_day.sql` file. The guide also includes the schema for the `transfers_ethereum_erc20_rolling_hour` table, as found in the `transfers_ethereum_erc20_schema.yml` file.\n\nThe `final-day-balance.md` guide covers the Final Daily Balance feature, which provides a comprehensive view of daily Ethereum ERC20 token balances, including price data and compliance checks. It explains the use of the `balances_ethereum_erc20_day.sql` file and the schema for the `balances_ethereum_erc20_day` table, as found in the `transfers_ethereum_schema.yml` file.\n\nLastly, the `index.md` guide provides an overview of the entire process of tracking daily balances for ERC-20 tokens using the Dune app. It introduces the concept of ERC-20 tokens and their contract standard, as well as the modular series of spells used to track daily balances.\n\nThese guides are useful for analysts who want to gain a deeper understanding of the Dune Docs project and its features. By following the examples provided in the guides, analysts can effectively track daily balances for ERC-20 tokens and make informed decisions based on the data.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/contributing/examples/summary.md"}}],["110",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/contributing/index.md)\n\n# Spellbook Technical Guide\n\nThis technical guide is focused on the Spellbook feature of the Dune Docs project. The Spellbook is a collection of how-to guides for creating and using Spells, which are essentially SQL queries that can be saved and reused. \n\n## Casting a Spell from scratch\n\nThis section provides a link to a guide on how to add a Spell to the Spellbook. The guide is located in the `contributing/Adding A Spell` folder and is intended for users who want to learn by doing. The guide provides step-by-step instructions on how to create a new Spell and add it to the Spellbook.\n\n## Spellbook on GitHub\n\nThis section provides a link to the Spellbook repository on GitHub. Users who want to take a look under the hood can find the source code for the Spellbook here. The repository contains a variety of how-to guides for creating Spells.\n\n## Video Guides\n\nThis section provides links to two video guides on how to use the Spellbook. The first video is a DuneCon workshop presented by Megan Heintz, a member of the Dune Team who came up with the name \"Spellbook\". The workshop provides an overview of the Spellbook's infrastructure and demonstrates how to migrate data to a Spell. The second video is a tutorial presented by Andrew Hong, who shows how to create a pair, manage liquidity, swap through pairs, and pull and transform data on Ethereum using Spells.\n\nOverall, this technical guide provides users with resources for learning how to use the Spellbook feature of the Dune Docs project. Users can follow step-by-step guides, explore the source code on GitHub, or watch video tutorials to learn how to create and use Spells.\n## Questions: \n 1. What is the purpose of the Spellbook app and how does it relate to blockchain technology?\n    \n    The app technical guide does not provide clear information on the purpose of the Spellbook app or its relation to blockchain technology, so a blockchain SQL analyst might have to do further research or seek clarification from the developers.\n\n2. Are there any security measures in place to protect user data and transactions within the app?\n\n    The app technical guide does not mention any security measures in place to protect user data and transactions, so a blockchain SQL analyst might have to investigate further or consult with the developers to ensure the app is secure.\n\n3. What programming languages and frameworks were used to develop the Spellbook app?\n\n    The app technical guide does not provide information on the programming languages and frameworks used to develop the Spellbook app, so a blockchain SQL analyst might have to do further research or consult with the developers to determine the technology stack.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/contributing/index.md"}}],["111",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/contributing)\n\nThe `contributing` folder in the Dune Docs project focuses on the process of contributing a new Spell to the Spellbook, which is an open-source dbt repository for creating and maintaining high-level blockchain data tables using SQL and Jinja templating. The guides in this folder provide detailed instructions on how to set up Spellbook dbt, decide on a Spell to cast, set up a file structure for SQL, schema, and source files, identify and define sources, define expectations with schema and tests, write a Spell as a SELECT statement, configure alias and materialization strategy, and make a pull request to become an Archwizard.\n\nFor example, the guide \"2-decide-on-a-Spell-to-cast.md\" helps users decide on a Spell to cast by providing three ways to decide on a Spell, including having an idea based on previous experience with Dune, checking out Spellbook bounties in Dework, or asking for suggestions in the #spellbook Discord channel. The guide also provides an example of creating a migration Spell, specifically translating the Keep3r network `view_job_log` abstraction from Dune's v1 database into a V2 Spell.\n\nAnother example is the guide \"6-write-your-spell-as-SELECT-statement.md\", which covers the process of writing a Spell as a SELECT statement in the Dune Docs project. The guide provides a step-by-step process of migrating from V1 abstraction to V2 Spell, replacing hard-coded references with JINJA templating, and testing the SQL code and fixing errors.\n\nThese guides are useful for analysts and developers who want to contribute to the Spellbook project by creating and maintaining high-level blockchain data tables. By following the instructions provided in these guides, users can ensure that their Spells are properly structured, tested, and integrated into the Spellbook project. This will ultimately help make blockchain data more transparent, accessible, and meaningful for the entire community.\n\nOverall, the guides in this folder provide a comprehensive explanation of how to contribute a new Spell to the Spellbook project, making it easier for users to create and maintain high-level blockchain data tables using SQL and Jinja templating. The guides are well-structured and include examples to help users understand the process and contribute effectively to the project.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/contributing/summary.md"}}],["112",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/index.md)\n\nThe app technical guide covers the topic of Spells, which are custom tables constructed and maintained by Dune and the community. The guide explains that Spells are available on Dune V2 and can be queried from both Spark SQL and Dune SQL V2 Query Engines. The guide also provides a link to the Spellbook GitHub repository, where all the Spellbook Spell tables can be found. \n\nThe guide then introduces the new Spellbook, which is a retooling of the existing abstractions repository and a first-in-class open-source analytics engineering tool called dbt. The guide explains that dbt allows for the writing and management of unit tests to spot and prevent any issues in abstractions. It also allows for data integrity tests to be added with a single line in a YAML file. The guide highlights that dbt natively understands the dependencies between all models, which makes deploying and maintaining them easier. \n\nThe guide then goes on to explain Sector Spells, which are tables that take in data from multiple contracts and projects, standardize the data across them, and make it easy to query for this data and compare the metrics of different projects with each other. The guide notes that most of the sector dashboards depend on sector spells and that projects can easily get their data into these dashboards by making a pull request to the public GitHub repo. \n\nThe guide also explains Project Spells, which allow projects to assemble their data into one neat table that has all the data they need in one place. The main advantage of using Spells over just constructing a view is that Spells can deal with bigger amounts of data since they can run automatically in the background every few hours. \n\nFinally, the guide provides information on how to contribute to Spellbook and how to view available Spells. It notes that Spells are managed via the public Spellbook GitHub repository and that pull requests are welcome. The guide also provides a warning that the abstractions for V1 are no longer open for contributions and will be sunsetted with the V1 engine soon. \n\nOverall, the app technical guide provides a comprehensive overview of Spells, the Spellbook, and how to contribute to Spellbook. It is a useful resource for anyone looking to understand how to use Spells and how to contribute to the Spellbook project.\n## Questions: \n 1. What is the purpose of Spells in Dune and how are they maintained?\n- Spells are custom tables that cover a type of activity on the blockchain and are built and maintained by Dune and their community.\n\n2. What is the difference between Sector Spells and Project Spells?\n- Sector Spells standardize data from multiple contracts and projects, making it easy to query and compare metrics, while Project Spells allow projects to assemble their data into one table and deal with larger amounts of data automatically.\n\n3. What is dbt and how does it improve the process of creating Spells?\n- dbt is an open-source analytics engineering tool that injects classical software engineering practices into writing SQL, allowing for the creation and management of unit tests and easy addition of data integrity tests. It also understands the dependencies between all models, making deploying and maintaining Spells more efficient.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/index.md"}}],["113",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook)\n\nThe `spellbook` folder in the Dune Docs project focuses on the concept of Spells, which are custom tables constructed and maintained by Dune and the community. These tables are designed to make it easier for users to query and analyze blockchain data. The folder contains a main guide, `index.md`, which provides a comprehensive overview of Spells, the Spellbook, and how to contribute to the project. Additionally, there are two subfolders, `contributing` and `top tables`, which contain more specific guides on contributing new Spells and working with various data tables.\n\nThe `index.md` guide introduces Spells and the Spellbook, explaining their benefits and how they can be used with Dune V2 and Spark SQL. It also covers Sector Spells and Project Spells, which standardize data across multiple contracts and projects, making it easier to compare metrics and assemble data into one neat table. This guide is useful for anyone looking to understand how to use Spells and contribute to the Spellbook project.\n\nThe `contributing` subfolder contains guides that focus on the process of contributing a new Spell to the Spellbook. These guides provide detailed instructions on setting up Spellbook dbt, deciding on a Spell to cast, setting up a file structure, defining sources and expectations, writing a Spell as a SELECT statement, and making a pull request. For example, the guide \"6-write-your-spell-as-SELECT-statement.md\" covers the process of writing a Spell as a SELECT statement, migrating from V1 abstraction to V2 Spell, and testing the SQL code. These guides are useful for analysts and developers who want to contribute to the Spellbook project by creating and maintaining high-level blockchain data tables.\n\nThe `top tables` subfolder contains technical guides for various features and tables related to the Dune Docs project. These guides provide detailed explanations and examples for working with different aspects of the project, such as decentralized exchange trades, labels, NFT trades, token prices, and token metadata. For instance, the `dex.trades.md` guide covers the Dex.Trades app, which is a decentralized exchange aggregator that collects data from multiple DEX platforms into one simple table. This guide is useful for anyone looking to work with decentralized exchanges and aggregate data across multiple DEX platforms.\n\nOverall, the `spellbook` folder in the Dune Docs project provides a comprehensive explanation of Spells, the Spellbook, and how to contribute to the project. It is a valuable resource for analysts and developers who want to create and maintain high-level blockchain data tables using SQL and Jinja templating, making blockchain data more transparent, accessible, and meaningful for the entire community.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/summary.md"}}],["114",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/top tables/dex.trades.md)\n\n# Dex.Trades App Technical Guide\n\nThe Dex.Trades app is a decentralized exchange aggregator that collects data from multiple DEX platforms into one simple table. This guide provides an overview of the app and its features.\n\n## Overview\n\nDecentralized exchanges are the backbone of the DeFi industry, allowing users to swap any native (ETH) or ERC-20 token for any ERC-20 token through smart contracts. However, with so many decentralized exchanges available, it can be challenging to work with the smart contract data for all of them. Dex.Trades solves this problem by standardizing and normalizing trading data across virtually all relevant decentralized exchanges.\n\n## Column Data\n\nThe Dex.Trades table contains the following columns:\n\n- `block_time`: The timestamp of the block that included this transaction.\n- `token_a_symbol`: The symbol of one of the two tokens that got traded.\n- `token_b_symbol`: The symbol of one of the two tokens that got traded.\n- `token_a_amount`: The amount of token A that got traded.\n- `token_b_amount`: The amount of token B that got traded.\n- `project`: The DEX on which this trade was executed.\n- `version`: Which version of the DEX got used?\n- `blockchain`: Which blockchain did this occur on?\n- `taker`: Which contract called the DEX contract?\n- `maker`: In some special cases, there actually is a counterparty to transactions, and this party will get displayed here if applicable.\n- `token_a_amount_raw`: The raw amount of token A that got traded.\n- `token_b_amount_raw`: The raw amount of token B that got traded.\n- `usd_amount`: The USD value of this trade.\n- `token_a_address`: The ERC-20 token contract address of token A.\n- `token_b_address`: The ERC-20 token contract address of token B.\n- `exchange_contract_address`: The address of the decentralized exchange contract that made this trade possible.\n- `tx_hash`: The hash of the transaction that contained this trade.\n- `tx_from`: Which address initiated this transaction?\n- `tx_to`: What was the first smart contract that got called during this tx?\n- `trace_address`: Which position in the graph tree does the execution of the trade have?\n- `evt_index`: This logs index position in the block (cumulative amount of logs ordered by execution).\n- `trade_id`: Just for database magic.\n\n## Conclusion\n\nThe Dex.Trades app is an essential tool for anyone looking to work with decentralized exchanges. By aggregating data across multiple DEX platforms into one simple table, Dex.Trades makes it easy to query for trading data for your favorite tokens without having to deal with all of the different DEX smart contracts yourself. The scripts that generate the table can be found in the public Github repo.\n## Questions: \n 1. What is the purpose of dex.trades and how does it work?\n- Answer: dex.trades is a table that standardizes and normalizes trading data across multiple decentralized exchanges, making it easier to query for trading data for different tokens without having to deal with different DEX smart contracts. It works by aggregating data from various DEX platforms into one simple table.\n\n2. What specific data is included in the dex.trades table?\n- Answer: The dex.trades table includes data such as the timestamp of the block that included the transaction, the symbols and amounts of the tokens traded, the DEX on which the trade was executed, the blockchain on which it occurred, the contract addresses involved, and the USD value of the trade.\n\n3. Where can the scripts that generate the dex.trades table be found?\n- Answer: The scripts that generate the dex.trades table can be found in the public github repo at https://github.com/duneanalytics/spellbook/tree/master/ethereum/dex.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/top tables/dex.trades.md"}}],["115",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/top tables/labels.md)\n\n# Labels\n\nThe Labels technical guide is a feature on Dune that allows users to add, update, and query labels for any address. The guide explains what labels are, how to add them, and how to use them. \n\nA label is a piece of metadata about an address, a tag, or metadata. It comes in the form of a key-value pair. The key is the label type, and the value is the label name. Users can browse addresses and labels on the labels page. Labels on Dune are open-ended and crowd-sourced, meaning users are free to come up with new types and label names. \n\nThe guide provides examples of what users can do with labels, such as labeling all addresses that used a certain dapp, labeling all addresses that hold a certain amount of a token, labeling all addresses that use a dapp more than X times per month, and labeling all addresses that sent money to Binance. Users can also do more novel and involved things around user patterns like who did arbitrage trades or profited from flash loans and so much more.\n\nThe Labels table stores labels in the new `labels.labels` table, which has the following schema: `id`, `address`, `name`, `blockchain`, `author`, `source`, `updated_at`, `label_type`, and `model_name`. \n\nThe guide also provides a warning that the Using Labels section is currently under construction. \n\nOverall, the Labels technical guide provides a comprehensive overview of the Labels feature on Dune, including what labels are, how to add them, and how to use them. It also provides examples of what users can do with labels and explains how labels are stored in the Labels table.\n## Questions: \n 1. What is the purpose of the Labels feature on Dune?\n- The Labels feature on Dune allows users to add, update, and query labels for any address, providing metadata about an address in the form of a key-value pair.\n\n2. How are labels created on Dune?\n- Labels on Dune are open-ended and crowd-sourced, meaning users are free to come up with both new types and label names. Labels can be added using Dune queries, which can be used to label addresses based on various criteria such as dapp usage, token holdings, and more.\n\n3. What is the schema of the `labels.labels` table?\n- The `labels.labels` table stores labels and has columns for the label ID, address, name, blockchain, author, source, updated_at, label_type, and model_name.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/top tables/labels.md"}}],["116",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/top tables/nft.trades.md)\n\nThe `nft.trades` technical guide is a documentation of the effort to make NFT trading data easily available to everyone on Dune. The guide provides an overview of the `nft.trades` table, which aggregates and standardizes the data between different data platforms and provides auxiliary information and metadata all in one table. The guide explains how the dataset makes it extremely easy to query for any NFT related trading data across all indexed platforms. \n\nThe guide provides information on how the `nft.trades` table works, including Single Item Trade, Bundle Trade, and Aggregator Trade. The Single Item Trade occurs between a buyer and a seller, and they exchange an item that is uniquely identified by the combination of `nft_contract_address` and `token_id`. The Bundle Trade contains multiple items, and each of these items is uniquely identified through a combination of `nft_contract_address` and `token_id`. The Aggregator Trade is a trade in which a single trade transaction contains multiple items, and the approach is to unravel aggregator trades so that each row corresponds to a unique item that was traded, with its associated ID, price, collection, etc.\n\nThe guide also provides information on Platform and Royalty Fees. In the most recent version of `nft.trades`, information about the amount and percent of royalty fees in the original amount and in USD is available when this information was able to be retrieved. Royalty fees are going to the creator, and Platform fees are collected by the NFT platform. \n\nThe guide provides examples of queries that can be run on the `nft.trades` table, including All trades for a given NFT, Trades in the last 24 hour on a given platform, and Platform volumes in the last year. The guide also provides examples of dashboards that utilize parameters and look across the entire ecosystem.\n\nFinally, the guide provides a column data table that lists the column name, data type, and description of the `nft.trades` table. The guide also explains that the SQL code that processes the data for every marketplace is open source and available in their GitHub repository. Everyone can review the code, make pull requests, and submit code to add more marketplaces.\n## Questions: \n 1. What platforms are currently indexed by nft.trades?\n- OpenSea, Rarible, SuperRare, CryptoPunks, Foundation, and LooksRare are currently indexed by nft.trades.\n\n2. What metadata is provided about the traded NFT?\n- The metadata provided about the traded NFT includes nft_project_name and erc_standard.\n\n3. Can a blockchain SQL analyst add their own aggregator platform to the nft.trades table?\n- Yes, a blockchain SQL analyst can make a pull request to add their own aggregator platform to the nft.trades table.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/top tables/nft.trades.md"}}],["117",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/top tables/prices.md)\n\n# Prices\n\nThis technical guide covers the `Prices` feature of the Dune Docs project. The `Prices` feature allows users to get the price of almost all relevant ERC20 tokens. The data is pulled from the Coinpaprika API and the price is the volume-weighted price based on real-time market data, translated to USD.\n\nThe guide provides two tables for getting prices: `prices.usd` and `prices_from_dex_data`. The `prices.usd` table supports a range of ERC20 tokens. If the token you desire is not listed in this table, you can make a pull request to the GitHub repository. The `prices_from_dex_data` table creates price feeds based on decentralized exchange trading data. This table covers much more assets than `prices.usd`, since it covers all assets that are traded on any of the decentralized exchanges that are indexed in `dex.trades`. However, this table is very resource-intensive and can only be updated every few hours. Also, the resolution is only hourly, so if you need minutely prices, you should refer to `prices.usd`.\n\nThe guide provides a detailed explanation of how the `prices_from_dex_data` table works. The script generates median hourly prices based on data from decentralized exchanges found in `dex.trades`. It assigns asset prices based on a trading pair which has a price feed in `prices.usd`. For example, if the $SPELL/ETH pool is used, the $ETH price is contained in `prices.usd`, but the $SPELL price is not. In order to get the $SPELL price, the script will dynamically calculate the price of $SPELL based on the price of $ETH that was exchanged for it. The guide provides an example of how this calculation is done.\n\nThe guide also highlights known issues with the `prices_from_dex_data` table. In rare cases, the script will generate price feeds that are based on illiquid pairs and therefore report wrong data. This happens when all liquid trading pools of this token do not have a price feed in `prices.usd`. The guide provides an example of how this issue can occur and how to manually construct a price feed in such cases.\n\nOverall, this technical guide provides a comprehensive explanation of the `Prices` feature of the Dune Docs project, including how to use the `prices.usd` and `prices_from_dex_data` tables, how the `prices_from_dex_data` table works, and known issues with the table.\n## Questions: \n 1. What is the source of the price data for the decentralized exchange trading data table?\n- The source of the price data for the decentralized exchange trading data table is the trading data from decentralized exchanges found in `dex.trades`.\n\n2. What is the resolution for the `prices.usd` table?\n- The resolution for the `prices.usd` table is by minute.\n\n3. What are the known issues with the script that generates median hourly prices based on data from decentralized exchanges found in `dex.trades`?\n- In rare cases, the script will generate price feeds that are based on illiquid pairs and therefore report wrong data. This happens when all liquid trading pools of a token do not have a price feed in `prices.usd`. In cases like this, a manual price feed construction is required.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/top tables/prices.md"}}],["118",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/top tables)\n\nThis folder contains technical guides for various features and tables related to the Dune Docs project, specifically focusing on data tables and their usage. These guides provide detailed explanations, examples, and use cases for working with different aspects of the project, such as decentralized exchange trades, labels, NFT trades, token prices, and token metadata.\n\nFor example, the `dex.trades.md` guide covers the Dex.Trades app, which is a decentralized exchange aggregator that collects data from multiple DEX platforms into one simple table. This guide provides an overview of the app, its features, and the columns in the Dex.Trades table. This guide is useful for anyone looking to work with decentralized exchanges and aggregate data across multiple DEX platforms.\n\nThe `labels.md` guide focuses on the Labels feature, which allows users to add, update, and query labels for any address. This guide explains what labels are, how to add them, and how to use them. It also provides examples of what users can do with labels and explains how labels are stored in the Labels table.\n\nThe `nft.trades.md` guide documents the effort to make NFT trading data easily available on Dune. It provides an overview of the `nft.trades` table, which aggregates and standardizes the data between different data platforms and provides auxiliary information and metadata all in one table. This guide is useful for anyone looking to query NFT related trading data across all indexed platforms.\n\nThe `prices.md` guide covers the Prices feature,","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/top tables/summary.md"}}],["119",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables/spellbook/top tables/tokens.md)\n\n# Tokens\n\nThis section of the app technical guide for the Dune Docs project covers token transfers and metadata. The guide is aimed at individuals who will be working with fungible (ERC20) and non-fungible (ERC721 and ERC1155) tokens in their analysis. The guide provides information on two metadata tables and two transfer tables that are essential for working with tokens.\n\nThe metadata tables include:\n\n1. `tokens.erc20`: This table contains useful information such as the token `symbol` and the `decimals` for any given `contract_address`. The `decimals` information is needed to get the actual amount from raw amounts in on-chain data.\n\n2. `tokens.nft`: This table contains the collection `name` and `symbol` for any given `contract_address`.\n\nThese tables are usually joined on `contract_address` at the end of a query to make everything more human-readable.\n\nThe transfer tables include:\n\n1. `erc20_ethereum.evt_Transfer`: This table contains all transfer events for every ERC20 token. The guide provides a link to a video guide that explains how to get ERC20 balances, mints, and burns.\n\n2. `nft.transfers`: This table contains all transfer events for every ERC721 or ERC1155 token. The guide provides a link to a guide that explains how to leverage this table to find NFT balances, transfers, and mints.\n\nIf you're looking for information on how to calculate native token balances like Ethereum (ETH) balances, the guide provides a link to another guide that covers this topic.\n\nOverall, this section of the app technical guide provides essential information for individuals working with tokens in their analysis. The metadata and transfer tables are crucial for understanding token transfers and metadata, and the guide provides links to additional resources for further learning.\n## Questions: \n 1. What types of tokens does this app support?\n- The app supports both fungible (erc20) and nonfungible (erc721 and erc1155) tokens.\n\n2. What information can be found in the metadata tables?\n- The metadata tables contain information such as the token symbol, decimals, collection name, and symbol for a given contract address.\n\n3. What transfer events can be found in the transfer tables?\n- The transfer tables contain all transfer events for erc20, erc721, and erc1155 tokens, and can be used to find balances, transfers, mints, and burns.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/spellbook/top tables/tokens.md"}}],["120",{"pageContent":"[View code on GitHub](https://dune.com/docs/data-tables)\n\nThe Decoded Tables guide in the `docs/data-tables/decoded` folder focuses on decoding smart contract activity into human-readable tables on the Dune platform. This guide is essential for analysts and developers who want to understand and access the decoded data of smart contracts, events, and function calls on the Dune platform.\n\nThe guide covers the following topics:\n\n1. **Call Tables**: This section explains how Dune parses all message calls and transactions made to smart contracts in their own tables. It provides information on how the tables are named and how they are created on an individual contract level or a class of contracts. It also highlights a common misconception about `pure`, `read`, or `constant` functions not being recorded in Dune.\n\n2. **Event Logs**: This section covers the concept of event logs in smart contracts and how they are decoded into tables named according to a specific schema. It provides examples of how to name tables for the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL) and how to look at event logs of a transaction in Etherscan.\n\n3. **Decoding Process**: This section explains how Dune uses the ABI (Application Binary Interface) for smart contracts and the interface standard for standardized token smart contracts (ERC20, ERC721, etc.) to create tables for each event and function defined in the smart contract's ABI. It provides an example of decoding an ERC20 transfer event log and how to understand decoded data.\n\n4. **Accessing Decoded Data**: This section provides examples of how to access decoded data for specific events and function calls using the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL). It also explains how to check if contracts are already decoded by querying the `[blockchain].contracts` tables or using a dashboard.\n\n5. **Which Tables to Use**: This section discusses which tables to use (events or calls) and provides queries to explore decoded contracts, such as seeing all projects with decoded data or checking for multiple instances of a contract.\n\nThis guide is useful for analysts who want to access and analyze decoded data from smart contracts, events, and function calls on the Dune platform. For example, an analyst might use this guide to understand how to access decoded data for a specific ERC20 token transfer event or how to explore all projects with decoded data on the platform. By understanding the decoding process and how to access the decoded data, analysts can gain valuable insights into smart contract activity and interactions on the Dune platform.","metadata":{"source":".autodoc/docs/markdown/docs/data-tables/summary.md"}}],["121",{"pageContent":"[View code on GitHub](https://dune.com/docs/index.md)\n\n# Dune Quickstart\n\nThe Dune Quickstart guide is an introduction to the Dune app and its features. The guide is divided into three sections, each covering a different aspect of the app. \n\nThe first section explains why it is important to learn how to use Dune. It highlights the challenges of understanding, ingesting, and aggregating blockchain data, and how Dune can help overcome these challenges. The section also mentions the benefits of using Dune, such as the ability to perform cross-context analysis and showcase work to a large audience. \n\nThe second section of the guide focuses on analyzing Web3 data, specifically DEX volumes. It provides an interactive walkthrough of how to use the `dex.trades` table to find and preview data, write and run a basic query on the Dune SQL engine, and create and format a stacked bar chart visualization. The section also explains the concept of spellbook tables and provides links to column descriptions and documentation for lower-level tables. \n\nThe third section of the guide provides resources and guides for learning SQL and blockchain basics. It includes links to beginner resources such as the Dune Official Getting Started Video Series, weekly Web3 SQL problems, and all Ethereum and SQL Basics. The section also provides links to pure SQL practice problems and encourages users to join the Dune community on Discord to learn together. \n\nThe guide concludes by providing information on how to hire expert freelancers to help with advanced analysis. It includes a link to a questionnaire that users can fill out to reach out to the pool of expert freelancers. \n\nOverall, the Dune Quickstart guide is a comprehensive introduction to the Dune app and its features. It provides users with the necessary information to get started with Dune and perform basic and advanced analysis of Web3 data.\n## Questions: \n 1. What kind of blockchain data can be analyzed using Dune?\n- The app technical guide mentions that Dune can be used to analyze data from various chains, including EVMs like Ethereum, Polygon, Goerli, and Optimism, and non-EVM chains like Solana and Bitcoin.\n\n2. What are spellbook tables and how are they different from raw and decoded tables?\n- The app technical guide explains that spellbook tables are abstracted tables put together by star analysts in the community, while raw and decoded tables are lower level tables. Raw tables are defined in the guide, but for decoded tables, one would need to refer to the protocol's documentation.\n\n3. How can one get help with Dune or hire an expert freelancer?\n- The app technical guide suggests filling out a questionnaire on bounties.dune.com to reach out to a pool of expert freelancers. If that doesn't yield results, posting the bounty on relevant social channels and spreading it in networks may help. Additionally, one can join the Dune community on Discord and participate in the beginners and query-questions channels.","metadata":{"source":".autodoc/docs/markdown/docs/index.md"}}],["122",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/aggregate.md)\n\nThe app technical guide covers aggregate functions, which operate on a set of values to compute a single result. It explains how to order and filter during aggregation, and provides examples for each. The guide also lists general aggregate functions, bitwise aggregate functions, map aggregate functions, approximate aggregate functions, statistical aggregate functions, and lambda aggregate functions.\n\nOrdering during aggregation can be specified using an `order-by-clause` within the aggregate function. Filtering during aggregation can be done using the `FILTER` keyword with a `WHERE` clause. Examples are provided for both ordering and filtering.\n\nThe guide then lists various aggregate functions, including:\n\n- General aggregate functions like `arbitrary(x)`, `array_agg(x)`, `avg(x)`, `bool_and(boolean)`, `bool_or(boolean)`, `count(x)`, `max(x)`, `min(x)`, and `sum(x)`.\n- Bitwise aggregate functions like `bitwise_and_agg(x)` and `bitwise_or_agg(x)`.\n- Map aggregate functions like `histogram(x)`, `map_agg(key, value)`, `map_union(x(K,V))`, `map_union_agg(x(K,V))`, `multimap_agg(key, value)`, and `multimap_union(x(K,V))`.\n- Approximate aggregate functions like `approx_distinct(x)`, `approx_most_frequent(x, k)`, `approx_percentile(x, percentage)`, `approx_set(x)`, and `numeric_histogram(buckets, value)`.\n- Statistical aggregate functions like `corr(x, y)`, `covar_pop(y, x)`, `covar_samp(y, x)`, `kurtosis(x)`, `regr_intercept(y, x)`, `regr_slope(y, x)`, `skewness(x)`, `stddev(x)`, `variance(x)`, and `var_pop(x)`.\n- Lambda aggregate functions like `reduce_agg(inputValue T, initialState S, inputFunction(S, T, S), combineFunction(S, S, S))`.\n\nEach function is accompanied by a brief description and its return type.\n## Questions: \n 1. **Question:** What is the behavior of aggregate functions when dealing with null values?\n\n   **Answer:** Except for `count`, `count_if`, `max_by`, `min_by`, and `approx_distinct`, all aggregate functions ignore null values and return null for no input rows or when all values are null. For example, `sum` returns null rather than zero, and `avg` does not include null values in the count. The `coalesce` function can be used to convert null into zero.\n\n2. **Question:** How can I specify the ordering of input values for aggregate functions that produce different results depending on the order?\n\n   **Answer:** You can specify the ordering by writing an `order-by-clause` within the aggregate function. For example: `array_agg(x ORDER BY y DESC)` or `array_agg(x ORDER BY x, y, z)`.\n\n3. **Question:** How can I remove rows from aggregation processing based on a condition?\n\n   **Answer:** You can use the `FILTER` keyword with a condition expressed using a `WHERE` clause. This is evaluated for each row before it is used in the aggregation and is supported for all aggregate functions. For example: `aggregate_function(...) FILTER (WHERE <condition>)`.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/aggregate.md"}}],["123",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/array.md)\n\nThe app technical guide covers various array functions and operators used in SQL. It starts with the explanation of subscript operator `[]` used to access an element of an array, followed by the concatenation operator `||` used to concatenate arrays or elements of the same type.\n\nThe guide then dives into a comprehensive list of array functions, such as:\n\n- `allmatch()`, `anymatch()`, `array_distinct()`, `array_except()`, `array_intersect()`, and `array_join()` for various array operations.\n- `array_max()`, `array_min()`, `array_position()`, `array_remove()`, and `array_sort()` for sorting and finding elements in arrays.\n- `array_union()`, `array_overlap()`, `cardinality()`, `concat()`, and `combinations()` for combining and manipulating arrays.\n- `contains()`, `contains_sequence()`, `element_at()`, `filter()`, `flatten()`, and `ngrams()` for searching and filtering arrays.\n- `none_match()`, `reduce()`, `repeat()`, `reverse()`, `sequence()`, `shuffle()`, `slice()`, `trim_array()`, `transform()`, `zip()`, and `zip_with()` for advanced array operations and transformations.\n\nEach function is explained with its syntax, description, and examples to demonstrate its usage. This guide serves as a reference for users working with arrays in SQL, providing a detailed understanding of various array functions and operators.\n## Questions: \n 1. **Question:** How does the `allmatch()` function handle empty arrays and NULL values in the input array?\n   **Answer:** The `allmatch()` function returns `true` if the array is empty. If the predicate function returns `NULL` for one or more elements and `true` for all other elements, the `allmatch()` function returns `NULL`.\n\n2. **Question:** What are the limitations of the `combinations()` function in terms of input array size and the value of `n`?\n   **Answer:** The `combinations()` function has a limitation where `n` must not be greater than 5, and the total size of sub-groups generated must be smaller than 100,000.\n\n3. **Question:** What is the difference between the `element_at()` function and the subscript operator `[]` when accessing elements in an array?\n   **Answer:** The `element_at()` function returns `NULL` when accessing an index larger than the array length, whereas the subscript operator `[]` would fail in such a case. Additionally, if the index is negative, `element_at()` accesses elements from the last to the first.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/array.md"}}],["124",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/binary.md)\n\nThis app technical guide covers the binary data type and its associated functions in the Dune Docs project. The guide provides a detailed explanation of the binary operators and functions that can be used to manipulate binary data. The guide is divided into several sections, each of which covers a specific function or operator.\n\nThe first section covers binary operators, specifically the `||` operator, which performs concatenation. The following sections cover binary functions, including `concat()`, which concatenates binary data, `length()`, which returns the length of binary data in bytes, `lpad()`, which left-pads binary data with a specified number of bytes, and `rpad()`, which right-pads binary data with a specified number of bytes. The `substr()` function is also covered, which returns a substring of binary data from a specified starting position and length. Finally, the `reverse()` function is covered, which returns binary data with the bytes in reverse order.\n\nThe guide also covers several encoding functions, including base64 encoding functions such as `from_base64()`, which decodes binary data from a base64 encoded string, and `to_base64()`, which encodes binary data into a base64 string representation. The guide also covers base64url encoding functions, base32 encoding functions, hex encoding functions, and integer and floating-point encoding functions.\n\nThe guide concludes with a section on hashing functions, including `crc32()`, which computes the CRC-32 of binary data, and several functions that compute various hash values, including MD5, SHA1, SHA256, SHA512, SpookyHashV2, and xxHash. The guide also covers HMAC functions, including `hmac_md5()`, `hmac_sha1()`, `hmac_sha256()`, and `hmac_sha512()`, which compute HMAC values for binary data with the given key.\n\nOverall, this guide provides a comprehensive overview of the binary data type and its associated functions in the Dune Docs project. It includes detailed explanations of each function and operator, as well as examples of how to use them.\n## Questions: \n 1. What is the purpose of the dune docs app and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the dune docs app or its relation to blockchain technology.\n\n2. Are there any specific hashing functions that are recommended for use in blockchain applications?\n- The app technical guide mentions xxhash64() as a recommended hashing function for general purpose hashing, as it is faster and produces a better quality hash than crc32().\n\n3. Can the app handle encoding and decoding of binary data in various formats commonly used in blockchain applications?\n- Yes, the app technical guide provides functions for base64, base32, hex, and integer encoding and decoding, which are commonly used in blockchain applications.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/binary.md"}}],["125",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/bitwise.md)\n\nThe Bitwise section of the app technical guide covers the different functions available for performing bitwise operations in Dune Docs. The guide provides examples of how to use each function and the expected output. The functions covered in this guide include bit_count(), bitwise_and(), bitwise_not(), bitwise_or(), bitwise_xor(), bitwise_left_shift(), bitwise_right_shift(), and bitwise_right_shift_arithmetic().\n\nThe bit_count() function counts the number of bits set in a given value, treated as a bits-bit signed integer in 2's complement representation. The function takes two arguments, the value to count the bits in and the number of bits in the value. The function returns a bigint. The guide provides examples of how to use the function with different values and bit sizes.\n\nThe bitwise_and() function returns the bitwise AND of two values in 2's complement representation. The function takes two arguments, the two values to perform the operation on. The function returns a bigint. The guide provides an example of how to use the function with two values and the expected output.\n\nThe bitwise_not() function returns the bitwise NOT of a value in 2's complement representation. The function takes one argument, the value to perform the operation on. The function returns a bigint. The guide provides examples of how to use the function with different values and the expected output.\n\nThe bitwise_or() function returns the bitwise OR of two values in 2's complement representation. The function takes two arguments, the two values to perform the operation on. The function returns a bigint. The guide provides an example of how to use the function with two values and the expected output.\n\nThe bitwise_xor() function returns the bitwise XOR of two values in 2's complement representation. The function takes two arguments, the two values to perform the operation on. The function returns a bigint. The guide provides an example of how to use the function with two values and the expected output.\n\nThe bitwise_left_shift() function returns the left shifted value of a given value. The function takes two arguments, the value to shift and the number of bits to shift by. The function returns the same type as the input value. The guide provides examples of how to use the function with different values and the expected output.\n\nThe bitwise_right_shift() function returns the logical right shifted value of a given value. The function takes two arguments, the value to shift and the number of bits to shift by. The function returns the same type as the input value. The guide provides examples of how to use the function with different values and the expected output.\n\nThe bitwise_right_shift_arithmetic() function returns the arithmetic right shifted value of a given value. The function takes two arguments, the value to shift and the number of bits to shift by. The function returns the same type as the input value. The guide provides examples of how to use the function with different values and the expected output.\n\nOverall, the Bitwise section of the app technical guide provides a comprehensive overview of the different functions available for performing bitwise operations in Dune Docs. The guide includes examples of how to use each function and the expected output, making it easy for developers to understand and implement these functions in their code.\n## Questions: \n 1. What is the purpose of the dune docs app and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the dune docs app or its relation to blockchain technology, so a blockchain SQL analyst may need to seek additional information elsewhere.\n\n2. Can the bitwise functions be used with binary data stored in a SQL database?\n- The app technical guide does not provide information on whether the bitwise functions can be used with binary data stored in a SQL database, so a blockchain SQL analyst may need to test this or seek additional information elsewhere.\n\n3. Are there any limitations to the size of the values that can be used with the bitwise functions?\n- The app technical guide provides information on the behavior of the bitwise functions when shifting values by 64 or more bits, but it does not provide information on any other limitations to the size of the values that can be used with the functions. A blockchain SQL analyst may need to test this or seek additional information elsewhere.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/bitwise.md"}}],["126",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/comparison.md)\n\n# Comparisons\n\nThis technical guide covers comparison operators, range operators, null operators, greatest and least functions, quantified comparison predicates, and pattern comparison. It is a part of the Dune Docs project.\n\n## Comparison Operators\n\nThis section covers the comparison operators in SQL. The table lists the operators and their descriptions. The operators include `<`, `>`, `<=`, `>=`, `=`, `<>`, and `!=`. \n\n## Range Operator: BETWEEN\n\nThis section covers the `BETWEEN` operator, which tests if a value is within a specified range. The section provides examples of how to use the operator and how to test if a value does not fall within the specified range. The section also covers how `NULL` is evaluated in a `BETWEEN` or `NOT BETWEEN` statement.\n\n## IS NULL and IS NOT NULL\n\nThis section covers the `IS NULL` and `IS NOT NULL` operators, which test whether a value is null. The section provides examples of how to use the operators and how `NULL` is evaluated.\n\n## IS DISTINCT FROM and IS NOT DISTINCT FROM\n\nThis section covers the `IS DISTINCT FROM` and `IS NOT DISTINCT FROM` operators, which treat `NULL` as a known value and guarantee either a true or false outcome even in the presence of `NULL` input. The section provides examples of how to use the operators and how `NULL` is evaluated.\n\n## GREATEST and LEAST\n\nThis section covers the `GREATEST` and `LEAST` functions, which return the largest and smallest of the provided values, respectively. The section provides examples of how to use the functions and how `NULL` is evaluated.\n\n## Quantified Comparison Predicates: ALL, ANY and SOME\n\nThis section covers the `ALL`, `ANY`, and `SOME` quantifiers, which can be used together with comparison operators. The section provides examples of how to use the quantifiers and the meanings of some quantifier and comparison operator combinations.\n\n## Pattern Comparison: LIKE\n\nThis section covers the `LIKE` operator, which can be used to compare values with a pattern. The section provides examples of how to use the operator and how to match characters using the `_` and `%` symbols. The section also covers how to escape the wildcard characters `_` and `%`.\n\nOverall, this technical guide provides a comprehensive overview of comparison operators, range operators, null operators, greatest and least functions, quantified comparison predicates, and pattern comparison in SQL. It is a useful resource for developers working on the Dune Docs project.\n## Questions: \n 1. What comparison operators are supported by this app and what are their descriptions?\n- The app supports comparison operators such as `<`, `>`, `<=`, `>=`, `=`, `<>`, and `!=`, and their descriptions are provided in a table format.\n\n2. How does the app handle NULL values in the BETWEEN and NOT BETWEEN operators?\n- The app evaluates NULL values in the BETWEEN and NOT BETWEEN operators using standard NULL evaluation rules applied to the equivalent expression.\n\n3. What is the syntax and meaning of the LIKE operator in this app?\n- The LIKE operator can be used to compare values with a pattern using symbols such as `_` and `%`, and it is typically used as a condition in WHERE statements. The app also provides examples of how to negate the result and escape wildcard characters.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/comparison.md"}}],["127",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/conditional.md)\n\nThe app technical guide covers the conditional expressions in SQL. The guide explains the standard SQL `CASE` expression, which has two forms: the \"simple\" form and the \"searched\" form. The \"simple\" form searches each `value` expression from left to right until it finds one that equals `expression`. The `result` for the matching `value` is returned. If no match is found, the `result` from the `ELSE` clause is returned if it exists, otherwise null is returned. The \"searched\" form evaluates each boolean `condition` from left to right until one is true and returns the matching `result`. If no conditions are true, the `result` from the `ELSE` clause is returned if it exists, otherwise null is returned.\n\nThe `IF` expression has two forms, one supplying only a `true_value` and the other supplying both a `true_value` and a `false_value`. The `IF` expression evaluates and returns `true_value` if `condition` is true, otherwise null is returned and `true_value` is not evaluated. The `IF` expression evaluates and returns `true_value` if `condition` is true, otherwise evaluates and returns `false_value`.\n\nThe `COALESCE` function returns the first non-null `value` in the argument list. Like a `CASE` expression, arguments are only evaluated if necessary.\n\nThe `NULLIF` function returns null if `value1` equals `value2`, otherwise returns `value1`.\n\nThe `TRY` function evaluates an expression and handles certain types of errors by returning `NULL`. In cases where it is preferable that queries produce `NULL` or default values instead of failing when corrupt or invalid data is encountered, the `TRY` function may be useful. To specify default values, the `TRY` function can be used in conjunction with the `COALESCE` function. The following errors are handled by `TRY`: Division by zero, Invalid cast or function argument, and Numeric value out of range.\n\nThe guide provides examples of each of the conditional expressions and how they can be used in SQL queries.\n## Questions: \n 1. What is the purpose of the `TRY` function and how is it used in SQL queries?\n    \n    The `TRY` function is used to evaluate an expression and handle certain types of errors by returning `NULL`. It can be used in conjunction with the `COALESCE` function to specify default values in cases where queries produce `NULL` or default values instead of failing when corrupt or invalid data is encountered.\n    \n2. How does the `CASE` expression work in SQL and what are its two forms?\n    \n    The `CASE` expression in SQL has two forms: the \"simple\" form and the \"searched\" form. The \"simple\" form searches each `value` expression from left to right until it finds one that equals `expression`, while the \"searched\" form evaluates each boolean `condition` from left to right until one is true and returns the matching `result`.\n    \n3. What is the purpose of the `COALESCE` function in SQL and how is it used?\n    \n    The `COALESCE` function in SQL returns the first non-null `value` in the argument list. It is used like a `CASE` expression, where arguments are only evaluated if necessary.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/conditional.md"}}],["128",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/conversion.md)\n\n# Conversions\n\nThis section of the app technical guide for the Dune Docs project covers how Trino implicitly converts numeric and character values to the correct type if such a conversion is possible. However, Trino will not convert between character and numeric types. For example, a query that expects a varchar will not automatically convert a bigint value to an equivalent varchar. When necessary, values can be explicitly cast to a particular type.\n\nThe section also covers conversion functions, which include `cast()` and `try_cast()`. The `cast()` function explicitly casts a value as a type. This can be used to cast a varchar to a numeric value type and vice versa. The `try_cast()` function is like `cast()`, but returns null if the cast fails.\n\nThe Formatting section covers the `format()` and `format_number()` functions. The `format()` function returns a formatted string using the specified format string and arguments. The format string follows the syntax specified in the Java documentation. The `format_number()` function returns a formatted string using a unit symbol.\n\nThe Miscellaneous section covers the `typeof()` function, which returns the name of the type of the provided expression. Examples of expressions include integers, strings, and doubles.\n\nOverall, this section of the app technical guide provides information on how to convert values between different types and how to format values in a specific way. The guide also provides examples of how to use each function.\n## Questions: \n 1. What is the purpose of the Dune Docs project?\n- The app technical guide does not provide information on the purpose of the Dune Docs project.\n\n2. Does the app use any blockchain technology?\n- The app technical guide does not provide information on whether the app uses any blockchain technology.\n\n3. How does the app handle data storage and retrieval?\n- The app technical guide does not provide information on how the app handles data storage and retrieval.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/conversion.md"}}],["129",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/datetime.md)\n\nThe app technical guide covers various date and time functions and operators that can be used to manipulate date and time data types. It is divided into several sections, each focusing on a specific aspect of date and time manipulation.\n\n1. **Date and time operators**: This section provides a table of various arithmetic operators that can be used to perform operations on date and time data types, such as addition and subtraction of intervals.\n\n2. **Time zone conversion**: This section explains how to use the `AT TIME ZONE` operator to set the time zone of a timestamp.\n\n3. **Date and time functions**: This section covers various functions that can be used to extract and manipulate date and time values, such as `current_date`, `current_time`, `current_timestamp`, and `current_timezone`.\n\n4. **Truncation function**: This section explains the `date_trunc` function, which can be used to truncate a timestamp to a specified unit, such as day, month, or year.\n\n5. **Interval functions**: This section covers functions that can be used to add or subtract intervals of time, such as `date_add` and `date_diff`.\n\n6. **Duration function**: This section explains the `parse_duration` function, which can be used to parse a string representing a duration into an interval.\n\n7. **Human-readable seconds**: This section covers the `human_readable_seconds` function, which can be used to format a double value of seconds into a human-readable string.\n\n8. **MySQL date functions**: This section covers functions that use a format string compatible with MySQL's `date_parse` and `str_to_date` functions, such as `date_format` and `date_parse`.\n\n9. **Java date functions**: This section covers functions that use a format string compatible with JodaTime's DateTimeFormat pattern format, such as `format_datetime` and `parse_datetime`.\n\n10. **Extraction function**: This section explains the `extract` function, which can be used to extract various fields from date and time values, such as year, month, and day.\n\n11. **Convenience extraction functions**: This section covers various convenience functions that can be used to extract specific fields from date and time values, such as `day`, `month`, and `year`.\n## Questions: \n 1. **Question:** How can I perform time zone conversion using this app technical guide?\n   **Answer:** You can use the `AT TIME ZONE` operator to set the time zone of a timestamp. For example, `SELECT timestamp '2012-10-31 01:00 UTC' AT TIME ZONE 'America/Los_Angeles';` will convert the given timestamp to the specified time zone.\n\n2. **Question:** What are the supported units for the `date_trunc` function?\n   **Answer:** The `date_trunc` function supports the following units: `second`, `minute`, `hour`, `day`, `week`, `month`, `quarter`, and `year`.\n\n3. **Question:** How can I parse a date string in ISO 8601 format using this app technical guide?\n   **Answer:** You can use the `from_iso8601_date()` function to parse an ISO 8601 formatted date string into a `date`. For example, `SELECT from_iso8601_date('2020-05-11');` will parse the given date string and return the date `2020-05-11`.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/datetime.md"}}],["130",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/decimal.md)\n\n# Decimal Functions and Operators\n\nThis technical guide provides information on how to use decimal literals, binary arithmetic decimal operators, comparison operators, and unary decimal operators in the Dune Docs project.\n\n## Decimal Literals\n\nTo define a decimal literal, use the `DECIMAL 'xxxxxxx.yyyyyyy'` syntax. The precision of a decimal type for a literal will be equal to the number of digits in the literal (including trailing and leading zeros). The scale will be equal to the number of digits in the fractional part (including trailing zeros). The table below shows examples of decimal literals and their corresponding data types:\n\n| Example literal                     | Data type     |\n| ----------------------------------- | -------------|\n| `DECIMAL '0'`                       | `DECIMAL(1)` |\n| `DECIMAL '12345'`                   | `DECIMAL(5)` |\n| `DECIMAL '0000012345.1234500000'`   | `DECIMAL(20, 10)` |\n\n## Binary Arithmetic Decimal Operators\n\nStandard mathematical operators are supported for decimal types. The table below explains precision and scale calculation rules for the result. Assuming `x` is of type `DECIMAL(xp, xs)` and `y` is of type `DECIMAL(yp, ys)`:\n\n| Operation          | Result type precision                            | Result type scale |\n|--------------------|--------------------------------------------------|-------------------|\n| `x + y` and `x -y` | `min(38,1 +max(xs, ys) + max(xp - xs, yp - ys))` | `max(xs, ys)`     |\n| `x * y`            | `min(38, xp + yp)`                               | `xs + ys`         |\n| `x / y`            | `min(38, xp + ys + max(0, ys-xs))`               | `max(xs, ys)`     |\n| `x % y`            | `min(xp - xs, yp - ys) + max(xs, bs)`            | `max(xs, ys)`     |\n\nIf the mathematical result of the operation is not exactly representable with the precision and scale of the result data type, then an exception condition is raised: `Value is out of range`. When operating on decimal types with different scale and precision, the values are first coerced to a common super type. For types near the largest representable precision (38), this can result in \"Value is out of range\" errors when one of the operands doesn't fit in the common super type. For example, the common super type of decimal(38, 0) and decimal(38, 1) is decimal(38, 1), but certain values that fit in decimal(38, 0) cannot be represented as a decimal(38, 1).\n\n## Comparison Operators\n\nAll standard comparison operators work for the decimal type.\n\n## Unary Decimal Operators\n\nThe `-` operator performs negation. The type of result is the same as the type of the argument.\n\nThis guide provides a clear understanding of how to use decimal literals, binary arithmetic decimal operators, comparison operators, and unary decimal operators in the Dune Docs project. The examples provided in the guide help to illustrate how to use these features in practice.\n## Questions: \n 1. What is the purpose of the Dune Docs project and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the Dune Docs project or its relation to blockchain technology.\n\n2. Can the Decimal functions and operators be used with SQL databases commonly used in blockchain technology such as MySQL or PostgreSQL?\n- The app technical guide does not specify which SQL databases are compatible with the Decimal functions and operators.\n\n3. Are there any limitations or performance considerations when using the Decimal functions and operators with large datasets or complex calculations in a blockchain application?\n- The app technical guide does not provide information on limitations or performance considerations when using the Decimal functions and operators in a blockchain application.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/decimal.md"}}],["131",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/hyperloglog.md)\n\n# HyperLogLog Functions\n\nThis technical guide is focused on the `app` folder of the Dune Docs project and covers the implementation of the `approx_distinct` function using the HyperLogLog data structure in Trino. The guide provides an overview of the data structures, serialization, and functions used in the implementation.\n\n## Data Structures\n\nTrino implements HyperLogLog data sketches as a set of 32-bit buckets that store a maximum hash. These sketches can be stored sparsely or densely. The HyperLogLog data structure starts as the sparse representation, switching to dense when it is more efficient. The P4HyperLogLog structure is initialized densely and remains dense for its lifetime.\n\n## Serialization\n\nData sketches can be serialized to and deserialized from `varbinary`. This allows them to be stored for later use. Combined with the ability to merge multiple sketches, this allows one to calculate `approx_distinct` of the elements of a partition of a query, then for the entirety of a query with very little cost.\n\n## Functions\n\nThe guide provides an overview of the following functions:\n\n### approx_set()\n\n**``approx_set(x)``** → HyperLogLog\n\nReturns the `HyperLogLog` sketch of the input data set of `x`. This data sketch underlies `approx_distinct` and can be stored and used later by calling `cardinality()`.\n\n### cardinality()\n\n**``cardinality(hll)``** → bigint\n\nThis function performs `approx_distinct` on the data summarized by the `hll` HyperLogLog data sketch.\n\n### empty_hll()\n\n**``empty_hll()``** → HyperLogLog\n\nReturns an empty `HyperLogLog`.\n\n### merge()\n\n**``merge(hyperloglog)``** → HyperLogLog\n\nReturns the `HyperLogLog` of the aggregate union of the individual `hll` HyperLogLog structures.\n\nThe guide also provides an example of how to use these functions to calculate weekly or monthly unique users by combining daily unique users using `approx_set()` and `merge()`. The example also shows how to store the `HyperLogLog` sketch in `varbinary` format and use `cardinality()` to calculate the approximate distinct count. \n\nOverall, this guide provides a comprehensive overview of the HyperLogLog functions used in Trino and how they can be used to efficiently calculate approximate distinct counts.\n## Questions: \n 1. What is the advantage of using HyperLogLog data sketches for approximating distinct values in Trino? \n   \n   Answer: A blockchain SQL analyst might want to know the advantage of using HyperLogLog data sketches in Trino for approximating distinct values. The app technical guide explains that HyperLogLog data sketches are implemented as a set of 32-bit buckets that store a maximum hash, and they can be stored sparsely or densely, which makes them more efficient. \n\n2. How can data sketches be serialized and deserialized in Trino? \n\n   Answer: A blockchain SQL analyst might want to know how data sketches can be serialized and deserialized in Trino. The app technical guide explains that data sketches can be serialized to and deserialized from `varbinary`, which allows them to be stored for later use. \n\n3. What are some use cases of `approx_distinct` with `GROUPING SETS` that can be converted to use `HyperLogLog` in Trino? \n\n   Answer: A blockchain SQL analyst might want to know some use cases of `approx_distinct` with `GROUPING SETS` that can be converted to use `HyperLogLog` in Trino. The app technical guide explains that `approx_distinct` can be used to calculate the `HyperLogLog` for daily unique users, which allows weekly or monthly unique users to be calculated incrementally by combining the dailies.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/hyperloglog.md"}}],["132",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/index.md)\n\nThe app technical guide provides an overview of the built-in SQL functions and operators supported by Trino, which is the underlying data source for the DuneSQL project. The guide is divided into sections based on the type of function or operator, such as Aggregate, Array, Binary, Bitwise, Comparison, Conditional, Conversion, Date and time, Decimal, HyperLogLog, JSON, Lambda, Logical, Map, Math, Quantile digest, Regular expression, Set Digest, String, System, Table, Teradata, T-Digest, URL, UUID, varbinary, and Window.\n\nEach section provides a high-level purpose of the functions and operators, and how they can be used to implement complex functionality and behavior of the SQL executed by Trino. The guide also includes links to full alphabetical and topic lists of functions and operators, as well as a command to show all available functions, including custom functions, with their supported arguments and a short description.\n\nThe note at the beginning of the guide indicates that this section needs to be maintained by the DuneSQL team since they are implementing their own functions and operators and changing existing ones. This suggests that the guide is intended for developers working on the DuneSQL project who need to understand the built-in functions and operators supported by Trino and how they can be used to implement the desired functionality.\n\nFor example, a developer working on the DuneSQL project may need to use the Array functions to manipulate arrays of data, or the Date and time functions to perform calculations on dates and times. The guide provides a comprehensive list of functions and operators that can be used to achieve these tasks and more. Overall, the app technical guide serves as a valuable resource for developers working on the DuneSQL project who need to understand the built-in functions and operators supported by Trino.\n## Questions: \n 1. What is the purpose of DuneSQL and what underlying data sources does it operate on?\n- The app technical guide states that DuneSQL supports a wide range of built-in functions and operators and allows for implementation of complex functionality and behavior of SQL executed by Trino operating on underlying data sources. However, it does not specify what those underlying data sources are.\n\n2. Are there any limitations or restrictions on the use of custom functions in DuneSQL?\n- The note in the app technical guide mentions that the section on built-in functions and operators needs to be maintained by the team implementing custom functions and operators. A blockchain SQL analyst might want to know if there are any specific guidelines or restrictions on the use of custom functions in DuneSQL.\n\n3. How can a user find a specific function or operator in DuneSQL?\n- The app technical guide provides links to full alphabetical and topic-based lists of functions and operators, as well as a command to show all available functions. However, a blockchain SQL analyst might want to know if there are any additional search or filtering capabilities available to help locate a specific function or operator.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/index.md"}}],["133",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/lambda.md)\n\n# Lambda Expressions\n\nThis guide covers the use of lambda expressions in the Dune Docs project. Lambda expressions are anonymous functions that are passed as arguments to higher-order SQL functions. They are written with `->`. The guide provides examples of lambda expressions and their limitations. Most SQL expressions can be used in a lambda body, with the exception of subqueries and aggregations.\n\nThe guide provides examples of how to use lambda expressions in the Dune Docs project. The `transform` function can be used to obtain the squared elements of an array column or to safely cast the elements of an array to strings. Other columns can be captured as well within the lambda expression. The `any_match` function can be used to find the array elements containing at least one value greater than `100`. The `regexp_replace` function can be used to capitalize the first letter of a string.\n\nLambda expressions can also be applied in aggregation functions. The guide provides an example of the calculation of the sum of all elements of a column by making use of `reduce_agg`.\n\nOverall, this guide provides a comprehensive overview of the use of lambda expressions in the Dune Docs project. It covers the syntax of lambda expressions, their limitations, and provides examples of their use in various functions.\n## Questions: \n 1. What are lambda expressions in the context of this app and how are they used with SQL functions?\n- Lambda expressions are anonymous functions that are passed as arguments to higher-order SQL functions, and they are written with `->`. They can be used to manipulate array columns, cast elements to strings, and perform various calculations.\n\n2. What are the limitations of using lambda expressions in SQL?\n- Subqueries and aggregations are not supported in lambda bodies.\n\n3. Can lambda expressions be used in aggregation functions, and if so, how?\n- Yes, lambda expressions can be applied in aggregation functions such as `reduce_agg`, which can be used to calculate the sum of all elements in a column.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/lambda.md"}}],["134",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/list-by-topic.md)\n\nThis app technical guide provides a comprehensive list of functions organized by topic, such as aggregate, array, binary, bitwise, color, comparison, conditional, conversion, date and time, geospatial, hyperloglog, JSON, lambda, machine learning, map, math, quantile digest, regular expression, session, set digest, string, system, T-Digest, Teradata, URL, UUID, and window. Each topic section contains a list of related functions with brief descriptions and examples where appropriate.\n\nFor instance, the aggregate section covers functions like `approx_distinct`, `avg`, `count`, and `max`. The array section includes functions like `array_intersect`, `array_join`, and `array_sort`. The binary section covers functions such as `concat`, `crc32`, and `from_base64`. The guide also provides references to more detailed documentation for each topic, allowing users to explore each function in-depth.\n\nOverall, this guide serves as a valuable resource for users looking to understand and utilize the various functions available in the project app.\n## Questions: \n 1. **Question:** What are the specific use cases for the aggregate functions in the context of blockchain SQL analysis?\n   **Answer:** Aggregate functions can be used to perform calculations on a set of values, such as finding the average, sum, or count of specific data points in the blockchain. This can be helpful in analyzing trends, identifying patterns, and making data-driven decisions in the blockchain ecosystem.\n\n2. **Question:** How can the geospatial functions be applied to blockchain data analysis?\n   **Answer:** Geospatial functions can be used to analyze location-based data in the context of blockchain, such as tracking the geographical distribution of transactions, nodes, or users. This can provide insights into regional trends, network efficiency, and potential areas for growth or improvement in the blockchain network.\n\n3. **Question:** Are there any specific functions in the app technical guide that are tailored for blockchain data analysis, or do they all have general applicability?\n   **Answer:** The functions listed in the app technical guide are generally applicable to various types of data analysis, including blockchain. However, their usefulness in the context of blockchain analysis will depend on the specific data and use case being considered.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/list-by-topic.md"}}],["135",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/list.md)\n\nThis app technical guide provides a comprehensive list of functions and operators used in the project. The guide is organized alphabetically, with each letter header followed by a list of functions and operators starting with that letter.\n\nFor example, under the header `A`, you'll find functions like `abs`, `acos`, `ALL`, `all_match`, `AND`, `ANY`, `any_match`, `approx_distinct`, `approx_most_frequent`, `approx_percentile`, `approx_set`, `arbitrary`, `array_agg`, `array_distinct`, `array_except`, `array_intersect`, `array_join`, `array_max`, `array_min`, `array_position`, `array_remove`, `array_sort`, `array_union`, and `arrays_overlap`.\n\nEach function or operator is followed by a reference link, which provides more information about the specific function or operator. For instance, the `substring operator` reference link will provide more details on how to use the substring operator in the project.\n\nThe guide covers various sections of the project app, such as app, api, data-tables, query, and reference, as specified in the file path. By referring to this guide, users can quickly find the appropriate function or operator for their needs and learn how to apply them in the project app.\n## Questions: \n 1. **What specific functions are available for working with blockchain data in this app technical guide?**\n\n    The app technical guide provides a comprehensive list of functions and operators, but it does not specifically mention any functions tailored for blockchain data. A blockchain SQL analyst might need to use a combination of these functions to work with blockchain data.\n\n2. **Are there any functions or operators specifically designed for querying or analyzing smart contracts?**\n\n    The app technical guide does not mention any functions or operators explicitly designed for querying or analyzing smart contracts. However, a blockchain SQL analyst might be able to use the available functions and operators to analyze smart contract data.\n\n3. **How can I use the functions and operators in this app technical guide to analyze transaction data on a blockchain?**\n\n    While the app technical guide does not provide specific examples for analyzing transaction data on a blockchain, a blockchain SQL analyst can use the available functions and operators to create custom queries and analysis. For example, they can use mathematical operators, aggregation functions, and string manipulation functions to analyze transaction data and derive insights.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/list.md"}}],["136",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/logical.md)\n\n# Logical Operators\n\nThis section of the app technical guide for the Dune Docs project covers the logical operators used in SQL. The logical operators covered in this guide are `AND`, `OR`, and `NOT`. The guide provides a description of each operator and an example of how to use them.\n\n## Effect of NULL on Logical Operators\n\nThis section of the guide explains how `NULL` values affect the logical operators. The guide provides examples of how `NULL` values affect the result of an `AND` or `OR` comparison. If one or both sides of an `AND` comparison are `NULL`, the result may be `NULL`. If at least one side of an `OR` comparison is `TRUE`, the result is `TRUE`. The guide also provides a truth table that demonstrates how `NULL` values are handled in `AND` and `OR` comparisons.\n\nThe guide also explains that the logical complement of `NULL` is `NULL`. The guide provides an example of how to use the `NOT` operator with a `NULL` value and a truth table that demonstrates how `NULL` values are handled in `NOT` comparisons.\n\nOverall, this section of the app technical guide provides a comprehensive explanation of how logical operators work in SQL and how `NULL` values affect their behavior. The examples and truth tables provided in the guide make it easy to understand how to use these operators in practice.\n## Questions: \n 1. What is the purpose of this app and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the app or its relation to blockchain technology.\n\n2. Are there any security considerations related to the use of logical operators in SQL queries?\n- The app technical guide does not provide information on security considerations related to the use of logical operators in SQL queries.\n\n3. Can this app be integrated with blockchain databases that use SQL?\n- The app technical guide does not provide information on whether or not this app can be integrated with blockchain databases that use SQL.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/logical.md"}}],["137",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/map.md)\n\n# Map Functions and Operators\n\nThis technical guide is focused on the `app` folder of the Dune Docs project. It covers the use of map functions and operators in SQL. \n\nThe guide starts by explaining the subscript operator `[]`. This operator is used to retrieve the value corresponding to a given key from a map. An example is given to illustrate this. \n\nThe guide then goes on to explain various map functions that can be used in SQL. These functions include:\n\n- `cardinality()`: This function returns the cardinality (size) of the map `x`. An example is given to illustrate this.\n\n- `element_at()`: This function returns the value for a given `key`, or `NULL` if the key is not contained in the map. An example is given to illustrate this.\n\n- `map()`: This function returns an empty map or a map created using the given key/value arrays. Examples are given to illustrate this.\n\n- `map_from_entries()`: This function returns a map created from the given array of entries. An example is given to illustrate this.\n\n- `multimap_from_entries()`: This function returns a multimap created from the given array of entries. An example is given to illustrate this.\n\n- `map_entries()`: This function returns an array of all entries in the given map. An example is given to illustrate this.\n\n- `map_concat()`: This function returns the union of all the given maps. An example is given to illustrate this.\n\n- `map_filter()`: This function constructs a map from those entries of `map` for which `function` returns true. Examples are given to illustrate this.\n\n- `map_keys()`: This function returns all the keys in the map `x`.\n\n- `map_values()`: This function returns all the values in the map `x`.\n\n- `map_zip_with()`: This function merges the two given maps into a single map by applying `function` to the pair of values with the same key. Examples are given to illustrate this.\n\n- `transform_keys()`: This function returns a map that applies `function` to each entry of `map` and transforms the keys. Examples are given to illustrate this.\n\n- `transform_values()`: This function returns a map that applies `function` to each entry of `map` and transforms the values. Examples are given to illustrate this.\n\nOverall, this technical guide provides a comprehensive overview of map functions and operators in SQL. It explains each function in detail and provides examples to illustrate their use.\n## Questions: \n 1. What is the purpose of the `map()` function in this app and how is it used?\n   \n   The `map()` function is used to create an empty map or a map with key/value pairs. It can also be used with other functions like `map_filter()` and `map_zip_with()` to filter or merge maps based on certain conditions.\n\n2. How does the `transform_keys()` function work and what is its output format?\n   \n   The `transform_keys()` function applies a transformation function to each key in a map and returns a new map with the transformed keys and the original values. The output format is a map with the same value type as the input map, but with potentially different keys.\n\n3. Can the `map_concat()` function be used to merge maps with different value types?\n   \n   No, the `map_concat()` function can only be used to merge maps with the same key and value types. If the input maps have different value types, the function will return an error.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/map.md"}}],["138",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/math.md)\n\n# Mathematical functions and operators\n\nThis technical guide covers the mathematical functions and operators available in the Dune Docs project. The guide is divided into several sections, each of which covers a specific mathematical function or operator. \n\nThe first section covers mathematical operators, including addition, subtraction, multiplication, division, and modulus. \n\nThe second section covers mathematical functions, including `abs()`, `cbrt()`, `ceil()`, `ceiling()`, `degrees()`, `e()`, `exp()`, `floor()`, `ln()`, `log()`, `log2()`, `log10()`, `mod()`, `pi()`, `pow()`, `power()`, `radians()`, `round()`, `sign()`, `sqrt()`, `truncate()`, and `width_bucket()`. \n\nThe third section covers random functions, including `rand()`, `random()`, and `random(n)`. \n\nThe fourth section covers trigonometric functions, including `acos()`, `asin()`, `atan()`, `atan2()`, `cos()`, `cosh()`, `sin()`, `tan()`, and `tanh()`. \n\nThe fifth section covers floating point functions, including `infinity()`, `is_finite()`, `is_infinite()`, `is_nan()`, and `nan()`. \n\nThe sixth section covers base conversion functions, including `from_base()` and `to_base()`. \n\nThe seventh section covers statistical functions, including `cosine_similarity()`, `wilson_interval_lower()`, and `wilson_interval_upper()`. \n\nThe eighth section covers cumulative distribution functions, including `beta_cdf()`, `inverse_beta_cdf()`, `inverse_normal_cdf()`, and `normal_cdf()`. \n\nEach function is described in detail, including its input parameters and output format. Examples are provided where appropriate to illustrate how each function can be used. \n\nOverall, this guide provides a comprehensive overview of the mathematical functions and operators available in the Dune Docs project, making it a valuable resource for developers working on this project.\n## Questions: \n 1. What is the purpose of the dune docs app and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the dune docs app or its relation to blockchain technology.\n\n2. Are there any mathematical functions or operators that are specific to blockchain data analysis?\n- The app technical guide does not provide information on whether any of the mathematical functions or operators are specific to blockchain data analysis.\n\n3. Does the app technical guide provide information on how to integrate the mathematical functions and operators into a blockchain SQL database?\n- The app technical guide does not provide information on how to integrate the mathematical functions and operators into a blockchain SQL database.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/math.md"}}],["139",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/ml.md)\n\nThe app technical guide provides documentation for the machine learning plugin in the Dune Docs project. The plugin provides machine learning functionality as an aggregation function, enabling users to train Support Vector Machine (SVM) based classifiers and regressors for supervised learning problems. The guide covers the following topics:\n\n- Feature vector: To solve a problem with the machine learning technique, it is necessary to represent the data set with the sequence of pairs of labels and feature vectors. A feature vector is represented as a map-type value, whose key is an index of each feature, so that it can express a sparse vector. The guide provides an example of how to construct the feature from the existing numerical values using the `features()` function.\n\n- Classification: Classification is a type of supervised learning problem to predict the distinct label from the given feature vector. The guide provides an example of how to train a classification model using the `learn_classifier()` function and how to use the trained model to predict the label using the `classify()` function. The trained model can not be saved natively and needs to be passed in the format of a nested query.\n\n- Regression: Regression is another type of supervised learning problem, predicting continuous value, unlike the classification problem. The guide provides an example of how to create a model predicting `sepal_length` from the other 3 features using the `learn_regressor()` function and how to use the trained model to predict the target using the `regress()` function.\n\nThe guide also provides a list of machine learning functions available in the plugin, including `features()`, `learn_classifier()`, `learn_libsvm_classifier()`, `classify()`, `learn_regressor()`, `learn_libsvm_regressor()`, and `regress()`. Each function is described in detail, including its input and output parameters. The guide also notes that the machine learning functions are not optimized for distributed processing, and the capability to train large data sets is limited by the execution of the final training on a single instance. \n\nOverall, the guide provides a comprehensive overview of the machine learning plugin in the Dune Docs project, including how to use the plugin to solve classification and regression problems and the available machine learning functions.\n## Questions: \n 1. What is the limitation of the machine learning functions in terms of distributed processing?\n- The machine learning functions are not optimized for distributed processing, limiting the capability to train large data sets due to the execution of the final training on a single instance.\n\n2. What type of machine learning problems can be solved using this app?\n- This app can solve supervised learning problems, specifically classification and regression problems.\n\n3. What is the algorithm used for training the models internally?\n- The models are trained internally using libsvm.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/ml.md"}}],["140",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/qdigest.md)\n\n# Quantile Digest Functions\n\nThis technical guide covers the implementation of quantile digest functions in the Dune Docs project. A quantile digest is a data sketch that stores approximate percentile information. The Trino type for this data structure is called `qdigest`. The guide explains the data structures and functions used in the implementation of quantile digest functions.\n\n## Data Structures\n\nThe `qdigest` data structure takes a parameter that must be one of `bigint`, `double`, or `real`, which represent the set of numbers that may be ingested by the `qdigest`. They may be merged without losing precision, and for storage and retrieval, they may be cast to/from `VARBINARY`.\n\n## Functions\n\nThe guide explains the following functions used in the implementation of quantile digest functions:\n\n### merge()\n\n**``merge(qdigest)``** → qdigest\n\nMerges all input `qdigest`s into a single `qdigest`.\n\n### values_at_quantile()\n\n**``value_at_quantile(qdigest(T), quantile)``** → T\n\nReturns the approximate percentile value from the quantile digest given the number `quantile` between 0 and 1.\n\n### values_at_quantiles()\n\n**``values_at_quantiles(qdigest(T), quantiles)``** → array(T)\n\nReturns the approximate percentile values as an array given the input quantile digest and array of values between 0 and 1 which represent the quantiles to return.\n\n### qdigest_agg()\n\n**``qdigest_agg(x)``** → qdigest(same as x)\n\nReturns the `qdigest` which is composed of all input values of `x`.\n\n**``qdigest_agg(x, w)``** → qdigest(same as x)**\n\nReturns the `qdigest` which is composed of all input values of `x` using the per-item weight `w`.\n\n**``qdigest_agg(x, w, accuracy)``** → qdigest(same as x)**\n\nReturns the `qdigest` which is composed of all input values of `x` using the per-item weight `w` and maximum error of `accuracy`. `accuracy` must be a value greater than zero and less than one, and it must be constant for all input rows.\n\nIn summary, this guide provides an overview of the data structures and functions used in the implementation of quantile digest functions in the Dune Docs project. It explains the purpose of each function and how it applies to the project app. The guide also provides examples of the usage of each function.\n## Questions: \n 1. What is the purpose of the dune docs app and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the dune docs app or its relation to blockchain technology, so a blockchain SQL analyst may need to seek additional information from other sources.\n\n2. Can the `qdigest` data structure be used to store and retrieve data from a blockchain database?\n- The app technical guide does not provide information on whether the `qdigest` data structure can be used with a blockchain database, so a blockchain SQL analyst may need to experiment with the data structure or consult with other experts in the field.\n\n3. What is the maximum error of `accuracy` in the `qdigest_agg()` function and how does it affect the precision of the results?\n- The app technical guide states that `accuracy` must be a value greater than zero and less than one, but it does not provide information on how this value affects the precision of the results, so a blockchain SQL analyst may need to conduct further research or experimentation to determine the optimal value for their use case.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/qdigest.md"}}],["141",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/regexp.md)\n\nThe app technical guide covers the usage of regular expression functions in the Dune Docs project. The guide explains the syntax used in the Java pattern and highlights the differences in the implementation of the regular expression functions in the project. The guide provides examples of how to use each function in the project.\n\nThe guide covers the following functions:\n\n- regexp_count(): Returns the number of occurrences of a pattern in a string.\n- regexp_extract_all(): Returns an array of all substrings that match a pattern in a string.\n- regexp_extract(): Returns the first substring that matches a pattern in a string.\n- regexp_like(): Determines if a pattern is contained within a string.\n- regexp_position(): Returns the index of the nth occurrence of a pattern in a string.\n- regexp_replace(): Replaces substrings that match a pattern in a string with a replacement string or a function.\n- regexp_split(): Splits a string using a pattern and returns an array.\n\nThe guide also explains the differences in the implementation of Unicode character classes, blocks, and categories in the project. The guide provides examples of how to use each function with different parameters.\n\nOverall, the app technical guide provides a comprehensive explanation of how to use regular expression functions in the Dune Docs project. The guide is useful for developers who want to implement regular expressions in their code.\n## Questions: \n 1. What is the syntax used for regular expressions in this app?\n- The app uses Java pattern syntax for regular expressions, with a few exceptions.\n\n2. Are there any limitations or unsupported features for regular expressions in this app?\n- Yes, there are several limitations and unsupported features for regular expressions in this app, such as incorrect handling of boundaries for a non-spacing mark without a base character and lack of support for surrogate pairs.\n\n3. What are the available functions for working with regular expressions in this app?\n- The available functions for working with regular expressions in this app include regexp_count, regexp_extract_all, regexp_extract, regexp_like, regexp_position, regexp_replace, and regexp_split.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/regexp.md"}}],["142",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/setdigest.md)\n\n# Set Digest functions\n\nThis guide explains the Set Digest functions offered by Trino, which are used to estimate the Jaccard similarity coefficient between two sets. The MinHash technique is used to achieve this, which is commonly used in data mining to detect near-duplicate web pages at scale. The guide provides an example of how the Set Digest functions can be used to estimate the similarity between texts. The input texts are split using the function `ngrams` to 4-shingles, which are used as input for creating a set digest of each initial text. The set digests are compared to each other to get an approximation of the similarity of their corresponding initial texts. The guide also explains the data structures used by Trino to implement Set Digest data sketches, which include HyperLogLog and MinHash with a single hash function. The HyperLogLog structure is used for the approximation of the distinct elements in the original set, while the MinHash structure is used to store a low memory footprint signature of the original set. The Trino type for this data structure is called `setdigest`. Trino offers the ability to merge multiple Set Digest data sketches. The guide also explains how data sketches can be serialized to and deserialized from `varbinary`, allowing them to be stored for later use. \n\nThe guide provides examples of the functions offered by Trino for Set Digest, including `make_set_digest()`, `merge_set_digest()`, `intersection_cardinality()`, `jaccard_index()`, and `hash_counts()`. The `make_set_digest()` function composes all input values of `x` into a `setdigest`. The `merge_set_digest()` function returns the `setdigest` of the aggregate union of the individual `setdigest` Set Digest structures. The `intersection_cardinality()` function returns the estimation for the cardinality of the intersection of the two set digests. The `jaccard_index()` function returns the estimation of Jaccard index for the two set digests. The `hash_counts()` function returns a map containing the Murmur3Hash128 hashed values and the count of their occurrences within the internal MinHash structure belonging to `x`. \n\nOverall, this guide provides a detailed explanation of the Set Digest functions offered by Trino, including their data structures and functions. The guide also provides examples of how these functions can be used to estimate the similarity between texts.\n## Questions: \n 1. What is the purpose of the Set Digest functions in Trino and how are they used in data mining? \n   - The Set Digest functions in Trino are used to estimate the Jaccard similarity coefficient between two sets using the MinHash technique. They are commonly used in data mining to detect near-duplicate web pages at scale.\n2. What data structures are used in Trino to implement Set Digest data sketches? \n   - Trino implements Set Digest data sketches using HyperLogLog and MinHash with a single hash function. The HyperLogLog structure is used for the approximation of the distinct elements in the original set, while the MinHash structure is used to store a low memory footprint signature of the original set.\n3. What are some examples of functions available in Trino for working with Set Digest data sketches? \n   - Trino offers several functions for working with Set Digest data sketches, including make_set_digest(), merge_set_digest(), intersection_cardinality(), jaccard_index(), and hash_counts(). These functions can be used to create a setdigest, merge multiple Set Digest data sketches, estimate the cardinality of the intersection of two set digests, estimate the Jaccard index for two set digests, and return a map containing the hashed values and count of their occurrences within the internal MinHash structure belonging to a setdigest.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/setdigest.md"}}],["143",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/string.md)\n\n# String Functions and Operators\n\nThis technical guide covers the string operators and functions available in the Dune Docs project. The guide is divided into two sections: string operators and string functions. \n\nThe string operators section describes the `||` operator, which performs concatenation, and the `LIKE` statement, which can be used for pattern matching. \n\nThe string functions section contains a list of functions that can be used to manipulate strings. The functions are divided into two categories: Unicode functions and string functions. \n\nThe Unicode functions include the `normalize()` function, which transforms a string with the specified normalization form, and the `to_utf8()` function, which encodes a string into a UTF-8 varbinary representation. The `from_utf8()` function decodes a UTF-8 encoded string from binary. \n\nThe string functions include the `concat()` function, which returns the concatenation of two or more strings, and the `lower()` function, which converts a string to lowercase. The `replace()` function removes or replaces all instances of a substring in a string. The `trim()` function removes leading and trailing whitespace from a string. \n\nThe guide also includes examples of how to use each function. For example, the `luhn_check()` function tests whether a string of digits is valid according to the Luhn algorithm. \n\nNote that some functions assume that the input strings contain valid UTF-8 encoded Unicode code points. There are no explicit checks for valid UTF-8, and the functions may return incorrect results on invalid UTF-8. Invalid UTF-8 data can be corrected with `from_utf8()`. Additionally, the functions operate on Unicode code points and not user-visible characters (or grapheme clusters). Some languages combine multiple code points into a single user-perceived character, the basic unit of a writing system for a language, but the functions will treat each code point as a separate unit. \n\nThe guide also notes that the `lower()` and `upper()` functions do not perform locale-sensitive, context-sensitive, or one-to-many mappings required for some languages. Specifically, this will return incorrect results for Lithuanian, Turkish, and Azeri. \n\nOverall, this guide provides a comprehensive overview of the string operators and functions available in the Dune Docs project, along with examples of how to use each function.\n## Questions: \n 1. What is the purpose of the dune docs app?\n    \n    Answer: The app technical guide does not provide information about the purpose of the dune docs app. \n\n2. What are the potential issues with using the lower and upper functions for some languages?\n    \n    Answer: The lower and upper functions do not perform locale-sensitive, context-sensitive, or one-to-many mappings required for some languages. Specifically, this will return incorrect results for Lithuanian, Turkish, and Azeri.\n\n3. What is the purpose of the `luhn_check` function?\n    \n    Answer: The `luhn_check` function tests whether a `string` of digits is valid according to the Luhn algorithm. This checksum function, also known as `modulo 10` or `mod 10`, is widely applied on credit card numbers and government identification numbers to distinguish valid numbers from mistyped, incorrect numbers.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/string.md"}}],["144",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/system.md)\n\n# System Information\n\nThis section of the app technical guide for the Dune Docs project covers functions that provide information about the Trino cluster system environment. The Trino cluster is a distributed SQL query engine designed to query large datasets. The functions described in this section can be used to obtain information about the version of Trino being used on the cluster.\n\nThe `/connector/system` exposes various schemas and tables that can be queried to obtain more information about the Trino cluster system environment. The `version()` function is one such function that can be used to obtain the Trino version used on the cluster. This function returns a varchar value that is equivalent to the value of the `node_version` column in the `system.runtime.nodes` table.\n\nHere is an example of how to use the `version()` function:\n\n```\nSELECT version();\n```\n\nThis query will return the Trino version used on the cluster.\n\nOverall, this section of the app technical guide provides developers with the necessary information to obtain system information about the Trino cluster. This information can be useful for debugging and optimizing queries.\n## Questions: \n 1. What is the purpose of the Trino cluster system environment in the context of blockchain SQL analysis?\n- This app technical guide provides functions that offer information about the Trino cluster system environment. A blockchain SQL analyst might want to know how this environment can be utilized for their analysis.\n\n2. How does querying the `/connector/system` schema and tables relate to blockchain data analysis?\n- The app technical guide mentions that querying the various schemas and tables exposed by the `/connector/system` can provide more information about the Trino cluster system environment. A blockchain SQL analyst might want to know how this information can be used in their analysis.\n\n3. Is the `system.runtime.nodes` table relevant to blockchain data analysis?\n- The `version()` function returns the value of the `node_version` column in the `system.runtime.nodes` table. A blockchain SQL analyst might want to know if this table contains any relevant information for their analysis.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/system.md"}}],["145",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/table.md)\n\n# Table Functions\n\nThis technical guide explains table functions in the DuneSQL project. A table function is a function that returns a table and can be invoked inside the `FROM` clause of a query. The row type of the returned table can depend on the arguments passed with invocation of the function. If different row types can be returned, the function is a **polymorphic table function**. Polymorphic table functions allow you to dynamically invoke custom logic from within the SQL query. They can be used for working with external systems as well as for enhancing Trino with capabilities going beyond the SQL standard.\n\nThe guide explains how to invoke a table function in the `FROM` clause of a query. Table function invocation syntax is similar to a scalar function call. Every table function is provided by a catalog, and it belongs to a schema in the catalog. You can qualify the function name with a schema name, or with catalog and schema names. Otherwise, the standard Trino name resolution is applied. The connection between the function and the catalog must be identified because the function is executed by the corresponding connector. If the function is not registered by the specified catalog, the query fails.\n\nThe guide also explains two conventions of passing arguments to a table function: arguments passed by name and arguments passed positionally. In the first convention, you can pass the arguments in arbitrary order. Arguments declared with default values can be skipped. Argument names are resolved case-sensitive, and with automatic uppercasing of unquoted names. In the second convention, you must follow the order in which the arguments are declared. You can skip a suffix of the argument list, provided that all the skipped arguments are declared with default values. You cannot mix the argument conventions in one invocation.\n\nThe guide also explains that all arguments must be constant expressions, and they can be of any SQL type, which is compatible with the declared argument type. You can also use parameters in arguments. The guide provides examples of how to use table functions in SQL queries.\n\nHowever, the guide also warns that table functions are currently not in operation in DuneSQL and are a placeholder for future work. The guide also provides links to the developer guide and connector documentation for more information about adding new table functions and supported table functions, respectively.\n## Questions: \n 1. What is the purpose of a table function in DuneSQL?\n- A table function is a function returning a table that can be invoked inside the `FROM` clause of a query. It allows for dynamically invoking custom logic from within the SQL query, and can be used for working with external systems as well as for enhancing Trino with capabilities going beyond the SQL standard.\n\n2. How are table functions declared and supported in DuneSQL?\n- Connectors declare support for different functions on a per-connector basis through implementing dedicated interfaces. For guidance on adding new table functions, see the developer guide. For more information about supported table functions, refer to the connector documentation.\n\n3. What are the conventions for passing arguments to a table function in DuneSQL?\n- There are two conventions for passing arguments to a table function: arguments passed by name and arguments passed positionally. All arguments must be constant expressions and can be of any SQL type compatible with the declared argument type. Parameters can also be used in arguments. Mixing the argument conventions in one invocation is not allowed.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/table.md"}}],["146",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/tdigest.md)\n\n# T-Digest Functions\n\nThis technical guide covers the T-Digest functions in the Dune Docs project. A T-Digest is a data sketch that stores approximate percentile information. The Trino type for this data structure is called `tdigest`. T-Digests can be merged, and for storage and retrieval, they can be cast to and from `VARBINARY`.\n\n## Data Structures\n\nThis section explains the T-Digest data structure and its usage in the project. It provides information on how to store and retrieve T-Digests using `VARBINARY`.\n\n## Functions\n\nThis section covers the T-Digest functions available in the project. It explains the purpose of each function and how to use it. The functions covered in this guide are:\n\n### merge()\n\nThis function aggregates all inputs into a single `tdigest`.\n\nExample: `merge(tdigest)`\n\n### values_at_quantile()\n\nThis function returns the approximate percentile value from the T-Digest, given the number `quantile` between 0 and 1.\n\nExample: `value_at_quantile(tdigest, quantile)`\n\n### values_at_quantiles()\n\nThis function returns the approximate percentile values as an array, given the input T-Digest and an array of values between 0 and 1, which represent the quantiles to return.\n\nExample: `values_at_quantiles(tdigest, quantiles)`\n\n### tdigest_agg()\n\nThis function composes all input values of `x` into a `tdigest`. `x` can be of any numeric type.\n\nExample: `tdigest_agg(x)`\n\nThis function also composes all input values of `x` into a `tdigest` using the per-item weight `w`. `w` must be greater or equal to 1. `x` and `w` can be of any numeric type.\n\nExample: `tdigest_agg(x, w)`\n\nOverall, this guide provides a clear understanding of the T-Digest functions available in the Dune Docs project and how to use them.\n## Questions: \n 1. What is the purpose of the T-digest data structure and how is it used in this app?\n   \n   The T-digest data structure is used to store approximate percentile information and can be merged and cast to and from `VARBINARY`. It is used in this app to perform functions such as `merge()`, `value_at_quantile()`, `values_at_quantiles()`, and `tdigest_agg()`.\n\n2. What types of numeric input values are accepted by the `tdigest_agg()` function?\n   \n   The `tdigest_agg()` function can accept input values of any numeric type.\n\n3. Can the `values_at_quantiles()` function return percentile values outside of the range of 0 to 1?\n   \n   No, the `values_at_quantiles()` function only returns approximate percentile values as an array, given the input T-digest and an array of values between 0 and 1, which represent the quantiles to return.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/tdigest.md"}}],["147",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/teradata.md)\n\n# Teradata Functions\n\nThis technical guide provides compatibility with Teradata SQL. It is divided into two sections: String functions and Date functions.\n\n## String Functions\n\nThis section contains two functions:\n\n### char2()\n\n**``char2hexint(string)``** → varchar\n\nThis function returns the hexadecimal representation of the UTF-16BE encoding of the string.\n\n### index()\n\n**``index(string, substring)``** → bigint\n\nThis function is an alias for the `strpos` function.\n\n## Date Functions\n\nThis section contains three functions that use a format string that is compatible with the Teradata datetime functions. The following table describes the supported format specifiers:\n\n| Specifier | Description                   |\n|-----------|-------------------------------|\n| - / , . ; : | Punctuation characters are ignored |\n| dd        | Day of month (1-31)           |\n| hh        | Hour of day (1-12)            |\n| hh24      | Hour of the day (0-23)        |\n| mi        | Minute (0-59)                 |\n| mm        | Month (01-12)                 |\n| ss        | Second (0-59)                 |\n| yyyy      | 4-digit year                  |\n| yy        | 2-digit year                  |\n\n### to_char()\n\n**``to_char(timestamp, format)``** → varchar\n\nThis function formats `timestamp` as a string using `format`.\n\n### to_timestamp()\n\n**``to_timestamp(string, format)``** → timestamp\n\nThis function parses `string` into a `TIMESTAMP` using `format`.\n\n### to_date()\n\n**``to_date(string, format)``** → date\n\nThis function parses `string` into a `DATE` using `format`.\n\nThe purpose of this guide is to provide a reference for developers who need to use Teradata functions in their SQL queries. The guide explains the syntax and usage of each function, and provides examples of how to use them. The guide is organized into two sections: String functions and Date functions. The String functions section contains two functions: `char2()` and `index()`. The Date functions section contains three functions: `to_char()`, `to_timestamp()`, and `to_date()`. Each function is described in detail, including its input parameters and return type. The guide also provides a table of format specifiers that are used by the Date functions.\n## Questions: \n 1. What is the purpose of the app \"dune docs\" and how does it relate to blockchain technology?\n    \n    The app technical guide does not provide information on the purpose of \"dune docs\" or its relation to blockchain technology.\n\n2. Are there any specific date or time functions that are relevant for blockchain data analysis?\n    \n    The app technical guide provides date and time functions that are compatible with Teradata SQL, but it does not specify if any of these functions are relevant for blockchain data analysis.\n\n3. Does the app support any functions for working with JSON data?\n    \n    The app technical guide does not provide information on whether or not the app supports functions for working with JSON data.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/teradata.md"}}],["148",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/url.md)\n\n# URL Functions\n\nThis technical guide is focused on the URL functions in the Dune Docs project. The URL extraction functions extract components from HTTP URLs or any valid URIs conforming to `2396`. The syntax supported includes `[protocol:][//host[:port]][path][?query][#fragment]`. The extracted components do not contain URI syntax separators such as `:` or `?`.\n\n## Extraction Functions\n\nThe following are the extraction functions available in the Dune Docs project:\n\n### url_extract_fragment()\n\n**`url_extract_fragment(url)`** → varchar\n\nThis function returns the fragment identifier from `url`.\n\n### url_extract_host()\n\n**`url_extract_host(url)`** → varchar\n\nThis function returns the host from `url`.\n\n### url_extract_parameter()\n\n**`url_extract_parameter(url, name)`** → varchar\n\nThis function returns the value of the f query string parameter named `name` from `url`. Parameter extraction is handled in the typical manner as specified by RFC 1866#section-8.2.1.\n\n### url_extract_path()\n\n**`url_extract_path(url)`** → varchar\n\nThis function returns the path from `url`.\n\n### url_extract_port()\n\n**`url_extract_port(url)`** → bigint\n\nThis function returns the port number from `url`.\n\n### url_extract_protocol()\n\n**`url_extract_protocol(url)`** → varchar\n\nThis function returns the protocol from `url`.\n\n### url_extract_query()\n\n**`url_extract_query(url)`** → varchar\n\nThis function returns the query string from `url`.\n\n## Encoding Functions\n\nThe following are the encoding functions available in the Dune Docs project:\n\n### url_encode()\n\n**`url_encode(value)`** → varchar\n\nThis function escapes `value` by encoding it so that it can be safely included in URL query parameter names and values.\n\n### url_decode()\n\n**`url_decode(value)`** → varchar\n\nThis function unescapes the URL encoded `value`. This function is the inverse of `url_encode`.\n\nThe guide provides a clear explanation of the URL functions available in the Dune Docs project. The extraction functions extract components from HTTP URLs or any valid URIs conforming to `2396`. The encoding functions escape and unescape URL encoded values. The guide also provides examples of how to use each function.\n## Questions: \n 1. What is the purpose of the dune docs app and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the dune docs app or its relation to blockchain technology.\n\n2. Are there any security measures in place for the URL encoding and decoding functions?\n- The app technical guide does not mention any security measures for the URL encoding and decoding functions.\n\n3. Can the URL extraction functions be used to extract components from blockchain transactions or blocks?\n- The app technical guide does not provide information on whether the URL extraction functions can be used to extract components from blockchain transactions or blocks.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/url.md"}}],["149",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/uuid.md)\n\nThe app technical guide titled \"UUID functions\" covers the usage of the `uuid()` function in the Dune Docs project. The `uuid()` function generates a pseudo-randomly generated `uuid_type` of type 4. This function is useful for generating unique identifiers for various purposes within the app.\n\nThe guide provides a clear and concise explanation of the function and its purpose. It also includes an example of the function's response, which helps users understand what to expect when using the function.\n\nOverall, this section of the guide is focused on providing developers with the necessary information to use the `uuid()` function effectively in their code. It is a valuable resource for anyone working on the app's functionality and looking to generate unique identifiers.\n## Questions: \n 1. What is the purpose of the UUID functions in the context of the Dune Docs project?\n- The app technical guide does not provide context on how the UUID functions are used in the Dune Docs project, so a blockchain SQL analyst might want to know more about the specific use case.\n\n2. Are there any limitations or constraints on the UUIDs generated by the `uuid()` function?\n- The app technical guide does not mention any limitations or constraints on the UUIDs generated by the `uuid()` function, so a blockchain SQL analyst might want to know if there are any potential issues with using these UUIDs in a blockchain context.\n\n3. Is there any additional documentation or examples available for using the UUID functions in Dune Docs?\n- The app technical guide only provides a brief description of the `uuid()` function, so a blockchain SQL analyst might want to know if there are any additional resources available for learning how to use this function effectively in the Dune Docs project.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/uuid.md"}}],["150",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/varbinary.md)\n\n# Varbinary Functions\n\nThis technical guide covers the helper functions available in Dune SQL for byte array manipulation and conversion. The guide is focused on the `app` folder of the Dune Docs project.\n\nThe guide starts by introducing the varbinary type used to represent byte arrays in Dune SQL. It then lists the byte array manipulation functions available in Dune SQL, including `bytearray_concat`, `bytearray_length`, `bytearray_ltrim`, `bytearray_position`, `bytearray_replace`, `bytearray_reverse`, `bytearray_rtrim`, `bytearray_starts_with`, and `bytearray_substring`. Each function is described in detail, including its input and output types, and examples are provided where appropriate.\n\nThe guide then covers the byte array to numeric functions available in Dune SQL, including `bytearray_to_integer`, `bytearray_to_bigint`, `bytearray_to_decimal`, `bytearray_to_uint256`, `bytearray_to_int256`, and `bytea2numeric`. The guide notes that these functions throw an overflow exception if the byte array is larger than the number of bytes supported of the type, even if the most significant bytes are all zero. It also recommends using `bytearray_ltrim` to trim the zero bytes from the left.\n\nOverall, this technical guide provides a comprehensive overview of the byte array manipulation and conversion functions available in Dune SQL. It is a useful resource for developers working with byte arrays in Dune SQL and provides clear examples of how to use each function.\n## Questions: \n 1. What is the purpose of Dune SQL's varbinary type and how does it relate to blockchain data? \n- The blockchain SQL analyst might want to know more about the use case for varbinary type and how it is used to represent byte arrays in Dune SQL, as this could impact how they work with blockchain data stored in byte array format.\n\n2. How do the byte array manipulation functions in Dune SQL compare to similar functions in other SQL languages? \n- The analyst might want to compare the functionality and syntax of Dune SQL's byte array manipulation functions to those in other SQL languages they are familiar with, in order to better understand how to use them effectively.\n\n3. What is the significance of the byte array to numeric conversion functions in Dune SQL for blockchain data analysis? \n- The analyst might want to know more about how the byte array to numeric conversion functions work and how they can be used to analyze blockchain data stored in byte array format, particularly for values such as integers and decimals.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/varbinary.md"}}],["151",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/Functions-and-operators/window.md)\n\n# Window Functions\n\nThis section of the app technical guide covers window functions in the Dune Docs project. Window functions are used to perform calculations across rows of the query result. They run after the `HAVING` clause but before the `ORDER BY` clause. Invoking a window function requires special syntax using the `OVER` clause to specify the window. \n\nThe `Window functions` header explains how to specify the window in two ways: by a reference to a named window specification defined in the `WINDOW` clause, or by an in-line window specification which allows defining window components as well as referring to the window components pre-defined in the `WINDOW` clause. \n\nThe `Aggregate functions` header explains that all `aggregate` functions can be used as window functions by adding the `OVER` clause. The aggregate function is computed for each row over the rows within the current row's window frame. \n\nThe `Ranking functions` header explains the different ranking functions available in Dune Docs. These functions include `cume_dist()`, `dense_rank()`, `ntile()`, `percent_rank()`, `rank()`, and `row_number()`. Each function is explained in detail, including its syntax and what it returns. \n\nThe `Value functions` header explains the different value functions available in Dune Docs. These functions include `f_value()`, `last_value()`, `nth_value()`, `lead()`, and `lag()`. Each function is explained in detail, including its syntax and what it returns. \n\nThe guide provides examples for each function to help users understand how to use them in their queries. \n\nOverall, this guide provides a comprehensive overview of window functions in Dune Docs, including how to specify windows, aggregate functions, ranking functions, and value functions.\n## Questions: \n 1. What is the purpose of the `OVER` clause in the window functions?\n- The `OVER` clause is used to specify the window for the window functions, which perform calculations across rows of the query result.\n\n2. Can all aggregate functions be used as window functions?\n- Yes, all aggregate functions can be used as window functions by adding the `OVER` clause.\n\n3. What is the difference between `rank()` and `dense_rank()`?\n- `rank()` produces gaps in the sequence for tie values in the ordering, while `dense_rank()` does not produce gaps for tie values.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/Functions-and-operators/window.md"}}],["152",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-language/datatypes.md)\n\nThe app technical guide covers various data types used in DuneSQL, including:\n\n- **Boolean**: Captures boolean values `true` and `false`.\n- **Integer**: Different integer types such as `TINYINT`, `SMALLINT`, `INTEGER`, `BIGINT`, `UINT256`, and `INT256`.\n- **Floating-point**: `REAL` and `DOUBLE` types implementing the IEEE Standard 754 for Binary Floating-Point Arithmetic.\n- **Fixed-precision**: `DECIMAL` type with specified precision and scale.\n- **String**: `VARCHAR`, `CHAR`, `VARBINARY`, and `JSON` types.\n- **Date and time**: Various date and time types like `DATE`, `TIME`, `TIMESTAMP`, and `INTERVAL`.\n- **Structural**: `ARRAY`, `MAP`, and `ROW` types for complex data structures.\n- **Network address**: `IPADDRESS` type for IPv4 and IPv6 addresses.\n- **UUID**: Represents a Universally Unique IDentifier.\n- **HyperLogLog**: Data sketch for efficient computation of approximate distinct count.\n- **SetDigest**: Data sketch for calculating Jaccard similarity coefficient between two sets.\n- **Quantile digest**: Summary structure for capturing approximate distribution of data.\n- **T-Digest**: Summary structure similar to qdigest with higher performance, lower memory usage, and higher accuracy at high and low percentiles.\n\nThe guide provides examples and detailed explanations for each data type, including their usage, properties, and functions.\n## Questions: \n 1. **What are the differences between the `UINT256` and `INT256` data types, and when should each be used in EVM smart contracts?**\n\n   The `UINT256` data type is a 256-bit unsigned integer, representing only non-negative integers, including very large positive integers and zero. The `INT256` data type is a 256-bit signed integer, representing a wide range of values, including very large negative and positive integers, as well as zero. In EVM smart contracts, `UINT256` is commonly used for representing balances and other quantities, while `INT256` is used when the value can be negative.\n\n2. **How can I work with `VARBINARY` data types in DuneSQL, and are there any custom functions available for this purpose?**\n\n   In DuneSQL, addresses, hashes, calldata, and logs are stored as `VARBINARY` data types. You can use SQL statements with the binary data prefix `0x` and hexadecimal format for working with `VARBINARY` data types. DuneSQL also provides custom functions to make it easier to work with `VARBINARY` data types, which can be found on the [varbinary functions](/querying-with-DuneSQL/functions/varbinary/) page.\n\n3. **What are the differences between the `QDigest` and `TDigest` data structures, and when should each be used?**\n\n   Both `QDigest` and `TDigest` are summary structures that capture the approximate distribution of data for a given input set and can be queried to retrieve approximate quantile values. However, `TDigest` has some advantages over `QDigest`, including higher performance, lower memory usage, and higher accuracy at high and low percentiles. Both structures are additive, meaning they can be merged together without losing precision. You should choose the appropriate structure based on your performance, memory, and accuracy requirements.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-language/datatypes.md"}}],["153",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-language/index.md)\n\n# Overview\n\nThe Overview section of the Dune Docs app technical guide provides an introduction to DuneSQL, a custom-built query engine optimized for blockchain data. DuneSQL is built on a fork of TrinoSQL, an ANSI SQL compliant query engine that allows users to integrate their favorite data tools with any underlying data source. \n\nThe section notes that DuneSQL validates and translates SQL statements into the necessary operations on the connected data source. It also provides a reference to the supported SQL data types and other general characteristics of the SQL support of DuneSQL. \n\nThe section includes links to a full SQL statement and syntax reference, as well as a reference to numerous SQL functions and operators provided by Trino. \n\nOverall, the Overview section serves as a high-level introduction to DuneSQL and its capabilities, providing context for the more detailed technical information provided in other sections of the app technical guide. \n\nExample: \n\nIf a user is new to DuneSQL and wants to understand its capabilities and how it differs from TrinoSQL, they can start by reading the Overview section. This will provide them with a basic understanding of DuneSQL's features and how it can be used with other data tools. They can then explore the other sections of the app technical guide for more detailed information on specific aspects of DuneSQL.\n## Questions: \n 1. What specific optimizations does DuneSQL have for blockchain data? \n- The app technical guide does not provide specific details on the optimizations made for blockchain data.\n\n2. Can DuneSQL connect to a blockchain database directly or does it require a separate data source? \n- The app technical guide does not provide information on whether DuneSQL can connect directly to a blockchain database or if it requires a separate data source.\n\n3. Are there any limitations or differences in the SQL data types supported by DuneSQL compared to TrinoSQL? \n- The app technical guide does not mention any limitations or differences in the SQL data types supported by DuneSQL compared to TrinoSQL.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-language/index.md"}}],["154",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-language/reserved.md)\n\nThe \"Reserved Keywords\" section of the app technical guide for the Dune Docs project provides a comprehensive list of all the keywords that are reserved in Trino, along with their status in the SQL standard. These reserved keywords must be quoted (using double quotes) in order to be used as an identifier. \n\nThis section is important for developers who are working on the app feature that involves writing SQL queries. It is essential to know which keywords are reserved in Trino and must be quoted to avoid syntax errors. \n\nFor example, if a developer wants to use the keyword \"SELECT\" as a column name in a table, they must quote it as \"SELECT\" to avoid conflicts with the reserved keyword. \n\nThe table in this section lists all the reserved keywords in alphabetical order, along with their status in the SQL standard. The SQL standard status indicates whether the keyword is reserved or non-reserved in the standard. \n\nOverall, this section serves as a quick reference for developers working on the app feature that involves writing SQL queries. It helps them avoid syntax errors and ensures that their queries run smoothly.\n## Questions: \n 1. What is the purpose of the dune docs app?\n- The app technical guide provided does not give any information about the purpose of the dune docs app, so a blockchain SQL analyst might have this question.\n\n2. How does the dune docs app use SQL?\n- The app technical guide lists all the reserved keywords in Trino SQL, but it does not explain how the dune docs app uses SQL, so a blockchain SQL analyst might have this question.\n\n3. Are there any specific SQL features or functions that the dune docs app requires?\n- The app technical guide does not mention any specific SQL features or functions that the dune docs app requires, so a blockchain SQL analyst might have this question.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-language/reserved.md"}}],["155",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-language/sql-support.md)\n\nThe SQL statement support section of the app technical guide in the dune docs project provides information on how to use SQL statements in the app. This section is located in the 'api' folder of the project. \n\nThe guide starts by explaining what SQL is and how it is used in the app. It then goes on to provide examples of SQL statements that can be used in the app, such as SELECT, INSERT, UPDATE, and DELETE. Each example is accompanied by a detailed explanation of what the statement does and how it can be used in the app.\n\nThe guide also covers how to use parameters in SQL statements, which allows for more dynamic and flexible queries. It provides examples of how to use parameters in SELECT, INSERT, and UPDATE statements.\n\nIn addition, the guide explains how to handle errors that may occur when using SQL statements in the app. It provides information on how to catch and handle errors using try-catch blocks.\n\nOverall, the SQL statement support section of the app technical guide is a comprehensive resource for developers who need to use SQL statements in the app. It provides clear explanations and examples of how to use SQL statements, as well as tips for handling errors that may occur.\n## Questions: \n ## Question 1\nWhat specific SQL statements does the app support?\n### Answer\nThe app technical guide does not provide information on the specific SQL statements supported. Further documentation or communication with the developers may be necessary to obtain this information.\n\n## Question 2\nDoes the app support any blockchain-specific SQL statements?\n### Answer\nThe app technical guide does not mention any blockchain-specific SQL statements. It is unclear if the app is designed for use with blockchain technology.\n\n## Question 3\nAre there any limitations or restrictions on the use of SQL statements within the app?\n### Answer\nThe app technical guide does not provide information on any limitations or restrictions on the use of SQL statements. Further documentation or communication with the developers may be necessary to obtain this information.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-language/sql-support.md"}}],["156",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-language)\n\nThe `docs/query/DuneSQL-reference/SQL-language` folder contains a comprehensive guide on various aspects of DuneSQL, a custom-built query engine optimized for blockchain data. This guide is essential for developers and analysts working on the app feature that involves writing SQL queries and understanding the data types supported by DuneSQL.\n\nThe `datatypes.md` file provides an in-depth explanation of the various data types used in DuneSQL, such as Boolean, Integer, Floating-point, Fixed-precision, String, Date and time, Structural, Network address, UUID, HyperLogLog, SetDigest, Quantile digest, and T-Digest. This guide is useful for developers who need to understand the properties and functions of each data type when designing database schemas or writing SQL queries.\n\nThe `index.md` file serves as an overview of DuneSQL, its capabilities, and how it differs from TrinoSQL. This high-level introduction is beneficial for users who are new to DuneSQL and want to understand its features and integration with other data tools.\n\nThe `reserved.md` file lists all the reserved keywords in Trino, along with their status in the SQL standard. This section is crucial for developers to avoid syntax errors when writing SQL queries by quoting reserved keywords.\n\nThe `sql-support.md` file offers a detailed guide on using SQL statements in the app, including examples of SELECT, INSERT, UPDATE, and DELETE statements. It also covers the use of parameters in SQL statements for more dynamic and flexible queries and provides tips on handling errors that may occur.\n\nFor example, a developer working on a feature that requires querying blockchain data can refer to the `datatypes.md` file to understand the appropriate data types to use in their queries. They can also consult the `sql-support.md` file for examples of SQL statements and how to use parameters for more dynamic queries. If they encounter a reserved keyword in their query, they can refer to the `reserved.md` file to ensure they quote it correctly to avoid syntax errors.\n\nOverall, the guide in this folder is an essential resource for developers and analysts working on the app feature that involves writing SQL queries and understanding the data types supported by DuneSQL. It provides clear explanations, examples, and tips to ensure smooth and efficient querying of blockchain data.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-language/summary.md"}}],["157",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/alter-materialized-view.md)\n\n# ALTER MATERIALIZED VIEW\n\n## Synopsis\n\nThis section provides a brief overview of the `ALTER MATERIALIZED VIEW` command. The command is used to rename an existing materialized view. The syntax for the command is as follows:\n\n``` text\nALTER MATERIALIZED VIEW [ IF EXISTS ] name RENAME TO new_name\nALTER MATERIALIZED VIEW name SET PROPERTIES property_name = expression [, ...]\n```\n\n## Description\n\nThis section provides a detailed explanation of the `ALTER MATERIALIZED VIEW` command. The command is used to change the name of an existing materialized view. The optional `IF EXISTS` clause suppresses the error if the materialized view does not exist. However, the error is not suppressed if the materialized view does not exist, but a table or view with the given name exists.\n\n### SET PROPERTIES\n\nThis section explains the `SET PROPERTIES` statement that can be used with the `ALTER MATERIALIZED VIEW` command. The `ALTER MATERIALIZED VIEW SET PROPERTIES` statement followed by some number of `property_name` and `expression` pairs applies the specified properties and values to a materialized view. Omitting an already-set property from this statement leaves that property unchanged in the materialized view. A property in a `SET PROPERTIES` statement can be set to `DEFAULT`, which reverts its value back to the default in that materialized view. However, support for `ALTER MATERIALIZED VIEW SET PROPERTIES` varies between connectors. Refer to the connector documentation for more details.\n\n## Examples\n\nThis section provides examples of how to use the `ALTER MATERIALIZED VIEW` command. The examples include:\n\n- Renaming a materialized view `people` to `users` in the current schema\n- Renaming a materialized view `people` to `users`, if materialized view `people` exists in the current catalog and schema\n- Setting view properties (`x = y`) in materialized view `people`\n- Setting multiple view properties (`foo = 123` and `foo bar = 456`) in materialized view `people`\n- Setting view property `x` to its default value in materialized view `people`\n\n## See also\n\nThis section provides links to related commands that can be used with the `ALTER MATERIALIZED VIEW` command. The related commands include:\n\n- `create-materialized-view`\n- `refresh-materialized-view`\n- `drop-materialized-view`\n## Questions: \n 1. What is the purpose of the `ALTER MATERIALIZED VIEW` statement in this app? \n- The `ALTER MATERIALIZED VIEW` statement is used to change the name of an existing materialized view.\n\n2. How does the `SET PROPERTIES` statement work in this app? \n- The `SET PROPERTIES` statement followed by some number of `property_name` and `expression` pairs applies the specified properties and values to a materialized view. Ommitting an already-set property from this statement leaves that property unchanged in the materialized view.\n\n3. Is support for `ALTER MATERIALIZED VIEW SET PROPERTIES` consistent across all connectors? \n- No, support for `ALTER MATERIALIZED VIEW SET PROPERTIES` varies between connectors. It is recommended to refer to the connector documentation for more details.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/alter-materialized-view.md"}}],["158",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/alter-table.md)\n\n# ALTER TABLE\n\n## Synopsis\n\nThe `ALTER TABLE` statement is used to change the definition of an existing table. The statement can be used to rename a table, add or drop a column, rename a column, change the data type of a column, set authorization, set properties, and execute a command. \n\n## Description\n\nThe `ALTER TABLE` statement has several clauses that can be used to modify a table. The `IF EXISTS` clause can be used before the table name or column name to suppress errors if the table or column does not exist. The `IF NOT EXISTS` clause can be used before the column name to suppress errors if the column already exists. \n\nThe `SET PROPERTIES` clause can be used to apply specified properties and values to a table. The statement can be used to set a property to `DEFAULT`, which reverts its value back to the default in that table. However, support for `ALTER TABLE SET PROPERTIES` varies between connectors, as not all connectors support modifying table properties.\n\nThe `EXECUTE` clause can be used to modify the table according to the specified command and parameters. The `=>` operator can be used for passing named parameter values. The left side is the name of the parameter, the right side is the value being passed.\n\n## Examples\n\nThe following are examples of how to use the `ALTER TABLE` statement:\n\n- Rename table `users` to `people`: `ALTER TABLE users RENAME TO people;`\n- Rename table `users` to `people` if table `users` exists: `ALTER TABLE IF EXISTS users RENAME TO people;`\n- Add column `zip` to the `users` table: `ALTER TABLE users ADD COLUMN zip varchar;`\n- Add column `zip` to the `users` table if table `users` exists and column `zip` not already exists: `ALTER TABLE IF EXISTS users ADD COLUMN IF NOT EXISTS zip varchar;`\n- Drop column `zip` from the `users` table: `ALTER TABLE users DROP COLUMN zip;`\n- Drop column `zip` from the `users` table if table `users` and column `zip` exists: `ALTER TABLE IF EXISTS users DROP COLUMN IF EXISTS zip;`\n- Rename column `id` to `user_id` in the `users` table: `ALTER TABLE users RENAME COLUMN id TO user_id;`\n- Rename column `id` to `user_id` in the `users` table if table `users` and column `id` exists: `ALTER TABLE IF EXISTS users RENAME column IF EXISTS id to user_id;`\n- Change type of column `id` to `bigint` in the `users` table: `ALTER TABLE users ALTER COLUMN id SET DATA TYPE bigint;`\n- Change owner of table `people` to user `alice`: `ALTER TABLE people SET AUTHORIZATION alice`\n- Allow everyone with role public to drop and alter table `people`: `ALTER TABLE people SET AUTHORIZATION ROLE PUBLIC`\n- Set table properties (`x = y`) in table `people`: `ALTER TABLE people SET PROPERTIES x = 'y';`\n- Set multiple table properties (`foo = 123` and `foo bar = 456`) in table `people`: `ALTER TABLE people SET PROPERTIES foo = 123, \"foo bar\" = 456;`\n- Set table property `x` to its default value in table`people`: `ALTER TABLE people SET PROPERTIES x = DEFAULT;`\n- Collapse files in a table that are over 10 megabytes in size, as supported by the Hive connector: `ALTER TABLE hive.schema.test_table EXECUTE optimize(file_size_threshold => '10MB')`\n\n## See also\n\n`create-table`\n## Questions: \n 1. What is the purpose of the `SET PROPERTIES` statement in the `ALTER TABLE` command?\n   \n   The `SET PROPERTIES` statement in the `ALTER TABLE` command is used to apply specified properties and values to a table. It can be used to change the default value of a property back to the default in that table.\n\n2. What is the purpose of the `EXECUTE` statement in the `ALTER TABLE` command?\n   \n   The `EXECUTE` statement in the `ALTER TABLE` command is used to modify the table according to the specified command and parameters. It supports different commands on a per-connector basis.\n\n3. Which connectors support the `ALTER TABLE SET PROPERTIES` statement?\n   \n   Support for `ALTER TABLE SET PROPERTIES` varies between connectors, as not all connectors support modifying table properties.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/alter-table.md"}}],["159",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/alter-view.md)\n\n# ALTER VIEW\n\n## Synopsis\n\nThe `ALTER VIEW` command allows for the modification of an existing view in the app. The command can be used to rename a view or change the owner of a view.\n\n``` text\nALTER VIEW name RENAME TO new_name\nALTER VIEW name SET AUTHORIZATION ( user | USER user | ROLE role )\n```\n\n## Description\n\nThe `ALTER VIEW` command is used to change the definition of an existing view. This command can be used to rename a view or change the owner of a view. Renaming a view is useful when the name of the view no longer accurately reflects the data it contains. Changing the owner of a view is useful when a user or role needs to take ownership of a view.\n\n## Examples\n\n### Renaming a view\n\nTo rename a view, use the `RENAME TO` clause followed by the new name of the view. For example, to rename the `people` view to `users`, use the following command:\n\n```\nALTER VIEW people RENAME TO users\n```\n\n### Changing the owner of a view\n\nTo change the owner of a view, use the `SET AUTHORIZATION` clause followed by the name of the user or role that will become the new owner. For example, to change the owner of the `people` view to user `alice`, use the following command:\n\n```\nALTER VIEW people SET AUTHORIZATION alice\n```\n\n## See also\n\n`create-view`{.interpreted-text role=\"doc\"}\n\nThis section of the app technical guide covers the `ALTER VIEW` command, which is used to modify an existing view in the app. The guide provides a synopsis of the command, including the syntax and available options. The description explains the purpose of the command and how it can be used to rename a view or change the owner of a view. The examples demonstrate how to use the command to rename a view or change the owner of a view. Finally, the guide provides a reference to the `create-view` command for further information. This guide is located in the `app` folder of the `dune docs` project.\n## Questions: \n 1. What is the purpose of this app and how does it relate to blockchain technology?\n    - This app technical guide is related to SQL database management and does not have a direct connection to blockchain technology.\n2. Can this app be used to manage data stored on a blockchain?\n    - It is unclear from this app technical guide whether it can be used to manage data stored on a blockchain or if it is only applicable to traditional SQL databases.\n3. Are there any security features built into this app to protect against unauthorized access or tampering of data?\n    - The app technical guide does not provide information on any security features or measures implemented in the app.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/alter-view.md"}}],["160",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/analyze.md)\n\n# ANALYZE\n\nThe `ANALYZE` command is used to collect table and column statistics for a given table. This section of the app technical guide provides a synopsis, description, and examples of how to use the `ANALYZE` command.\n\nThe synopsis provides the basic syntax of the `ANALYZE` command, which includes the table name and an optional `WITH` clause that can be used to provide connector-specific properties. \n\nThe description explains that the `ANALYZE` command is used to collect table and column statistics for a given table. It also provides information on how to use the optional `WITH` clause to specify connector-specific properties. To list all available properties, the guide recommends running the following query: `SELECT * FROM system.metadata.analyze_properties`.\n\nThe examples section provides several examples of how to use the `ANALYZE` command. These examples include analyzing a table, analyzing a table in a specific catalog and schema, analyzing partitions from a partitioned table, and analyzing specific columns for partitions from a partitioned table. \n\nOverall, this section of the app technical guide provides a comprehensive overview of how to use the `ANALYZE` command to collect table and column statistics for a given table. It also provides helpful examples to illustrate how to use the command in different scenarios.\n## Questions: \n 1. What is the purpose of the `ANALYZE` command in this app and how does it relate to blockchain technology?\n- The `ANALYZE` command collects table and column statistics for a given table, which may be useful for optimizing queries and improving performance. It is not directly related to blockchain technology, but could be used in conjunction with a blockchain database to analyze data stored on the chain.\n\n2. Are there any limitations or restrictions on the types of tables or data that can be analyzed using this command?\n- The app technical guide does not mention any specific limitations or restrictions on the types of tables or data that can be analyzed using the `ANALYZE` command. However, it may be worth investigating whether certain data formats or structures are better suited for analysis than others.\n\n3. How can the optional `WITH` clause be used to provide connector-specific properties, and what are some examples of these properties?\n- The `WITH` clause can be used to provide connector-specific properties that may affect how the `ANALYZE` command operates. Examples of these properties include `partitions` (to specify which partitions to analyze), `columns` (to specify which columns to analyze), and `sample_size` (to control the size of the sample used for analysis). The full list of available properties can be obtained by running the query `SELECT * FROM system.metadata.analyze_properties`.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/analyze.md"}}],["161",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/create-materialized-view.md)\n\n# CREATE MATERIALIZED VIEW\n\n## Synopsis\n\nThis section provides the syntax for creating a new materialized view. The `CREATE MATERIALIZED VIEW` statement is used to create and validate the definition of a new materialized view. The statement includes the `view_name` and a `select` query. The `refresh-materialized-view` statement is required after the creation to populate the materialized view with data. \n\n## Description\n\nThis section explains the concept of materialized views and how they differ from regular views. Materialized views are a physical manifestation of the query results at the time of refresh. The data is stored and can be referenced by future queries. Queries accessing materialized views are typically faster than retrieving data from a view created with the same query. Any computation, aggregation, and other operation to create the data is performed once during refresh of the materialized views, as compared to each time of accessing the view. Multiple reads of view data over time, or by multiple users, all trigger repeated processing. This is avoided for materialized views.\n\nThe section also explains the optional clauses that can be used with the `CREATE MATERIALIZED VIEW` statement. The `OR REPLACE` clause causes the materialized view to be replaced if it already exists rather than raising an error. The `IF NOT EXISTS` clause causes the materialized view only to be created or replaced if it does not exist yet. The `COMMENT` clause causes a `string` comment to be stored with the metadata about the materialized view. The comment is displayed with the `show-create-materialized-view` statement and is available in the table `system.metadata.materialized_view_properties`. The `WITH` clause is used to define properties for the materialized view creation. Separate multiple property/value pairs by commas. The connector uses the properties as input parameters for the materialized view refresh operation. The supported properties are different for each connector and detailed in the SQL support section of the specific connector's documentation.\n\n## Examples\n\nThis section provides examples of how to create a materialized view using the `CREATE MATERIALIZED VIEW` statement. The examples include creating a simple materialized view over a table that only includes cancelled orders, creating or replacing a materialized view that summarizes orders across all orders from all customers, creating a materialized view for a catalog using the Iceberg connector, and setting multiple properties.\n\n## See also\n\nThis section provides links to related statements that can be used with the `CREATE MATERIALIZED VIEW` statement. The related statements include `drop-materialized-view`, `show-create-materialized-view`, and `refresh-materialized-view`.\n## Questions: \n 1. What is the purpose of a materialized view in the context of a blockchain SQL database?\n- A blockchain SQL analyst might want to know how materialized views can be used to improve query performance and reduce repeated processing of data.\n\n2. How does the `refresh-materialized-view` statement work and when should it be used?\n- A blockchain SQL analyst might want to know more about the process of refreshing a materialized view and how it ensures that the view stays in sync with the source tables.\n\n3. What are the supported properties for creating a materialized view using the Iceberg connector?\n- A blockchain SQL analyst might want to know more about the specific properties that can be defined when creating a materialized view using the Iceberg connector, and how they can be used to optimize performance.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/create-materialized-view.md"}}],["162",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/create-table-as.md)\n\n# CREATE TABLE AS\n\n## Synopsis\n\nThe `CREATE TABLE AS` statement is used to create a new table that contains the result of a `SELECT` query. This statement can be used to create a new table with or without data. \n\n## Description\n\nThis section of the app technical guide provides a detailed explanation of the `CREATE TABLE AS` statement. It explains how to create a new table with the results of a `SELECT` query and how to set properties on the newly created table. \n\nThe guide explains that the `CREATE TABLE AS` statement can be used to create a new table with the results of a `SELECT` query. It also explains that the `CREATE TABLE` statement can be used to create an empty table. The guide also explains that the `IF NOT EXISTS` clause can be used to suppress the error if the table already exists. \n\nThe guide also explains that the `WITH` clause can be used to set properties on the newly created table. It provides an example of how to list all available table properties using a query. \n\n## Examples\n\nThis section of the app technical guide provides examples of how to use the `CREATE TABLE AS` statement. It provides examples of how to create a new table with the results of a `SELECT` query and how to set properties on the newly created table. \n\nThe examples show how to create a new table with the results of a `SELECT` query and how to specify column names for the new table. The examples also show how to create a new table that summarizes data from an existing table. \n\nThe examples also show how to create a new table if it does not already exist and how to create an empty table with the same schema as an existing table. \n\n## See also\n\nThis section of the app technical guide provides links to related statements that are used in conjunction with the `CREATE TABLE AS` statement. It provides links to the `CREATE TABLE` statement and the `SELECT` statement.\n## Questions: \n 1. What is the purpose of the `WITH` clause in the `CREATE TABLE AS` statement?\n   \n   The `WITH` clause in the `CREATE TABLE AS` statement is used to set properties on the newly created table. \n\n2. How can a blockchain SQL analyst list all available table properties?\n   \n   A blockchain SQL analyst can list all available table properties by running the following query: `SELECT * FROM system.metadata.table_properties`.\n\n3. Can the `CREATE TABLE AS` statement be used to create an empty table?\n   \n   No, the `CREATE TABLE AS` statement is used to create a new table containing the result of a `SELECT` query. To create an empty table, the `CREATE TABLE` statement should be used.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/create-table-as.md"}}],["163",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/create-table.md)\n\nThe `CREATE TABLE` section of the Dune Docs project is a technical guide that explains how to create a new, empty table with specified columns. The guide provides a synopsis of the syntax for creating a table, which includes the table name, column names, data types, and optional clauses such as `IF NOT EXISTS`, `COMMENT`, and `WITH`. \n\nThe `IF NOT EXISTS` clause is optional and suppresses an error if the table already exists. The `COMMENT` clause is also optional and allows the user to add a comment to the table. The `WITH` clause is used to set properties on the newly created table or on single columns. The guide provides examples of how to use the `WITH` clause to set the format of the table to 'ORC' and to add a comment to a column.\n\nThe guide also explains how to use the `LIKE` clause to include all the column definitions from an existing table in the new table. Multiple `LIKE` clauses may be specified, which allows copying the columns from multiple tables. If `INCLUDING PROPERTIES` is specified, all of the table properties are copied to the new table. If the `WITH` clause specifies the same property name as one of the copied properties, the value from the `WITH` clause will be used. The default behavior is `EXCLUDING PROPERTIES`. The `INCLUDING PROPERTIES` option maybe specified for at most one table.\n\nThe guide provides examples of how to create a new table, create a table if it does not already exist, and create a new table using the columns from an existing table plus additional columns at the start and end. \n\nOverall, the `CREATE TABLE` section of the Dune Docs project is a comprehensive guide that explains how to create a new table with specified columns and optional clauses. The guide provides examples of how to use the different clauses and options to customize the table creation process.\n## Questions: \n 1. What is the purpose of the `WITH` clause in the `CREATE TABLE` statement?\n   \n   The `WITH` clause can be used to set properties on the newly created table or on single columns.\n\n2. How can a blockchain SQL analyst list all available table properties?\n   \n   A blockchain SQL analyst can run the following query: `SELECT * FROM system.metadata.table_properties`.\n\n3. Can the `LIKE` clause be used to copy columns from multiple tables?\n   \n   Yes, multiple `LIKE` clauses may be specified, which allows copying the columns from multiple tables.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/create-table.md"}}],["164",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/create-view.md)\n\n# CREATE VIEW\n\nThe `CREATE VIEW` command is used to create a new view of a `SELECT` query. A view is a logical table that can be referenced by future queries. Views do not contain any data. Instead, the query stored by the view is executed every time the view is referenced by another query. \n\nThe optional `OR REPLACE` clause causes the view to be replaced if it already exists rather than raising an error. \n\nThe `SECURITY` clause specifies the security mode of the view. In the default `DEFINER` security mode, tables referenced in the view are accessed using the permissions of the view owner (the *creator* or *definer* of the view) rather than the user executing the query. This allows providing restricted access to the underlying tables, for which the user may not be allowed to access directly. In the `INVOKER` security mode, tables referenced in the view are accessed using the permissions of the user executing the query (the *invoker* of the view). A view created in this mode is simply a stored query. Regardless of the security mode, the `current_user` function will always return the user executing the query and thus may be used within views to filter out rows or otherwise restrict access.\n\nThe `COMMENT` clause is used to add a comment to the view. \n\nThe `AS` keyword is used to specify the query that defines the view. \n\nThe `EXAMPLES` section provides examples of how to create views. \n\nThe `SEE ALSO` section provides links to related commands such as `DROP VIEW` and `SHOW CREATE VIEW`. \n\nOverall, this guide covers the `CREATE VIEW` command, which is used to create a new view of a `SELECT` query. It explains how to specify the security mode of the view, add a comment to the view, and provides examples of how to create views. This guide is relevant to the `API` section of the `dune docs` project, which involves creating and managing views for the application.\n## Questions: \n 1. What is the purpose of the `CREATE VIEW` command in the context of a blockchain SQL database?\n- Answer: A blockchain SQL analyst might want to know how the `CREATE VIEW` command can be used to create logical tables that can be referenced by future queries in order to summarize or filter blockchain data.\n\n2. How does the `DEFINER` security mode work, and what implications does it have for blockchain data access?\n- Answer: A blockchain SQL analyst might want to know how the `DEFINER` security mode allows tables referenced in the view to be accessed using the permissions of the view owner, which could be useful for providing restricted access to blockchain data.\n\n3. Are there any limitations or best practices for using the `CREATE VIEW` command in the context of a blockchain SQL database?\n- Answer: A blockchain SQL analyst might want to know if there are any limitations or best practices for using the `CREATE VIEW` command in order to optimize performance or avoid potential security risks when working with blockchain data.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/create-view.md"}}],["165",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/delete.md)\n\n## DELETE\n\nThe `DELETE` section of the app technical guide covers the process of deleting rows from a table in the Dune Docs project. The `DELETE` command is used to remove one or more rows from a table based on a specified condition. The syntax for the `DELETE` command is as follows:\n\n``` text\nDELETE FROM table_name [ WHERE condition ]\n```\n\nThe `WHERE` clause is optional and is used to specify a condition that must be met for the rows to be deleted. If the `WHERE` clause is not specified, all rows from the table will be deleted.\n\nThe `Examples` section provides some sample use cases for the `DELETE` command in the Dune Docs project. The first example shows how to delete all line items that were shipped by air. The second example shows how to delete all line items for low priority orders by using a subquery to select the order keys for low priority orders. The third example shows how to delete all orders from the `orders` table.\n\nThe `Limitations` section notes that some connectors may have limited or no support for the `DELETE` command. Users are advised to consult the connector documentation for more information.\n\nOverall, the `DELETE` section of the app technical guide provides a clear and concise explanation of how to use the `DELETE` command in the Dune Docs project. The examples provided help to illustrate the different ways in which the `DELETE` command can be used, while the limitations section provides important information about potential issues that users may encounter when using the command.\n## Questions: \n 1. What type of database is this `DELETE` command applicable to?\n- The app technical guide does not specify the type of database, so the blockchain SQL analyst may need to refer to the connector documentation to determine if it is compatible with their specific database.\n\n2. Are there any restrictions on the use of the `WHERE` clause?\n- The app technical guide does not mention any restrictions on the use of the `WHERE` clause, but the blockchain SQL analyst may need to refer to the connector documentation to determine if there are any limitations or differences in syntax.\n\n3. How does this `DELETE` command affect the blockchain data?\n- The app technical guide does not mention any specific impact on blockchain data, so the blockchain SQL analyst may need to consider how this command fits into the overall blockchain architecture and data flow.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/delete.md"}}],["166",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/describe-input.md)\n\n## `DESCRIBE INPUT`\n\nThe `DESCRIBE INPUT` statement is used to list the input parameters of a prepared statement along with the position and type of each parameter. This statement is useful when you need to know the types of the parameters in a prepared statement, especially when some of the parameter types cannot be determined.\n\nThe `DESCRIBE INPUT` statement takes the name of the prepared statement as its argument. The output of the statement is a table that shows the position and type of each parameter in the prepared statement. If a parameter type cannot be determined, it will appear as `unknown`.\n\n### Examples\n\n#### Example 1\n\nIn this example, we prepare a query with three parameters and then describe the input parameters of the prepared statement using `DESCRIBE INPUT`.\n\n``` sql\nPREPARE my_select1 FROM\nSELECT ? FROM nation WHERE regionkey = ? AND name < ?;\n```\n\n``` sql\nDESCRIBE INPUT my_select1;\n```\n\nThe output of the `DESCRIBE INPUT` statement will be:\n\n``` text\nPosition | Type\n--------------------\n       0 | unknown\n       1 | bigint\n       2 | varchar\n(3 rows)\n```\n\nThis output shows that the prepared statement `my_select1` has three input parameters. The first parameter has an unknown type, while the second parameter is of type `bigint` and the third parameter is of type `varchar`.\n\n#### Example 2\n\nIn this example, we prepare a query with no parameters and then describe the input parameters of the prepared statement using `DESCRIBE INPUT`.\n\n``` sql\nPREPARE my_select2 FROM\nSELECT * FROM nation;\n```\n\n``` sql\nDESCRIBE INPUT my_select2;\n```\n\nThe output of the `DESCRIBE INPUT` statement will be:\n\n``` text\nPosition | Type\n-----------------\n(0 rows)\n```\n\nThis output shows that the prepared statement `my_select2` has no input parameters.\n\n### See also\n\n- `PREPARE`: prepares a statement for execution.\n## Questions: \n 1. What is the purpose of the `DESCRIBE INPUT` statement in the context of a blockchain SQL database?\n- A blockchain SQL analyst might want to know how to use the `DESCRIBE INPUT` statement to list the input parameters of a prepared statement and their types, which can be useful for debugging and optimizing blockchain queries.\n\n2. How does the `DESCRIBE INPUT` statement handle unknown parameter types?\n- A blockchain SQL analyst might want to know how the `DESCRIBE INPUT` statement handles unknown parameter types, which are listed as `unknown` in the output.\n\n3. Are there any other related SQL statements or functions that a blockchain SQL analyst should be aware of when working with prepared statements?\n- A blockchain SQL analyst might want to know if there are any other related SQL statements or functions that work with prepared statements, such as the `prepare` statement mentioned in the \"See also\" section.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/describe-input.md"}}],["167",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/describe-output.md)\n\n# Dune Docs App Technical Guide\n\n## Describe Output\n\nThe `DESCRIBE OUTPUT` statement is used to list the output columns of a prepared statement in the Dune Docs app. This includes the column name (or alias), catalog, schema, table, type, type size in bytes, and a boolean indicating if the column is aliased. \n\nThe `DESCRIBE OUTPUT` statement is useful for debugging and understanding the structure of a prepared statement. It can be used to verify that the output columns of a prepared statement match the expected structure.\n\nThe `DESCRIBE OUTPUT` statement takes the following syntax:\n\n``` text\nDESCRIBE OUTPUT statement_name\n```\n\nWhere `statement_name` is the name of the prepared statement to describe.\n\n### Examples\n\nThe following examples demonstrate how to use the `DESCRIBE OUTPUT` statement in the Dune Docs app:\n\n#### Example 1\n\nPrepare and describe a query with four output columns:\n\n``` sql\nPREPARE my_select1 FROM\nSELECT * FROM nation;\n\nDESCRIBE OUTPUT my_select1;\n```\n\nThis will output the following:\n\n``` text\nColumn Name | Catalog | Schema | Table  |  Type   | Type Size | Aliased\n-------------+---------+--------+--------+---------+-----------+---------\nnationkey   | tpch    | sf1    | nation | bigint  |         8 | false\nname        | tpch    | sf1    | nation | varchar |         0 | false\nregionkey   | tpch    | sf1    | nation | bigint  |         8 | false\ncomment     | tpch    | sf1    | nation | varchar |         0 | false\n(4 rows)\n```\n\n#### Example 2\n\nPrepare and describe a query whose output columns are expressions:\n\n``` sql\nPREPARE my_select2 FROM\nSELECT count(*) as my_count, 1+2 FROM nation;\n\nDESCRIBE OUTPUT my_select2;\n```\n\nThis will output the following:\n\n``` text\nColumn Name | Catalog | Schema | Table |  Type  | Type Size | Aliased\n-------------+---------+--------+-------+--------+-----------+---------\nmy_count    |         |        |       | bigint |         8 | true\n_col1       |         |        |       | bigint |         8 | false\n(2 rows)\n```\n\n#### Example 3\n\nPrepare and describe a row count query:\n\n``` sql\nPREPARE my_create FROM\nCREATE TABLE foo AS SELECT * FROM nation;\n\nDESCRIBE OUTPUT my_create;\n```\n\nThis will output the following:\n\n``` text\nColumn Name | Catalog | Schema | Table |  Type  | Type Size | Aliased\n-------------+---------+--------+-------+--------+-----------+---------\nrows        |         |        |       | bigint |         8 | false\n(1 row)\n```\n\n## See also\n\n`prepare`{.interpreted-text role=\"doc\"}\n\nThe `prepare` statement is used to prepare a SQL statement for execution in the Dune Docs app. It is often used in conjunction with the `DESCRIBE OUTPUT` statement to debug and understand the structure of prepared statements.\n## Questions: \n 1. What is the purpose of the `DESCRIBE OUTPUT` statement in the context of a blockchain SQL analyst's work?\n- A blockchain SQL analyst might want to know how to use the `DESCRIBE OUTPUT` statement to list the output columns of a prepared statement, including the column name (or alias), catalog, schema, table, type, type size in bytes, and a boolean indicating if the column is aliased.\n\n2. How can a blockchain SQL analyst use the `DESCRIBE OUTPUT` statement to prepare and describe a query with expressions as output columns?\n- A blockchain SQL analyst can use the `DESCRIBE OUTPUT` statement to prepare and describe a query with expressions as output columns by specifying the name of the prepared statement that contains the query.\n\n3. What is the relationship between the `DESCRIBE OUTPUT` statement and the `prepare` statement in the context of a blockchain SQL analyst's work?\n- The `DESCRIBE OUTPUT` statement is related to the `prepare` statement in that it is used to describe the output columns of a prepared statement that was created using the `prepare` statement.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/describe-output.md"}}],["168",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/describe.md)\n\nThis app technical guide covers the `DESCRIBE` command in the Dune Docs project. The `DESCRIBE` command is used to display the structure of a table in a database. The guide provides a synopsis of the command, which is `DESCRIBE table_name`, where `table_name` is the name of the table to be described. \n\nThe guide also explains that `DESCRIBE` is an alias for `show-columns`, which is another command that can be used to display the structure of a table. This information is useful for users who may be more familiar with the `show-columns` command and want to use it instead of `DESCRIBE`.\n\nOverall, this guide provides a clear and concise explanation of the `DESCRIBE` command and its purpose in the Dune Docs project. An example of how to use the command would be:\n\n``` text\nDESCRIBE customers\n```\n\nThis would display the structure of the `customers` table in the database.\n## Questions: \n 1. What is the purpose of the `DESCRIBE` command in the context of the dune docs project?\n- The app technical guide describes `DESCRIBE` as an alias for `show-columns`, but it is unclear how this command is used within the project.\n\n2. Does the dune docs project use SQL databases, and if so, which ones?\n- The `DESCRIBE` command is commonly used in SQL databases, so a blockchain SQL analyst may want to know if the dune docs project uses any SQL databases and which ones specifically.\n\n3. Are there any specific security measures in place to protect the SQL databases used by the dune docs project?\n- Since SQL databases can contain sensitive information, a blockchain SQL analyst may want to know if there are any security measures in place to protect the databases used by the dune docs project. The app technical guide does not provide any information on this topic.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/describe.md"}}],["169",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/execute.md)\n\n## `EXECUTE`\n\nThe `EXECUTE` header in this technical guide covers the syntax and usage of the `EXECUTE` statement in SQL. The `EXECUTE` statement is used to execute a prepared statement with the name `statement_name`. The `USING` clause is used to define parameter values for the prepared statement. \n\nThe `Description` section of this guide provides a brief explanation of the `EXECUTE` statement and its usage. The `Examples` section provides two examples of how to use the `EXECUTE` statement. The first example shows how to prepare and execute a query with no parameters. The second example shows how to prepare and execute a query with two parameters. The `See also` section provides a reference to the `prepare` statement, which is used to prepare a statement for execution.\n\nThis section of the technical guide is relevant to the `app` folder of the Dune Docs project, which likely includes an application that interacts with a SQL database. The `EXECUTE` statement is a fundamental part of SQL and is used to execute prepared statements, which can improve performance and security when executing SQL queries. By providing clear documentation on the syntax and usage of the `EXECUTE` statement, this technical guide can help developers working on the Dune Docs app to write efficient and secure SQL queries.\n## Questions: \n 1. What is the purpose of the `EXECUTE` statement in this app and how does it relate to blockchain technology?\n   \n   The `EXECUTE` statement is used to execute a prepared statement with specified parameter values. A blockchain SQL analyst might want to know how this statement is used in the app to interact with a blockchain database.\n\n2. Are there any security measures in place to prevent unauthorized execution of prepared statements? \n\n   The app technical guide does not mention any security measures related to prepared statement execution. A blockchain SQL analyst might want to know if there are any measures in place to prevent unauthorized access to the database.\n\n3. Can prepared statements be reused across multiple transactions or are they only valid for a single transaction? \n\n   The app technical guide does not provide information on the scope of prepared statements. A blockchain SQL analyst might want to know if prepared statements can be reused across multiple transactions or if they are only valid for a single transaction.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/execute.md"}}],["170",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/explain-analyze.md)\n\n# EXPLAIN ANALYZE\n\nThe `EXPLAIN ANALYZE` command is used to execute a statement and show the distributed execution plan of the statement along with the cost of each operation. This command is useful for analyzing the performance of a query and identifying any bottlenecks. \n\nThe `VERBOSE` option provides more detailed information and low-level statistics, which may require knowledge of Trino internals and implementation details. However, it should be noted that the stats may not be entirely accurate, especially for queries that complete quickly.\n\nThe guide provides an example of how to use the `EXPLAIN ANALYZE` command to analyze a query. In the example, the CPU time spent in each stage is shown, as well as the relative cost of each plan node in the stage. For each plan node, additional statistics are provided, such as average input per node instance. These statistics are useful when one wants to detect data anomalies for a query, such as skewness.\n\nWhen the `VERBOSE` option is used, some operators may report additional information. For example, the window function operator will output additional metrics such as CPU time distribution, input rows distribution, and scheduled time distribution.\n\nOverall, the `EXPLAIN ANALYZE` command is a powerful tool for analyzing the performance of a query and identifying any bottlenecks. By providing detailed information about the execution plan and cost of each operation, it allows developers to optimize their queries and improve the overall performance of their application.\n## Questions: \n 1. What is the purpose of the `EXPLAIN ANALYZE` statement in this app?\n- The `EXPLAIN ANALYZE` statement is used to execute a query and show the distributed execution plan of the statement along with the cost of each operation.\n\n2. What is the `VERBOSE` option and when might it be useful?\n- The `VERBOSE` option provides more detailed information and low-level statistics, which may be useful for understanding Trino internals and implementation details. It might be useful when trying to detect data anomalies for a query.\n\n3. Are the stats generated by `EXPLAIN ANALYZE` always accurate?\n- No, the stats may not be entirely accurate, especially for queries that complete quickly.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/explain-analyze.md"}}],["171",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/explain.md)\n\nThe app technical guide covers the usage of the `EXPLAIN` statement in various formats and types to analyze and validate SQL query execution plans. The guide provides a detailed explanation of the `EXPLAIN` statement syntax, options, and descriptions of different plan fragment types.\n\nThe guide is divided into the following sections:\n\n1. **Synopsis**: This section provides the syntax for the `EXPLAIN` statement, including the available options for format and type.\n\n2. **Description**: This section explains the purpose of the `EXPLAIN` statement and the different plan fragment types, such as `SINGLE`, `HASH`, `ROUND_ROBIN`, `BROADCAST`, and `SOURCE`.\n\n3. **Examples**: This section contains various examples demonstrating the usage of the `EXPLAIN` statement with different types and formats. The examples include:\n   - EXPLAIN (TYPE LOGICAL): Shows the logical execution plan in text format.\n   - EXPLAIN (TYPE LOGICAL, FORMAT JSON): Shows the logical execution plan in JSON format.\n   - EXPLAIN (TYPE DISTRIBUTED): Shows the distributed execution plan in text format.\n   - EXPLAIN (TYPE DISTRIBUTED, FORMAT JSON): Shows the distributed execution plan in JSON format.\n   - EXPLAIN (TYPE VALIDATE): Validates the supplied query statement for syntactical and semantic correctness.\n   - EXPLAIN (TYPE IO): Shows the input and output details about the accessed objects in JSON format.\n\n4. **See also**: This section provides a reference to the `explain-analyze` documentation for further reading.\n## Questions: \n 1. **What are the different output formats supported by the EXPLAIN command?**\n\n   The EXPLAIN command supports three output formats: TEXT, GRAPHVIZ, and JSON. These formats allow users to view the execution plan in different representations, making it easier to understand and analyze the plan.\n\n2. **What are the different types of execution plans that can be generated using the EXPLAIN command?**\n\n   The EXPLAIN command can generate four types of execution plans: LOGICAL, DISTRIBUTED, VALIDATE, and IO. The LOGICAL and DISTRIBUTED plans show the logical and distributed execution plans of a statement, respectively. The VALIDATE plan checks the statement for syntactical and semantic correctness, while the IO plan provides input and output details about the accessed objects in JSON format.\n\n3. **How does the EXPLAIN command represent data distribution in the execution plan?**\n\n   The EXPLAIN command represents data distribution in the execution plan using fragment types. The fragment types include SINGLE, HASH, ROUND_ROBIN, BROADCAST, and SOURCE. These types specify how the fragment is executed by Trino nodes and how the data is distributed between fragments.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/explain.md"}}],["172",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/index.md)\n\n# Overview\n\nThis technical guide provides an overview of DuneSQL, an ANSI SQL compliant query engine that follows the standard SQL syntax. The guide is divided into chapters that describe the SQL syntax used in Trino, a reference to the supported SQL data types, and numerous SQL functions and operators provided by Trino.\n\nThe first chapter of the guide provides a brief introduction to DuneSQL and its compliance with the ANSI SQL standard. The subsequent chapters provide a comprehensive list of SQL commands and functions supported by Trino, including:\n\n- ALTER MATERIALIZED VIEW\n- ALTER SCHEMA\n- ALTER TABLE\n- ALTER VIEW\n- ANALYZE\n- CALL\n- COMMENT\n- COMMIT\n- CREATE MATERIALIZED VIEW\n- CREATE ROLE\n- CREATE SCHEMA\n- CREATE TABLE\n- CREATE TABLE AS\n- CREATE VIEW\n- DEALLOCATE PREPARE\n- DELETE\n- DESCRIBE\n- DESCRIBE INPUT\n- DESCRIBE OUTPUT\n- DROP MATERIALIZED VIEW\n- DROP ROLE\n- DROP SCHEMA\n- DROP TABLE\n- DROP VIEW\n- EXECUTE\n- EXPLAIN\n- EXPLAIN ANALYZE\n- GRANT\n- GRANT ROLES\n- INSERT\n- MATCH_RECOGNIZE\n- MERGE\n- Row pattern recognition in window structures\n- PREPARE\n- REFRESH MATERIALIZED VIEW\n- RESET SESSION\n- REVOKE\n- REVOKE ROLES\n- ROLLBACK\n- SELECT\n- SET ROLE\n- SET SESSION\n- SET TIME ZONE\n- SHOW CATALOGS\n- SHOW COLUMNS\n- SHOW CREATE MATERIALIZED VIEW\n- SHOW CREATE SCHEMA\n- SHOW CREATE TABLE\n- SHOW CREATE VIEW\n- SHOW FUNCTIONS\n- SHOW GRANTS\n- SHOW ROLE GRANTS\n- SHOW ROLES\n- SHOW SCHEMAS\n- SHOW SESSION\n- SHOW STATS\n- SHOW TABLES\n- START TRANSACTION\n- TRUNCATE\n- UPDATE\n- USE\n- VALUES\n\nThe guide also includes a note indicating that the section on SQL syntax may be summarized on a single page, as the project mostly uses basic SELECT statements. \n\nOverall, this technical guide provides a comprehensive reference for developers working with DuneSQL and Trino, outlining the supported SQL commands and functions available for use in the project.\n## Questions: \n 1. What is the purpose of DuneSQL and how does it relate to blockchain technology?\n- The app technical guide does not provide information on how DuneSQL relates to blockchain technology, so a blockchain SQL analyst may want to know if this tool is specifically designed for blockchain data analysis or if it can be used for any type of SQL data analysis.\n\n2. Are there any limitations or differences in the SQL syntax used in Trino compared to other SQL query engines?\n- The app technical guide mentions that it describes the SQL syntax used in Trino, so a blockchain SQL analyst may want to know if there are any limitations or differences in the SQL syntax used in Trino compared to other SQL query engines, especially if they are used to working with a different SQL syntax.\n\n3. Does DuneSQL support any specific SQL functions or operators that are commonly used in blockchain data analysis?\n- The app technical guide mentions that Trino provides numerous SQL functions and operators, but it does not specify if any of these are particularly useful for blockchain data analysis. A blockchain SQL analyst may want to know if there are any specific SQL functions or operators that are commonly used in blockchain data analysis that are supported by DuneSQL.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/index.md"}}],["173",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/insert.md)\n\n## `INSERT` Command\n\nThe `INSERT` command is used to add new rows to a table in the Dune Docs project. The syntax for the command is as follows:\n\n``` text\nINSERT INTO table_name [ ( column [, ... ] ) ] query\n```\n\nThe `table_name` parameter specifies the name of the table to insert the new rows into. The optional `column` parameter specifies the columns to insert data into. If the list of column names is specified, they must exactly match the list of columns produced by the query. Each column in the table not present in the column list will be filled with a `null` value. Otherwise, if the list of columns is not specified, the columns produced by the query must exactly match the columns in the table being inserted into.\n\nThe `query` parameter specifies the data to insert into the table. This can be a `SELECT` statement or a list of values. \n\n### Examples\n\nHere are some examples of how to use the `INSERT` command in the Dune Docs project:\n\n- Load additional rows into the `orders` table from the `new_orders` table:\n\n    ``` sql\n    INSERT INTO orders\n    SELECT * FROM new_orders;\n    ```\n\n- Insert a single row into the `cities` table:\n\n    ``` sql\n    INSERT INTO cities VALUES (1, 'San Francisco');\n    ```\n\n- Insert multiple rows into the `cities` table:\n\n    ``` sql\n    INSERT INTO cities VALUES (2, 'San Jose'), (3, 'Oakland');\n    ```\n\n- Insert a single row into the `nation` table with the specified column list:\n\n    ``` sql\n    INSERT INTO nation (nationkey, name, regionkey, comment)\n    VALUES (26, 'POLAND', 3, 'no comment');\n    ```\n\n- Insert a row without specifying the `comment` column. That column will be `null`:\n\n    ``` sql\n    INSERT INTO nation (nationkey, name, regionkey)\n    VALUES (26, 'POLAND', 3);\n    ```\n\n### See also\n\n- `values` command: This command is used to insert a single row into a table with a list of values.\n## Questions: \n 1. What is the purpose of this app and how does it relate to blockchain technology?\n- The app technical guide is for an SQL database tool called dune docs, and there is no explicit mention of blockchain technology. A blockchain SQL analyst might want to know if this tool is specifically designed for use with blockchain databases or if it has any features that are particularly useful for analyzing blockchain data.\n\n2. Are there any security features built into this app to protect against unauthorized access or data breaches?\n- The app technical guide does not mention any security features, so a blockchain SQL analyst might want to know if there are any measures in place to ensure the security of sensitive data, especially if the app is being used to analyze blockchain transactions that contain confidential information.\n\n3. Can this app be used to analyze data from multiple blockchain networks or is it limited to a specific blockchain platform?\n- The app technical guide does not provide information about which blockchain networks or platforms it is compatible with, so a blockchain SQL analyst might want to know if the app can be used to analyze data from a variety of blockchain networks or if it is limited to a specific platform.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/insert.md"}}],["174",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/match-recognize.md)\n\nThe app technical guide covers the `MATCH_RECOGNIZE` clause, which is used to detect patterns in a set of rows using row pattern syntax based on regular expressions. The guide explains various components of the `MATCH_RECOGNIZE` clause, such as partitioning and ordering, row pattern measures, rows per match, after match skip, row pattern syntax, row pattern union variables, row pattern variable definitions, and row pattern recognition expressions.\n\nThe guide provides examples to illustrate the usage of the `MATCH_RECOGNIZE` clause, such as detecting a V-shape pattern in the `totalprice` column of orders made by a customer. It also explains the usage of various subclauses, such as `PARTITION BY`, `ORDER BY`, `MEASURES`, `ROWS PER MATCH`, `AFTER MATCH SKIP`, `PATTERN`, `SUBSET`, and `DEFINE`.\n\nAdditionally, the guide covers the usage of pattern navigation functions, aggregate functions, and the `RUNNING` and `FINAL` semantics in the context of row pattern recognition. It also discusses the evaluation of expressions in empty matches and unmatched rows.\n## Questions: \n 1. **What is the purpose of the `MATCH_RECOGNIZE` clause in the app technical guide?**\n\n   The `MATCH_RECOGNIZE` clause is an optional subclause of the `FROM` clause, used to detect patterns in a set of rows. Patterns of interest are specified using row pattern syntax based on regular expressions. For each detected match, one or more rows are returned, containing requested information about the match.\n\n2. **How can I use the `MEASURES` clause in the app technical guide?**\n\n   The `MEASURES` clause allows you to specify what information is retrieved from a matched sequence of rows. It consists of measure expressions that are scalar expressions whose value is computed based on a match. Each measure defines an output column of the pattern recognition, and the column can be referenced with the `measure_name`.\n\n3. **What is the difference between `ONE ROW PER MATCH` and `ALL ROWS PER MATCH` in the app technical guide?**\n\n   `ONE ROW PER MATCH` is the default option, where for every match, a single row of output is produced, consisting of `PARTITION BY` columns and measures. `ALL ROWS PER MATCH` produces an output row for every row of a match, unless it is excluded from the output by the exclusion syntax. Output consists of `PARTITION BY` columns, `ORDER BY` columns, measures, and remaining columns from the input table.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/match-recognize.md"}}],["175",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/merge.md)\n\n# MERGE\n\nThe `MERGE` statement is used to conditionally update and/or delete rows of a table and/or insert new rows into a table. This section of the app technical guide provides a detailed explanation of the `MERGE` statement, including its syntax, description, examples, and limitations.\n\nThe `MERGE` statement has the following syntax:\n\n``` text\nMERGE INTO target_table [ [ AS ]  target_alias ]\nUSING { source_table | query } [ [ AS ] source_alias ]\nON search_condition\nwhen_clause [...]\n```\n\nwhere `when_clause` is one of:\n\n``` text\nWHEN MATCHED [ AND condition ]\n    THEN DELETE\n```\n\n``` text\nWHEN MATCHED [ AND condition ]\n    THEN UPDATE SET ( column = expression [, ...] )\n```\n\n``` text\nWHEN NOT MATCHED [ AND condition ]\n    THEN INSERT [ column_list ] VALUES (expression, ...)\n```\n\nThe `MERGE` statement supports an arbitrary number of `WHEN` clauses with different `MATCHED` conditions, executing the `DELETE`, `UPDATE`, or `INSERT` operation in the first `WHEN` clause selected by the `MATCHED` state and the match condition.\n\nFor each source row, the `WHEN` clauses are processed in order. Only the first matching `WHEN` clause is executed, and subsequent clauses are ignored. A `MERGE_TARGET_ROW_MULTIPLE_MATCHES` exception is raised when a single target table row matches more than one source row.\n\nIf a source row is not matched by any `WHEN` clause and there is no `WHEN NOT MATCHED` clause, the source row is ignored.\n\nIn `WHEN` clauses with `UPDATE` operations, the column value expressions can depend on any field of the target or the source. In the `NOT MATCHED` case, the `INSERT` expressions can depend on any field of the source.\n\nThe examples provided in this section illustrate how to use the `MERGE` statement to delete customers, update purchases, and insert new rows into a table. The examples show how to use the `MERGE` statement with different `WHEN` clauses and match conditions.\n\nThe `MERGE` statement has some limitations. Any connector can be used as a source table for a `MERGE` statement. However, only connectors that support the `MERGE` statement can be the target of a merge operation. Refer to the connector documentation for more information.\n\nIn summary, the `MERGE` statement is a powerful SQL statement that allows you to conditionally update and/or delete rows of a table and/or insert new rows into a table. The `MERGE` statement supports an arbitrary number of `WHEN` clauses with different `MATCHED` conditions, executing the `DELETE`, `UPDATE`, or `INSERT` operation in the first `WHEN` clause selected by the `MATCHED` state and the match condition. The examples provided in this section illustrate how to use the `MERGE` statement with different `WHEN` clauses and match conditions.\n## Questions: \n 1. What is the purpose of the `MERGE` statement in the context of a blockchain SQL database?\n- Answer: A blockchain SQL analyst might want to know how the `MERGE` statement can be used to conditionally update, delete, and insert rows in a table, and whether it can be used to modify blockchain data.\n\n2. Are there any limitations to using the `MERGE` statement with blockchain data?\n- Answer: A blockchain SQL analyst might want to know if there are any limitations to using the `MERGE` statement with blockchain data, and whether any specific connectors are required.\n\n3. Can the `MERGE` statement be used to modify data in a blockchain network?\n- Answer: A blockchain SQL analyst might want to know if the `MERGE` statement can be used to modify data in a blockchain network, and if so, what implications this might have for the integrity and security of the network.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/merge.md"}}],["176",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/pattern-recognition-in-window.md)\n\nThis technical guide covers the topic of row pattern recognition in window structures for the Dune Docs project. The guide explains how to define a window frame with row pattern recognition, which involves many syntactical components, mandatory or optional, and enforces certain limitations on the frame extent. The guide also describes the pattern recognition clauses, including the `PATTERN` and `DEFINE` clauses, which specify a row pattern and define the row pattern primary variables in terms of boolean conditions that must be satisfied. \n\nThe `MEASURES` clause is also explained, which is syntactically similar to the `MEASURES` clause of `MATCH_RECOGNIZE`. However, the semantics of this clause differs between `MATCH_RECOGNIZE` and window. The `AFTER MATCH SKIP` clause, `INITIAL` or `SEEK` modifier, and `SUBSET` clause are also covered in detail. \n\nThe guide then explains how pattern recognition in window processes input rows in two different cases: upon a row pattern measure call over the window and upon a window function call over the window. The output row produced for each input row consists of all values from the input row and the value of the called measure or window function, computed with respect to the pattern match associated with the row. \n\nFinally, the guide covers empty matches and unmatched rows. An empty match is a successful match that does not involve any pattern variables, while an unmatched row is a row for which no match can be found. The guide explains that in most cases, the results for empty matches and unmatched rows are the same, but a constant measure can be helpful to distinguish between them. \n\nOverall, this guide provides a detailed explanation of row pattern recognition in window structures, including the syntax and semantics of the various clauses involved, and how input rows are processed with pattern recognition.\n## Questions: \n 1. What is the difference between row pattern recognition in window structures and in `MATCH_RECOGNIZE`?\n- The app technical guide explains that in window structures, the pattern matching can neither match rows nor retrieve input values outside the frame, unlike in `MATCH_RECOGNIZE` where the pattern search can explore all rows until the partition end, and all rows of the partition are available for computations.\n\n2. What are the limitations of the `frame_extent` in a window frame with row pattern recognition?\n- The `frame_extent` with row pattern recognition must be defined in terms of `ROWS`, and the frame start must be at the `CURRENT ROW`, which limits the allowed frame extent values to `ROWS BETWEEN CURRENT ROW AND CURRENT ROW`, `ROWS BETWEEN CURRENT ROW AND <expression> FOLLOWING`, and `ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING`.\n\n3. Can you specify `ONE ROW PER MATCH` or `ALL ROWS PER MATCH` in window structures?\n- No, you cannot specify `ONE ROW PER MATCH` or `ALL ROWS PER MATCH` in window structures because all calls over window, whether they are regular window functions or measures, must comply with the window semantics, which is supposed to produce exactly one output row for every input row. The output mode of pattern recognition in window is a combination of `ONE ROW PER MATCH` and `WITH UNMATCHED ROWS`.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/pattern-recognition-in-window.md"}}],["177",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/prepare.md)\n\nThe `PREPARE` section of the app technical guide covers the functionality of preparing SQL statements for execution at a later time. This feature is located in the `app` folder of the project. The `Synopsis` section provides the syntax for the `PREPARE` statement, which takes in a statement name and the SQL statement to be prepared. \n\nThe `Description` section explains that prepared statements are queries that are saved in a session with a given name. These statements can include parameters in place of literals to be replaced at execution time. Parameters are represented by question marks. The section also provides examples of how to prepare select and insert queries with and without parameters.\n\nThe `Examples` section provides code snippets demonstrating how to prepare select and insert queries with and without parameters. The examples show how to use the `PREPARE` statement to save a select query with a given name, how to prepare a select query with parameters, and how to prepare an insert query.\n\nThe `See also` section lists related statements that can be used in conjunction with `PREPARE`, such as `execute`, `deallocate-prepare`, `describe-input`, and `describe-output`. These statements are also located in the `app` folder of the project and can be used to execute, deallocate, and describe prepared statements.\n\nOverall, the `PREPARE` section of the app technical guide provides a comprehensive overview of how to prepare SQL statements for execution at a later time in the project's `app` folder.\n## Questions: \n 1. What is the purpose of the `PREPARE` statement in the context of a blockchain SQL database?\n- A blockchain SQL analyst might want to know how the `PREPARE` statement can be used to optimize query performance and reduce network traffic when interacting with the blockchain database.\n\n2. Are there any security concerns related to using prepared statements in this app?\n- A blockchain SQL analyst might want to know if there are any vulnerabilities or risks associated with using prepared statements in the app, especially if sensitive data is being queried or inserted.\n\n3. How does the `PREPARE` statement interact with other SQL commands in the app?\n- A blockchain SQL analyst might want to understand how the `PREPARE` statement fits into the overall architecture of the app and how it can be used in conjunction with other SQL commands to achieve specific goals.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/prepare.md"}}],["178",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/refresh-materialized-view.md)\n\n# Refresh Materialized View\n\nThe `Refresh Materialized View` section of the app technical guide covers the process of initially populating or refreshing the data stored in a materialized view. The materialized view must be defined with `create-materialized-view`. The data is retrieved from the underlying tables accessed by the defined query.\n\nThe initial population of the materialized view can be processing intensive since it reads the data from the source tables and performs physical write operations. The refresh operation can be less intensive if the underlying data has not changed and the connector has implemented a mechanism to be aware of that. The specific implementation and performance varies by connector used to create the materialized view.\n\nThe `Synopsis` section provides a code snippet that shows the syntax for refreshing a materialized view. The `Description` section provides a detailed explanation of the process of refreshing a materialized view, including the fact that the materialized view must be defined with `create-materialized-view`. The section also explains that the initial population of the materialized view can be processing intensive, and that the refresh operation can be less intensive if the underlying data has not changed.\n\nThe `See also` section provides links to related sections of the app technical guide, including `create-materialized-view`, `drop-materialized-view`, and `show-create-materialized-view`.\n\nExample:\n\nTo refresh a materialized view named `sales_data`, the following code can be used:\n\n``` text\nREFRESH MATERIALIZED VIEW sales_data\n```\n## Questions: \n 1. What is the purpose of the `REFRESH MATERIALIZED VIEW` command in the context of a blockchain SQL database?\n- Answer: A blockchain SQL analyst might want to know how this command can be used to update or retrieve data from materialized views in the blockchain database.\n\n2. How does the performance of the `REFRESH MATERIALIZED VIEW` command vary depending on the connector used to create the materialized view?\n- Answer: A blockchain SQL analyst might want to understand how different connectors can affect the performance of this command when working with materialized views in the blockchain database.\n\n3. Are there any security considerations or limitations when using the `REFRESH MATERIALIZED VIEW` command in the context of a blockchain SQL database?\n- Answer: A blockchain SQL analyst might want to know if there are any security risks or limitations associated with using this command to update or retrieve data from materialized views in the blockchain database.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/refresh-materialized-view.md"}}],["179",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/reset-session.md)\n\n# RESET SESSION\n\n## Synopsis\n\nThe `RESET SESSION` command is used to reset a session property value to its default value. This command can be used to reset a specific session property or a property within a specific catalog.\n\n## Description\n\nThe `RESET SESSION` command is used to reset a session property value to its default value. This command can be used to reset a specific session property or a property within a specific catalog. The syntax for resetting a session property is as follows:\n\n``` text\nRESET SESSION name\nRESET SESSION catalog.name\n```\n\nThe first syntax resets a session property to its default value. The second syntax resets a property within a specific catalog to its default value.\n\n## Examples\n\nHere are some examples of how to use the `RESET SESSION` command:\n\n``` sql\nRESET SESSION optimize_hash_generation;\nRESET SESSION hive.optimized_reader_enabled;\n```\n\nThe first example resets the `optimize_hash_generation` session property to its default value. The second example resets the `optimized_reader_enabled` property within the `hive` catalog to its default value.\n\n## See also\n\n- `set-session`: This command is used to set the value of a session property.\n- `show-session`: This command is used to display the current value of a session property.\n## Questions: \n 1. What is the purpose of the `RESET SESSION` command in the context of a blockchain SQL database?\n- Answer: A blockchain SQL analyst might want to know how the `RESET SESSION` command can be used to manage session properties in the context of a blockchain database.\n\n2. How does the `RESET SESSION` command interact with other SQL commands commonly used in blockchain databases?\n- Answer: A blockchain SQL analyst might want to know how the `RESET SESSION` command can be used in conjunction with other SQL commands to optimize performance or manage data consistency.\n\n3. Are there any security implications to using the `RESET SESSION` command in a blockchain database?\n- Answer: A blockchain SQL analyst might want to know if there are any security risks associated with using the `RESET SESSION` command, and if so, how to mitigate them.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/reset-session.md"}}],["180",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/show-catalogs.md)\n\nThe app technical guide covers the `SHOW CATALOGS` feature of the project app. This feature allows users to list the available catalogs. The `Synopsis` section provides the syntax for the feature, which is `SHOW CATALOGS [ LIKE pattern ]`. The `Description` section explains how to use the optional `LIKE` clause to filter the results to a desired subset. An example is given to illustrate how to find catalogs that begin with a specific letter or pattern. \n\nThis feature is useful for users who need to quickly view the available catalogs in the app. By using the `LIKE` clause, users can filter the results to a specific subset of catalogs, which can save time and make it easier to find the desired catalog. \n\nExample: \n\nTo list all available catalogs, the user can simply enter `SHOW CATALOGS` in the app. \n\nTo find catalogs that begin with the letter \"t\", the user can enter `SHOW CATALOGS LIKE 't%'`. This will return a list of all catalogs that start with the letter \"t\". \n\nOverall, the `SHOW CATALOGS` feature is a helpful tool for users to quickly view and filter the available catalogs in the app.\n## Questions: \n 1. What is the purpose of the `SHOW CATALOGS` command in this app?\n- The `SHOW CATALOGS` command is used to list the available catalogs in the app.\n\n2. Can the `LIKE` clause be used to filter results based on more complex patterns?\n- It is not specified in the app technical guide whether the `LIKE` clause can be used to filter results based on more complex patterns.\n\n3. Is there any additional functionality or options available for the `SHOW CATALOGS` command?\n- The app technical guide does not provide information on any additional functionality or options available for the `SHOW CATALOGS` command.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/show-catalogs.md"}}],["181",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/show-columns.md)\n\nThe `SHOW COLUMNS` section of the app technical guide covers the functionality of listing the columns in a specified table, along with their data type and other attributes. This feature is located in the `query` section of the project app. \n\nThe `Synopsis` section provides the syntax for using this feature, which includes the `SHOW COLUMNS` command followed by the name of the table to be queried. An optional `LIKE` clause can also be included to filter the results based on a specified pattern. \n\nThe `Description` section provides further details on how to use the `LIKE` clause to filter the results. An example query is provided to demonstrate how to find columns ending in `key` using the `LIKE` clause. \n\nOverall, this section of the app technical guide serves as a reference for developers who need to retrieve information about the columns in a specific table. The `SHOW COLUMNS` feature can be useful for debugging and troubleshooting, as well as for gaining a better understanding of the structure of a database.\n## Questions: \n 1. What is the purpose of the `SHOW COLUMNS` command in the context of a blockchain application?\n- A blockchain SQL analyst might want to know how this command is used in the specific context of the dune docs project and how it relates to the blockchain data being analyzed.\n\n2. Can the `LIKE` pattern be used to filter columns based on specific blockchain data attributes?\n- The analyst might want to know if the `LIKE` pattern can be used to filter columns based on specific blockchain data attributes, such as transaction ID or block height.\n\n3. Are there any limitations or considerations when using the `SHOW COLUMNS` command with blockchain data?\n- The analyst might want to know if there are any limitations or considerations when using the `SHOW COLUMNS` command with blockchain data, such as potential performance issues or compatibility with different blockchain platforms.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/show-columns.md"}}],["182",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/show-create-materialized-view.md)\n\nThe `SHOW CREATE MATERIALIZED VIEW` section of the app technical guide covers the SQL command used to display the SQL statement that creates a specified materialized view in the app. The `view_name` parameter specifies the name of the materialized view for which the SQL statement is to be displayed. This command is useful for developers who want to view the SQL statement used to create a materialized view for debugging or optimization purposes.\n\nThe `See also` section provides links to related commands that are used to create, drop, and refresh materialized views. The `create-materialized-view` command is used to create a new materialized view, while the `drop-materialized-view` command is used to delete an existing materialized view. The `refresh-materialized-view` command is used to update the data in a materialized view with the latest data from the underlying tables.\n\nAn example of how this command can be used is as follows:\n\n``` text\nSHOW CREATE MATERIALIZED VIEW sales_by_region;\n```\n\nThis command would display the SQL statement used to create the `sales_by_region` materialized view in the app. Developers can use this information to optimize the performance of the materialized view or to troubleshoot any issues that may arise. Overall, this section of the app technical guide provides developers with a useful tool for working with materialized views in the app.\n## Questions: \n 1. What is the purpose of the `SHOW CREATE MATERIALIZED VIEW` command in the context of a blockchain SQL database?\n- The blockchain SQL analyst might want to know how this command can be used to retrieve the SQL statement that creates a specific materialized view in the database.\n\n2. How does the `create-materialized-view` command mentioned in the `See also` section relate to the `SHOW CREATE MATERIALIZED VIEW` command?\n- The analyst might want to know how the `create-materialized-view` command can be used to create a new materialized view, and how it differs from the `SHOW CREATE MATERIALIZED VIEW` command which is used to retrieve the SQL statement that creates an existing materialized view.\n\n3. Can the `SHOW CREATE MATERIALIZED VIEW` command be used to modify or update an existing materialized view?\n- The analyst might want to know if this command can be used to make changes to an existing materialized view, or if it is only used to retrieve the SQL statement that creates the view.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/show-create-materialized-view.md"}}],["183",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/show-create-table.md)\n\n## `SHOW CREATE TABLE`\n\nThe `SHOW CREATE TABLE` command is used to display the SQL statement that was used to create a specified table. This command is useful when you need to recreate a table or when you want to see the exact structure of a table. \n\n### Synopsis\n\n``` text\nSHOW CREATE TABLE table_name\n```\n\n### Description\n\nThe `SHOW CREATE TABLE` command is used to display the SQL statement that was used to create a specified table. This command is useful when you need to recreate a table or when you want to see the exact structure of a table. \n\n### Examples\n\nThe following example shows how to use the `SHOW CREATE TABLE` command to display the SQL statement that was used to create the `orders` table:\n\n``` text\nSHOW CREATE TABLE sf1.orders;\n```\n\nThis will output the following SQL statement:\n\n``` text\nCREATE TABLE tpch.sf1.orders (\norderkey bigint,\norderstatus varchar,\ntotalprice double,\norderdate varchar\n)\nWITH (\nformat = 'ORC',\npartitioned_by = ARRAY['orderdate']\n)\n```\n\n### See also\n\n`create-table`{.interpreted-text role=\"doc\"}\n\nThis command is useful in the `data-tables` section of the project, where tables are created and managed. It allows users to view the exact SQL statement used to create a table, which can be useful for debugging or recreating tables.\n## Questions: \n 1. What is the purpose of the `SHOW CREATE TABLE` command in the context of a blockchain SQL analyst? \n   - A blockchain SQL analyst might want to know how to create tables in a database to store blockchain data, and this command can show them the SQL statement needed to do so.\n   \n2. Can this command be used with all SQL databases commonly used in blockchain analysis, or are there limitations? \n   - A blockchain SQL analyst might want to know if this command is compatible with the specific SQL database they are using for blockchain analysis, as some databases may have different syntax or limitations.\n   \n3. Are there any security concerns or best practices to keep in mind when using this command to view SQL statements? \n   - A blockchain SQL analyst might want to know if there are any potential security risks or best practices to follow when using this command to view SQL statements, especially if they are working with sensitive blockchain data.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/show-create-table.md"}}],["184",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/show-create-view.md)\n\nThe `SHOW CREATE VIEW` section of the app technical guide covers the functionality of displaying the SQL statement that creates a specified view. The `Synopsis` header provides an example of the syntax for using this command, which is `SHOW CREATE VIEW view_name`. The `Description` header explains that this command will display the SQL statement that was used to create the specified view. This can be useful for understanding how a view was created or for troubleshooting any issues with the view.\n\nThe `See also` header provides a reference to the `create-view` command, which is related to the `SHOW CREATE VIEW` command. This command is used to create a new view in the database. By referencing this command, users can easily navigate to the appropriate section of the documentation to learn more about creating views.\n\nAn example of how this command might be used in the context of the app could be if a user is experiencing issues with a particular view and wants to understand how it was created. They could use the `SHOW CREATE VIEW` command to display the SQL statement that created the view, which could help them identify any issues with the view's creation. Overall, this section of the app technical guide provides a clear explanation of how to use the `SHOW CREATE VIEW` command and its purpose within the app.\n## Questions: \n 1. What database management system is this app technical guide for?\n- This information is not provided in the app technical guide. \n\n2. Can this command be used to show the SQL statement for a materialized view?\n- This information is not provided in the app technical guide. \n\n3. Are there any limitations or restrictions on using this command for views created with complex SQL statements?\n- This information is not provided in the app technical guide.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/show-create-view.md"}}],["185",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/show-functions.md)\n\n# Explanation of the Dune Docs App Technical Guide\n\n## Show Functions\n\nThe `Show Functions` section of the guide explains how to list all the functions available for use in queries. The section provides a synopsis of the command, which is `SHOW FUNCTIONS [ LIKE pattern ]`. The optional `LIKE` clause can be used to filter the results to a desired subset. The section also provides a description of the information that is displayed for each function returned, which includes the function name, return type, argument types, function type, deterministic, and description.\n\nThe section provides an example of how to use the `LIKE` clause to filter the results to functions beginning with `array`. The example query is `SHOW FUNCTIONS LIKE 'array%';`.\n\nThe section also explains that `SHOW FUNCTIONS` works with both built-in functions and custom functions. An example is provided of how to use the `LIKE` clause to filter the results to custom functions beginning with `cf`. The example query is `SHOW FUNCTIONS LIKE 'cf%';`. The section then provides a table of the three custom functions that are available, which includes the function name, return type, argument types, function type, deterministic, and description.\n\nOverall, the `Show Functions` section of the guide provides a clear explanation of how to list all the functions available for use in queries and how to filter the results to a desired subset. The section also provides helpful examples of how to use the `LIKE` clause to filter the results to functions beginning with a specific pattern and how to filter the results to custom functions.\n## Questions: \n 1. What is the purpose of this app and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the app or its relation to blockchain technology.\n\n2. Can this app be used to query data stored on a blockchain?\n- The app technical guide does not provide information on the type of data that can be queried or the data storage system used by the app.\n\n3. Are there any security features built into this app to protect against unauthorized access or manipulation of data?\n- The app technical guide does not provide information on any security features built into the app.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/show-functions.md"}}],["186",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/show-schemas.md)\n\nThe \"Show Schemas\" section of the app technical guide covers the syntax and usage of the `SHOW SCHEMAS` command in the Dune Docs project. This command is used to list the schemas in a specified catalog or in the current catalog. The command takes two optional parameters: `FROM catalog` specifies the catalog to list the schemas from, and `LIKE pattern` allows for filtering the results to a desired subset based on a pattern.\n\nThe guide provides an example of using the `LIKE` clause to find schemas that have `3` as the third character in their name. The response to this query would be a list of all schemas in the specified catalog (or current catalog if none is specified) that match the given pattern.\n\nOverall, this section of the guide is useful for developers who need to work with database schemas in the Dune Docs project. It provides clear instructions on how to use the `SHOW SCHEMAS` command and includes an example to help illustrate its usage.\n## Questions: \n 1. What database management system does this app technical guide apply to?\n- The app technical guide does not specify which database management system it applies to.\n\n2. Can this command be used to show schemas in a blockchain database?\n- It is unclear from the app technical guide whether this command can be used to show schemas in a blockchain database.\n\n3. Are there any limitations or restrictions on the use of the `LIKE` clause?\n- The app technical guide does not provide information on any limitations or restrictions on the use of the `LIKE` clause.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/show-schemas.md"}}],["187",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/show-session.md)\n\nThe \"Show Session\" section of the app technical guide covers the functionality of listing the current session properties in the Dune Docs app. The `SHOW SESSION` command is used to display the session properties, and an optional `LIKE` clause can be used to filter the results based on a specified pattern. The example provided in the guide shows how to use the `LIKE` clause to find session properties that begin with \"query\". \n\nThe purpose of this section is to provide users with a way to view the current session properties in the app, which can be useful for troubleshooting or debugging purposes. The guide also references other related commands, such as `reset-session` and `set-session`, which can be used to modify the session properties.\n\nOverall, this section of the guide is focused on the app folder of the Dune Docs project, specifically on the functionality related to managing and viewing session properties.\n## Questions: \n 1. What is the purpose of the `SHOW SESSION` command in the context of a blockchain SQL database?\n- The blockchain SQL analyst might want to know how this command can be used to manage or monitor sessions in the database.\n\n2. How does the `LIKE` clause work in the `SHOW SESSION` command?\n- The blockchain SQL analyst might want to know how to use the `LIKE` clause to filter the results of the `SHOW SESSION` command based on a pattern.\n\n3. Are there any other related commands or functions that a blockchain SQL analyst should be aware of when working with sessions in the database?\n- The blockchain SQL analyst might want to know if there are any other commands or functions that are related to managing or monitoring sessions in the database, and how they can be used in conjunction with the `SHOW SESSION` command.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/show-session.md"}}],["188",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/show-stats.md)\n\nThe \"Show Stats\" section of the app technical guide covers the functionality of the `SHOW STATS` command in the Dune Docs project. This command is used to retrieve approximated statistics for a specified table or query. The syntax for using this command is `SHOW STATS FOR table` or `SHOW STATS FOR (query)`.\n\nThe returned statistics are presented as a row for each column, as well as a summary row for the table. The columns returned include `column_name`, `data_size`, `distinct_values_count`, `nulls_fractions`, `row_count`, `low_value`, and `high_value`. The `column_name` column displays the name of the column, while the `data_size` column displays the total size in bytes of all the values in the column. The `distinct_values_count` column displays the estimated number of distinct values in the column, while the `nulls_fractions` column displays the portion of values in the column that are `NULL`. The `row_count` column displays the estimated number of rows in the table, while the `low_value` and `high_value` columns display the lowest and highest values found in the column, respectively.\n\nIt is important to note that any additional statistics collected on the data source, other than those listed in the table, are not included in the returned statistics. Additionally, if any statistics are not populated or unavailable on the data source, they will be returned as `NULL`.\n\nAn example of using the `SHOW STATS` command would be `SHOW STATS FOR my_table`, which would return the approximated statistics for the `my_table` table. Another example would be `SHOW STATS FOR (SELECT * FROM my_table WHERE column_name = 'value')`, which would return the approximated statistics for the results of the specified query.\n## Questions: \n 1. What is the data source for the statistics returned by this app?\n- The app technical guide does not provide information on the data source for the statistics returned.\n\n2. Can this app be used to gather statistics on tables or queries from a blockchain database?\n- The app technical guide does not mention anything specific to blockchain databases, so it is unclear whether it can be used for this purpose.\n\n3. How accurate are the estimated statistics returned by this app?\n- The app technical guide does not provide information on the accuracy of the estimated statistics returned.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/show-stats.md"}}],["189",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/show-tables.md)\n\nThe app technical guide covers the `SHOW TABLES` feature of the Dune Docs project. This feature allows users to list the tables in a specified schema or in the current schema. The `LIKE` clause is optional and can be used to filter the results to a desired subset. The guide provides an example of how to use the `LIKE` clause to find tables that begin with a specific letter. \n\nThe `Synopsis` section provides a brief overview of the `SHOW TABLES` command and its syntax. The `Description` section provides more detailed information on how to use the command, including the optional `FROM` and `LIKE` clauses. The section also provides an example of how to use the `LIKE` clause to filter results. \n\nOverall, this guide is useful for users who need to view a list of tables in a schema or the current schema. The `LIKE` clause provides additional flexibility for users who need to filter results to a specific subset.\n## Questions: \n 1. What is the purpose of the `SHOW TABLES` command in the context of a blockchain SQL database?\n- A blockchain SQL analyst might want to know how this command can be used to list tables in a blockchain database schema.\n\n2. Can the `LIKE` clause be used to search for specific tables in a blockchain database schema?\n- Yes, the `LIKE` clause can be used to filter the results to a desired subset of tables in a schema.\n\n3. Is there any difference in how the `SHOW TABLES` command works in the context of a blockchain database compared to a traditional SQL database?\n- This app technical guide does not provide information on any differences in how the `SHOW TABLES` command works in the context of a blockchain database compared to a traditional SQL database.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/show-tables.md"}}],["190",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/update.md)\n\n## Update\n\nThe `UPDATE` section of the app technical guide covers the syntax, description, examples, and limitations of updating selected columns values in existing rows in a table. The `UPDATE` statement is used to modify the existing records in a table. \n\nThe `Synopsis` section provides the syntax of the `UPDATE` statement, which includes the table name, the columns to be updated, and the `WHERE` clause to specify the rows to be updated. \n\nThe `Description` section explains how the `UPDATE` statement works. It mentions that the columns named in the `column = expression` assignments will be updated for all rows that match the `WHERE` condition. It also explains that when the type of the expression and the type of the column differ, the usual implicit CASTs, such as widening numeric fields, are applied to the `UPDATE` expression values.\n\nThe `Examples` section provides some examples of how to use the `UPDATE` statement. The first example updates the status of all purchases that haven't been assigned a ship date. The second example updates the account manager and account assign date for all customers. The third example updates the manager to be the name of the employee who matches the manager ID.\n\nThe `Limitations` section mentions that some connectors have limited or no support for `UPDATE`. It advises users to see connector documentation for more details.\n\nOverall, the `UPDATE` section of the app technical guide provides a comprehensive guide on how to use the `UPDATE` statement to modify the existing records in a table. It covers the syntax, description, examples, and limitations of the `UPDATE` statement.\n## Questions: \n 1. What is the purpose of the `UPDATE` command in the context of this app?\n- The `UPDATE` command is used to update selected columns values in existing rows in a table.\n\n2. How are column update expressions evaluated when the type of the expression and the type of the column differ?\n- When the type of the expression and the type of the column differ, the usual implicit CASTs, such as widening numeric fields, are applied to the `UPDATE` expression values.\n\n3. Are there any limitations to the `UPDATE` command in this app? If so, where can the details be found?\n- Yes, some connectors have limited or no support for `UPDATE`. Details can be found in the connector documentation.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/update.md"}}],["191",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/use.md)\n\n# Dune Docs App Technical Guide: USE\n\n## Synopsis\n\nThe `USE` command is used to update the session to use a specific catalog and schema. The syntax for using this command is as follows:\n\n``` text\nUSE catalog.schema\nUSE schema\n```\n\n## Description\n\nThe `USE` command is used to specify the catalog and schema that should be used for subsequent queries in the session. If a catalog is not specified, the schema is resolved relative to the current catalog. This command is useful when working with multiple catalogs and schemas, as it allows you to easily switch between them without having to fully qualify table names in subsequent queries.\n\n## Examples\n\nHere are some examples of how to use the `USE` command:\n\n``` sql\nUSE hive.finance;\n```\n\nThis command sets the current catalog to `hive` and the current schema to `finance`.\n\n``` sql\nUSE information_schema;\n```\n\nThis command sets the current schema to `information_schema`, relative to the current catalog.\n\nOverall, the `USE` command is a useful tool for managing catalogs and schemas in a session, and can help simplify subsequent queries by allowing you to work with unqualified table names.\n## Questions: \n 1. What is the purpose of the \"USE\" command in this app and how does it relate to blockchain technology?\n   - The \"USE\" command updates the session to use a specified catalog and schema. A blockchain SQL analyst might want to know how this command can be used to interact with blockchain data stored in a SQL database.\n\n2. Can multiple catalogs and schemas be used simultaneously with this app?\n   - The app technical guide does not provide information on whether multiple catalogs and schemas can be used simultaneously. A blockchain SQL analyst might want to know if this is possible and how it can be achieved.\n\n3. Are there any security considerations to keep in mind when using the \"USE\" command?\n   - The app technical guide does not mention any security considerations related to using the \"USE\" command. A blockchain SQL analyst might want to know if there are any potential security risks associated with using this command and how to mitigate them.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/use.md"}}],["192",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/SQL-statement-syntax/values.md)\n\n## `VALUES`\n\nThe `VALUES` header defines a literal inline table. It can be used anywhere a query can be used, such as the `FROM` clause of a `SELECT` statement, an `INSERT` statement, or even at the top level. `VALUES` creates an anonymous table without column names, but the table and columns can be named using an `AS` clause with column aliases.\n\nThe `VALUES` header is located in the `query` folder of the project, which suggests that it is a part of the query functionality of the app. The examples provided in the guide show how to use the `VALUES` header to return a table with one or more columns and rows, select columns from the table, and create a new table with columns and data from the `VALUES` table.\n\nThe `VALUES` header is followed by a `Synopsis` section that provides the syntax for using the header. The `Description` section provides a detailed explanation of what the header does and how it works. The `Examples` section provides examples of how to use the header in different scenarios. Finally, the `See also` section provides links to other related headers in the project, such as `INSERT` and `SELECT`.\n\nOverall, the `VALUES` header is a useful tool for creating tables with specific data and columns, and it can be used in a variety of contexts within the app.\n## Questions: \n 1. What is the purpose of the `VALUES` function in the context of a blockchain SQL database?\n- Answer: A blockchain SQL analyst might want to know how the `VALUES` function can be used to create and manipulate tables in a blockchain SQL database.\n\n2. Can the `VALUES` function be used to insert data into an existing table in a blockchain SQL database?\n- Answer: A blockchain SQL analyst might want to know if the `VALUES` function can be used to insert data into an existing table in a blockchain SQL database, or if it can only be used to create new tables.\n\n3. Are there any limitations to the size or complexity of the tables that can be created using the `VALUES` function in a blockchain SQL database?\n- Answer: A blockchain SQL analyst might want to know if there are any limitations to the size or complexity of the tables that can be created using the `VALUES` function in a blockchain SQL database, or if there are any performance considerations to keep in mind when using this function.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/SQL-statement-syntax/values.md"}}],["193",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference/index.md)\n\n# DuneSQL Overview\n\nThe DuneSQL Overview is a technical guide that provides an introduction to DuneSQL, a custom-built query engine optimized for blockchain data. The guide explains that DuneSQL is based on the open-source TrinoSQL engine and incorporates additional optimizations to handle blockchain-specific requirements. \n\n## Functions and Operators\n\nThis section of the guide covers the wide array of functions and operators that DuneSQL provides. These functions and operators enable users to perform various operations on their data, including arithmetic, string manipulation, date and time calculations, and much more. \n\nExample: `SELECT COUNT(*) FROM transactions WHERE block_number > 1000000;`\n\n## SQL Statement Syntax\n\nThe SQL Statement Syntax section explains that DuneSQL follows the standard SQL syntax, which consists of a series of clauses that define how data should be retrieved, manipulated, or stored. Commonly used clauses include SELECT, FROM, WHERE, GROUP BY, ORDER BY, and LIMIT. The guide also notes that administrative statements such as `create`, `update`, `delete`, and `drop` are disabled to ensure that the data in the database is not modified in any way. However, users can query queries in DuneSQL to replace the ability to create views and tables. \n\nExample: `SELECT * FROM transactions WHERE from_address = '0x123456789abcdef';`\n\n## SQL Language\n\nThe SQL Language section explains that the SQL language used in DuneSQL is ANSI-compliant, allowing users to leverage their existing SQL knowledge while working with blockchain data. Additionally, DuneSQL introduces custom data types and functions to better handle unique aspects of blockchain data, such as varbinary data types for addresses and hashes, as well as int256 and uint256 data types for large numeric values. \n\nExample: `SELECT COUNT(*) FROM transactions WHERE to_address = '0x987654321fedcba';`\n\nOverall, the DuneSQL Overview technical guide provides a comprehensive introduction to DuneSQL and its capabilities for efficient analysis of blockchain data.\n## Questions: \n 1. What optimizations has DuneSQL incorporated to handle blockchain-specific requirements?\n- DuneSQL has incorporated additional optimizations to handle blockchain-specific requirements.\n\n2. Can administrative statements such as create, update, delete, and drop be executed in DuneSQL?\n- No, all administrative statements are disabled in DuneSQL to ensure that the data in the database is not modified in any way.\n\n3. What custom data types and functions has DuneSQL introduced to better handle unique aspects of blockchain data?\n- DuneSQL has introduced custom data types and functions such as varbinary data types for addresses and hashes, as well as int256 and uint256 data types for large numeric values.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/index.md"}}],["194",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/DuneSQL-reference)\n\nThe `docs/query/DuneSQL-reference` folder contains a technical guide focused on DuneSQL, a custom-built query engine optimized for blockchain data. This guide is essential for developers and analysts working on the app feature that involves writing SQL queries and understanding the data types supported by DuneSQL.\n\nThe `index.md` file provides an overview of DuneSQL, its capabilities, and how it differs from TrinoSQL. It covers the wide array of functions and operators that DuneSQL provides, such as arithmetic, string manipulation, date and time calculations, and more. It also explains that DuneSQL follows the standard SQL syntax and is ANSI-compliant, allowing users to leverage their existing SQL knowledge while working with blockchain data.\n\nFor example, a developer working on a feature that requires querying blockchain data can refer to the `index.md` file to understand the basic syntax and capabilities of DuneSQL:\n\n```\nSELECT COUNT(*) FROM transactions WHERE block_number > 1000000;\n```\n\nThe `SQL-language` subfolder contains a comprehensive guide on various aspects of DuneSQL. The `datatypes.md` file provides an in-depth explanation of the various data types used in DuneSQL, such as Boolean, Integer, Floating-point, Fixed-precision, String, Date and time, Structural, Network address, UUID, HyperLogLog, SetDigest, Quantile digest, and T-Digest. This guide is useful for developers who need to understand the properties and functions of each data type when designing database schemas or writing SQL queries.\n\nFor example, a developer working on a feature that requires querying blockchain data can refer to the `datatypes.md` file to understand the appropriate data types to use in their queries:\n\n```\nSELECT COUNT(*) FROM transactions WHERE to_address = '0x987654321fedcba';\n```\n\nThe `reserved.md` file lists all the reserved keywords in Trino, along with their status in the SQL standard. This section is crucial for developers to avoid syntax errors when writing SQL queries by quoting reserved keywords.\n\nThe `sql-support.md` file offers a detailed guide on using SQL statements in the app, including examples of SELECT, INSERT, UPDATE, and DELETE statements. It also covers the use of parameters in SQL statements for more dynamic and flexible queries and provides tips on handling errors that may occur.\n\nOverall, the guide in this folder is an essential resource for developers and analysts working on the app feature that involves writing SQL queries and understanding the data types supported by DuneSQL. It provides clear explanations, examples, and tips to ensure smooth and efficient querying of blockchain data.","metadata":{"source":".autodoc/docs/markdown/docs/query/DuneSQL-reference/summary.md"}}],["195",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/dunesql-changes.md)\n\n# DuneSQL migration\n\nThis technical guide provides documentation regarding the changes to DuneSQL that occurred on March 2nd, 2023. The guide is divided into several sections, each of which covers a specific aspect of the migration. \n\nThe first section of the guide explains the changes that were made to DuneSQL. Specifically, DuneSQL now uses the same data types as the underlying EVM blockchain. This means that addresses, transaction hashes, and other encoded data are now stored as `varbinary` datatype. Additionally, `uint256` and `int256` are now supported, allowing for full wei-level precision calculations. The guide also explains that logs are now indexed from 0 instead of 1, and the `from_hex` native function has been modified to transform varchar to varbinary.\n\nThe second section of the guide explains what these changes mean for users. The switch to the `varbinary` datatype should significantly improve query speed, and the removal of string casts and conversions should make queries more readable and easier to maintain. Additionally, the introduction of `uint256` and `int256` allows for full wei-level precision calculations. \n\nThe third section of the guide explains what users need to do to adjust to these changes. Specifically, users need to remove the `-- dunesql_alpha_deprecated` comment from their queries, adjust all occurrences of `0x` strings to fit the new data types, and remove any `varchar -> double`, `varchar -> decimals`, or `varchar -> bigint` casts. If queries used any columns from logs tables, users will need to adjust the indexing of topics. \n\nThe fourth section of the guide explains what will happen if users do not adjust their queries. If the `-- dunesql_alpha_deprecated` comment is not removed from a query, it will continue to run against the old data types until March 23, 2023. After that date, the query will no longer run, and users will need to update it to use compatible functions.\n\nThe fifth section of the guide provides a table of common errors and fixes that users may encounter. \n\nOverall, this technical guide provides a comprehensive overview of the changes that were made to DuneSQL and what users need to do to adjust to these changes. It also provides examples of queries that need to be adjusted and common errors that users may encounter.\n## Questions: \n 1. What are the current issues with datatypes in some tables in DuneSQL and when are they expected to be resolved?\n- The current issues with datatypes in some tables in DuneSQL are affecting some Spellbook tables, `snapshot.*` and `cowswap.*`, and can be temporarily fixed by casting the columns which are incorrectly still `varchar` to `varbinary` with `from_hex(x)`. The issue is still to be resolved and there is no expected date for the resolution.\n\n2. What are the benefits of switching to the `varbinary` datatype in DuneSQL?\n- Switching to the `varbinary` datatype should significantly improve the speed of queries by approximately 30%. Additionally, it eliminates the need for string casts and conversions, making queries more readable and easier to maintain. Finally, the introduction of `uint256` and `int256` allows for full wei-level precision calculations.\n\n3. What are some common errors and fixes that might be encountered when using DuneSQL after the changes?\n- Some common errors and fixes that might be encountered when using DuneSQL after the changes include needing to cast varchar to varbinary using `from_hex(x)`, casting to `uint256` using `cast(xxx as uint256)`, using `bytearray_substring` and `bytearray_starts_with` instead of LIKE expression, and adjusting the indexing of topics in logs tables from `Topic1` to `Topic0`, `Topic2` to `Topic1`, etc.","metadata":{"source":".autodoc/docs/markdown/docs/query/dunesql-changes.md"}}],["196",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/index.md)\n\n# DuneSQL: Query Engine for Blockchain Data\n\nThe DuneSQL app technical guide provides an overview of the custom-built query engine designed for efficient analysis of blockchain data. DuneSQL is a fork of TrinoSQL, an open-source, distributed SQL query engine for running interactive analytic queries against data sources of all sizes ranging from gigabytes to petabytes. The guide highlights the additional optimizations incorporated into DuneSQL to handle blockchain-specific requirements.\n\nThe guide outlines the features of DuneSQL, including blockchain varbinary data types, native support for uint256 and int256 data types, columnar storage format, and querying a query. The blockchain varbinary data types are designed for storing addresses, hashes, and other encoded data. The native support for uint256 and int256 data types is ideal for handling large numbers commonly found in blockchain data, with built-in functions for ease of use. The columnar storage format is optimized for fast reads, organizing data in columns rather than rows, enabling quick access to single columns for aggregation or filtering. Querying a query allows users to create reusable queries, build up complex queries, and reuse queries as views.\n\nThe guide provides extensive documentation for DuneSQL, which can be found in the DuneSQL Reference section of the documentation. The DuneSQL Reference section includes SQL statement reference, SQL language reference, and functions and operators. The guide also highlights the importance of understanding DuneSQL storage for an efficient query-writing process. The Storage section of the documentation provides details on the database layout and querying techniques.\n\nThe guide provides resources and support for assistance with DuneSQL, including a Google search for TrinoSQL-related queries, talking to an AI assistant about TrinoSQL-related questions, and the official Trino docs - Functions and Operators. Users can also join the #dune-sql Discord channel to connect with the team and the community for help and support.\n\nFinally, the guide encourages feedback and suggestions for improvement. Users can email dunesql-feedback@dune.com with any concerns or ideas for optimization.\n\nOverall, the DuneSQL app technical guide provides a comprehensive overview of the custom-built query engine designed for efficient analysis of blockchain data. The guide highlights the features of DuneSQL, provides extensive documentation, and offers resources and support for assistance with DuneSQL.\n## Questions: \n 1. What optimizations does DuneSQL incorporate to handle blockchain-specific requirements?\n- DuneSQL incorporates additional optimizations to handle blockchain-specific requirements, but the specific details are not provided in the app technical guide.\n\n2. What blockchain data types does DuneSQL support?\n- DuneSQL supports blockchain varbinary data types for storing addresses, hashes, and other encoded data, as well as native support for uint256 and int256 data types for handling large numbers commonly found in blockchain data.\n\n3. What resources are available for assistance with DuneSQL?\n- Resources for assistance with DuneSQL include a Google search for TrinoSQL-related queries, talking to an AI assistant about TrinoSQL-related questions, joining the #dune-sql Discord channel, and referring to the official Trino docs for functions and operators.","metadata":{"source":".autodoc/docs/markdown/docs/query/index.md"}}],["197",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/query-a-query.md)\n\n# Query a Query\n\nThis section of the DuneSQL app technical guide explains how to query a query in DuneSQL. This feature allows users to create reusable queries, build up complex queries, and reuse queries as views.\n\n## Query queries as views in Dune SQL\n\nIn DuneSQL, all non-parameterized queries can be queried as views in other queries using the identifier `query_<queryId>`. For example, to query a query with ID 1234, the syntax would be:\n```\nselect * from query_1234\n```\nThe `queryId` is part of the URL of a query.\n\nIt is important to note that:\n- All output columns of the query being queried must be named. This means that queries like `select 1` or `select count(*) from ethereum.transactions` cannot be queried, but queries like `select 1 as v` and `select count(*) as total from ethereum.transactions` can be queried.\n- Parametrized queries are not supported.\n- Only public queries can be queried. Support for querying private queries will be added in the future.\n- Only saved queries can be queried.\n- Only queries written in Dune SQL can be queried.\n\nThe ability to query a query is useful for creating more complex queries and reusing queries as views. An example query is provided in the guide for reference.\n\nOverall, this section of the app technical guide provides a clear explanation of how to query a query in DuneSQL and the limitations of this feature. It is a useful reference for users who want to create more complex queries and reuse queries as views.\n## Questions: \n 1. What is DuneSQL and how does it relate to blockchain technology?\n- This app technical guide does not provide information on how DuneSQL relates to blockchain technology, so a blockchain SQL analyst might want to know more about the context and use cases of this tool.\n\n2. Can parameterized queries be queried as views in DuneSQL?\n- No, according to the app technical guide, only non-parameterized queries can be queried as views in DuneSQL.\n\n3. Is it possible to query private queries in DuneSQL?\n- No, the app technical guide states that only public queries can be queried as views in DuneSQL, and support for querying private queries will be added in the future.","metadata":{"source":".autodoc/docs/markdown/docs/query/query-a-query.md"}}],["198",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/storage.md)\n\n# Storage\n\nThe Storage section of the Dune Docs app technical guide provides an overview of the differences and thinking behind the V2 database structure. The guide explains how databases read data from storage into memory to transform and return blockchain data according to Dune queries' logic. The guide focuses on the differences between row-oriented and column-oriented databases and how they affect query speed.\n\nThe guide starts by explaining how databases store data in pages, which traditionally contain rows of information. Multiple pages make one data file, and a table consists of one or more data files. The guide then explains how databases read data into memory by the page, and page size and the number of pages loaded are key bottlenecks for query speed. The guide explains that traditional databases store pages by row and are best suited for retrieving all columns of one row or data from multiple sequential rows. \n\nThe guide then explains that Dune V2 runs on column-oriented tables, which store data on AWS S3 using the parquet file format. The guide explains that parquet is a hybrid approach between row-oriented databases and column-oriented databases since a table still consists of multiple parquet files, which are themselves partitioned by rows. Inside the parquet files, the pages themselves contain columns instead of rows. The guide explains that the database is still roughly stored in a row-oriented format, but the individual values are stored in column orientation inside pages. \n\nThe guide then explains how the database uses min/max values to efficiently skip over entire parquet files or column chunks within parquet files while scanning through a table. The guide explains that the performance cost is mostly relevant for base tables like ethereum.transactions, bnb.logs, erc20_ethereum.erc20_evt_transfer, etc., which contain very large datasets that aren't pre-filtered. \n\nThe guide provides examples of Dune V2 queries and how they work. The first example queries for transaction hashes, and the guide explains how the query is inefficient because the only filter condition is a hash string. The guide explains that the query engine can skip a few column chunks where the min/max value stored in the parquet file footer is 0xa0 - 0xcd, but those will be a rare exception. The guide provides a more efficient query that filters by block number. \n\nThe guide also provides an example of aggregating data over a large amount of logical rows. The guide explains that this is mainly a case study to illustrate how efficient DuneV2 is in aggregating data over a large set of logical rows. \n\nThe guide concludes by stating that Dune will continue to innovate on these datasets and its database architecture to make every query run as fast as possible on V2. The guide encourages users to send feedback or identify areas of improvement to optimize the system.\n## Questions: \n 1. What is the difference between row-oriented and column-oriented databases, and why did Dune V2 choose to use a column-oriented approach?\n- Row-oriented databases store data in pages by row, while column-oriented databases store data in pages by column. Dune V2 chose to use a column-oriented approach because it is more efficient for querying data across a large amount of logical rows, which is common in blockchain systems.\n\n2. How does Dune V2 handle indexing, and what are the limitations of this approach?\n- Dune V2 uses the `min/max` values stored in the footer of each parquet file to efficiently skip over entire files or column chunks while scanning through a table. However, the `min/max` values of strings are oftentimes not very useful, which can make queries that reference them inefficient since all related pages will need to be read into memory.\n\n3. How does Dune V2 make querying for data across a large amount of logical rows more efficient?\n- Dune V2 stores data in column-oriented pages across parquet files, which allows it to read only the data that is actually needed for a query. This makes querying for data across a large amount of logical rows much more efficient and enables queries that were formerly impossible due to timing out.","metadata":{"source":".autodoc/docs/markdown/docs/query/storage.md"}}],["199",{"pageContent":"[View code on GitHub](https://dune.com/docs/query)\n\nThe `docs/query` folder contains a technical guide focused on DuneSQL, a custom-built query engine optimized for blockchain data analysis. This guide is essential for developers and analysts working on app features that involve writing SQL queries and understanding the data types supported by DuneSQL.\n\nFor example, a developer working on a feature that requires querying blockchain data can refer to the `dunesql-changes.md` file to understand the migration changes that occurred on March 2nd, 2023, and how to adjust their queries accordingly. The guide provides examples of queries that need to be adjusted and common errors that users may encounter.\n\nThe `index.md` file provides an overview of DuneSQL, its features, and how it differs from TrinoSQL. It covers the wide array of functions and operators that DuneSQL provides, such as arithmetic, string manipulation, date and time calculations, and more. It also explains that DuneSQL follows the standard SQL syntax and is ANSI-compliant, allowing users to leverage their existing SQL knowledge while working with blockchain data.\n\nThe `query-a-query.md` file explains how to query a query in DuneSQL, allowing users to create reusable queries, build up complex queries, and reuse queries as views. This feature is useful for creating more complex queries and reusing queries as views. An example query is provided in the guide for reference.\n\nThe `storage.md` file provides an overview of the differences and thinking behind the V2 database structure, focusing on the differences between row-oriented and column-oriented databases and how they affect query speed. The guide provides examples of Dune V2 queries and how they work, as well as tips for optimizing query performance.\n\nThe `syntax-differences.md` file provides a comprehensive guide for migrating queries from Postgres and Spark SQL to Dune SQL. It is a valuable resource for developers who are new to Dune SQL and need to migrate their queries from other databases.\n\nThe `DuneSQL-reference` subfolder contains a comprehensive guide on various aspects of DuneSQL, such as data types, reserved keywords, and SQL statement support. This guide is useful for developers who need to understand the properties and functions of each data type when designing database schemas or writing SQL queries.\n\nOverall, the guide in this folder is an essential resource for developers and analysts working on app features that involve writing SQL queries and understanding the data types supported by DuneSQL. It provides clear explanations, examples, and tips to ensure smooth and efficient querying of blockchain data.","metadata":{"source":".autodoc/docs/markdown/docs/query/summary.md"}}],["200",{"pageContent":"[View code on GitHub](https://dune.com/docs/query/syntax-differences.md)\n\nThe app technical guide provides a comprehensive guide for migrating queries from Postgres to Dune SQL and from SparkSQL to DuneSQL. The guide covers the syntax and operator differences between Postgres, Spark, and Dune SQL. It provides a detailed comparison of the syntax and keyword operator differences between the three databases. The guide explains the differences in syntax for various operations such as math or numeric operations, array-based indexing, implicit type conversions, addresses, selecting keyword columns, alias naming, exponentiation notation, interval argument, generate_series, handling decimals for prices.usd, defining NULL array, encoding strings to hex, get JSON object differences, group by an alias, explicit date/time casting, checking if an item exists in an array, explode, median, using “is True/False,” string data type, casting as strings, aggregate functions, user-generated views, and event logs topic indexing.\n\nThe guide provides examples for each of the syntax differences and explains how to use them in Dune SQL. It also highlights the differences in syntax between Dune SQL and other databases, such as Postgres and Spark SQL. The guide recommends avoiding the use of double quotes in Dune SQL, as the parser sometimes treats words in double quotes as a string and sometimes as an object like a column name.\n\nOverall, the app technical guide provides a comprehensive guide for migrating queries from Postgres and Spark SQL to Dune SQL. It is a valuable resource for developers who are new to Dune SQL and need to migrate their queries from other databases.\n## Questions: \n 1. What are the differences in handling decimals for prices.usd in Dune SQL compared to Postgres and Spark SQL?\n- In Dune SQL, decimals for prices.usd are replaced by tokens_[blockchain].erc20.decimals.\n\n2. How does Dune SQL handle implicit type conversions between character and numeric types compared to Postgres and Spark SQL?\n- Dune SQL does not have implicit type conversions between character and numeric types, unlike Postgres and Spark SQL.\n\n3. What is the recommended approach for using double quotes in Dune SQL?\n- Double quotes are not recommended in Dune SQL, as the parser sometimes treats words in double quotes as a string and sometimes as an object like a column name.","metadata":{"source":".autodoc/docs/markdown/docs/query/syntax-differences.md"}}],["201",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/citing-dune.md)\n\n# Citing Dune\n\nThis section of the app technical guide for Dune Docs covers how to correctly reference and cite Dune queries and dashboards. The guide emphasizes the importance of crediting the creators of the queries, visualizations, and dashboards that are shared on the platform. \n\nThe guide provides specific instructions on how to credit the creators of the content, including a direct link to dune.com, a Dune logo, and a reference to the specific creator(s) of the content. The guide also provides examples of how to credit a specific query or dashboard, including the use of the creator's username and the name of the query or dashboard.\n\nThe guide also includes a section on the limitations of commercial use. It states that any form of copying, transmitting, transferring, modifying, or creating derivative works from the original queries and public dashboard is strictly prohibited. Additionally, any form of exploiting any portion, use, or access to Dune without the express written permission by Dune is not allowed.\n\nOverall, this guide is important for users of the Dune platform to understand how to properly credit the creators of the content they use and share. It also serves as a reminder of the limitations of commercial use and the importance of obtaining permission from Dune before using or exploiting any portion of the platform.\n## Questions: \n 1. What type of data does Dune Docs provide and how is it sourced?\n- According to the app technical guide, Dune Docs provides queries, visualizations, and dashboards. The data is sourced from the creators (\"Wizards\") who build these features on the platform.\n\n2. Can Dune Docs data be used for commercial purposes?\n- The app technical guide states that any form of commercial use, including copying, modifying, or creating derivative works, is strictly prohibited without express written permission from Dune.\n\n3. How can Dune Docs data be properly cited and credited?\n- The app technical guide provides specific instructions for citing Dune Docs data, including including a Dune logo, a direct link to dune.com, and a reference to credit the creator(s) of the specific query, dashboard, or data.","metadata":{"source":".autodoc/docs/markdown/docs/reference/citing-dune.md"}}],["202",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/dune-bounties.md)\n\nThe Dune Bounties technical guide is a comprehensive guide that explains how Dune Analytics empowers projects and wizards to collaborate through $$ incentives. The guide is divided into several sections that cover different aspects of the Dune Bounties project. \n\nThe guide starts by introducing Dune Analytics as a go-to solution for on-demand crypto analytics. It then highlights the problem that Wizards and Projects face in finding each other and how Dune Bounties solves this problem by creating a marketplace that handles task creation, application process, communication, reputation, and payments. \n\nThe guide then explains how Dune Bounties works by leveraging dework.xyz to set up a bounty board that manages Dune internal bounty programs. The guide also provides detailed instructions on how organizations can connect with Dune Wizards and how Wizards can find tasks. \n\nThe guide also provides some notes about working on Dune, which can be roughly separated into two parts: the App Layer and the Data Layer. The App Layer contains Queries, Visualizations, and Dashboards, while the Data Layer allows Wizards to produce scalable and persistent work by standardizing and normalizing data. \n\nThe guide concludes with a Dune Bounties FAQ section that answers common questions about the project, such as how much to pay Wizards, how Wizards get paid, and how to choose the right applicant. \n\nOverall, the Dune Bounties technical guide is an excellent resource for anyone interested in learning about Dune Analytics and how it empowers projects and Wizards to collaborate through $$ incentives. The guide provides detailed instructions on how to use Dune Bounties, making it easy for organizations and Wizards to get started.\n## Questions: \n 1. What is the purpose of Dune Bounties and how does it relate to blockchain data analysis?\n    \n    Dune Bounties is a marketplace that connects projects in need of web3 analytics with Dune Wizards who want jobs. It allows for task creation, application process, communication, reputation, and payments, and is web3 native. This platform can be used by blockchain SQL analysts to find jobs and get paid for their work.\n\n2. How does Dune Bounties handle payments and what wallets does it integrate with?\n    \n    Dune Bounties uses Dework's native payment feature, which allows Wizards to connect their wallet in their Dework profile and get paid as soon as the bounty is paid out by the Project that created the task. Dework integrates with Metamask, Gnosis Safe, Utopia Labs, and Phantom wallet for Solana-based payments.\n\n3. How can Dune Bounties help with data normalization and standardization for blockchain data analysis?\n    \n    Dune Bounties can help with data normalization and standardization by allowing projects to define tasks with the \"Dune Analytics\" Skill, which will appear in the Dune hub. By transforming raw data and adding it to the `opensea.trades` table inside of Spellbook, Dune Wizards can easily work with the data as it's cleaned and standardized. This makes it more likely that Wizards will incorporate the data into their work as the `nft.trades` table contains data from all marketplaces across all chains.","metadata":{"source":".autodoc/docs/markdown/docs/reference/dune-bounties.md"}}],["203",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/events.md)\n\n# App Technical Guide: Events\n\nThis guide covers the Events feature of the Dune app. The purpose of this feature is to facilitate community engagement and participation in events, both online and in-person. \n\nThe first section of the guide emphasizes the importance of community in the Dune app and how events are a key aspect of building and maintaining that community. It encourages users to join the Community Discord to connect with other users and learn from them. \n\nThe second section of the guide provides information on how to access the events calendar on the Dune app. Users can view both streamed and in-person events on the calendar. The guide also includes a step-by-step tutorial on how to subscribe to the calendar and add it to their own personal calendar. \n\nExample: \nTo join the Dune community and stay up-to-date on events, users can follow the link to the Community Discord provided in the guide. They can also access the events calendar by visiting events.dune.com and subscribing to the calendar using the tutorial provided in the guide. \n\nOverall, the Events feature of the Dune app is designed to foster a sense of community and encourage user engagement through events. This guide provides users with the necessary information to participate in these events and stay informed about upcoming ones.\n## Questions: \n 1. What is the purpose of the Dune app and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the Dune app or its relation to blockchain technology.\n\n2. Does the app use any SQL databases to manage event data?\n- The app technical guide does not mention the use of any SQL databases to manage event data.\n\n3. Are there any APIs or integrations available for developers to access event data?\n- The app technical guide does not provide information on any APIs or integrations available for developers to access event data.","metadata":{"source":".autodoc/docs/markdown/docs/reference/events.md"}}],["204",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/faq/does-dune-have-a-token.md)\n\nThis app technical guide is focused on the topic of whether or not Dune has a token. The guide provides a clear and concise answer to this question, stating that Dune does not have a token. \n\nThis information is important for users who may be looking to integrate Dune with other applications or services that require a token for authentication. By knowing that Dune does not have a token, users can adjust their integration plans accordingly and explore alternative authentication methods.\n\nThe guide is short and to the point, with the header and body text both clearly stating the answer to the question. No further explanation or examples are provided, as none are needed for this particular topic. Overall, this guide serves as a helpful reference for users seeking information on Dune's authentication capabilities.\n## Questions: \n 1. What is the purpose of Dune Docs? \n- The app technical guide does not provide information on the purpose of Dune Docs, which may be a concern for a blockchain SQL analyst who needs to understand the context of the app.\n\n2. Does Dune Docs integrate with any blockchain technology? \n- The app technical guide does not mention any integration with blockchain technology, which may be a relevant question for a blockchain SQL analyst.\n\n3. Is there any information on the app's architecture or database structure? \n- The app technical guide only provides information on the presence of a token, but does not offer any details on the app's architecture or database structure, which may be important for a blockchain SQL analyst to understand.","metadata":{"source":".autodoc/docs/markdown/docs/reference/faq/does-dune-have-a-token.md"}}],["205",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/faq/does-dune-have-an-api.md)\n\n# App Technical Guide: Does Dune have an API?\n\nThis guide covers the topic of whether Dune, the project in question, has an API. The answer is yes, and this guide provides information on how to access it. \n\nThe first header states that Dune does have an API, and the following paragraph explains that users need to sign up for a paid plan and add on API access to use it. The guide also provides a link to pricing details for those interested in learning more. \n\nThe second header provides a link to learn more about how to use the API. This section likely covers the technical details of using the API, such as authentication, endpoints, and data formats. \n\nFinally, the guide notes that users without API access can still export results as CSV and embed Dune charts on their page for free. The link provided in this section leads to a guide on how to embed Dune charts. \n\nOverall, this guide serves as a brief introduction to Dune's API and provides links to more detailed information on how to access and use it. \n\nExample: \n\nTo access Dune's API, users must first sign up for a paid plan and add on API access. Once they have access, they can use the API to retrieve data from Dune. For example, a user could use the API to retrieve a list of all companies in Dune's database. The API documentation provides more information on how to use the API, including authentication and endpoint details.\n## Questions: \n 1. What kind of data can be accessed through Dune's API?\n- The app technical guide does not provide information on the specific data that can be accessed through Dune's API.\n\n2. Is there a limit to the number of API requests that can be made?\n- The app technical guide does not mention any limits on the number of API requests that can be made.\n\n3. Are there any security measures in place to protect user data accessed through the API?\n- The app technical guide does not provide information on the security measures in place to protect user data accessed through the API.","metadata":{"source":".autodoc/docs/markdown/docs/reference/faq/does-dune-have-an-api.md"}}],["206",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/faq/how-are-results-refreshing.md)\n\nThe app technical guide provides information on how often results are refreshed in the Dune app. The guide starts by directing users to the Meta Monitoring dashboard to view the current time it takes for new data to be added to Dune. \n\nThe guide then explains how results are refreshed in the app. When a visualization is viewed on a query page or dashboard, the Dune backend checks the age of the most recent result. If the result is older than three hours, Dune automatically queues an execution for the query and runs it in the background. This ensures that dashboards are always up to date when they are being viewed, and the query creator does not need to set a refresh schedule. \n\nIt is important to note that the query execution queue is separate from each individual user's queue when they create and run queries in the query editor. \n\nOverall, this guide provides users with a clear understanding of how results are refreshed in the Dune app and how they can ensure that their dashboards are always up to date. The guide also directs users to the Meta Monitoring dashboard for more information on the current time it takes for new data to be added to Dune. \n\nExample: \nIf a user creates a dashboard in the Dune app and views a visualization on that dashboard, the Dune backend will automatically check the age of the most recent result. If the result is older than three hours, Dune will queue an execution for the query and run it in the background to ensure that the dashboard is up to date. The user does not need to set a refresh schedule for the dashboard.\n## Questions: \n 1. What is the definition of \"stale\" results in this app and how is it determined?\n   \n   The definition of \"stale\" results in this app is currently defined as >3 hours old. It is determined by the age of the most recent result.\n\n2. Is there a way for users to manually refresh the data or do they have to wait for the automatic refresh?\n\n   It is not mentioned in the app technical guide whether users can manually refresh the data or not. Further investigation or clarification may be needed.\n\n3. How does the app handle errors or failed executions during the automatic refresh process?\n\n   The app technical guide does not provide information on how the app handles errors or failed executions during the automatic refresh process. It may be necessary to consult the app's documentation or contact the developer for more information.","metadata":{"source":".autodoc/docs/markdown/docs/reference/faq/how-are-results-refreshing.md"}}],["207",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/faq/how-does-dune-get-its-data.md)\n\n# App Technical Guide: How does Dune get data?\n\nThis guide provides an overview of how Dune, the project being documented, obtains its data. The guide explains that Dune works with node providers across the industry to ingest raw historical data from various blockchains. However, it does not include state data. \n\nThe guide also mentions that Dune does not discriminate against any smart contract and users can submit any contract via the decoding page. The decoding page is located in the data-tables folder under the decoded subfolder. The only prerequisite for submitting a contract is an ABI, which is used to decode the contract. In most cases, the ABI is already available on Etherscan, but there may be edge cases where it is not available. \n\nOverall, this guide provides a high-level understanding of how Dune obtains its data and how users can submit their own contracts for decoding. It is useful for anyone who wants to understand the data sources used by Dune and how to work with smart contracts on the platform. \n\nExample: \n\nSuppose a user wants to work with a smart contract on the Dune platform. They can submit the contract via the decoding page, which is located in the data-tables folder under the decoded subfolder. The user needs to provide the ABI for the contract, which is used to decode it. Once the contract is decoded, the user can work with it on the Dune platform in a matter of hours.\n## Questions: \n 1. What blockchains does Dune Docs currently support for data ingestion?\n- The app technical guide mentions that Dune Docs is working with node providers across the industry to ingest data from blockchains, but does not specify which blockchains are currently supported.\n\n2. Does Dune Docs include state data in its database?\n- The app technical guide states that Dune Docs ingests all raw historical data from blockchains, but explicitly mentions that it does not include state data. A blockchain SQL analyst may want to know if this limitation affects their ability to analyze data on the platform.\n\n3. How does Dune Docs handle smart contracts without an ABI?\n- The app technical guide mentions that an ABI is required to decode a smart contract, but does not provide information on how Dune Docs handles contracts without an ABI. A blockchain SQL analyst may want to know if there are any workarounds or limitations to working with contracts that do not have an ABI available.","metadata":{"source":".autodoc/docs/markdown/docs/reference/faq/how-does-dune-get-its-data.md"}}],["208",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/faq)\n\nThe `docs/reference/faq` folder contains a collection of app technical guides that answer frequently asked questions about the Dune project. These guides provide valuable information for users who want to understand various aspects of Dune, such as its data sources, API access, and result refreshing mechanisms.\n\nFor example, the `does-dune-have-a-token.md` guide clarifies that Dune does not have a token, which is essential for users looking to integrate Dune with other applications or services that require token-based authentication. This information helps users adjust their integration plans and explore alternative authentication methods.\n\nThe `does-dune-have-an-api.md` guide confirms that Dune has an API and provides information on how to access it. Users must sign up for a paid plan and add on API access to use the API. This guide also provides links to pricing details and more in-depth information on using the API, such as authentication, endpoints, and data formats. This guide is useful for users who want to retrieve data from Dune programmatically, for example, to obtain a list of all companies in Dune's database.\n\nIn the `how-are-results-refreshing.md` guide, users can learn about the result refreshing mechanism in the Dune app. The guide explains that when a visualization is viewed on a query page or dashboard, Dune checks the age of the most recent result. If the result is older than three hours, Dune automatically queues an execution for the query and runs it in the background. This ensures that dashboards are always up to date when viewed, without the need for the query creator to set a refresh schedule.\n\nLastly, the `how-does-dune-get-its-data.md` guide offers an overview of how Dune obtains its data by working with node providers across the industry to ingest raw historical data from various blockchains. The guide also explains how users can submit their own smart contracts for decoding via the decoding page, provided they have an ABI. This information is useful for users who want to understand Dune's data sources and work with smart contracts on the platform.\n\nOverall, the guides in the `docs/reference/faq` folder provide concise and relevant information for users who want to understand various aspects of the Dune project. These guides are essential for analysts who are curious about using the project and need clarification on specific features or functionalities.","metadata":{"source":".autodoc/docs/markdown/docs/reference/faq/summary.md"}}],["209",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/index.md)\n\n# App Technical Guide: Reference\n\nThe Reference section of the Dune Docs project is designed to provide answers to common questions about the app. This section is particularly useful for users who are new to the app and need help getting started. \n\nThe header of the guide provides a brief overview of what users can expect to find in the Reference section. It explains that this section is the place to get answers to \"who, what, where\" questions. For example, users can find information about what data exists in Dune Tables, what tools are helpful for building dashboards, and where to find Dune events and support. \n\nThe guide also mentions that the Reference section includes a few supplemental resources, such as Wizard Tools. This is an example of how the guide provides specific examples of what users can expect to find in this section of the app. \n\nThe note at the beginning of the guide is worth mentioning as well. It explains that the Reference section is a catch-all for information that doesn't fit neatly into other sections of the app. This is a helpful reminder that users may need to look in multiple places to find the information they need. \n\nOverall, the Reference section of the Dune Docs project is a valuable resource for users who need help navigating the app. It provides answers to common questions and includes supplemental resources to help users get the most out of the app.\n## Questions: \n 1. What is the purpose of Dune Tables and what kind of data can be found in them?\n   - The app technical guide mentions finding answers to \"what data exists in Dune Tables\" which may be of interest to a blockchain SQL analyst looking to work with the data.\n   \n2. Are there any specific dashboard building tools recommended by the app?\n   - The guide mentions finding answers to \"what tools are helpful for building dashboards\" which may be of interest to a blockchain SQL analyst looking to create visualizations for the data.\n\n3. What are the Wizard Tools mentioned in the guide and how can they be used in conjunction with Dune Docs?\n   - The guide mentions supplemental resources like Wizard Tools that may be helpful for a blockchain SQL analyst looking to enhance their work as a \"Wizard\".","metadata":{"source":".autodoc/docs/markdown/docs/reference/index.md"}}],["210",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/press-kit.md)\n\n# Dune Docs App Technical Guide: Press Kit\n\nThe Press Kit section of the Dune Docs project provides access to Dune's brand assets. This guide covers the different types of logos available in the Press Kit and how they should be used.\n\n## Primary - Standard Logo\n\nThe primary Dune logo is the standard logo that should be used whenever possible. This logo is horizontal and is displayed in the following format:\n\n![Dune horizontal logo cover](images/dune-horizontal-logo-cover.png)\n\nThe following files are available for the primary standard logo:\n\n- dune-standard-logo.svg\n- dune-standard-logo@2x.png\n- dune-standard-logo-dark.svg\n- dune-standard-logo-dark@2x.png\n\n## Vertical Logo\n\nThe vertical logo is an alternative to the primary standard logo. This logo is vertical and is displayed in the following format:\n\n![Dune vertical logo cover](images/dune-vertical-logo-cover.png)\n\nThe following files are available for the vertical logo:\n\n- dune-vertical-logo.svg\n- dune-vertical-logo@2x.png\n- dune-vertical-logo-dark.svg\n- dune-vertical-logo-dark@2x.png\n\n## Icon Only\n\nThe icon only logo is a simplified version of the Dune logo that only includes the icon. This logo is displayed in the following format:\n\n![Dune icon only](images/dune-icon-only.svg)\n\nThe following files are available for the icon only logo:\n\n- dune-icon-only.svg\n- dune-icon-only@2x.png\n\n## Complete Set of All Logos\n\nThe complete set of all logos is available in a zip file that can be downloaded from the Press Kit section of the Dune Docs project. This file includes all of the logos mentioned above.\n\nOverall, the Press Kit section of the Dune Docs project provides users with access to Dune's brand assets, including different types of logos. This guide explains the different types of logos available and how they should be used. By following these guidelines, users can ensure that they are using Dune's brand assets correctly and consistently.\n## Questions: \n 1. What is the purpose of the Dune app and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the Dune app or its relation to blockchain technology.\n\n2. Are there any specific guidelines or restrictions on how the Dune brand assets can be used in blockchain-related projects?\n- The app technical guide does not provide any specific guidelines or restrictions on how the Dune brand assets can be used in blockchain-related projects.\n\n3. Is there any information on the file formats and sizes available for the Dune logos and icons?\n- Yes, the app technical guide provides information on the file formats and sizes available for the Dune logos and icons, including SVG and PNG formats in standard and high-resolution versions.","metadata":{"source":".autodoc/docs/markdown/docs/reference/press-kit.md"}}],["211",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/pricing.md)\n\nThis app technical guide covers the pricing feature of the Dune app. The guide provides information about the premium accounts and the additional features that come with them. The guide also includes a link to the pricing page where users can learn more and get started. The FAQ section of the guide answers general questions about billing history, upgrading, downgrading, and canceling subscriptions. The guide also explains how billing works when upgrading or downgrading and which query engine will be billed. The query execution section of the guide provides information about the performance tiers and the difference in performance between them. The section also explains when the rate for additional executions kicks in and how users can limit premium query usage to avoid paying extra fees. The features section of the guide answers questions about private queries, public dashboards, and watermarks. \n\nFor instance, the guide explains that private queries and dashboards, CSV exports, faster executions, no Dune watermarks, and processing for up to six queries at once are some of the additional features that come with premium accounts. The guide also provides steps on how to view billing history, upgrade, downgrade, or cancel a subscription. Additionally, the guide explains that upgrading immediately resets the billing cycle, while downgrades are applied at the end of the billing cycle. The guide also provides information about the performance difference between tiers and when the rate for additional executions kicks in. Finally, the guide explains that private queries can be added to public dashboards, and users can embed private queries on other websites. However, public dashboard URLs will always be watermarked. \n\nOverall, this guide provides users with detailed information about the pricing feature of the Dune app, including premium accounts, additional features, billing, and query execution. The guide is useful for users who want to learn more about the pricing feature and how to manage their subscriptions.\n## Questions: \n 1. What additional features are available with Dune Premium accounts?\n- Dune Premium accounts provide access to private queries and dashboards, CSV exports, faster executions, no Dune watermarks, and processing for up to 6 queries at once.\n\n2. How does billing work when upgrading or downgrading a subscription?\n- Upgrading immediately resets the billing cycle to the day of the upgrade, while downgrades are applied at the end of the billing cycle. Refunds for unused days are provided for upgrades, and the current tier benefits are kept until the end of the current cycle for downgrades.\n\n3. Which query engine is billed for queries and CSV downloads?\n- Queries and CSV downloads on both Dune Engine V2 and other datasets will be billed.","metadata":{"source":".autodoc/docs/markdown/docs/reference/pricing.md"}}],["212",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/recommended-reading.md)\n\n# Recommended Reading\n\nThis guide provides a list of recommended reading resources for users on their web3 data analytics journey. The resources are grouped into different categories, including Wizard Content, General Blockchain Info, DeFi, DAOs, Bridges/L2, EIPs, News and Info, Newsletters, and Cool Blockchain Data Websites. \n\nUnder Wizard Content, the guide lists content created by members of the Wizard community, including Journey to the Centre of Arakis by @1chioku, Andrew Hong's Mirror.xyz by @ilemi, and NiftyTable by @niftytable. \n\nThe General Blockchain Info section provides a link to Immersion Den, which is a collection of web3 information sources. \n\nThe DeFi section provides a link to the Biggest DeFi Hacks, which is a leaderboard of the biggest DeFi hacks. \n\nThe DAOs section provides links to DAO-related resources, including DAOs: Absorbing the Internet and DAO Central - Learn about DAOs. \n\nThe Bridges/L2 section provides a link to The ultimate guide to L2s on Ethereum, which is a comprehensive guide to Layer 2 scaling solutions on Ethereum. \n\nThe EIPs section provides a link to the Ethereum Improvement Proposals (EIPs) website, which is a repository of proposals for changes to the Ethereum protocol. \n\nThe News and Info section provides links to various news sources, including 21Shares, Blockworks, Decrypt, CoinDesk, Week in Ethereum News, Bankless, The Daily Ape, Finematics (helpful youtube videos), and Gaby's Web3 reading list. \n\nThe Newsletters section provides links to various newsletters, including The Dune Digest, CryptoPragmatist, Messari, The Daily Gwei, OurNetwork data newsletter, and NotBoring. \n\nFinally, the Cool Blockchain Data Websites section provides links to various websites that provide blockchain data, including cryptofees.info, ultrasound.money, fees.wtf, and liquidated.live. \n\nOverall, this guide provides a comprehensive list of resources for users to explore as they navigate the world of web3 data analytics.\n## Questions: \n 1. What is the purpose of the Dune Docs app and how does it relate to blockchain SQL analysis?\n- The app technical guide does not provide information on the purpose of the Dune Docs app or its relation to blockchain SQL analysis.\n\n2. Are there any resources specifically related to blockchain SQL analysis included in the recommended reading?\n- The recommended reading includes resources related to web3 data analytics in general, but does not specifically mention blockchain SQL analysis.\n\n3. Can users suggest additional resources to be included in the recommended reading list?\n- Yes, users can suggest additional resources to be included in the recommended reading list by proposing changes on the GitHub page provided in the guide.","metadata":{"source":".autodoc/docs/markdown/docs/reference/recommended-reading.md"}}],["213",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference)\n\nThe `docs/reference` folder contains a variety of app technical guides that provide essential information for users working with the Dune project. These guides cover topics such as citing Dune, Dune Bounties, events, pricing, and support, among others. They are designed to help users understand various aspects of the Dune platform and how to use its features effectively.\n\nFor example, the `citing-dune.md` guide is crucial for users who want to correctly reference and cite Dune queries and dashboards. It emphasizes the importance of crediting the creators of the queries, visualizations, and dashboards shared on the platform. The guide provides specific instructions on how to credit the creators, including a direct link to dune.com, a Dune logo, and a reference to the specific creator(s) of the content. This guide is important for users to understand how to properly credit the creators of the content they use and share.\n\nThe `dune-bounties.md` guide is a comprehensive resource that explains how Dune Analytics empowers projects and wizards to collaborate through $$ incentives. It covers various aspects of the Dune Bounties project, such as task creation, application process, communication, reputation, and payments. This guide is an excellent resource for anyone interested in learning about Dune Analytics and how it empowers projects and Wizards to collaborate through $$ incentives.\n\nThe `events.md` guide covers the Events feature of the Dune app, which is designed to foster a sense of community and encourage user engagement through events. Users can follow the link to the Community Discord provided in the guide and access the events calendar by visiting events.dune.com. This guide provides users with the necessary information to participate in these events and stay informed about upcoming ones.\n\nThe `pricing.md` guide provides detailed information about the pricing feature of the Dune app, including premium accounts, additional features, billing, and query execution. This guide is useful for users who want to learn more about the pricing feature and how to manage their subscriptions.\n\nOverall, the guides in the `docs/reference` folder provide concise and relevant information for users who want to understand various aspects of the Dune project. These guides are essential for analysts who are curious about using the project and need clarification on specific features or functionalities.","metadata":{"source":".autodoc/docs/markdown/docs/reference/summary.md"}}],["214",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/support-feedback.md)\n\n# Support & Feedback\n\nThis technical guide provides information on how to get support and leave feedback for the Dune app. The guide is divided into two main sections: \"How to Get Support\" and \"How to Leave Feedback.\"\n\nThe \"How to Get Support\" section provides users with two options for getting help. The first option is to use the search bar located above the guide. The second option is to join the Dune Discord server and ask for help in one of the relevant support channels. The guide lists seven channels, each with a specific focus, such as beginners, query questions, data tables, decoding, dashboards and visualization, spellbook, and Dune API. \n\nThe \"How to Leave Feedback\" section provides users with three options for leaving feedback. The first option is to leave a suggestion on the Canny board. The second option is to use one of the three feedback channels in Discord, which are general feedback, bug reports, and feature requests. The third option is to open a GitHub issue or submit a pull request if the feedback is related to Docs feedback fixes or additions.\n\nThe guide also provides information on how to handle account issues. Users are advised to send an email to support@dune.com for any issues related to their account, billing, or any other administrative problems.\n\nOverall, this technical guide is a useful resource for users who need help with the Dune app or want to provide feedback. The guide provides clear instructions on how to get support and leave feedback, and it also lists the relevant channels and options for each. The guide is well-organized and easy to follow, making it a valuable tool for users of the Dune app.\n## Questions: \n 1. What is the purpose of Dune Docs and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of Dune Docs or its relation to blockchain technology.\n\n2. Are there any specific SQL queries or data tables related to blockchain that can be accessed through Dune Docs?\n- The app technical guide provides information on relevant support channels for building queries and questions related to data tables in Dune, but does not specify if they are related to blockchain specifically.\n\n3. Is there any information on the security measures in place for Dune Docs, especially considering the sensitive nature of blockchain data?\n- The app technical guide does not provide information on the security measures in place for Dune Docs.","metadata":{"source":".autodoc/docs/markdown/docs/reference/support-feedback.md"}}],["215",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/v1-sunsetting.md)\n\n# Sunsetting Dune V1\n\nThis technical guide covers the decommissioning of Dune Engine V1 and the transition to V2 as the primary platform. The guide provides details on the decommissioning process, including the timeline for each blockchain, and what users can expect during each step. \n\nThe guide starts by announcing that with the release of the Polygon decoded tables on Dune Engine V2, all Raw and Decoded data that was on V1 is now on V2. As a result, the decommissioning process has started, and blockchains on V1 are being decommissioned as the transition to V2 is made. \n\nThe guide then provides details on the decommissioning process, which is the same for all blockchains. The process has four steps, starting with a fair warning that the blockchain will be decommissioned in the future, followed by the removal of the blockchain from the blockchain selection dropdown, making existing queries still editable on V1, but no new queries can be created on V1 dataset. The third step is where V1 queries for the given blockchain become read-only, and forking and updating to DuneSQL is required. Queries can still be run, but no changes can be made. The final step is where no new data will be ingested, and no new query executions on V1 databases, decommission complete. Queries have to be forked and adjusted to V2.\n\nThe guide also provides a schedule for the decommissioning of each blockchain, including the kickoff date and the completion date for each step. \n\nFinally, the guide provides links to resources where users can learn more about DuneSQL, how searching in V2 works, and general insights from Dune Arcana videos. Users can also join live office hours or ask questions in the #query-questions Discord channel.\n\nOverall, this guide provides a clear and detailed explanation of the decommissioning process for Dune Engine V1 and what users can expect during each step. It also provides helpful resources for users to learn more about the transition to V2 and ask questions.\n## Questions: \n 1. What is the reason for sunsetting Dune V1 and transitioning to V2 as the primary platform?\n   \n   Answer: The reason for sunsetting Dune V1 and transitioning to V2 as the primary platform is due to the release of the Polygon decoded tables on Dune Engine V2, which now has all Raw and Decoded data that was on V1 on V2.\n\n2. What are the implications for existing and new contracts that are submitted for decoding on all blockchains?\n   \n   Answer: No new contracts that are submitted for decoding (on all blockchains) will be decoded on V1, they will only be decoded on V2 (already decoded contracts will continue to work as normal).\n\n3. What is the decommissioning schedule for Dune V1 databases and what are the steps involved in the decommissioning process?\n   \n   Answer: The decommissioning schedule for Dune V1 databases is provided in the table in the technical guide. The steps involved in the decommissioning process include: (1) kicking off the decommissioning, (2) removal of the blockchain from the blockchain selection dropdown, (3) V1 queries for the given blockchain will become read only, and (4) no new data will be ingested and no new query executions on V1 databases, decommission complete. Queries have to be forked and adjusted to V2.","metadata":{"source":".autodoc/docs/markdown/docs/reference/v1-sunsetting.md"}}],["216",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/wizard-tools/blockchain-explorers.md)\n\n# Blockchain Explorers\n\nThis section of the app technical guide covers the primary web-based explorers for the most popular blockchains. The purpose of this guide is to provide an overview of what blockchain explorers are and how they can be used by data analysts/scientists to explore a blockchain. \n\nThe guide explains that blockchain explorers provide an online interface for users to look up any particular blockchain of choice and retrieve data about transactions, addresses, blocks, and fees, amongst others. The guide then lists the primary web-based explorers for the most popular blockchains, including Ethereum, Solana, Arbitrum, Polygon, Optimism, Avalanche C-Chain, Binance Smart Chain, and Gnosis Chain. \n\nThe guide also highlights that while blockchain explorers won't let users do half of the cool things Dune does, they are indispensable for figuring out how certain protocols work and what data needs to be included in queries. \n\nExample: If a data analyst/scientist wants to explore the Ethereum blockchain, they can use the Etherscan explorer listed in the guide to retrieve data about transactions, addresses, blocks, and fees. \n\nOverall, this section of the app technical guide provides a useful overview of blockchain explorers and their importance for data analysts/scientists.\n## Questions: \n 1. What is the purpose of Blockchain Explorers?\n- Blockchain Explorers allow Data Analysts/Scientists to explore a blockchain by providing an online interface to retrieve data about transactions, addresses, blocks, and fees, amongst others.\n\n2. What are some of the popular blockchains that this app technical guide covers?\n- This app technical guide covers popular blockchains such as Ethereum, Solana, Arbitrum, Polygon, Optimism, Avalanche C-Chain, Binance Smart Chain, and Gnosis Chain.\n\n3. How does this app technical guide compare to Dune in terms of functionality?\n- The app technical guide acknowledges that while Blockchain Explorers won't let you do half of the cool things Dune does, they are indispensable for figuring out how certain protocols work and what data you need to include in your queries.","metadata":{"source":".autodoc/docs/markdown/docs/reference/wizard-tools/blockchain-explorers.md"}}],["217",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/wizard-tools/helpful-dashboards.md)\n\n# Helpful Dashboards\n\nThis app technical guide covers a list of dashboards that are useful for those who want to learn Dune, Data Analytics, and Blockchain Analysis skills. The guide is divided into two sections: Tutorial Dashboards and Reference Dashboards.\n\nThe Tutorial Dashboards section contains dashboards that are great for learning new skills. The dashboards include Tips and Tricks for Dune V2 Queries and Visualizations, Data Visualization Cheat Sheet, Event and Function Signature Sleuthing, Getting Started, and Contract Quickstart. Each dashboard is created by a different user and provides a unique perspective on how to use Dune.\n\nThe Reference Dashboards section contains dashboards that are helpful to refer to while building queries. The dashboards include Meta Monitoring, Is my Contract Decoded Yet?, and Dune DB Guide. These dashboards provide useful information that can help users build queries more efficiently.\n\nThe guide also encourages users to submit their own dashboards by submitting a GitHub Pull Request. If the dashboard is helpful, it will be added to the list.\n\nOverall, this guide provides a list of dashboards that can help users learn Dune, Data Analytics, and Blockchain Analysis skills. It also provides a list of reference dashboards that can help users build queries more efficiently.\n## Questions: \n 1. What is the purpose of the Dune Docs app?\n- The app technical guide does not provide a clear answer to this question.\n\n2. What kind of data can be analyzed using the dashboards provided by Dune Docs?\n- The dashboards are designed for Dune, Data Analytics, and Blockchain Analysis skills.\n\n3. Can users contribute their own dashboards to the app?\n- Yes, users can submit their own dashboards via a GitHub Pull Request and if deemed helpful, they will be added to the list.","metadata":{"source":".autodoc/docs/markdown/docs/reference/wizard-tools/helpful-dashboards.md"}}],["218",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/wizard-tools/index.md)\n\n# Wizard Tools\n\nThis section of the app technical guide covers some of the non-Dune tools that the wizards use to make their magic happen. The tools listed here are helpful for learning about ERC-xxx standards, EVM resources, smart contract auditing, blockchain data sleuthing, and more. \n\nSome of the tools listed include OpenZepplin's ERC-xxx Standards Docs, which are helpful for learning how each ERC-xxx standard works. The EVM Handbook is a curated list of EVM resources for aspiring blockchain data analysts. Solidity Visual Developer for VS Code is a helpful suite of tools for smart contract auditing inside of VS code. Deth.net is a set of Ethereum developer tools that help with blockchain data sleuthing. \n\nZK Zhao's map of the Crypto Data Landscape is helpful for getting a sense of the current crypto data ecosystem. His Chaininsight tool is pretty cool too, and could help you build the next trending dashboard before someone else does. \n\nOther tools listed include DeepDAO, which provides stats on DAOs and their treasuries, and DethCode, which lets you go into an Ethereum smart contract's code to read the comments or the actual logic to help understand the smart contract's emitted data. \n\nThere are also resources for learning about Solidity, such as freeCodeCamp's Learn Solidity Handbook and Ethernaut, a wargame where you \"hack\" a set of smart contracts. Advanced Ethereum Mini Courses assume you have an understanding of Solidity, React, Truffle, and Web3, but are a good resource for understanding how theory applies to practice. \n\nFinally, the Online Ethereum Transaction Decoder is a tool that can be used to decode Ethereum transactions. \n\nOverall, this section of the app technical guide provides a comprehensive list of tools and resources that can be used to learn about and work with Ethereum and smart contracts.\n## Questions: \n 1. What is the purpose of this app and how does it relate to blockchain technology?\n- The app is called \"Wizard Tools\" and provides a list of non-Dune tools that wizards use to make things. It is unclear how this app specifically relates to blockchain technology.\n\n2. Are there any tools listed that specifically relate to SQL analysis of blockchain data?\n- None of the tools listed in this app technical guide specifically relate to SQL analysis of blockchain data.\n\n3. Are there any resources listed that could help with understanding smart contracts and their data structure?\n- Yes, Sidekik and DethCode are both listed as resources that can help with understanding smart contracts and their data structure.","metadata":{"source":".autodoc/docs/markdown/docs/reference/wizard-tools/index.md"}}],["219",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/wizard-tools)\n\nThe `docs/reference/wizard-tools` folder contains a collection of guides and resources that are essential for data analysts and scientists working with Dune Analytics. These guides cover various aspects of blockchain analysis, data visualization, and query building, providing users with a comprehensive understanding of the tools and techniques used in the field.\n\nThe `blockchain-explorers.md` guide offers an overview of the primary web-based explorers for popular blockchains such as Ethereum, Solana, Arbitrum, and more. These explorers are crucial for understanding how certain protocols work and what data needs to be included in queries. For example, a data analyst can use the Etherscan explorer to retrieve data about transactions, addresses, blocks, and fees on the Ethereum blockchain.\n\nThe `helpful-dashboards.md` guide lists tutorial and reference dashboards that can help users learn Dune, Data Analytics, and Blockchain Analysis skills. Tutorial Dashboards, such as Tips and Tricks for Dune V2 Queries and Visualizations, provide valuable insights for learning new skills. Reference Dashboards, like Meta Monitoring, offer useful information for building queries more efficiently.\n\nThe `index.md` guide covers non-Dune tools that are helpful for learning about ERC-xxx standards, EVM resources, smart contract auditing, and blockchain data sleuthing. Resources like OpenZeppelin's ERC-xxx Standards Docs, Solidity Visual Developer for VS Code, and DeepDAO provide users with a comprehensive understanding of Ethereum and smart contracts.\n\nThe `utility-queries.md` guide provides a list of queries that can be used as a starting point for building custom queries. These queries are categorized using tags such as \"decoding\", \"query starting point\", \"NFT\", and \"parameters\". For instance, the \"Is my Contract decoded yet\" queries can be used to check if a contract has been decoded on different networks like Polygon, xDAI, and BSC.\n\nOverall, the guides and resources in the `wizard-tools` folder are invaluable for data analysts and scientists working with Dune Analytics. They offer a comprehensive understanding of blockchain analysis, data visualization, and query building, enabling users to create efficient and accurate queries for their projects.","metadata":{"source":".autodoc/docs/markdown/docs/reference/wizard-tools/summary.md"}}],["220",{"pageContent":"[View code on GitHub](https://dune.com/docs/reference/wizard-tools/utility-queries.md)\n\n# Utility Queries\n\nThis section of the Dune Docs project provides a list of queries that can be used to build other queries. The purpose of this section is to provide a starting point for users who want to create their own custom queries. The queries listed here are created by other users and are available for anyone to use.\n\nThe table provided in this section lists the name and link of each query, as well as the tag associated with it. The tag is used to categorize the queries and make it easier for users to find what they are looking for. The tags used in this section are \"decoding\", \"query starting point\", \"NFT\", and \"parameters\".\n\nFor example, the \"Is my Contract decoded yet\" queries by @0xBoxer are tagged as \"decoding\". These queries can be used to check if a contract has been decoded yet on different networks such as Polygon, xDAI, and BSC. The queries created by @ilemi are tagged as \"query starting point\" and can be used as a starting point for users who want to create their own custom queries. The query created by @hildobby is tagged as \"parameters\" and can be used to get the address from ENS.\n\nIf users have their own queries that they think should be included in this section, they can propose their changes by following the link provided in the description. \n\nOverall, this section of the Dune Docs project is a useful resource for users who want to create their own custom queries. By providing a list of queries that can be used as a starting point, users can save time and effort when creating their own queries.\n## Questions: \n 1. What is the purpose of the Dune Docs app and how does it relate to blockchain technology?\n- The Dune Docs app provides a list of utility queries that can be used to build queries related to blockchain technology.\n\n2. How can the utility queries listed in the app be used by a blockchain SQL analyst?\n- The utility queries listed in the app can be used as starting points for building more complex queries related to decoding contracts, analyzing event signatures and functions, and retrieving NFTs held by an address.\n\n3. Can users contribute their own utility queries to the Dune Docs app?\n- Yes, users can propose changes and contribute their own utility queries to the Dune Docs app by submitting them through the GitHub repository linked in the app.","metadata":{"source":".autodoc/docs/markdown/docs/reference/wizard-tools/utility-queries.md"}}],["221",{"pageContent":"[View code on GitHub](https://dune.com/docs)\n\nThe `decoding-contracts.md` guide in the `docs/data-tables/decoded` folder focuses on decoding smart contract activity into human-readable tables on the Dune platform. This guide is essential for analysts and developers who want to understand and access the decoded data of smart contracts, events, and function calls on the Dune platform.\n\nThe guide covers the following topics:\n\n1. **Call Tables**: This section explains how Dune parses all message calls and transactions made to smart contracts in their own tables. It provides information on how the tables are named and how they are created on an individual contract level or a class of contracts. It also highlights a common misconception about `pure`, `read`, or `constant` functions not being recorded in Dune.\n\n2. **Event Logs**: This section covers the concept of event logs in smart contracts and how they are decoded into tables named according to a specific schema. It provides examples of how to name tables for the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL) and how to look at event logs of a transaction in Etherscan.\n\n3. **Decoding Process**: This section explains how Dune uses the ABI (Application Binary Interface) for smart contracts and the interface standard for standardized token smart contracts (ERC20, ERC721, etc.) to create tables for each event and function defined in the smart contract's ABI. It provides an example of decoding an ERC20 transfer event log and how to understand decoded data.\n\n4. **Accessing Decoded Data**: This section provides examples of how to access decoded data for specific events and function calls using the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL). It also explains how to check if contracts are already decoded by querying the `[blockchain].contracts` tables or using a dashboard.\n\n5. **Which Tables to Use**: This section discusses which tables to use (events or calls) and provides queries to explore decoded contracts, such as seeing all projects with decoded data or checking for multiple instances of a contract.\n\nThis guide is useful for analysts who want to access and analyze decoded data from smart contracts, events, and function calls on the Dune platform. For example, an analyst might use this guide to understand how to access decoded data for a specific ERC20 token transfer event or how to explore all projects with decoded data on the platform. By understanding the decoding process and how to access the decoded data, analysts can gain valuable insights into smart contract activity and interactions on the Dune platform.","metadata":{"source":".autodoc/docs/markdown/docs/summary.md"}}],["222",{"pageContent":"[View code on GitHub](https://dune.com/license.md)\n\nThis app technical guide provides information on the licensing of the Dune Analytics AS software. The guide explains that the software is licensed under the MIT License, which grants users the right to use, copy, modify, merge, publish, distribute, sublicense, and sell copies of the software. However, this is subject to certain conditions, including the inclusion of the copyright notice and permission notice in all copies or substantial portions of the software.\n\nThe purpose of this guide is to inform users of the licensing terms and conditions of the Dune Analytics AS software. It is important for users to understand these terms in order to comply with the license and avoid any legal issues.\n\nAn example of how this guide applies to the app section of the project is that developers who are building apps using the Dune Analytics AS software need to ensure that they comply with the licensing terms and conditions. This may involve including the copyright notice and permission notice in their app, as well as ensuring that they do not infringe on any of the rights granted by the license.\n\nOverall, this guide serves as an important reference for users of the Dune Analytics AS software, providing them with the information they need to use the software in compliance with the MIT License.\n## Questions: \n 1. What is the purpose of the Dune Docs app?\n   - The app technical guide does not provide information on the purpose of the Dune Docs app. Further documentation or research may be necessary to determine its purpose.\n\n2. Does the Dune Docs app use a blockchain or SQL database?\n   - The app technical guide does not provide information on whether the Dune Docs app uses a blockchain or SQL database. Additional documentation or analysis of the app's code may be necessary to determine this.\n\n3. Are there any specific technical requirements or dependencies needed to run the Dune Docs app?\n   - The app technical guide does not provide information on any specific technical requirements or dependencies needed to run the Dune Docs app. Additional documentation or analysis of the app's code may be necessary to determine this.","metadata":{"source":".autodoc/docs/markdown/license.md"}}],["223",{"pageContent":"[View code on GitHub](https://dune.com/requirements.txt)\n\n# App Technical Guide\n\nThis guide covers the necessary dependencies required to run the Dune Docs app. The following dependencies are required:\n\n- `mkdocs-material==9.*`: This is a Material Design theme for MkDocs, a static site generator for building project documentation. This theme provides a clean and modern look for the Dune Docs app.\n\n- `mkdocs-awesome-pages-plugin`: This is a plugin for MkDocs that allows for the creation of custom navigation menus. This is useful for organizing the documentation in a way that makes sense for the user.\n\n- `mkdocs-video`: This is a plugin for MkDocs that allows for the embedding of videos in the documentation. This is useful for providing visual aids to the user.\n\n- `mkdocs-redirects`: This is a plugin for MkDocs that allows for the creation of redirects. This is useful for maintaining backwards compatibility with old URLs.\n\nEach file in this guide covers a specific topic related to the Dune Docs app. The purpose of each header is as follows:\n\n- `mkdocs-material`: This file covers the Material Design theme for MkDocs. It explains how to install and configure the theme for the Dune Docs app.\n\n- `mkdocs-awesome-pages-plugin`: This file covers the Awesome Pages plugin for MkDocs. It explains how to install and configure the plugin for the Dune Docs app.\n\n- `mkdocs-video`: This file covers the Video plugin for MkDocs. It explains how to install and use the plugin for embedding videos in the Dune Docs app.\n\n- `mkdocs-redirects`: This file covers the Redirects plugin for MkDocs. It explains how to create and use redirects in the Dune Docs app.\n\nFor example, to install the Material Design theme for MkDocs, the following command can be used:\n\n```\npip install mkdocs-material==9.*\n```\n\nOverall, this guide provides a comprehensive overview of the dependencies required to run the Dune Docs app, as well as how to install and configure them.\n## Questions: \n 1. What is the purpose of this app and how does it relate to blockchain technology? \n- The app technical guide does not provide information on the purpose of the app or its relation to blockchain technology.\n\n2. Are there any specific SQL databases or technologies that this app is designed to work with? \n- The app technical guide does not mention any specific SQL databases or technologies that the app is designed to work with.\n\n3. Does this app have any features or capabilities related to data analysis or visualization? \n- The app technical guide does not provide information on any features or capabilities related to data analysis or visualization.","metadata":{"source":".autodoc/docs/markdown/requirements.md"}}]]
