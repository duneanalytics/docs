[View code on GitHub](https://dune.com/docs/data-tables/raw/event-logs.md)

# Event Logs

This guide covers the `Event Logs` tables that store all logs data generated by smart contracts. The logs are an elegant way to store tiny amounts of data on EVM blockchains for a small amount of gas. Specifically, event logs are useful to let other people know something has happened without them having to query contracts individually. The guide provides a list of tables for the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL) for different chains. 

The `Tables` section of the guide provides a list of tables for the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL) for different chains. The tables are named after the chain they belong to and contain logs data generated by smart contracts. The tables are useful for querying contracts that are not yet decoded or are not able to be decoded since the code of the smart contract is not public. 

The `Column Data` section of the guide provides a description of the columns in the `Event Logs` tables. The columns include `contract_address`, `topic1`, `topic2`, `topic3`, `topic4`, `data`, `tx_hash`, `block_hash`, `block_number`, `block_time`, `index`, and `tx_index`. The columns contain information such as the address of the contract that emitted the log, keccak256 hash of a flattened event declaration string, unindexed data containing further information on the event, the transaction hash of the transaction that produced this log, and the time when the block was mined that includes this log. 

For more information on this topic, the guide provides a link to an article on understanding event logs on the Ethereum blockchain. 

Example:
```
|   Chain           |   Table             | Notes |
| ----------------  | ------------------- | ----- |
| Ethereum Mainnet  | `ethereum.logs`     |       |
| Gnosis Chain      | `gnosis.logs`       |       |
| Polygon           | `polygon.logs`      |       |
| Optimism          | `optimism.logs`     |       |
| Optimism (legacy) | `optimism_legacy_ovm1.logs` |       |
| BNB Chain         | `bnb.logs`          |       |
| Arbitrum          | `arbitrum.logs`     |       |
| Avalanche C-Chain  | `avalanche_c.logs` |       |
```
The above example shows the tables for the V2 Engine (Spark SQL) for different chains. 

```
|   Chain              |   Table         | Notes |
| -------------------  | --------------- | ----- |
| Ethereum Mainnet     | `ethereum.logs` |       |
| Gnosis Chain (xDai)  | `xdai.logs`     |       |
| Polygon              | `polygon.logs`  |       |
| Optimism (OVM 1 & 2) | `optimism.logs` |       |
| BNB Chain (BSC)      | `bsc.logs`      |       |
```
The above example shows the tables for the V1 Engine (PostgreSQL) for different chains. 

### Column Data

|   Column name      |   Data type     |    Description   |
| ------------------ | :------------: | -------------------------------------------------------------- |
| `contract_address` | _bytea_        | The address of the contract that emitted the log               |
| `topic1`           | _bytea_        | keccak256 hash of a flattened event declaration string         |
| `topic2`           | _bytea_        | Second indexed `topic` of the event                            |
| `topic3`           | _bytea_        | Third indexed `topic` of the event                             |
| `topic4`           | _bytea_        | Fourth indexed `topic` of the event                            |
| `data`             | _bytea_        | Unindexed data containing further information on the event     |
| `tx_hash`          | _bytea_        | The transaction hash of the transaction that produced this log |
| `block_hash`       | _bytea_        | A unique identifier for that block                             |
| `block_number`     | _int8_         | The length of the blockchain in blocks                         |
| `block_time`       | _timestamptz_  | The time when the block was mined that includes this log       |
| `index`            | _numeric_      | This logs index position in the block (cumulative amount of logs ordered by execution) |
| `tx_index`         | _numeric_      | The index position of the transaction in this block (cumulative amount of transactions ordered by execution) |

The above example shows the columns in the `Event Logs` tables.
## Questions: 
 1. What is the purpose of the Event Logs tables in this app and how are they useful for blockchain analysis?
   
   The Event Logs tables store all logs data generated by smart contracts and can be useful for querying contracts that are not yet decoded or are not able to be decoded since the code of the smart contract is not public. They are also useful for letting other people know something has happened without them having to query contracts individually.

2. What engines are used to store the data in the tables and what chains are supported by each engine?
   
   The V2 Engine (Spark SQL) is used to store data in the tables and supports Ethereum Mainnet, Gnosis Chain, Polygon, Optimism, Optimism (legacy), BNB Chain, and Avalanche C-Chain. The V1 Engine (PostgreSQL) is also used and supports Ethereum Mainnet, Gnosis Chain (xDai), Polygon, Optimism (OVM 1 & 2), and BNB Chain (BSC).

3. What are the different column data types and what information do they contain?
   
   The different column data types include contract_address, topic1, topic2, topic3, topic4, data, tx_hash, block_hash, block_number, block_time, index, and tx_index. They contain information such as the address of the contract that emitted the log, keccak256 hash of a flattened event declaration string, unindexed data containing further information on the event, the transaction hash of the transaction that produced this log, and the time when the block was mined that includes this log.
