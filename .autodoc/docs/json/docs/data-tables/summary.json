{
  "folderName": "data-tables",
  "folderPath": "docs/data-tables",
  "url": "https://dune.com/docs/data-tables",
  "files": [
    {
      "fileName": "index.md",
      "filePath": "docs/data-tables/index.md",
      "url": "https://dune.com/docs/data-tables/index.md",
      "summary": "# Tables and Chains Overview\n\nThis technical guide provides an overview of the tables and chains available in the Dune app. The guide is divided into two main sections: The Four Kinds of Tables and Available Chains.\n\nThe Four Kinds of Tables section explains how Dune ingests data from node providers to create raw tables, which are then decoded using contract ABIs to provide easier to work with decoded tables. Abstracted tables are then created to standardize and aggregate the data, giving users the easiest to work with spell tables. The section also provides links to the raw data, decoded data, spellbook, and community tables.\n\nThe Available Chains section provides a list of the chains available to query in Dune. For each chain, the section provides a brief overview of the chain, its history, and its technical details. The section also includes links to the chain's documentation and other resources.\n\nFor example, the Ethereum Mainnet section provides a brief history of Ethereum, its updates, and its decentralized platform. The section also includes a link to the Ethereum Developer Docs. Similarly, the BNB Chain (BSC) section explains how BNB Chain follows most of the rules of Ethereum Mainnet but has not implemented EIP1559. The section also includes a link to the BNB Chain Documentation.\n\nOverall, this technical guide provides a comprehensive overview of the tables and chains available in the Dune app. It is a useful resource for users who want to understand how Dune ingests data and creates tables, as well as for users who want to query specific chains and understand their technical details.",
      "questions": "1. What kind of data can be queried from the Dune Docs app for each available chain?\n- The app ingests data from node providers to fill raw tables, which are then decoded using contract ABIs to provide decoded tables. Abstracted tables are then created to standardize and aggregate the data, giving users the easiest to work with spell tables. \n\n2. How does the gas calculation differ for transactions on Optimism and Arbitrum compared to Ethereum Mainnet?\n- Optimism processes transactions outside of Ethereum Mainnet, reducing congestion on the base layer and improving scalability. Arbitrum is an optimistic rollup that settles its transactions on Ethereum Mainnet, but its execution environment differs from the Mainnet EVM implementation in its calculation of gas costs. \n\n3. What is the difference between BNB Chain and Ethereum Mainnet in terms of gas fees and fee burning?\n- BNB Chain follows most of the rules of Ethereum Mainnet, but has not implemented EIP1559. Instead, it relies on BEP-95 to burn fees that accrue during usage of the platform. Furthermore, the gas limit per block is set to 100 million, enabling more transactions to be processed in a given block. Transactions fees are paid in BNB instead of ETH."
    }
  ],
  "folders": [
    {
      "folderName": "community",
      "folderPath": "docs/data-tables/community",
      "url": "https://dune.com/docs/data-tables/community",
      "files": [
        {
          "fileName": "index.md",
          "filePath": "docs/data-tables/community/index.md",
          "url": "https://dune.com/docs/data-tables/community/index.md",
          "summary": "# Dune Docs App Technical Guide: Community\n\nThis section of the Dune Docs project contains data that has been submitted and hosted on Dune by third-party data providers. The purpose of this guide is to provide an overview of the Community section and its features.\n\n## Availability\n\nThe Community section is only available on the V2 Engine. It is important to note that this section is still under development, and the infrastructure is being built to support more datasets.\n\n## Purpose\n\nWhile blockchain data is interesting on its own, sometimes off-chain data or augmented on-chain data is needed as well. The Community section is designed to partner with selected organizations that stream their data directly to Dune. This allows for a more comprehensive view of the data and can provide additional insights.\n\n## Data Providers\n\nThe Community section currently features two data providers: Flashbots and Reservoir. Each provider has its own page with more detailed information about the data they provide.\n\n### Flashbots\n\nFlashbots is a research and development organization that focuses on miner-extractable value (MEV) and the fair distribution of this value. Their page on the Community section provides data related to MEV and other metrics.\n\n### Reservoir\n\nReservoir is a data provider that focuses on Ethereum data. Their page on the Community section provides data related to Ethereum transactions, including gas usage and transaction volume.\n\nIt is important to note that these are just two examples of data providers that may be featured in the Community section. As the infrastructure is built out, more providers may be added.\n\nOverall, the Community section of the Dune Docs project is designed to provide additional data insights through partnerships with third-party data providers. While still under development, this section has the potential to provide valuable information to users of the Dune platform.",
          "questions": "1. What is the V2 Engine and why is it necessary for accessing the Community section?\n- The V2 Engine is required for accessing the Community section, but the guide does not provide information on what it is or why it is necessary.\n\n2. What types of off-chain or augmented on-chain data are being provided by the selected organizations?\n- The guide mentions that selected organizations are streaming their data directly to Dune, but does not provide any information on the types of data being provided.\n\n3. Is there a timeline for when more datasets will be supported in the Community section?\n- The guide mentions that the infrastructure for the Community section is still being built out and that more datasets cannot be supported at the current moment, but does not provide any information on when this may change."
        }
      ],
      "folders": [
        {
          "folderName": "flashbots",
          "folderPath": "docs/data-tables/community/flashbots",
          "url": "https://dune.com/docs/data-tables/community/flashbots",
          "files": [
            {
              "fileName": "arbitrages.md",
              "filePath": "docs/data-tables/community/flashbots/arbitrages.md",
              "url": "https://dune.com/docs/data-tables/community/flashbots/arbitrages.md",
              "summary": "# Dune Docs App Technical Guide: Arbitrages\n\nThe `arbitrages` section of the Dune Docs project is focused on providing additional information about each arbitrage trade. The `flashbots.arbitrages` table contains records with details such as block number, account address, time of record creation, available amount before and after the arbitrage, profit amount, profit token address, protocols involved in the transaction, transaction hash, and timestamp of the latest update of the file.\n\nThe purpose of this technical guide is to provide a clear understanding of the `arbitrages` section of the Dune Docs project. The guide explains the structure of the `flashbots.arbitrages` table, including the column names, data types, and descriptions. It also provides query examples that can be used to retrieve information from the table.\n\nFor instance, the `Total Arb Protocols` query example provided in the guide can be used to retrieve the total number of arbitrage protocols involved in the transaction. This query can be accessed through the link provided in the guide.\n\nOverall, this technical guide serves as a reference for developers and users who want to understand the `arbitrages` section of the Dune Docs project. It provides a clear and concise explanation of the table structure and query examples that can be used to retrieve information from the table.",
              "questions": "1. What is the purpose of the `flashbots.arbitrages` table in the context of blockchain technology?\n- The `flashbots.arbitrages` table contains records with additional information about each arbitrage trade in the blockchain, which can be useful for analyzing trading patterns and identifying potential opportunities for profit.\n\n2. How can a blockchain SQL analyst use the query examples provided in the technical guide?\n- The query examples provided in the technical guide can be used by a blockchain SQL analyst to retrieve specific data from the `flashbots.arbitrages` table, such as information about the protocols involved in a transaction or the profit amount after an arbitrage.\n\n3. Are there any limitations or potential issues with using SQL to analyze blockchain data?\n- While SQL can be a powerful tool for analyzing blockchain data, there are some limitations and potential issues to be aware of, such as the need to handle large amounts of data and the possibility of inaccuracies due to the decentralized nature of the blockchain."
            },
            {
              "fileName": "index.md",
              "filePath": "docs/data-tables/community/flashbots/index.md",
              "url": "https://dune.com/docs/data-tables/community/flashbots/index.md",
              "summary": "# Flashbots\n\nThis section of the app technical guide covers the Flashbots project, a research and development organization focused on ensuring that MEV (Miner Extractable Value) incentives do not become opaque and undemocratic. MEV refers to the profit that miners can extract from reordering, censoring, or including transactions in a block. \n\nThe guide notes that Flashbots' open source engine for generating MEV data, mev-inspect-py, powers dashboards such as mev-explore and Dune's Flashbots integration. The section encourages researchers and developers to report any bugs or implement new features to improve the engine. \n\nThe guide provides links to the Flashbots documentation and Discord server for more information and updates on their data and mev-inspect. \n\nExample: If a developer is working on integrating Flashbots into their project, they can refer to the documentation and join the Discord server to stay up-to-date on any changes or improvements to the engine. They can also report any bugs they encounter to help improve the engine for the community.",
              "questions": "1. What is the purpose of Flashbots and how does it relate to MEV incentives?\n- Flashbots is a research and development organization that aims to prevent MEV incentives from becoming opaque and undemocratic. MEV-inspect-py, their open source engine for generating MEV data, powers dashboards such as mev-explore and Dune's Flashbots integration.\n\n2. How can blockchain SQL analysts contribute to improving Flashbots' open source engine?\n- Flashbots encourages researchers and developers to report and help correct any found bugs, or implement any new features. They can consult the documentation and join the Flashbots discord for more information and updates on their data and mev-inspect.\n\n3. What resources are available for developers and researchers interested in using Flashbots?\n- Flashbots provides documentation on their website and a Discord server for more information and updates on their data and mev-inspect. They also encourage community contributions to improve their open source engine."
            },
            {
              "fileName": "liquidations.md",
              "filePath": "docs/data-tables/community/flashbots/liquidations.md",
              "url": "https://dune.com/docs/data-tables/community/flashbots/liquidations.md",
              "summary": "# Liquidations\n\nThe `liquidations` section of the Dune Docs project focuses on providing details related to executed liquidations. The `flashbots.liquidations` table contains information about liquidations executed using the MEV strategy. The table includes details such as the time of record creation, transaction hash, trace pattern related to the position of the transaction in the chain of all transactions related to the MEV trade, underlying token address of the debt to pay, amount received from the liquidation, protocol name, address of the liquidated user, address of the liquidator user, address of the received asset, block number, amount of purchased debt, and timestamp of the latest update of the file.\n\nThe purpose of this guide is to provide a detailed explanation of the `flashbots.liquidations` table and its columns. The guide also includes a link to query examples for liquidations by protocol. This information is useful for developers who want to understand how liquidations work and how to access the data related to executed liquidations.\n\nAn example of a query that can be run using the `flashbots.liquidations` table is the `Liquidations by Protocol` query, which can be found at [https://dune.com/queries/625715/1166880](https://dune.com/queries/625715/1166880). This query provides information about liquidations executed by protocol, including the protocol name, number of liquidations, total received amount, and average received amount.\n\nOverall, the `liquidations` section of the Dune Docs project provides valuable information for developers who want to understand how liquidations work and how to access the data related to executed liquidations using the MEV strategy.",
              "questions": "1. What is the purpose of the `flashbots.liquidations` table in the context of blockchain and how is it related to MEV (Miner Extractable Value)? \n- The `flashbots.liquidations` table contains details related to executed liquidations, which is another MEV strategy. It is related to MEV because it involves extracting value from transactions before they are included in a block.\n\n2. Can you provide more information on the `trace_address` column and how it relates to the position of the transaction in the chain of all transactions related to the MEV trade? \n- The `trace_address` column contains a trace pattern related to the position of the transaction in the chain of all transactions related to the MEV trade. This can be useful for analyzing the flow of transactions and identifying potential bottlenecks or inefficiencies.\n\n3. Are there any limitations or considerations to keep in mind when using the `debt_purchase_amount` column for analysis? \n- It may be important to consider the specific context and protocol being used when analyzing the `debt_purchase_amount` column, as the amount of purchased debt may vary depending on the protocol and other factors. Additionally, it may be useful to compare this column to other relevant metrics to gain a more complete understanding of the data."
            },
            {
              "fileName": "mev_summary.md",
              "filePath": "docs/data-tables/community/flashbots/mev_summary.md",
              "url": "https://dune.com/docs/data-tables/community/flashbots/mev_summary.md",
              "summary": "# mev_summary\n\nThe `mev_summary` section of the Dune Docs project is focused on providing a summary of all the classified transactions. The `flashbots.mev_summary` table contains information on the various transactions that have taken place, including the block timestamp, block number, base fee per gas, direct transfer to miner's address, error (if any), gas price, amount of gas spent, amount of gas used, total profit from the transaction in USD, address of the miner, payment received by the miner in USD, main interacted protocol, list of protocols involved in the transaction, hash of the transaction, type of the MEV (e.g. arbitrage), and timestamp of the latest update of the file.\n\nThis section of the app technical guide provides a detailed description of the various columns in the `flashbots.mev_summary` table, including their data type and description. For example, the `block_timestamp` column contains a timestamp of the block, while the `gas_price` column contains the price of the gas. The guide also provides a query example that can be used to retrieve information from the `flashbots.mev_summary` table.\n\nOverall, the `mev_summary` section of the Dune Docs project is an important resource for anyone looking to understand the various transactions that have taken place on the platform. By providing detailed information on each transaction, including the type of MEV and the protocols involved, this section of the app technical guide helps users gain a better understanding of how the platform works and how they can use it to their advantage.",
              "questions": "1. What is the purpose of the `mev_summary` table in the context of blockchain and SQL analysis?\n- The `mev_summary` table contains a summary of all classified transactions, which could be useful for analyzing miner revenue and profit in the context of MEV (miner-extractable value) strategies.\n\n2. Are there any limitations or potential issues with using this table for blockchain and SQL analysis?\n- The technical guide does not provide information on any limitations or potential issues with using this table, so a blockchain SQL analyst may need to investigate further to ensure the data is accurate and complete.\n\n3. Are there any additional resources or documentation available for using the `mev_summary` table in Dune Docs?\n- The technical guide provides a link to query examples, but it is unclear if there are any additional resources or documentation available for using this table in Dune Docs. A blockchain SQL analyst may need to reach out to the Dune Docs team or community for more information."
            },
            {
              "fileName": "sandwiched-swaps.md",
              "filePath": "docs/data-tables/community/flashbots/sandwiched-swaps.md",
              "url": "https://dune.com/docs/data-tables/community/flashbots/sandwiched-swaps.md",
              "summary": "# Sandwiched Swaps\n\nThe Sandwiched Swaps section of the Dune Docs project focuses on the `flashbots.sandwiched_swaps` table, which contains additional data about one or more swaps that were sandwiched with a corresponding sandwich in the database. This section provides a detailed explanation of the columns in the table and their respective data types.\n\nThe `created_at` column contains the time of the record's creation, while the `block_number` column contains the block number of the transaction. The `sandwich_id` column contains the internal ID of the sandwiched swap, and the `trace_address` column contains the trace pattern related to the position of the swap in the chain of all swaps related to the arbitrage trade. Finally, the `transaction_hash` column contains the transaction hash, and the `timestamp` column contains the timestamp of the latest update of the file.\n\nThis section also provides query examples for the `flashbots.sandwiched_swaps` table, which can be used as a reference for developers working on the Dune Docs project. The query examples include the column name, data type, and description of each column in the table.\n\nOverall, the Sandwiched Swaps section of the Dune Docs project provides a comprehensive guide to the `flashbots.sandwiched_swaps` table, including its purpose, columns, and query examples. This information is essential for developers working on the Dune Docs project to understand the structure and functionality of the table and to use it effectively in their work.",
              "questions": "1. What is the purpose of the sandwiched_swaps table in the context of blockchain and SQL analysis?\n- A blockchain SQL analyst might want to know how the sandwiched_swaps table fits into the overall data schema and how it can be used to analyze arbitrage trades involving swaps.\n\n2. Are there any limitations or constraints on the data that can be queried from the sandwiched_swaps table?\n- A blockchain SQL analyst might want to know if there are any restrictions on the types of queries that can be run on the sandwiched_swaps table, such as limitations on the time range or block numbers that can be queried.\n\n3. How frequently is the sandwiched_swaps table updated and what triggers these updates?\n- A blockchain SQL analyst might want to know how often the sandwiched_swaps table is updated and what events trigger these updates, such as new blocks being added to the blockchain or new transactions being processed."
            },
            {
              "fileName": "sandwiches.md",
              "filePath": "docs/data-tables/community/flashbots/sandwiches.md",
              "url": "https://dune.com/docs/data-tables/community/flashbots/sandwiches.md",
              "summary": "# Sandwiches Table\n\nThe `sandwiches` table is a part of the Dune Docs project and contains detailed information about executed sandwiches. The table consists of the following columns:\n\n- `created_at`: This column contains the time of the record's creation.\n- `block_number`: This column contains the block number.\n- `backrun_swap_trace_address`: This column contains the address of the swap in the backrun transaction.\n- `backrun_swap_transaction_hash`: This column contains the transaction hash of the backrun transaction of the specified sandwich.\n- `frontrun_swap_trace_address`: This column contains the address of the swap in the frontrun transaction.\n- `frontrun_swap_transaction_hash`: This column contains the transaction hash of the frontrun transaction of the specified sandwich.\n- `id`: This column contains the internal id of the sandwich.\n- `profit_amount`: This column contains the profit amount after the arbitrage.\n- `profit_token_address`: This column contains the address of the profit asset.\n- `sandwicher_address`: This column contains the address of the sandwicher.\n- `timestamp`: This column contains the timestamp of the latest update of the file.\n\nThe `sandwiches` table is used to keep track of executed sandwiches and their details. For example, it can be used to analyze the performance of the sandwicher and the profitability of the arbitrage. \n\nHere is an example of how the `sandwiches` table can be queried:\n\n```\nSELECT *\nFROM sandwiches\nWHERE sandwicher_address = '0x1234567890abcdef'\n```\n\nThis query will return all the sandwiches executed by the sandwicher with the address `0x1234567890abcdef`.",
              "questions": "1. What is the purpose of the \"sandwiches\" table in the Dune Docs app?\n- The \"sandwiches\" table contains detailed information about executed sandwiches, including the time of record creation, block number, swap addresses and transaction hashes, profit amount and token address, sandwicher address, and timestamp of the latest update of the file.\n\n2. How is the data in the \"sandwiches\" table stored and accessed?\n- The data in the \"sandwiches\" table is stored in columns with corresponding data types and descriptions, and can be accessed through SQL queries.\n\n3. Are there any limitations or potential issues with using SQL to analyze the data in the \"sandwiches\" table?\n- It is unclear from the provided technical guide whether there are any limitations or potential issues with using SQL to analyze the data in the \"sandwiches\" table. A blockchain SQL analyst may need to consult additional documentation or perform further testing to determine any such limitations or issues."
            }
          ],
          "folders": [],
          "summary": "The Flashbots folder in the Dune Docs project focuses on providing comprehensive information and guides related to the Flashbots project, which is a research and development organization aimed at ensuring that MEV (Miner Extractable Value) incentives remain transparent and democratic. This folder contains various files that cover different aspects of the Flashbots project, such as arbitrages, liquidations, mev_summary, sandwiched swaps, and sandwiches.\n\nFor instance, the `arbitrages.md` file provides a detailed explanation of the `flashbots.arbitrages` table, which contains records with information about each arbitrage trade. Developers can use this guide to understand the table structure and retrieve information using query examples provided in the guide, such as the `Total Arb Protocols` query.\n\nThe `liquidations.md` file focuses on the `flashbots.liquidations` table, which contains information about liquidations executed using the MEV strategy. Developers can use this guide to understand the table structure and access data related to executed liquidations using query examples provided in the guide, such as the `Liquidations by Protocol` query.\n\nThe `mev_summary.md` file covers the `flashbots.mev_summary` table, which provides a summary of all classified transactions. This guide helps users understand the various transactions that have taken place on the platform, including the type of MEV and the protocols involved. The guide also provides a query example that can be used to retrieve information from the `flashbots.mev_summary` table.\n\nThe `sandwiched-swaps.md` file focuses on the `flashbots.sandwiched_swaps` table, which contains additional data about one or more swaps that were sandwiched with a corresponding sandwich in the database. This guide provides a detailed explanation of the columns in the table and their respective data types, as well as query examples for developers working on the Dune Docs project.\n\nLastly, the `sandwiches.md` file provides a comprehensive guide to the `flashbots.sandwiches` table, which contains detailed information about executed sandwiches. This guide is essential for developers working on the Dune Docs project to understand the structure and functionality of the table and to use it effectively in their work.\n\nOverall, the Flashbots folder in the Dune Docs project serves as a valuable resource for developers and users who want to understand the Flashbots project and its various aspects. The guides provided in this folder offer clear and concise explanations of the table structures, column descriptions, and query examples that can be used to retrieve information from the tables.",
          "questions": ""
        },
        {
          "folderName": "reservoir",
          "folderPath": "docs/data-tables/community/reservoir",
          "url": "https://dune.com/docs/data-tables/community/reservoir",
          "files": [
            {
              "fileName": "ask-events.md",
              "filePath": "docs/data-tables/community/reservoir/ask-events.md",
              "url": "https://dune.com/docs/data-tables/community/reservoir/ask-events.md",
              "summary": "# Ask Events\n\nThis section of the app technical guide covers the `reservoir.ask_events` table, which contains records with information about each ask change. The table includes various columns such as `id`, `kind`, `contract`, `token_id`, `order_id`, `maker`, `price`, `quantity_remaining`, `valid_from`, `valid_until`, `source`, `tx_hash`, `tx_timestamp`, and `created_at`. \n\nThe `id` column represents the internal event ID, while the `kind` column represents the type of event (e.g. new-order, expiry, sale, cancel, balance-change, approval-change, bootstrap, revalidation, reprice). The `contract` column contains the contract address, and the `token_id` column contains the ID of the token in the collection. The `order_id` column represents the associated ask ID, and the `maker` column contains the associated ask maker wallet address. The `price` column represents the associated ask price in native currency, and the `quantity_remaining` column represents the associated ask tokens remaining. The `valid_from` and `valid_until` columns represent the associated ask validity start and expiration, respectively. The `source` column contains the source of the order (e.g. opensea.io), while the `tx_hash` and `tx_timestamp` columns represent the associated transaction hash and timestamp, respectively. Finally, the `created_at` column represents the timestamp the event was recorded.\n\nThis section also includes query examples that can be found at the specified URLs. These queries can be used to retrieve information from the `reservoir.ask_events` table. \n\nOverall, this section of the app technical guide provides a detailed overview of the `reservoir.ask_events` table and its various columns. It also includes query examples that can be used to retrieve information from the table.",
              "questions": "1. What is the purpose of the `reservoir.ask_events` table in the Dune Docs app?\n- The `reservoir.ask_events` table contains records with information about each ask change in the app.\n\n2. What are some examples of query options available for the `reservoir.ask_events` table?\n- Query examples for the `reservoir.ask_events` table can be found at the following links: [https://dune.com/queries/1302858/2232178](https://dune.com/queries/1302858/2232178) and [https://dune.com/queries/1302863/2232189](https://dune.com/queries/1302863/2232189).\n\n3. What types of events are included in the `kind` column of the `reservoir.ask_events` table?\n- The `kind` column in the `reservoir.ask_events` table includes various event types such as new-order, expiry, sale, cancel, balance-change, approval-change, bootstrap, revalidation, and reprice."
            },
            {
              "fileName": "asks.md",
              "filePath": "docs/data-tables/community/reservoir/asks.md",
              "url": "https://dune.com/docs/data-tables/community/reservoir/asks.md",
              "summary": "## Reservoir.asks\n\nThis section of the app technical guide covers the `reservoir.asks` table, which contains records with information about each listing. The table includes various columns such as `id`, `kind`, `status`, `contract`, `token_id`, `maker`, `taker`, `price`, `start_price`, `end_price`, `currency_address`, `currency_symbol`, `currency_price`, `dynamic`, `quantity`, `quantity_filled`, `quantity_remaining`, `valid_from`, `valid_until`, `nonce`, `source`, `fee_bps`, `expiration`, `raw_data`, `created_at`, and `updated_at`. Each column is described in detail, including its data type and a brief explanation of its purpose.\n\nThe purpose of this guide is to provide developers with a clear understanding of the `reservoir.asks` table and its columns, as well as how to query the table. The guide includes two query examples that can be found at the provided links. Developers can use this information to build applications that interact with the `reservoir.asks` table, such as a marketplace or trading platform.\n\nFor example, a developer building a trading platform could use the `price` column to display the current price of a listing, the `quantity` column to show the amount of tokens available for purchase, and the `valid_from` and `valid_until` columns to display the start and end times of the listing. The `maker` and `taker` columns could be used to identify the parties involved in the transaction, and the `fee_bps` column could be used to calculate the listing fee.\n\nOverall, this section of the app technical guide provides a comprehensive overview of the `reservoir.asks` table and its columns, as well as practical examples of how to use the information to build applications that interact with the table.",
              "questions": "1. What is the purpose of the `reservoir.asks` table in the Dune Docs app?\n- The `reservoir.asks` table contains records with information about each listing in the app.\n\n2. What kind of data is stored in the `price` column of the `reservoir.asks` table?\n- The `price` column stores the current price of the listing in native currency.\n\n3. Is there any information in the `reservoir.asks` table about the transaction history of a listing?\n- No, there is no information in the `reservoir.asks` table about the transaction history of a listing."
            },
            {
              "fileName": "attribute-keys.md",
              "filePath": "docs/data-tables/community/reservoir/attribute-keys.md",
              "url": "https://dune.com/docs/data-tables/community/reservoir/attribute-keys.md",
              "summary": "## Attribute Keys\n\nThe `attribute_keys` section of the app technical guide provides information about the `reservoir.attribute_keys` table. This table contains records with information about each attribute key. The table has seven columns: `id`, `collection_id`, `key`, `kind`, `rank`, `created_at`, and `updated_at`. \n\n- `id`: This is the internal attribute key id.\n- `collection_id`: This is the associated collection id.\n- `key`: This is the name of the attribute.\n- `kind`: This is the value type, which can be string, number, date, or range.\n- `rank`: This is the sort order.\n- `created_at`: This is the timestamp the attribute key was created.\n- `updated_at`: This is the timestamp the attribute key was updated.\n\nThe guide also provides a link to query examples for the `reservoir.attribute_keys` table. The link leads to a page on the Dune website that provides examples of queries that can be run on the table. \n\nOverall, this section of the guide is useful for developers who need to work with the `reservoir.attribute_keys` table in the Dune app. It provides a clear understanding of the table's structure and contents, as well as examples of how to query the table.",
              "questions": "1. What is the purpose of the `reservoir.attribute_keys` table in the context of the dune docs app? \n   - The `reservoir.attribute_keys` table contains information about each attribute key in the app, including its name, type, and associated collection.\n2. How are attribute keys sorted in the `reservoir.attribute_keys` table? \n   - Attribute keys are sorted by their `rank` column in the `reservoir.attribute_keys` table.\n3. Are there any examples of queries that can be run using the `reservoir.attribute_keys` table? \n   - Yes, query examples can be found at the URL provided in the app technical guide: [https://dune.com/queries/1302930/2232305](https://dune.com/queries/1302930/2232305)."
            },
            {
              "fileName": "attributes.md",
              "filePath": "docs/data-tables/community/reservoir/attributes.md",
              "url": "https://dune.com/docs/data-tables/community/reservoir/attributes.md",
              "summary": "# Attributes\n\nThe `reservoir.attributes` table contains records with information about each attribute. This section of the app technical guide provides a detailed description of the columns in this table, including their data types and descriptions. \n\nThe `id` column is an internal attribute ID, while the `attribute_key_id` column is an internal attribute key ID. The `value` column contains the attribute value, and the `token_count` column indicates the number of tokens that have the attribute. The `on_sale_count` column indicates the number of tokens that have the attribute and are currently on sale. \n\nThe `floor_sell_value` column contains the current floor ask price, while the `sell_updated_at` column indicates the timestamp of the last update to the floor sale. The `collection_id` column contains the associated collection ID, and the `kind` column indicates the value type (string, number, date, range). The `key` column contains the associated key name. \n\nFinally, the `created_at` and `updated_at` columns indicate the timestamps of when the attribute was created and last updated, respectively. \n\nThis section also provides two query examples for the `reservoir.attributes` table, which can be found at the provided links. These examples can be used as a reference for querying the table in the app.",
              "questions": "1. What is the purpose of the `reservoir.attributes` table in the context of the Dune Docs project? \n   - The `reservoir.attributes` table contains records with information about each attribute in the Dune Docs project.\n2. How is the `token_count` column calculated and what does it represent? \n   - The `token_count` column represents the amount of tokens that have the attribute, but it is unclear how it is calculated based on the information provided in the technical guide.\n3. Are there any limitations or constraints on the data types that can be stored in the `value` column? \n   - The technical guide does not provide information on any limitations or constraints on the data types that can be stored in the `value` column."
            },
            {
              "fileName": "bid-events.md",
              "filePath": "docs/data-tables/community/reservoir/bid-events.md",
              "url": "https://dune.com/docs/data-tables/community/reservoir/bid-events.md",
              "summary": "# Bid Events\n\nThe `bid_events` table is a part of the Dune Docs project and contains records with information about each bid change. This table is located in the `data-tables` folder of the project.\n\nThe table has several columns that provide information about the bid event, including the event ID, event type, event status, contract address, token set ID, associated bid ID, bid maker wallet address, bid price, bid value, bid tokens remaining, bid validity start and expiration, source of the order, associated transaction hash, and timestamp the event was recorded.\n\nThe purpose of this table is to provide a record of all bid changes that occur within the system. This information can be used to track the progress of bids, monitor the performance of the system, and identify any issues that may arise.\n\nQuery examples for this table are not yet available, but they will be added to the project in the future.\n\nOverall, the `bid_events` table is an important component of the Dune Docs project, providing valuable information about the bidding process within the system.",
              "questions": "1. What is the purpose of the `reservoir.bid_events` table in the context of the Dune Docs project?\n- The `reservoir.bid_events` table contains records with information about each bid change in the project.\n\n2. What are the different types of events that can be found in the `kind` column of the `reservoir.bid_events` table?\n- The different types of events that can be found in the `kind` column of the `reservoir.bid_events` table include new-order, expiry, sale, cancel, balance-change, approval-change, bootstrap, revalidation, and reprice.\n\n3. How is the value of a bid represented in the `reservoir.bid_events` table?\n- The value of a bid is represented in the `reservoir.bid_events` table as the associated bid value in native currency."
            },
            {
              "fileName": "bids.md",
              "filePath": "docs/data-tables/community/reservoir/bids.md",
              "url": "https://dune.com/docs/data-tables/community/reservoir/bids.md",
              "summary": "# Bids\n\n## Reservoir.bids\n\nThis section of the app technical guide covers the `reservoir.bids` table, which contains records with information about each bid. The table includes various columns such as `id`, `kind`, `status`, `contract`, `token_set_id`, `maker`, `taker`, `price`, `value`, `currency_address`, `currency_symbol`, `currency_price`, `quantity`, `quantity_filled`, `quantity_remaining`, `valid_from`, `valid_until`, `nonce`, `source`, `fee_bps`, `expiration`, `raw_data`, `created_at`, and `updated_at`.\n\nThe `id` column represents the internal order id, while the `kind` column represents the protocol name (e.g. seaport). The `status` column represents the order status (active, inactive), and the `contract` column represents the contract address. The `token_set_id` column represents the id of the token set, while the `maker` and `taker` columns represent the maker and taker wallet addresses, respectively.\n\nThe `price` column represents the current price in native currency, while the `value` column represents the current value in native currency. The `currency_address` column represents the currency address, and the `currency_symbol` column represents the currency symbol. The `currency_price` column represents the currency price.\n\nThe `quantity` column represents the amount of tokens that is listed, while the `quantity_filled` column represents the amount of tokens that was filled. The `quantity_remaining` column represents the amount of tokens remaining, and the `valid_from` and `valid_until` columns represent the listing start and end times, respectively.\n\nThe `nonce` column represents the order nonce of the maker, while the `source` column represents the source of the listing (e.g. opensea.io). The `fee_bps` column represents the listing fee, and the `expiration` column represents the associated transaction hash. The `raw_data` column represents the raw order data (format will vary per source).\n\nFinally, the `created_at` and `updated_at` columns represent the timestamps the listing was created and updated, respectively.\n\nQuery examples for this table can be found at the link provided in the guide.",
              "questions": "1. What is the purpose of the dune docs project and how does this table fit into it?\n- This app technical guide only provides information about the `reservoir.bids` table and does not give context about the overall purpose of the dune docs project.\n\n2. How is the data in this table being collected and updated?\n- The app technical guide does not provide information about the data collection and update process for this table.\n\n3. Are there any constraints or limitations on the data types or values that can be stored in this table?\n- The app technical guide does not mention any constraints or limitations on the data types or values that can be stored in this table."
            },
            {
              "fileName": "collection-floor-ask-events.md",
              "filePath": "docs/data-tables/community/reservoir/collection-floor-ask-events.md",
              "url": "https://dune.com/docs/data-tables/community/reservoir/collection-floor-ask-events.md",
              "summary": "# Collection Floor Ask Events\n\nThis section of the app technical guide covers the `reservoir.collection_floor_ask_events` table, which contains records with information about each collection floor ask change. The table includes columns such as `id`, `kind`, `collection_id`, `contract`, `token_id`, `order_id`, `maker`, `price`, `previous_price`, `valid_until`, `source`, `tx_hash`, `tx_timestamp`, and `created_at`.\n\nThe `id` column is an internal event ID, while the `kind` column specifies the type of event (e.g. new-order, expiry, sale, cancel, balance-change, approval-change, bootstrap, revalidation, reprice). The `collection_id` column contains the ID of the collection, and the `contract` column contains the contract address. The `token_id` column specifies the ID of the token in the collection, and the `order_id` column contains the associated ask ID. The `maker` column contains the wallet address of the associated ask maker, and the `price` column contains the associated ask price in native currency. The `previous_price` column contains the previous floor ask price in native currency, and the `valid_until` column specifies the expiration of the associated ask. The `source` column contains the source of the order (e.g. opensea.io), while the `tx_hash` column contains the associated transaction hash. The `tx_timestamp` column specifies the timestamp of the associated transaction, and the `created_at` column contains the timestamp the event was recorded.\n\nThis section also includes query examples for the `reservoir.collection_floor_ask_events` table, which can be found at the following links:\n\n- [https://dune.com/queries/1302799/2232083](https://dune.com/queries/1302799/2232083)\n- [https://dune.com/queries/1302841/2232151](https://dune.com/queries/1302841/2232151)\n\nOverall, this section of the app technical guide provides a detailed overview of the `reservoir.collection_floor_ask_events` table and its columns, as well as query examples for working with the table.",
              "questions": "1. What is the purpose of the `reservoir.collection_floor_ask_events` table in the context of the Dune Docs project? \n   - The `reservoir.collection_floor_ask_events` table contains records with information about each collection floor ask change.\n2. What kind of events are included in the `kind` column of the table? \n   - The `kind` column includes event types such as new-order, expiry, sale, cancel, balance-change, approval-change, bootstrap, revalidation, and reprice.\n3. Are there any limitations or restrictions on the data that can be queried from this table? \n   - The app technical guide does not provide information on any limitations or restrictions on the data that can be queried from this table."
            },
            {
              "fileName": "collection-top-bid-events.md",
              "filePath": "docs/data-tables/community/reservoir/collection-top-bid-events.md",
              "url": "https://dune.com/docs/data-tables/community/reservoir/collection-top-bid-events.md",
              "summary": "# Collection Top Bid Events\n\nThe `collection_top_bid_events` table is a part of the Dune Docs project and contains records with information about each collection top bid change. This table is located in the `data-tables` folder of the project.\n\nThe table has several columns, including `id`, `kind`, `collection_id`, `contract`, `token_id`, `order_id`, `maker`, `price`, `previous_price`, `valid_until`, `source`, `tx_hash`, `tx_timestamp`, and `created_at`. Each column has a specific data type and description.\n\nThe `id` column is an internal event ID, while the `kind` column specifies the type of event, such as `new-order`, `expiry`, `sale`, `cancel`, `balance-change`, `approval-change`, `bootstrap`, `revalidation`, or `reprice`. The `collection_id` column contains the ID of the collection, and the `contract` column contains the contract address. The `token_id` column contains the ID of the token in the collection, and the `order_id` column contains the associated bid ID. The `maker` column contains the associated bid maker wallet address, and the `price` column contains the associated bid price in native currency.\n\nThe `previous_price` column contains the previous top bid price in native currency, and the `valid_until` column contains the associated bid validity expiration. The `source` column specifies the source of the order, such as `opensea.io`, and the `tx_hash` column contains the associated transaction hash. The `tx_timestamp` column contains the associated transaction timestamp, and the `created_at` column contains the timestamp the event was recorded.\n\nThe `collection_top_bid_events` table can be queried using SQL. Query examples can be found in the project, but the link is currently TBD. This table is useful for tracking changes in top bids for collections and analyzing bidding behavior.",
              "questions": "1. What is the purpose of the `reservoir.collection_top_bid_events` table in the context of the dune docs project?\n- The `reservoir.collection_top_bid_events` table contains records with information about each collection top bid change in the dune docs project.\n\n2. What are the different event types that can be found in the `kind` column of the `reservoir.collection_top_bid_events` table?\n- The `kind` column in the `reservoir.collection_top_bid_events` table contains different event types such as new-order, expiry, sale, cancel, balance-change, approval-change, bootstrap, revalidation, and reprice.\n\n3. How are the bid prices represented in the `price` and `previous_price` columns of the `reservoir.collection_top_bid_events` table?\n- The `price` and `previous_price` columns in the `reservoir.collection_top_bid_events` table represent the associated bid price and previous top bid price in native currency, respectively."
            },
            {
              "fileName": "collections.md",
              "filePath": "docs/data-tables/community/reservoir/collections.md",
              "url": "https://dune.com/docs/data-tables/community/reservoir/collections.md",
              "summary": "# Collections\n\nThis section of the app technical guide focuses on the `reservoir.collections` table, which contains records with information about each NFT collection. The table includes various columns such as `id`, `slug`, `name`, `description`, `token_count`, `contract`, `day1_rank`, `day7_rank`, `day30_rank`, `all_time_rank`, `day1_volume`, `day7_volume`, `day30_volume`, `all_time_volume`, `day1_volume_change`, `day7_volume_change`, `day30_volume_change`, `floor_ask_value`, `day1_floor_sale_value`, `day7_floor_sale_value`, `day30_floor_sale_value`, `day1_floor_sale_change`, `day7_floor_sale_change`, `day30_floor_sale_change`, `created_at`, and `updated_at`.\n\nThe purpose of this guide is to provide developers with information on how to query the `reservoir.collections` table and understand the meaning of each column. The guide includes two query examples that can be found at the provided links. \n\nDevelopers can use this information to build features that utilize NFT collections, such as displaying information about a specific collection or analyzing trends in NFT trading volume and floor sale prices. For example, a developer could use the `day1_volume` column to display the trading volume of a specific collection over the past day, or use the `floor_ask_value` column to display the current floor sale price of a collection in its native currency.\n\nOverall, this section of the app technical guide provides valuable information for developers looking to work with NFT collections in the Dune Docs project.",
              "questions": "1. What is the purpose of the `reservoir.collections` table in the Dune Docs app?\n- The `reservoir.collections` table contains records with information about each NFT collection.\n\n2. What type of data is stored in the `day1_rank`, `day7_rank`, `day30_rank`, and `all_time_rank` columns?\n- The `day1_rank`, `day7_rank`, `day30_rank`, and `all_time_rank` columns store ranking information for the NFT collections.\n\n3. What is the format of the query examples provided in the app technical guide?\n- The query examples provided in the app technical guide are in the form of links to Dune.com queries."
            },
            {
              "fileName": "index.md",
              "filePath": "docs/data-tables/community/reservoir/index.md",
              "url": "https://dune.com/docs/data-tables/community/reservoir/index.md",
              "summary": "# Reservoir\n\nThe Reservoir section of the Dune Docs project focuses on enabling the next generation of NFT products and liquidity sources through open-source, on-chain NFT order aggregation. This header provides links to the Reservoir dashboard, documentation, and Discord channel for further information and support.\n\n## Dashboard\n\nThe Reservoir dashboard link provided in this section directs users to the Reservoir0x dashboard on Dune.com. This dashboard provides a visual representation of Reservoir's on-chain NFT order aggregation, allowing users to view and analyze data related to NFT trades and liquidity sources.\n\n## Docs\n\nThe Reservoir documentation link provided in this section directs users to the Reservoir.tools documentation page. This page provides detailed information on how to use Reservoir's open-source, on-chain NFT order aggregation platform. The documentation covers topics such as installation, configuration, and usage of the Reservoir platform.\n\n## Discord\n\nThe Reservoir Discord link provided in this section directs users to the Reservoir Discord channel. This channel provides a community forum for Reservoir users to ask questions, share information, and collaborate on the development of the Reservoir platform.\n\nOverall, the Reservoir section of the Dune Docs project provides users with the resources they need to understand and utilize Reservoir's on-chain NFT order aggregation platform. The dashboard, documentation, and Discord channel all work together to provide a comprehensive support system for Reservoir users.",
              "questions": "1. What is the purpose of Reservoir in the blockchain ecosystem?\n- Reservoir is enabling the next generation of NFT products and liquidity sources through open-source, on-chain NFT order aggregation.\n\n2. What kind of data can be accessed through the Reservoir dashboard?\n- The Reservoir dashboard provides access to data related to the Reservoir project, such as order aggregation.\n\n3. Are there any additional resources available for developers looking to integrate Reservoir into their projects?\n- Yes, the Reservoir documentation provides additional resources for developers looking to integrate Reservoir into their projects."
            },
            {
              "fileName": "sales.md",
              "filePath": "docs/data-tables/community/reservoir/sales.md",
              "url": "https://dune.com/docs/data-tables/community/reservoir/sales.md",
              "summary": "# Sales\n\nThis section of the app technical guide covers the `reservoir.sales` table, which contains records with information about each sale. The table includes various columns such as `id`, `contract`, `token_id`, `order_id`, `order_kind`, `order_side`, `order_source`, `from`, `to`, `price`, `usd_price`, `currency_address`, `currency_symbol`, `currency_price`, `amount`, `fill_source`, `aggregator_source`, `wash_trading_score`, `is_primary`, `tx_hash`, `tx_log_index`, `tx_batch_index`, `tx_timestamp`, `created_at`, and `updated_at`.\n\nThe purpose of this guide is to provide an overview of the `reservoir.sales` table and its columns, as well as query examples that can be used to retrieve data from the table. The guide also includes a description of each column, its data type, and its purpose.\n\nFor example, the `id` column contains the internal sale id, while the `contract` column contains the contract address. The `price` column contains the sale price in the native currency, while the `usd_price` column contains the sale price in USD. The `amount` column contains the amount of tokens sold, while the `is_primary` column indicates whether the sale is a paid mint.\n\nThe guide also includes query examples that can be used to retrieve data from the `reservoir.sales` table. These examples demonstrate how to use the `SELECT` statement to retrieve specific columns from the table, as well as how to use the `WHERE` clause to filter the results based on specific criteria.\n\nOverall, this section of the app technical guide provides a comprehensive overview of the `reservoir.sales` table and its columns, as well as query examples that can be used to retrieve data from the table.",
              "questions": "1. What is the purpose of the `reservoir.sales` table in the context of blockchain? \n- The `reservoir.sales` table contains records with information about each sale in the blockchain context.\n\n2. What is the significance of the `currency_address` and `currency_symbol` columns in the `reservoir.sales` table? \n- The `currency_address` and `currency_symbol` columns in the `reservoir.sales` table indicate the currency used for a particular sale in the blockchain context.\n\n3. How is the `wash_trading_score` column calculated in the `reservoir.sales` table? \n- The `wash_trading_score` column in the `reservoir.sales` table is calculated based on past sales and indicates the internal wash trading score in the blockchain context."
            },
            {
              "fileName": "token-attributes.md",
              "filePath": "docs/data-tables/community/reservoir/token-attributes.md",
              "url": "https://dune.com/docs/data-tables/community/reservoir/token-attributes.md",
              "summary": "# Explanation of the App Technical Guide for Dune Docs\n\nThe app technical guide for Dune Docs is a documentation resource that provides information on the different features and functionalities of the Dune Docs project. The guide is organized into different sections, each of which covers a specific aspect of the project. \n\nThe first section of the guide is focused on token attributes. The `reservoir.token_attributes` table contains records with information about each NFT token attribute. The table includes columns such as `id`, `contract`, `token_id`, `attribute_id`, `collection_id`, `key`, `value`, `created_at`, and `updated_at`. These columns provide information about the internal token attribute ID, contract address, token ID, attribute ID, collection ID, attribute name, attribute value, and timestamps for when the attribute was created and updated. \n\nThe guide also includes query examples for the `reservoir.token_attributes` table, which can be found at the provided URL. These examples demonstrate how to query the table to retrieve specific information about token attributes. \n\nOverall, the app technical guide for Dune Docs is a valuable resource for developers and users who want to learn more about the different features and functionalities of the project. The guide provides detailed information on each aspect of the project, including tables, queries, and other important components. By using this guide, developers and users can gain a better understanding of how the project works and how to use it effectively.",
              "questions": "1. What is the purpose of the `reservoir.token_attributes` table in the context of a blockchain application? \n- The `reservoir.token_attributes` table contains information about each NFT token attribute, which may be relevant for tracking ownership or other metadata associated with the tokens.\n\n2. How are the `contract` and `collection_id` fields used in this table? \n- The `contract` field contains the address of the contract associated with the token, while the `collection_id` field contains the internal ID of the collection to which the token belongs. These fields may be used to link token attributes to specific contracts or collections.\n\n3. Are there any limitations or constraints on the types of data that can be stored in the `value` field? \n- The app technical guide does not provide information on any limitations or constraints on the types of data that can be stored in the `value` field. A blockchain SQL analyst may need to consult additional documentation or perform testing to determine any such limitations."
            },
            {
              "fileName": "token-floor-ask-events.md",
              "filePath": "docs/data-tables/community/reservoir/token-floor-ask-events.md",
              "url": "https://dune.com/docs/data-tables/community/reservoir/token-floor-ask-events.md",
              "summary": "# Token Floor Ask Events\n\nThis section of the app technical guide covers the `reservoir.token_floor_ask_events` table, which contains records with information about each NFT token floor ask change. The table includes various columns such as `id`, `kind`, `contract`, `token_id`, `order_id`, `maker`, `price`, `previous_price`, `nonce`, `valid_from`, `valid_until`, `source`, `tx_hash`, `tx_timestamp`, and `created_at`.\n\nThe `kind` column specifies the type of event, which can be one of the following: `new-order`, `expiry`, `sale`, `cancel`, `balance-change`, `approval-change`, `bootstrap`, `revalidation`, or `reprice`. The `contract` column specifies the address of the contract associated with the event, while the `token_id` column specifies the ID of the token in the collection. The `order_id` column specifies the associated ask ID, and the `maker` column specifies the wallet address of the ask maker.\n\nThe `price` column specifies the associated ask price in native currency, while the `previous_price` column specifies the previous ask price in native currency. The `nonce` column specifies the order nonce of the maker, and the `valid_from` and `valid_until` columns specify the validity start and expiration of the ask. The `source` column specifies the source of the order, such as `opensea.io`. The `tx_hash` column specifies the associated transaction hash, and the `tx_timestamp` column specifies the associated transaction timestamp. Finally, the `created_at` column specifies the timestamp the event was recorded.\n\nThis section also includes two query examples that can be found at the specified URLs. These queries can be used to retrieve information from the `reservoir.token_floor_ask_events` table.",
              "questions": "1. What is the purpose of this table in the context of the dune docs project?\n- As a technical guide documentation expert, it is not clear from this table alone what the overall purpose of the dune docs project is, so a blockchain SQL analyst might have this question.\n\n2. What is the meaning of the \"kind\" column and what are the possible values?\n- The \"kind\" column is described as an event type, but it is not clear what each possible value represents, so a blockchain SQL analyst might have this question.\n\n3. Are there any other tables or data sources that are related to this one and can be used to gain a more complete understanding of NFT token floor asks?\n- This table provides information about NFT token floor ask changes, but it is possible that there are other tables or data sources that are related to this one and can provide additional context or insights, so a blockchain SQL analyst might have this question."
            },
            {
              "fileName": "tokens.md",
              "filePath": "docs/data-tables/community/reservoir/tokens.md",
              "url": "https://dune.com/docs/data-tables/community/reservoir/tokens.md",
              "summary": "# App Technical Guide: Tokens\n\n## Reservoir.tokens\n\nThis section of the app technical guide covers the `reservoir.tokens` table, which contains records with information about each NFT token. The table includes various columns such as `id`, `contract`, `token_id`, `name`, `description`, `collection_id`, `owner`, `floor_ask_id`, `floor_ask_value`, `floor_ask_maker`, `floor_ask_valid_from`, `floor_ask_valid_to`, `floor_ask_source`, `last_sale_value`, `last_sale_timestamp`, `created_at`, and `updated_at`.\n\nThe `id` column represents the internal token ID, while the `contract` column contains the contract address. The `token_id` column represents the ID of the token in the collection, and the `name` and `description` columns contain the name and description of the NFT, respectively. The `collection_id` column represents the associated collection ID, and the `owner` column contains the wallet address of the owner.\n\nThe `floor_ask_id`, `floor_ask_value`, `floor_ask_maker`, `floor_ask_valid_from`, `floor_ask_valid_to`, and `floor_ask_source` columns represent the floor ask details, such as the ID, value, maker wallet address, listing start and end times, and source (e.g. opensea.io). The `last_sale_value` and `last_sale_timestamp` columns represent the associated transaction timestamp.\n\nFinally, the `created_at` and `updated_at` columns represent the timestamps when the token was created and updated, respectively.\n\nThis section also includes query examples that can be found at the specified URLs. These examples can be used to retrieve information from the `reservoir.tokens` table.\n\nOverall, this section of the app technical guide provides a detailed overview of the `reservoir.tokens` table and its various columns, as well as query examples that can be used to retrieve information from the table.",
              "questions": "1. What is the purpose of the `reservoir.tokens` table in the context of blockchain? \n- The `reservoir.tokens` table contains records with information about each NFT token, which can be useful for tracking ownership and transaction history.\n\n2. Are there any limitations or restrictions on the types of queries that can be run on this table? \n- The app technical guide does not provide information on any limitations or restrictions on queries that can be run on this table. \n\n3. How frequently is the `reservoir.tokens` table updated with new token information? \n- The app technical guide does not provide information on the frequency of updates to the `reservoir.tokens` table."
            }
          ],
          "folders": [],
          "summary": "The `docs/data-tables/community/reservoir` folder contains a comprehensive app technical guide for the Reservoir project, which focuses on enabling the next generation of NFT products and liquidity sources through open-source, on-chain NFT order aggregation. The guide is organized into different sections, each covering a specific aspect of the project, such as token attributes, sales, collections, and various events related to bids and asks.\n\nFor example, the `asks.md` section provides an in-depth overview of the `reservoir.asks` table, which contains records with information about each listing. Developers can use this information to build applications that interact with the `reservoir.asks` table, such as a marketplace or trading platform. The guide also includes query examples that can be used to retrieve data from the table.\n\nAnother example is the `attributes.md` section, which covers the `reservoir.attributes` table containing records with information about each attribute. This section provides a detailed description of the columns in this table and includes query examples that can be used as a reference for querying the table in the app.\n\nThe `tokens.md` section covers the `reservoir.tokens` table, which contains records with information about each NFT token. This section provides a detailed overview of the table and its various columns, as well as query examples that can be used to retrieve information from the table.\n\nOverall, this app technical guide serves as a valuable resource for developers and users who want to learn more about the different features and functionalities of the Reservoir project. The guide provides detailed information on each aspect of the project, including tables, queries, and other important components. By using this guide, developers and users can gain a better understanding of how the project works and how to use it effectively.",
          "questions": ""
        }
      ],
      "summary": "The `docs/data-tables/community` folder contains a comprehensive app technical guide for the Community section of the Dune Docs project. This section focuses on providing additional data insights through partnerships with third-party data providers, such as Flashbots and Reservoir. The guide is organized into different sections, each covering a specific aspect of the project, such as availability, purpose, and data providers.\n\nFor example, the `index.md` file provides an overview of the Community section, its availability on the V2 Engine, and its purpose in providing off-chain data or augmented on-chain data. This guide helps users understand the importance of the Community section and how it can provide additional insights through partnerships with selected organizations.\n\nThe guide also covers two data providers currently featured in the Community section: Flashbots and Reservoir. Each provider has its own subfolder with more detailed information about the data they provide. For instance, the `flashbots` subfolder contains various files that cover different aspects of the Flashbots project, such as arbitrages, liquidations, mev_summary, sandwiched swaps, and sandwiches. These guides provide clear and concise explanations of the table structures, column descriptions, and query examples that can be used to retrieve information from the tables.\n\nSimilarly, the `reservoir` subfolder contains a comprehensive app technical guide for the Reservoir project, which focuses on enabling the next generation of NFT products and liquidity sources through open-source, on-chain NFT order aggregation. The guide is organized into different sections, each covering a specific aspect of the project, such as token attributes, sales, collections, and various events related to bids and asks.\n\nOverall, the Community section of the Dune Docs project serves as a valuable resource for developers and users who want to access additional data insights through partnerships with third-party data providers. The guides provided in this folder offer clear and concise explanations of the table structures, column descriptions, and query examples that can be used to retrieve information from the tables. By using this guide, developers and users can gain a better understanding of how the Community section works and how to use it effectively in their work.",
      "questions": ""
    },
    {
      "folderName": "decoded",
      "folderPath": "docs/data-tables/decoded",
      "url": "https://dune.com/docs/data-tables/decoded",
      "files": [
        {
          "fileName": "call-tables.md",
          "filePath": "docs/data-tables/decoded/call-tables.md",
          "url": "https://dune.com/docs/data-tables/decoded/call-tables.md",
          "summary": "# Call Tables\n\nThis technical guide explains how Dune parses all message calls and transactions made to smart contracts in their own tables. The guide provides information on how the tables are named and how they are created on an individual contract level or a class of contracts. \n\nThe guide also explains how Dune records transactions in the table when a smart contract is called by an externally owned account (EOA) or another smart contract. The guide provides an example of how Dune records a transaction when a Uniswap v3 pool gets created via the Uniswap v3 factory function `createPool`. \n\nThe guide also explains how Dune decodes all calls to all instances of a smart contract into one table when multiple instances of a contract exist. The guide provides an example of how Dune collects data in the table when there is a transaction calling the `swap` function of any instance of a Uniswap v3 pair contract. \n\nThe guide also highlights a common misconception that web3.js, web3.py, and all other methods of locally calling a `pure`, `read`, or `constant` function do not broadcast or publish anything on the blockchain and are therefore not recorded in Dune. However, if one of these functions is invoked by another smart contract in the context of a transaction, this will be broadcast on the chain and therefore accessible in Dune. \n\nThe guide concludes by providing further reading materials on the difference between a transaction and a call, Soliditylang.org documentation, and how Calldata is encoded. \n\nOverall, this technical guide provides a comprehensive understanding of how Dune parses all message calls and transactions made to smart contracts in their own tables. It is a useful resource for developers who want to understand how Dune records transactions and how to access the data recorded in Dune.",
          "questions": "1. What specific blockchain networks does Dune Docs support for parsing message calls and transactions? \n- The app technical guide does not provide information on the specific blockchain networks supported by Dune Docs for parsing message calls and transactions.\n\n2. Can Dune Docs record message calls made by smart contracts to external systems or APIs? \n- The app technical guide does not provide information on whether Dune Docs can record message calls made by smart contracts to external systems or APIs.\n\n3. How does Dune Docs handle state data stored in the memory of a smart contract? \n- The app technical guide states that state data stored in the memory of a smart contract is not available on Dune, but it does not provide information on how Dune Docs handles this type of data."
        },
        {
          "fileName": "event-logs.md",
          "filePath": "docs/data-tables/decoded/event-logs.md",
          "url": "https://dune.com/docs/data-tables/decoded/event-logs.md",
          "summary": "# Event Logs\n\nThis technical guide covers the concept of event logs in smart contracts. Smart contracts emit event logs when certain predefined actions are completed. The structure published in these logs is predefined by the developer of the smart contract, and the content is dynamically created during the transaction. \n\nThe guide explains that logs are useful for monitoring, alerting, and keeping track of what happens inside a smart contract. Logs are also useful for data analysis since they reliably present data that is intended to be analyzed post factum. The guide provides an example of how to search for the keyword `emit` in the source code of a smart contract to see which logs can be emitted by a smart contract.\n\nThe guide also explains how event logs for smart contracts are decoded into tables named accordingly to a specific schema. The schema is different for the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL). The guide provides examples of how to name tables for each engine.\n\nThe guide provides an example of how to look at the event logs of a transaction in Etherscan. The example is in the context of the uniswap v3 factory, and the event that gets emitted upon the creation of a new pool. The event is called `PoolCreated`, and it gives information like the tokens in the pool, the fee tier of this pool, and the tick spacing. The guide provides examples of how to name tables for each engine.\n\nThe guide explains that if there are multiple instances of a contract, all event logs across all instances of this smart contract are collected in one table. The guide provides an example of how all uniswap v3 pool `swap` events (on ethereum) are stored in a table.\n\nFinally, the guide provides further reading resources on understanding event logs on the Ethereum blockchain and everything you ever wanted to know about events and logs on Ethereum. \n\nOverall, this guide provides a comprehensive explanation of event logs in smart contracts and how they are decoded into tables. It also provides examples of how to name tables for each engine and how to look at event logs of a transaction in Etherscan.",
          "questions": "1. What is the purpose of the Dune Docs app and how does it relate to blockchain SQL analysis?\n   \n   The Dune Docs app provides technical documentation for decoding event logs emitted by smart contracts on the blockchain. This information is useful for blockchain SQL analysts who want to monitor, alert, and keep track of what happens inside a smart contract.\n\n2. How are event logs stored in Dune Docs and what is the naming convention for the tables?\n\n   Event logs for smart contracts are decoded into tables named according to the schema `[projectname_blockchain].[contractName]_evt_[eventName]` for the V2 Engine (Spark SQL) and `[projectname].\"[contractName]_evt_[eventName]\"` for the V1 Engine (PostgreSQL). For example, the event log for the Uniswap V3 pool creation event is stored in the table `uniswap_v3_ethereum.Factory_evt_PoolCreated` for the V2 Engine and `uniswap_v3.\"Factory_evt_PoolCreated\"` for the V1 Engine.\n\n3. How are event logs from multiple instances of a contract handled in Dune Docs?\n\n   Event logs from multiple instances of a contract are collected in one table. For example, all Uniswap V3 pool swap events on Ethereum are stored in the table `uniswap_v3_ethereum.Pair_evt_Swap` for the V2 Engine and `uniswap_v3.\"Pair_evt_Swap\"` for the V1 Engine. The `contract_address` column indicates which smart contract emitted the event."
        },
        {
          "fileName": "index.md",
          "filePath": "docs/data-tables/decoded/index.md",
          "url": "https://dune.com/docs/data-tables/decoded/index.md",
          "summary": "The Decoded Tables guide covers the process of decoding smart contract activity into human-readable tables on the Dune platform. It explains how Dune uses the ABI (Application Binary Interface) for smart contracts and the interface standard for standardized token smart contracts (ERC20, ERC721, etc.) to create tables for each event and function defined in the smart contract's ABI. \n\nThe guide provides examples of how to access decoded data for specific events and function calls using the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL). It also explains how to check if contracts are already decoded by querying the `[blockchain].contracts` tables or using a dashboard.\n\nThe guide further explains how decoding works, using the ABI to call a smart contract or interpret the data it emits. It provides an example of decoding an ERC20 transfer event log and how to understand decoded data.\n\nThe guide also discusses which tables to use (events or calls) and provides queries to explore decoded contracts, such as seeing all projects with decoded data or checking for multiple instances of a contract.",
          "questions": "1. **How can I check if a specific contract has already been decoded in the Dune database?**\n\nYou can check if a contract has been decoded by querying the `[blockchain].contracts` tables through the database or by using the provided dashboard links for V2 Engine (Spark SQL) and V1 Engine (PostgreSQL) in the app technical guide.\n\n2. **How long does it take to decode a smart contract once it has been submitted?**\n\nIt usually takes about 24 hours to initially decode a smart contract. You can check the status of your contract's decoding process using the \"Is my Contract decoded yet?\" dashboard link provided in the app technical guide.\n\n3. **How can I submit multiple contracts for decoding at the same time?**\n\nTo submit a batch of contracts for decoding, use the provided CSV template in the app technical guide and fill it in with the appropriate information for the contracts you want to decode. Then, send the completed CSV file to decoding@dune.com."
        }
      ],
      "folders": [],
      "summary": "The Decoded Tables guide in the `docs/data-tables/decoded` folder focuses on decoding smart contract activity into human-readable tables on the Dune platform. This guide is essential for analysts and developers who want to understand and access the decoded data of smart contracts, events, and function calls on the Dune platform.\n\nThe guide covers the following topics:\n\n1. **Call Tables**: This section explains how Dune parses all message calls and transactions made to smart contracts in their own tables. It provides information on how the tables are named and how they are created on an individual contract level or a class of contracts. It also highlights a common misconception about `pure`, `read`, or `constant` functions not being recorded in Dune.\n\n2. **Event Logs**: This section covers the concept of event logs in smart contracts and how they are decoded into tables named according to a specific schema. It provides examples of how to name tables for the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL) and how to look at event logs of a transaction in Etherscan.\n\n3. **Decoding Process**: This section explains how Dune uses the ABI (Application Binary Interface) for smart contracts and the interface standard for standardized token smart contracts (ERC20, ERC721, etc.) to create tables for each event and function defined in the smart contract's ABI. It provides an example of decoding an ERC20 transfer event log and how to understand decoded data.\n\n4. **Accessing Decoded Data**: This section provides examples of how to access decoded data for specific events and function calls using the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL). It also explains how to check if contracts are already decoded by querying the `[blockchain].contracts` tables or using a dashboard.\n\n5. **Which Tables to Use**: This section discusses which tables to use (events or calls) and provides queries to explore decoded contracts, such as seeing all projects with decoded data or checking for multiple instances of a contract.\n\nThis guide is useful for analysts who want to access and analyze decoded data from smart contracts, events, and function calls on the Dune platform. For example, an analyst might use this guide to understand how to access decoded data for a specific ERC20 token transfer event or how to explore all projects with decoded data on the platform. By understanding the decoding process and how to access the decoded data, analysts can gain valuable insights into smart contract activity and interactions on the Dune platform.",
      "questions": ""
    },
    {
      "folderName": "raw",
      "folderPath": "docs/data-tables/raw",
      "url": "https://dune.com/docs/data-tables/raw",
      "files": [
        {
          "fileName": "blocks.md",
          "filePath": "docs/data-tables/raw/blocks.md",
          "url": "https://dune.com/docs/data-tables/raw/blocks.md",
          "summary": "# Blocks\n\nThis section of the app technical guide covers the concept of blocks in blockchains and rollups. A block is a collection of transactions that incrementally alter the state of an EVM system. Transactions within a block can only be executed one after the other, not in parallel. The purpose of this section is to provide an understanding of how blocks work in the context of the Dune Docs project.\n\n## Tables\n\nThis section provides tables that are useful for identifying block activity and transaction changes over time. There are two tables provided, one for the V2 Engine (Spark SQL) and one for the V1 Engine (PostgreSQL). Each table contains information about the chains, tables, and notes for each chain. For example, the Ethereum Mainnet chain has a table called `ethereum.blocks` that contains information about blocks on the Ethereum Mainnet.\n\n## Column Data\n\nThis section provides a description of the data contained in each column of the block tables. The table contains columns such as `time`, `number`, `hash`, `parent hash`, `gas limit`, `gas used`, `miner`, `difficulty`, `total difficulty`, `nonce`, `size`, and `base_fee_per_gas`. Each column is described in detail, including its data type and a brief description of its purpose.\n\n### Example\n\nThis section provides an example of the data contained in the block tables. The example is in the form of a video that demonstrates how to use the block tables to identify block activity and transaction changes over time.\n\nOverall, this app technical guide provides a comprehensive understanding of blocks in the context of the Dune Docs project. It covers the tables and column data that are useful for identifying block activity and transaction changes over time. The guide is useful for developers who are working on the Dune Docs project and need to understand how blocks work in the context of the project.",
          "questions": "1. What is the purpose of the Dune Docs app and how does it relate to blockchain SQL analysis?\n    \n    The app technical guide describes the tables and column data related to blocks in various blockchain chains. A blockchain SQL analyst might want to know how this information can be used in their analysis and what specific insights they can gain from it.\n\n2. Are there any limitations or gaps in the data provided by the Dune Docs app that might impact blockchain SQL analysis?\n\n    The tables provided in the app technical guide do not contain certain information such as `nonce`, `miner`, `difficulty`, `total_difficulty`, `size`, and `base_fee_per_gas` for some chains. A blockchain SQL analyst might want to know how these limitations might impact their analysis and if there are any workarounds.\n\n3. How does the Dune Docs app handle rollups and how can this information be used in blockchain SQL analysis?\n\n    The app technical guide mentions that blocks are the building blocks of rollups, but it does not provide specific information on how rollups are handled in the app. A blockchain SQL analyst might want to know how rollups are represented in the app and how this information can be used in their analysis."
        },
        {
          "fileName": "event-logs.md",
          "filePath": "docs/data-tables/raw/event-logs.md",
          "url": "https://dune.com/docs/data-tables/raw/event-logs.md",
          "summary": "# Event Logs\n\nThis guide covers the `Event Logs` tables that store all logs data generated by smart contracts. The logs are an elegant way to store tiny amounts of data on EVM blockchains for a small amount of gas. Specifically, event logs are useful to let other people know something has happened without them having to query contracts individually. The guide provides a list of tables for the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL) for different chains. \n\nThe `Tables` section of the guide provides a list of tables for the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL) for different chains. The tables are named after the chain they belong to and contain logs data generated by smart contracts. The tables are useful for querying contracts that are not yet decoded or are not able to be decoded since the code of the smart contract is not public. \n\nThe `Column Data` section of the guide provides a description of the columns in the `Event Logs` tables. The columns include `contract_address`, `topic1`, `topic2`, `topic3`, `topic4`, `data`, `tx_hash`, `block_hash`, `block_number`, `block_time`, `index`, and `tx_index`. The columns contain information such as the address of the contract that emitted the log, keccak256 hash of a flattened event declaration string, unindexed data containing further information on the event, the transaction hash of the transaction that produced this log, and the time when the block was mined that includes this log. \n\nFor more information on this topic, the guide provides a link to an article on understanding event logs on the Ethereum blockchain. \n\nExample:\n```\n|   Chain           |   Table             | Notes |\n| ----------------  | ------------------- | ----- |\n| Ethereum Mainnet  | `ethereum.logs`     |       |\n| Gnosis Chain      | `gnosis.logs`       |       |\n| Polygon           | `polygon.logs`      |       |\n| Optimism          | `optimism.logs`     |       |\n| Optimism (legacy) | `optimism_legacy_ovm1.logs` |       |\n| BNB Chain         | `bnb.logs`          |       |\n| Arbitrum          | `arbitrum.logs`     |       |\n| Avalanche C-Chain  | `avalanche_c.logs` |       |\n```\nThe above example shows the tables for the V2 Engine (Spark SQL) for different chains. \n\n```\n|   Chain              |   Table         | Notes |\n| -------------------  | --------------- | ----- |\n| Ethereum Mainnet     | `ethereum.logs` |       |\n| Gnosis Chain (xDai)  | `xdai.logs`     |       |\n| Polygon              | `polygon.logs`  |       |\n| Optimism (OVM 1 & 2) | `optimism.logs` |       |\n| BNB Chain (BSC)      | `bsc.logs`      |       |\n```\nThe above example shows the tables for the V1 Engine (PostgreSQL) for different chains. \n\n### Column Data\n\n|   Column name      |   Data type     |    Description   |\n| ------------------ | :------------: | -------------------------------------------------------------- |\n| `contract_address` | _bytea_        | The address of the contract that emitted the log               |\n| `topic1`           | _bytea_        | keccak256 hash of a flattened event declaration string         |\n| `topic2`           | _bytea_        | Second indexed `topic` of the event                            |\n| `topic3`           | _bytea_        | Third indexed `topic` of the event                             |\n| `topic4`           | _bytea_        | Fourth indexed `topic` of the event                            |\n| `data`             | _bytea_        | Unindexed data containing further information on the event     |\n| `tx_hash`          | _bytea_        | The transaction hash of the transaction that produced this log |\n| `block_hash`       | _bytea_        | A unique identifier for that block                             |\n| `block_number`     | _int8_         | The length of the blockchain in blocks                         |\n| `block_time`       | _timestamptz_  | The time when the block was mined that includes this log       |\n| `index`            | _numeric_      | This logs index position in the block (cumulative amount of logs ordered by execution) |\n| `tx_index`         | _numeric_      | The index position of the transaction in this block (cumulative amount of transactions ordered by execution) |\n\nThe above example shows the columns in the `Event Logs` tables.",
          "questions": "1. What is the purpose of the Event Logs tables in this app and how are they useful for blockchain analysis?\n   \n   The Event Logs tables store all logs data generated by smart contracts and can be useful for querying contracts that are not yet decoded or are not able to be decoded since the code of the smart contract is not public. They are also useful for letting other people know something has happened without them having to query contracts individually.\n\n2. What engines are used to store the data in the tables and what chains are supported by each engine?\n   \n   The V2 Engine (Spark SQL) is used to store data in the tables and supports Ethereum Mainnet, Gnosis Chain, Polygon, Optimism, Optimism (legacy), BNB Chain, and Avalanche C-Chain. The V1 Engine (PostgreSQL) is also used and supports Ethereum Mainnet, Gnosis Chain (xDai), Polygon, Optimism (OVM 1 & 2), and BNB Chain (BSC).\n\n3. What are the different column data types and what information do they contain?\n   \n   The different column data types include contract_address, topic1, topic2, topic3, topic4, data, tx_hash, block_hash, block_number, block_time, index, and tx_index. They contain information such as the address of the contract that emitted the log, keccak256 hash of a flattened event declaration string, unindexed data containing further information on the event, the transaction hash of the transaction that produced this log, and the time when the block was mined that includes this log."
        },
        {
          "fileName": "index.md",
          "filePath": "docs/data-tables/raw/index.md",
          "url": "https://dune.com/docs/data-tables/raw/index.md",
          "summary": "# Raw Tables\n\nThe Raw Tables section of the Dune Docs project provides users with raw, unfiltered, and unedited data. This allows users to query for any transaction, block, event log, or trace across the blockchains that Dune supports. Raw data tables are particularly useful for obtaining meta information about the blockchain, a transaction, traces, or certain events.\n\nHowever, queries that have been written using raw data tables are notoriously hard to understand and audit due to the nature of the encoded data commonly found in these tables. Furthermore, the raw data tables have a very large number of rows and hence can be slow to query. Most of the time, users are better off submitting contracts for decoding and working with decoded data.\n\n## EVM Raw Table Data\n\nEthereum Virtual Machine (EVM) powers all chains in Dune except Solana and Bitcoin, meaning they share the base structure for underlying data. The following are the different types of EVM raw table data available in the Dune Docs project:\n\n- **Blocks**: Blocks are the building blocks of blockchains and rollups.\n- **Event Logs**: Event Logs are data that gets generated by smart contracts.\n- **Traces**: Traces contain information about the execution of smaller atomic actions generated by transactions.\n- **Transactions**: Transactions are cryptographically signed instructions from accounts.\n\nOverall, the Raw Tables section of the Dune Docs project provides users with a comprehensive guide on how to work with raw data tables. It also highlights the limitations of using raw data tables and suggests alternative methods for working with blockchain data. The section on EVM Raw Table Data provides users with a detailed explanation of the different types of raw data tables available for Ethereum Virtual Machine (EVM) and how they can be used.",
          "questions": "1. What types of blockchain data can be queried using raw tables in Dune Docs?\n- Raw tables in Dune Docs allow for querying of any transaction, block, event log, or trace across the blockchains that Dune supports.\n\n2. What are some challenges associated with using raw data tables for queries?\n- Queries written using raw data tables can be difficult to understand and audit due to the encoded data commonly found in these tables. Additionally, raw data tables can have a large number of rows and be slow to query.\n\n3. Which blockchains in Dune Docs are powered by the Ethereum Virtual Machine (EVM)?\n- All chains in Dune Docs except for Solana and Bitcoin are powered by the Ethereum Virtual Machine (EVM)."
        },
        {
          "fileName": "traces.md",
          "filePath": "docs/data-tables/raw/traces.md",
          "url": "https://dune.com/docs/data-tables/raw/traces.md",
          "summary": "# Traces\n\nThe Traces tables contain information about the execution of smaller atomic actions generated by transactions. Transactions can trigger smaller atomic actions that modify the internal state of an Ethereum Virtual Machine. Information about the execution of these actions is logged and can be found stored as an EVM execution trace, or just a trace. In Etherscan, these are referred to as \"internal transactions\". The guide provides information on the tables and column data of the traces.\n\n## Tables\n\nThe tables are divided into two engines, V1 and V2. The V2 engine uses Spark SQL, while the V1 engine uses PostgreSQL. The tables are divided by chain and contain information such as the value measured in wei, gas, gas used, block hash, success, tx index, sub-traces, error, tx success, tx hash, from, to, trace address, type, address, code, call type, input, and output. \n\n## Column Data\n\nThe column data provides a detailed description of the data types and their descriptions. For instance, the `block_time` column is of type `timestamptz` and represents the time when the block was mined. The `value` column is of type `numeric` and represents the amount of `[chain_gas_token]` sent in this transaction. The `gas` column is of type `numeric` and represents the gas provided with the message call. The `gas_used` column is of type `numeric` and represents the gas consumed by the transaction in wei. The `success` column is of type `boolean` and represents a true/false value that shows if the trace action succeeded. \n\n## Gas used in `.traces`\n\nThe `gas_used` column in the `.traces` tables is a bit hard to understand. The `gas_used` of a trace will always include the gas consumed by the trace and all its subtraces. The `gas_used` of the initial call will not contain the cost of making the call in the first place. You need to add 21000 gas units + the cost of sending zero + non-zero bytes to the `gas_used` value of the top trace to arrive at the \"true\" `gas_used` value. \n\n## Creation Traces\n\nThe creation traces table contains information about the creation of a smart contract and the transfer of ether to it. The table is divided by chain and contains information such as block time, block number, tx hash, address, from, and code. \n\nThe guide provides examples of the tables and column data. For instance, the guide provides an example of the V2 engine (Spark SQL) table for Ethereum Mainnet. The guide also provides an example of the creation traces table for Ethereum Mainnet. \n\nOverall, the guide provides a detailed explanation of the Traces tables and column data. It also provides examples of the tables and column data.",
          "questions": "1. What is the purpose of the `traces` tables in the different chains listed in the guide?\n- The `traces` tables contain information about the execution of smaller atomic actions generated by transactions in different chains listed in the guide.\n\n2. What is the difference between the V1 and V2 engines in terms of the PostgreSQL database used?\n- The V1 engine uses PostgreSQL while the V2 engine uses Spark SQL.\n\n3. What is the `gas_used` column in the `.traces` tables and how is it calculated?\n- The `gas_used` column in the `.traces` tables includes the gas consumed by the trace and all its subtraces, but not the cost of making the call in the first place. To arrive at the \"true\" `gas_used` value, 21000 gas units plus the cost of sending zero and non-zero bytes should be added to the `gas_used` value of the top trace."
        },
        {
          "fileName": "transactions.md",
          "filePath": "docs/data-tables/raw/transactions.md",
          "url": "https://dune.com/docs/data-tables/raw/transactions.md",
          "summary": "# Transactions\n\nThis section of the app technical guide covers transactions in the Ethereum network. Transactions are cryptographically signed instructions from accounts that initiate a transaction to update the state of the Ethereum network. Transactions always originate from externally owned accounts, and a smart contract cannot initiate a transaction. Transactions need to be broadcast to the whole network, and any node can broadcast a request for a transaction to be executed on the EVM. After this happens, a miner will execute the transaction and propagate the resulting state change to the rest of the network. \n\nThe official Ethereum documentation provides more information on transactions [here](https://ethereum.org/en/developers/docs/transactions).\n\n## Tables\n\nThis section of the app technical guide provides a table of the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL) for different chains. The table lists the chain, table, and notes. \n\n### Example\n\nAn example of the table is shown below:\n\n|   Chain           |   Table               | Notes |\n| ----------------  | --------------------- | ----- |\n| Ethereum Mainnet  | `ethereum.transactions`     |  |\n| Gnosis Chain      | `gnosis.transactions`       |  |\n| Polygon           | `polygon.transactions`      |  |\n| Optimism          | `optimism.transactions`     | No EIP1559 so does not contain  `access_list`, `max_fee_per_gas`,`max_priority_fee_per_gas`, `priority_fee_per_gas` and `type` is always `Legacy` |\n| Optimism (legacy) | `optimism_legacy_ovm1.transactions` | No EIP1559 so does not contain  `access_list`, `max_fee_per_gas`,`max_priority_fee_per_gas`, `priority_fee_per_gas` and `type` is always `Legacy` |\n| BNB Chain         | `bnb.transactions`          | No EIP1559 so does not contain  `access_list`, `max_fee_per_gas`,`max_priority_fee_per_gas`, `priority_fee_per_gas` and `type` is always `Legacy` |\n| Arbitrum          | `arbitrum.transactions`     | No EIP1559 so does not contain  `access_list`, `max_fee_per_gas`,`max_priority_fee_per_gas`, `priority_fee_per_gas` and `type` is always `Legacy`. Gas is measured in `ArbGas` instead of `wei` |\n| Avalanche C-Chain  | `avalanche_c.transactions` | Does not contain. Gas is measured in `nanoavax` instead of `wei` |\n\n## Column Data\n\nThis section of the app technical guide provides a table of column data for transactions. The table lists the column, data type, and description. \n\n### Example\n\nAn example of the table is shown below:\n\n|  Column  **            |  Data type   |  Description                                                   |\n| -------------------------- | :-----------: | ---------------------------------------------------------------- |\n| `block_time`               | _timestamptz_ | The time when the block was mined that includes this transaction |\n| `block_number`             | _int8_        | The length of the blockchain in blocks                     |\n| `value`                      | _numeric_     | The amount of `[chain_gas_token]` sent in this transaction in `wei`. Note that ERC20 tokens do not show up here |\n| `gas_limit`                | _numeric_     | The gas limit in `wei` (ArbGas for Arbitrum) |\n| `gas_price`                | _numeric_     | The gas price in `wei`                                    |\n| `gas_used`                 | _numeric_     | The gas consumed by the transaction in `wei`              |\n| `max_fee_per_gas`          | _numeric_     | The maximum fee per gas the transaction sender is willing to pay total (introduced by [EIP1559](https://eips.ethereum.org/EIPS/eip-1559)) |\n| `max_priority_fee_per_gas` | _numeric_     | Maximum fee per gas the transaction sender is willing to give to miners to incentivize them to include their transaction (introduced by [EIP1559](https://eips.ethereum.org/EIPS/eip-1559)) |\n| `priority_fee_per_gas`     | _numeric_     | The priority fee paid out to the miner for this transaction (introduced by [EIP1559](https://eips.ethereum.org/EIPS/eip-1559)) |\n| `nonce`                    | _numeric_     | The transaction nonce, unique to that wallet               |\n| `index`                    | _numeric_     | The transactions index position in the block               |\n| `success`                  | _boolean_     | A true/false value that shows if the transaction succeeded |\n| `from`                     | _bytea_       | Address of the sender                                      |\n| `to`                       | _bytea_       | Address of the receiver. `null` when its a contract creation transaction |\n| `block_hash`               | _bytea_       | A unique identifier for that block                         |\n| `data`                     | _bytea_       | Can either be empty, a hex encoded message or instructions for a smart contract call |\n| `hash`                     | _bytea_       | The hash of the transaction                                |\n| `type`                     | _text_        | The type of the transaction: `Legacy`, `AccessList`, or `DynamicFee` |\n| `access_list`              | _jsonb_       | A list of addresses and storage keys the transaction intends to access. See [EIP2930](https://eips.ethereum.org/EIPS/eip-2930). Applicable if the transaction is of type `AccessList` or `DynamicFee` |\n| `effective_gas_price` | _numeric_      | [Arbitrum and Avalanche C-Chain only] The gas price this transaction paid in `wei` (Arbitrum) or `nanoavax` (Avalanche) |\n| `gas_used_for_l1` | _numeric_ | [Arbitrum only] The gas consumed by the L1 resources used for this transaction in ArbGas |\n| `l1_gas_used` | _numeric_ | [Optimism only] The costs to send the input `calldata` to L1 |\n| `l1_gas_price` | _numeric_ | [Optimism only] The gas price on L1 |\n| `l1_fee` | _numeric_ | [Optimism only] The amount in wei paid on L1  |\n| `l1_fee_scalar` | _numeric_ | [Optimism only] Variable parameter that makes sure that gas costs on L1 get covered + profits |\n| `l1_block_number` | _numeric_ | [Optimism only] The block_number of the block in which this transaction got batch settled on L1 |\n| `l1_timestamp` | _numeric_ | [Optimism only] The timestamp of the block in which this transaction got batch settled on L1 |\n| `l1_tx_origin` | _numeric_ | [Optimism only] ?? |\n\nThis table provides a detailed description of the column data for transactions. It lists the column name, data type, and description. The column data includes information such as the time when the block was mined that includes this transaction, the length of the blockchain in blocks, the amount of `[chain_gas_token]` sent in this transaction in `wei`, the gas limit in `wei` (ArbGas for Arbitrum), the gas price in `wei`, the gas consumed by the transaction in `wei`, the maximum fee per gas the transaction sender is willing to pay total (introduced by EIP1559), the maximum fee per gas the transaction sender is willing to give to miners to incentivize them to include their transaction (introduced by EIP1559), the priority fee paid out to the miner for this transaction (introduced by EIP1559), the transaction nonce, unique to that wallet, the transactions index position in the block, a true/false value that shows if the transaction succeeded, the address of the sender, the address of the receiver (null when it's a contract creation transaction), a unique identifier for that block, and more. \n\nOverall, this section of the app technical guide provides a detailed description of transactions in the Ethereum network, including tables and column data.",
          "questions": "1. What is the purpose of the Transactions table in this app and what data does it contain?\n- The Transactions table contains data on transactions from various blockchain networks, including Ethereum Mainnet, Polygon, and BNB Chain, among others. It includes information such as the block time, block number, gas limit, gas price, gas used, and transaction hash, among others.\n2. Does this app support EIP1559 and how is it reflected in the Transactions table?\n- The app supports EIP1559, but not all blockchain networks included in the Transactions table have implemented it. For networks that have implemented it, the Transactions table includes columns for `max_fee_per_gas`, `max_priority_fee_per_gas`, and `priority_fee_per_gas`.\n3. How does this app handle gas measurement for different blockchain networks?\n- Gas measurement varies across different blockchain networks, and the Transactions table reflects this by using different units of measurement such as `wei`, `ArbGas`, and `nanoavax`. The table also includes columns such as `effective_gas_price` and `gas_used_for_l1` to account for gas measurement differences in specific networks like Arbitrum."
        }
      ],
      "folders": [
        {
          "folderName": "bitcoin",
          "folderPath": "docs/data-tables/raw/bitcoin",
          "url": "https://dune.com/docs/data-tables/raw/bitcoin",
          "files": [
            {
              "fileName": "blocks.md",
              "filePath": "docs/data-tables/raw/bitcoin/blocks.md",
              "url": "https://dune.com/docs/data-tables/raw/bitcoin/blocks.md",
              "summary": "The Blocks section of the app technical guide covers the `bitcoin.blocks` feature of the project. This feature provides information about Bitcoin blocks, including their time, height, date, hash, transaction count, size, and various other details. \n\nThe guide provides a table with a detailed breakdown of each column in the `bitcoin.blocks` feature, including the column name, column type, and a description of what each column represents. For example, the `time` column represents the block time, while the `height` column represents the block number. \n\nThis information is useful for developers who are working with Bitcoin blocks and need to access specific details about them. For example, a developer building a Bitcoin wallet app might use this feature to display information about recent Bitcoin blocks to their users. \n\nOverall, the Blocks section of the app technical guide provides a comprehensive overview of the `bitcoin.blocks` feature, making it easier for developers to understand and use this feature in their projects.",
              "questions": "1. What is the purpose of the `bitcoin.blocks` table in this app? \n- The `bitcoin.blocks` table contains information about individual blocks in the Bitcoin blockchain, including their height, hash, transaction count, and various other metrics.\n\n2. How is the `total_reward` column calculated? \n- The `total_reward` column represents the static reward given to the miner and is calculated as the sum of the outputs in the coinbase transaction (the first transaction).\n\n3. What is the significance of the `difficulty` column? \n- The `difficulty` column represents the estimated amount of work done to find this block relative to the estimated amount of work done to find block 0. It is a measure of the level of difficulty in mining the block and is used to adjust the mining difficulty level of the network."
            },
            {
              "fileName": "index.md",
              "filePath": "docs/data-tables/raw/bitcoin/index.md",
              "url": "https://dune.com/docs/data-tables/raw/bitcoin/index.md",
              "summary": "# App Technical Guide: Bitcoin\n\nThis guide provides information on how to work with Bitcoin data in the Dune Docs project. Bitcoin is a non-EVM chain, and its raw data looks different from other chains. The guide covers the available data and how to access it.\n\n## Data Available\n\nThis section lists the types of Bitcoin data available in the Dune Docs project. The data is organized into four categories:\n\n- Blocks: This page provides information on Bitcoin blocks, including their height, hash, and timestamp. It also includes data on the number of transactions and the total fees.\n- Transactions: This page provides information on Bitcoin transactions, including their hash, size, and fee. It also includes data on the number of inputs and outputs.\n- Outputs: This page provides information on Bitcoin outputs, including their value and script.\n- Inputs: This page provides information on Bitcoin inputs, including their previous output and script.\n\nEach page provides detailed information on the data available, as well as examples of how to query the data using the Dune Analytics platform.\n\n## Additional Resources\n\nThis guide also includes a link to a full written guide on getting started with Bitcoin data analysis. The guide provides additional information on how to analyze Bitcoin data using the Dune Analytics platform.\n\nOverall, this guide is a useful resource for anyone looking to work with Bitcoin data in the Dune Docs project. It provides a clear overview of the available data and how to access it, as well as additional resources for further learning.",
              "questions": "1. What kind of data is available for analysis in this app?\n- The app technical guide lists blocks, transactions, outputs, and inputs as available data for analysis.\n\n2. Is this app specifically designed for analyzing Bitcoin data or can it be used for other blockchain data as well?\n- The title and description of the app technical guide suggest that it is specifically designed for analyzing Bitcoin data.\n\n3. Are there any specific tools or programming languages required to use this app?\n- The app technical guide does not mention any specific tools or programming languages required to use this app."
            },
            {
              "fileName": "inputs.md",
              "filePath": "docs/data-tables/raw/bitcoin/inputs.md",
              "url": "https://dune.com/docs/data-tables/raw/bitcoin/inputs.md",
              "summary": "# Inputs\n\nThe `Inputs` section of the app technical guide covers the `bitcoin.inputs` feature of the project. This feature provides a table with detailed information about the inputs of a Bitcoin transaction. The table includes columns such as `block_time`, `block_date`, `block_height`, `index`, `tx_id`, `spent_block_height`, `spent_tx_id`, `spent_output_number`, `value`, `address`, `type`, `coinbase`, `is_coinbase`, `script_asm`, `script_hex`, `script_desc`, `script_signature_asm`, `script_signature_hex`, `sequence`, and `witness_data`.\n\nEach column is described in detail, including its data type and a brief explanation of its purpose. For example, the `block_time` column contains a timestamp of when the block was mined, while the `value` column contains the number of Satoshis attached to the input. The `address` column contains the address that owned or owns the output used as input, and the `type` column contains the address type of the input.\n\nThe `Inputs` section is useful for developers who need to access detailed information about Bitcoin transactions. For example, a developer building a Bitcoin wallet app might use this feature to display transaction details to the user. \n\nExample usage:\n```python\nimport dune_docs\n\ninputs_table = dune_docs.bitcoin.inputs\nprint(inputs_table.head())\n```\nThis code imports the `dune_docs` module and accesses the `bitcoin.inputs` feature. It then prints the first few rows of the table using the `head()` method.",
              "questions": "1. What is the purpose of this app and how does it relate to blockchain technology?\n- The app is not explicitly stated in the provided technical guide, so a blockchain SQL analyst might need more information on the context and use case of the app to understand its relevance to blockchain technology.\n\n2. How is the data in the `bitcoin.inputs` table sourced and updated?\n- The technical guide does not provide information on the data source or update frequency of the `bitcoin.inputs` table, which could be important for a blockchain SQL analyst to understand the reliability and timeliness of the data.\n\n3. Are there any limitations or known issues with the app's handling of bitcoin input data?\n- The technical guide does not mention any potential issues or limitations with the app's handling of bitcoin input data, but a blockchain SQL analyst might want to know if there are any known bugs or edge cases that could affect the accuracy or completeness of the data."
            },
            {
              "fileName": "outputs.md",
              "filePath": "docs/data-tables/raw/bitcoin/outputs.md",
              "url": "https://dune.com/docs/data-tables/raw/bitcoin/outputs.md",
              "summary": "The Outputs section of the app technical guide for the Dune Docs project provides a detailed description of the `bitcoin.outputs` table. This table contains information about the outputs of Bitcoin transactions, including the block time, block date, block height, block hash, transaction ID, output index, value, script ASM, script hex, address, and address type. \n\nThe purpose of this section is to provide developers with a clear understanding of the data contained in the `bitcoin.outputs` table and how it can be used in the Dune Docs app. For example, developers can use this table to track the movement of Bitcoin between addresses, analyze transaction patterns, and identify potential fraud or money laundering activities.\n\nEach column in the table is described in detail, including the data type, description, and any relevant examples. For instance, the `value` column contains the number of Satoshis attached to each output, which can be used to calculate the total value of a transaction. The `address` column contains the address that owns each output, which can be used to track the movement of Bitcoin between addresses.\n\nOverall, the Outputs section of the app technical guide provides developers with a comprehensive overview of the `bitcoin.outputs` table and its role in the Dune Docs app. By understanding the data contained in this table, developers can build more powerful and effective tools for analyzing Bitcoin transactions.",
              "questions": "1. What data source does this app technical guide pull from to populate the `bitcoin.outputs` table? \n   - This information is not provided in the app technical guide and would require further investigation or clarification from the developers.\n2. Can this app technical guide be used to track outputs for other cryptocurrencies besides Bitcoin? \n   - Again, this information is not provided in the app technical guide and would require further investigation or clarification from the developers.\n3. Are there any limitations or known issues with the data provided in the `bitcoin.outputs` table? \n   - This information is not provided in the app technical guide and would require further investigation or clarification from the developers."
            },
            {
              "fileName": "transactions.md",
              "filePath": "docs/data-tables/raw/bitcoin/transactions.md",
              "url": "https://dune.com/docs/data-tables/raw/bitcoin/transactions.md",
              "summary": "# Transactions\n\nThe Transactions section of the Dune Docs project provides a detailed guide on the `bitcoin.transactions` feature. The guide contains a table with column names, types, and descriptions of the data that can be accessed through this feature. The table includes information such as the block time, block date, block height, block hash, index, ID, input value, output value, fee, input count, output count, size, virtual size, whether the transaction is a coinbase transaction, and the transaction encoded as hexadecimal.\n\nThe guide also provides definitions for the `input`, `input.script_signature`, `input.script_pub_key`, `output`, and `output.script_pub_key` fields. These fields are of type `STRUCT` and allow for representing nested hierarchical data with key-value pairs. The `input` field contains information about transaction inputs, such as the number of Satoshis attached to the output, the height of the output, the transaction ID of the output, the number of the output in the transaction's outputs, and the script signature and public key. The `output` field contains information about transaction outputs, such as the number of Satoshis attached to the output, the public key, and the index of the output within a transaction.\n\nThe guide notes that the `input` field is an `array(row(map))` type, and provides examples of how to work with the columns using syntax such as `input[1].witness_data[2]` or `input[3].script_pub_key.address`, depending on the lengths of arrays within each value.\n\nOverall, the Transactions section of the Dune Docs project provides a comprehensive guide to the `bitcoin.transactions` feature, including detailed information on the data that can be accessed and how to work with the nested hierarchical data types.",
              "questions": "1. What data source does this app technical guide pull from to populate the `bitcoin.transactions` table?\n- The app technical guide does not provide information on the data source used to populate the `bitcoin.transactions` table.\n\n2. Can this app technical guide be used to query transactions from other cryptocurrencies besides Bitcoin?\n- The app technical guide does not provide information on whether it can be used to query transactions from other cryptocurrencies besides Bitcoin.\n\n3. How can the `input` and `output` fields be used to track the flow of funds in a Bitcoin transaction?\n- The `input` and `output` fields can be used to track the flow of funds in a Bitcoin transaction by providing information on the value, height, transaction ID, output number, coinbase data, sequence number, witness data, script signature, and script public key for each input and output."
            }
          ],
          "folders": [],
          "summary": "The `docs/data-tables/raw/bitcoin` folder in the Dune Docs project focuses on providing comprehensive guides for working with raw Bitcoin data. This data is organized into four main categories: Blocks, Transactions, Outputs, and Inputs. Each category has a dedicated markdown file that explains the respective feature in detail, including the available data, data types, and how to access and use the data in the Dune Docs app.\n\nFor example, the `blocks.md` file covers the `bitcoin.blocks` feature, which provides information about Bitcoin blocks, such as their time, height, date, hash, transaction count, and size. Developers working with Bitcoin blocks can use this feature to display information about recent Bitcoin blocks in their applications, such as a Bitcoin wallet app.\n\nSimilarly, the `transactions.md` file provides a detailed guide on the `bitcoin.transactions` feature, which contains information about Bitcoin transactions, including their hash, size, fee, and the number of inputs and outputs. The guide also explains how to work with nested hierarchical data types, such as `input` and `output` fields, which can be useful for developers analyzing transaction patterns or tracking the movement of Bitcoin between addresses.\n\nThe `outputs.md` file focuses on the `bitcoin.outputs` table, which contains information about the outputs of Bitcoin transactions. This table can be used to analyze transaction patterns, track the movement of Bitcoin between addresses, and identify potential fraud or money laundering activities.\n\nLastly, the `inputs.md` file covers the `bitcoin.inputs` feature, which provides a table with detailed information about the inputs of a Bitcoin transaction. Developers can use this feature to display transaction details to users in applications like a Bitcoin wallet app.\n\nOverall, the guides in this folder provide a clear understanding of the raw Bitcoin data available in the Dune Docs project and how to access and use it effectively. By following these guides, developers can build powerful tools for analyzing Bitcoin transactions and blocks, which can be useful in various applications and projects.",
          "questions": ""
        },
        {
          "folderName": "solana",
          "folderPath": "docs/data-tables/raw/solana",
          "url": "https://dune.com/docs/data-tables/raw/solana",
          "files": [
            {
              "fileName": "account-activity.md",
              "filePath": "docs/data-tables/raw/solana/account-activity.md",
              "url": "https://dune.com/docs/data-tables/raw/solana/account-activity.md",
              "summary": "# Account Activity\n\nThis section of the app technical guide covers the `Solana.account_activity` table, which contains information from the transactions table focused on account usage. Each row in the table contains all information about an account's usage in a transaction. The purpose of this table is to provide a detailed view of how an account is being used in the Solana blockchain.\n\nThe table contains several columns, each with a specific purpose. The `block_slot` column contains the slot of the block in which the transaction occurred. The `block_hash` column contains the hash of the block in which the transaction occurred. The `block_time` column contains the timestamp of when the account usage occurred. The `block_date` column contains the date of when the account usage occurred. The `address` column contains the address of the account, also referred to as the public key. The `tx_index` column contains the index of the transaction in the block. The `tx_id` column contains the ID of the transaction in which the account usage occurred. The `tx_success` column indicates whether the transaction succeeded and was committed. The `signed` column indicates whether this account signed the transaction. The `writeable` column indicates whether this account was granted read-write access in the transaction. The `pre_balance` column contains the balance of the account before the transaction was processed. The `pre_token_balance` column contains the token balance before the transaction was processed. The `post_balance` column contains the balance of the account after the transaction was processed. The `post_token_balance` column contains the token balance after the transaction was processed. The `balance_change` column contains the balance change that occurred as part of the transaction. The `token_balance_change` column contains the token balance change that occurred as part of the transaction. The `token_mint_address` column contains the address the associated token address is minting from (i.e. the actual token address). The `token_owner_address` column contains the address that owns this token address.\n\nAn example use case for this table would be to track the usage of a specific account over time. By analyzing the data in this table, developers can gain insights into how an account is being used and make informed decisions about how to optimize their application. For example, if an account is being used frequently and experiencing high traffic, developers may want to consider optimizing the account to handle the increased load.",
              "questions": "1. What blockchain platform is this app technical guide for?\n- The app technical guide is for the Solana blockchain platform.\n\n2. What specific account information is included in the Solana.account_activity table?\n- The Solana.account_activity table contains information about an account's usage in a transaction, including the account's address, pre- and post-transaction balances, and token balances.\n\n3. What is the purpose of the token_mint_address and token_owner_address columns?\n- The token_mint_address column indicates the address from which the associated token is being minted, while the token_owner_address column indicates the address that owns the token address. This information can be useful for tracking token ownership and usage."
            },
            {
              "fileName": "blocks.md",
              "filePath": "docs/data-tables/raw/solana/blocks.md",
              "url": "https://dune.com/docs/data-tables/raw/solana/blocks.md",
              "summary": "# Blocks\n\n## Solana.blocks\n\nThis section of the app technical guide covers the `Solana.blocks` table, which contains block data within Solana's blockchain. The purpose of this table is to identify block activity and transaction changes over time. The table includes several columns such as `hash`, `height`, `slot`, `time`, `date`, `parent_slot`, `previous_block___hash`, `total_transactions`, `successful_transactions`, and `failed_transactions`. Each column has a specific data type and description, which is explained in the table.\n\nFor example, the `hash` column is a string that represents the hash of the block, base-58 encoded. The `height` column is a bigint that represents the number of blocks beneath this block. The `time` column is a timestamp that represents the estimated time this block was produced. The `total_transactions` column is a bigint that represents the total number of transactions in this block. The `successful_transactions` column is a bigint that represents the number of successful transactions in this block. The `failed_transactions` column is a bigint that represents the number of failed transactions in this block.\n\nThe guide also provides two Solana Query examples that can be used with the `Solana.blocks` table. The first example is \"Solana blocks over time,\" which can be found at [https://dune.xyz/queries/389979](https://dune.xyz/queries/389979). This query shows the number of blocks produced over time. The second example is \"Transactions per day,\" which can be found at [https://dune.xyz/queries/390045](https://dune.xyz/queries/390045). This query shows the number of transactions produced per day.\n\nOverall, this section of the app technical guide provides a detailed explanation of the `Solana.blocks` table and its columns. It also provides useful examples of Solana Queries that can be used with this table.",
              "questions": "1. What is the purpose of the `hash` column in the `Solana.blocks` table?\n- The `hash` column in the `Solana.blocks` table contains the hash of each block in Solana's blockchain, encoded in base-58. A blockchain SQL analyst might want to know how this hash is generated and how it is used within the blockchain.\n\n2. How can the `Solana.blocks` table be used to analyze transaction activity over time?\n- The `Solana.blocks` table can be used to identify block activity and transaction changes over time. A blockchain SQL analyst might want to know how to join this table with other tables in order to analyze transaction activity in more detail.\n\n3. Are there any limitations to the data provided in the `Solana.blocks` table?\n- The `Solana.blocks` table provides information on the number of successful and failed transactions in each block, but it does not provide details on the specific transactions themselves. A blockchain SQL analyst might want to know if there are any other limitations to the data provided in this table, and if there are other tables or data sources that can be used to supplement this information."
            },
            {
              "fileName": "index.md",
              "filePath": "docs/data-tables/raw/solana/index.md",
              "url": "https://dune.com/docs/data-tables/raw/solana/index.md",
              "summary": "# Solana Technical Guide\n\nThis technical guide provides information on Solana's raw data and how it differs from other chains. The guide is divided into two main sections: Data Available and Changelog.\n\n## Data Available\n\nThis section provides a list of tables available in Solana's data. The tables are:\n\n- Account Activity: This table contains information from the transactions table focused on account usage.\n- Blocks: Blocks are the building blocks of blockchains and rollups.\n- Rewards: This table contains data about rewards paid out on Solana.\n- Transactions: Transactions are cryptographically signed instructions from accounts.\n- Vote Transactions: This table contains the full set of vote transactions that are submitted by validators to vote on a block.\n\n## Changelog\n\nThis section provides a list of changes made to Solana's data. The changes are:\n\n### 2022-03-25\n\nThe `solana.account_activity` table has been updated to a new version. The new version of the table contains additional information around token activity. The following columns were added to the table:\n\n- `pre_token_balances`: The token balance before the transaction was processed.\n- `post_token_balances`: The token balance after the transaction was processed.\n- `token_balance_changes`: The balance change that occurred as part of the transaction.\n\n### 2022-03-18\n\nThe `solana.account_activity` table was released. The table contains all of the information about an account’s usage in a transaction. The table is optimized to run with ‘WHERE address = …’ queries.\n\n### 2022-03-01\n\nThe `solana.transactions` table has been upgraded to a new version. The new version of the table uses cleaner array structs to make it easier to extract useful information. The vote transactions have also been split into their own table `solana.vote_transactions`, so queries using `solana.transactions` will have better performance. Unfortunately, the table change also means that some existing queries will now break and need to be changed.\n\nThe changes made to the `solana.transactions` table are:\n\n- You won't need to check if a transaction is a vote transaction, which has typically been done with `WHERE ARRAY_CONTAINS(account_keys, \"Vote111111111111111111111111111111111111111\") = false`.\n- The `error_index` and `error_message` columns have been removed, and have been merged into the `error` column (which is a struct). So now instead of `WHERE error_index is not null`, a query should do `WHERE error is not null`.\n- Structs containing indexes to `account_keys` now include the account address directly, so there is no need to use the `account_keys` column to look up the account addresses.\n- The `pre_token_balances` and `post_token_balances` columns have changed. The token balance is now included in the field `amount`. And as mentioned above, the struct in the array now has a field `account`, which is the account of the token balance.\n- The `instructions` column has changed. As mentioned above, the struct in the array now has a field `executing_account`, which is the account executing the instruction.\n- The `inner_instructions` column is removed, and inner instructions have been moved into the `instructions` column.\n\nIn summary, this technical guide provides information on Solana's raw data and the available tables. It also highlights the changes made to the `solana.account_activity` and `solana.transactions` tables. The guide is useful for developers who want to work with Solana's data and need to understand the changes made to the tables.",
              "questions": "1. What is Solana and how does it differ from other chains?\n- Solana is a non-EVM chain and its raw data looks different from other chains. \n\n2. What data is available in Solana and what information does each table contain?\n- Solana has several tables available, including account activity, blocks, rewards, transactions, and vote transactions. Each table contains specific data related to its name.\n\n3. What changes were made to the Solana tables in the latest update and how might this affect existing queries?\n- The latest update added new columns to the `solana.account_activity` table and split vote transactions into their own table. Existing queries may need to be updated to reflect changes in column names and structures."
            },
            {
              "fileName": "rewards.md",
              "filePath": "docs/data-tables/raw/solana/rewards.md",
              "url": "https://dune.com/docs/data-tables/raw/solana/rewards.md",
              "summary": "# Rewards\n\nThis section of the app technical guide covers the `Solana.rewards` table, which contains data about rewards paid out on Solana. The table is structured such that each row corresponds to one reward, and one block may contain zero or more rewards. The purpose of this table is to provide information about rewards paid out on the Solana blockchain, which can be useful for analyzing trends and patterns in reward distribution.\n\nThe table contains several columns, each with a specific purpose. The `block_slot` column contains the block's slot index in the ledger, while the `block_hash` column contains the hash of the block, base-58 encoded. The `block_time` column contains the estimated time the block was produced, and the `block_date` column contains the date of the event. The `commission` column contains the vote account commission when the reward was credited, only present for voting and staking rewards. The `lamports` column contains the number of reward lamports credited or debited by the account, while the `pre_balance` column contains the account balance in lamports before the reward was applied. The `post_balance` column contains the account balance in lamports after the reward was applied, and the `recipient` column contains the public key, as a base-58 encoded string, of the account that received the reward. Finally, the `reward_type` column contains the type of reward, which can be \"fee\", \"rent\", \"voting\", or \"staking\".\n\nAn example query for this table is provided in the guide, which shows how to retrieve the Solana rewards fee per day. This query can be useful for analyzing the distribution of rewards over time and identifying any trends or patterns in reward distribution.\n\nOverall, this section of the app technical guide provides a detailed overview of the `Solana.rewards` table, including its purpose, structure, and columns. It also provides an example query to demonstrate how the table can be used to analyze reward distribution on the Solana blockchain.",
              "questions": "1. What is the purpose of the Solana.rewards table?\n    \n    The Solana.rewards table contains data about rewards paid out on Solana, with each row corresponding to one reward. It includes information such as the block slot, block hash, block time, commission, lamports, pre and post balance, recipient, and reward type.\n\n2. What types of rewards are included in the reward_type column?\n    \n    The reward_type column includes four types of rewards: \"fee\", \"rent\", \"voting\", and \"staking\". The commission column is also present for voting and staking rewards.\n\n3. Are there any limitations or restrictions on the data included in the Solana.rewards table?\n    \n    The app technical guide does not provide information on any limitations or restrictions on the data included in the Solana.rewards table. It is possible that a blockchain SQL analyst may have additional questions or concerns about the accuracy or completeness of the data."
            },
            {
              "fileName": "transactions.md",
              "filePath": "docs/data-tables/raw/solana/transactions.md",
              "url": "https://dune.com/docs/data-tables/raw/solana/transactions.md",
              "summary": "# Transactions\n\nThe Transactions section of the Dune Docs project provides a technical guide for the Solana.transactions table, which contains transaction data within Solana's blockchain. The table includes relevant data related to account, protocol, and program activity. The guide provides a detailed description of each column in the table, including the column name, column type, and description. \n\nThe guide also includes query examples that demonstrate how to extract data from the table. For example, the guide provides a query that shows NFT transactions of popular programs in the past seven days and an overview of the drift-protocol. \n\nThe guide also includes definitions for several data types used in the table, including STRUCT, which allows for representing nested hierarchical data and has key-value pairs. The guide provides examples of how to use these data types to extract data from the table. \n\nThe guide also includes definitions for several struct types used in the table, including token_balance, instructions, inner_instructions, and error. Each struct type includes a field, data type, and description. \n\nOverall, the Transactions section of the Dune Docs project provides a comprehensive technical guide for the Solana.transactions table, including detailed descriptions of each column and struct type, as well as query examples that demonstrate how to extract data from the table.",
              "questions": "1. What is the purpose of the Solana.transactions table?\n   \n   The Solana.transactions table contains transaction data within Solana's blockchain, including relevant data related to account, protocol, and program activity.\n\n2. What is the data type of the token_balance field in the Struct definitions?\n   \n   The data type of the token_balance field in the Struct definitions is Decimal.\n\n3. How can the STRUCT data type be used to group fields together?\n   \n   The STRUCT data type can be used to group fields together to make them more accessible, similar to a dictionary in Python."
            },
            {
              "fileName": "vote-transactions.md",
              "filePath": "docs/data-tables/raw/solana/vote-transactions.md",
              "url": "https://dune.com/docs/data-tables/raw/solana/vote-transactions.md",
              "summary": "# Vote Transactions\n\nThe Vote Transactions section of the Dune Docs project focuses on the Solana.vote_transactions table, which contains the full set of vote transactions submitted by validators to vote on a block. This table can be joined with the non-vote transactions table to get a full breakdown of all transactions. The schema of the Solana.vote_transactions table is the same as the main transactions table.\n\nThe guide provides a detailed description of each column in the Solana.vote_transactions table, including the column name, column type, and description. Some of the columns include block_slot, which is the block's slot index in the ledger, block_time, which is the estimated time the block was produced, and fee, which is the fee charged for the transaction. The guide also includes examples of queries that can be run on the Solana.vote_transactions table, such as the Solana transactions past 30 days query available on Dune.xyz.\n\nOverall, the Vote Transactions section of the Dune Docs project provides a comprehensive guide to the Solana.vote_transactions table, including its schema and how it can be used to analyze vote transactions submitted by validators. This information is useful for developers and analysts working with Solana.vote_transactions and looking to gain a deeper understanding of its structure and contents.",
              "questions": "1. What is the purpose of the dune docs app and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the dune docs app, so a blockchain SQL analyst may need to seek additional documentation or context. \n\n2. How does the Solana.vote_transactions table differ from the non-vote transactions table mentioned in the guide?\n- The guide mentions that the Solana.vote_transactions table contains only vote transactions submitted by validators to vote on a block, while the non-vote transactions table contains a full breakdown of all transactions. A blockchain SQL analyst may want to know more about the schema and contents of the non-vote transactions table.\n\n3. Can the instructions column in the Solana.vote_transactions table be used to track specific actions taken by validators during the voting process?\n- The guide mentions that the instructions column contains a list of instructions to execute in order, but it does not provide information on what those instructions may be. A blockchain SQL analyst may want to know if the instructions can be used to track specific actions taken by validators during the voting process."
            }
          ],
          "folders": [],
          "summary": "The `docs/data-tables/raw/solana` folder contains a comprehensive technical guide for working with Solana's raw data tables. These tables provide valuable insights into various aspects of the Solana blockchain, such as account activity, blocks, rewards, transactions, and vote transactions. This guide is essential for developers and analysts who want to work with Solana's data and understand the structure and contents of these tables.\n\nThe `account-activity.md` file covers the `Solana.account_activity` table, which contains information about account usage in transactions. This table can be used to track the usage of a specific account over time and optimize applications based on account activity patterns.\n\nThe `blocks.md` file provides information on the `Solana.blocks` table, which contains block data within Solana's blockchain. This table can be used to identify block activity and transaction changes over time. The guide also provides Solana Query examples that can be used with the `Solana.blocks` table.\n\nThe `index.md` file serves as an overview of the Solana Technical Guide, providing information on Solana's raw data and how it differs from other chains. It also highlights the changes made to the `solana.account_activity` and `solana.transactions` tables, making it useful for developers who need to understand the updates made to these tables.\n\nThe `rewards.md` file covers the `Solana.rewards` table, which contains data about rewards paid out on Solana. This table can be used to analyze trends and patterns in reward distribution, providing valuable insights into the Solana blockchain's reward system.\n\nThe `transactions.md` file provides a technical guide for the `Solana.transactions` table, which contains transaction data within Solana's blockchain. The guide includes detailed descriptions of each column and struct type, as well as query examples that demonstrate how to extract data from the table.\n\nFinally, the `vote-transactions.md` file focuses on the `Solana.vote_transactions` table, which contains the full set of vote transactions submitted by validators to vote on a block. This table can be joined with the non-vote transactions table to get a full breakdown of all transactions, providing a comprehensive view of validator voting activity on the Solana blockchain.\n\nOverall, the guide in this folder offers a detailed understanding of Solana's raw data tables and their usage. It is an invaluable resource for developers and analysts working with Solana data, providing examples and explanations that can help them make informed decisions and optimize their applications based on the insights gained from these tables.",
          "questions": ""
        }
      ],
      "summary": "The `docs/data-tables/raw` folder in the Dune Docs project focuses on providing comprehensive guides for working with raw, unfiltered, and unedited data from various blockchains, including Ethereum, Bitcoin, and Solana. This raw data is organized into different categories such as Blocks, Transactions, Event Logs, and Traces. Each category has a dedicated markdown file that explains the respective feature in detail, including the available data, data types, and how to access and use the data in the Dune Docs app.\n\nFor example, the `blocks.md` file covers the concept of blocks in blockchains and rollups, providing tables and column data that are useful for identifying block activity and transaction changes over time. Developers working with blockchain data can use this guide to understand how blocks work in the context of the Dune Docs project and extract valuable insights from the data.\n\nSimilarly, the `event-logs.md` file provides a detailed guide on the `Event Logs` tables that store all logs data generated by smart contracts. This guide is essential for developers who want to work with event logs and understand the structure and contents of these tables.\n\nThe `traces.md` file focuses on the Traces tables, which contain information about the execution of smaller atomic actions generated by transactions. This guide is useful for developers analyzing transaction patterns or tracking the movement of assets between addresses.\n\nLastly, the `transactions.md` file covers transactions in the Ethereum network, including tables and column data. This guide is essential for developers who want to work with transaction data and understand the structure and contents of these tables.\n\nIn addition to the Ethereum-focused guides, this folder also contains subfolders for Bitcoin and Solana, providing detailed guides for working with raw data from these blockchains.\n\nOverall, the guides in this folder provide a clear understanding of the raw data available in the Dune Docs project and how to access and use it effectively. By following these guides, developers can build powerful tools for analyzing blockchain transactions and blocks, which can be useful in various applications and projects.",
      "questions": ""
    },
    {
      "folderName": "spellbook",
      "folderPath": "docs/data-tables/spellbook",
      "url": "https://dune.com/docs/data-tables/spellbook",
      "files": [
        {
          "fileName": "index.md",
          "filePath": "docs/data-tables/spellbook/index.md",
          "url": "https://dune.com/docs/data-tables/spellbook/index.md",
          "summary": "The app technical guide covers the topic of Spells, which are custom tables constructed and maintained by Dune and the community. The guide explains that Spells are available on Dune V2 and can be queried from both Spark SQL and Dune SQL V2 Query Engines. The guide also provides a link to the Spellbook GitHub repository, where all the Spellbook Spell tables can be found. \n\nThe guide then introduces the new Spellbook, which is a retooling of the existing abstractions repository and a first-in-class open-source analytics engineering tool called dbt. The guide explains that dbt allows for the writing and management of unit tests to spot and prevent any issues in abstractions. It also allows for data integrity tests to be added with a single line in a YAML file. The guide highlights that dbt natively understands the dependencies between all models, which makes deploying and maintaining them easier. \n\nThe guide then goes on to explain Sector Spells, which are tables that take in data from multiple contracts and projects, standardize the data across them, and make it easy to query for this data and compare the metrics of different projects with each other. The guide notes that most of the sector dashboards depend on sector spells and that projects can easily get their data into these dashboards by making a pull request to the public GitHub repo. \n\nThe guide also explains Project Spells, which allow projects to assemble their data into one neat table that has all the data they need in one place. The main advantage of using Spells over just constructing a view is that Spells can deal with bigger amounts of data since they can run automatically in the background every few hours. \n\nFinally, the guide provides information on how to contribute to Spellbook and how to view available Spells. It notes that Spells are managed via the public Spellbook GitHub repository and that pull requests are welcome. The guide also provides a warning that the abstractions for V1 are no longer open for contributions and will be sunsetted with the V1 engine soon. \n\nOverall, the app technical guide provides a comprehensive overview of Spells, the Spellbook, and how to contribute to Spellbook. It is a useful resource for anyone looking to understand how to use Spells and how to contribute to the Spellbook project.",
          "questions": "1. What is the purpose of Spells in Dune and how are they maintained?\n- Spells are custom tables that cover a type of activity on the blockchain and are built and maintained by Dune and their community.\n\n2. What is the difference between Sector Spells and Project Spells?\n- Sector Spells standardize data from multiple contracts and projects, making it easy to query and compare metrics, while Project Spells allow projects to assemble their data into one table and deal with larger amounts of data automatically.\n\n3. What is dbt and how does it improve the process of creating Spells?\n- dbt is an open-source analytics engineering tool that injects classical software engineering practices into writing SQL, allowing for the creation and management of unit tests and easy addition of data integrity tests. It also understands the dependencies between all models, making deploying and maintaining Spells more efficient."
        }
      ],
      "folders": [
        {
          "folderName": "contributing",
          "folderPath": "docs/data-tables/spellbook/contributing",
          "url": "https://dune.com/docs/data-tables/spellbook/contributing",
          "files": [
            {
              "fileName": "index.md",
              "filePath": "docs/data-tables/spellbook/contributing/index.md",
              "url": "https://dune.com/docs/data-tables/spellbook/contributing/index.md",
              "summary": "# Spellbook Technical Guide\n\nThis technical guide is focused on the Spellbook feature of the Dune Docs project. The Spellbook is a collection of how-to guides for creating and using Spells, which are essentially SQL queries that can be saved and reused. \n\n## Casting a Spell from scratch\n\nThis section provides a link to a guide on how to add a Spell to the Spellbook. The guide is located in the `contributing/Adding A Spell` folder and is intended for users who want to learn by doing. The guide provides step-by-step instructions on how to create a new Spell and add it to the Spellbook.\n\n## Spellbook on GitHub\n\nThis section provides a link to the Spellbook repository on GitHub. Users who want to take a look under the hood can find the source code for the Spellbook here. The repository contains a variety of how-to guides for creating Spells.\n\n## Video Guides\n\nThis section provides links to two video guides on how to use the Spellbook. The first video is a DuneCon workshop presented by Megan Heintz, a member of the Dune Team who came up with the name \"Spellbook\". The workshop provides an overview of the Spellbook's infrastructure and demonstrates how to migrate data to a Spell. The second video is a tutorial presented by Andrew Hong, who shows how to create a pair, manage liquidity, swap through pairs, and pull and transform data on Ethereum using Spells.\n\nOverall, this technical guide provides users with resources for learning how to use the Spellbook feature of the Dune Docs project. Users can follow step-by-step guides, explore the source code on GitHub, or watch video tutorials to learn how to create and use Spells.",
              "questions": "1. What is the purpose of the Spellbook app and how does it relate to blockchain technology?\n    \n    The app technical guide does not provide clear information on the purpose of the Spellbook app or its relation to blockchain technology, so a blockchain SQL analyst might have to do further research or seek clarification from the developers.\n\n2. Are there any security measures in place to protect user data and transactions within the app?\n\n    The app technical guide does not mention any security measures in place to protect user data and transactions, so a blockchain SQL analyst might have to investigate further or consult with the developers to ensure the app is secure.\n\n3. What programming languages and frameworks were used to develop the Spellbook app?\n\n    The app technical guide does not provide information on the programming languages and frameworks used to develop the Spellbook app, so a blockchain SQL analyst might have to do further research or consult with the developers to determine the technology stack."
            }
          ],
          "folders": [
            {
              "folderName": "Adding A Spell",
              "folderPath": "docs/data-tables/spellbook/contributing/Adding A Spell",
              "url": "https://dune.com/docs/data-tables/spellbook/contributing/Adding A Spell",
              "files": [
                {
                  "fileName": "1-do-some-prerequisites and-set-up-Spellbook-dbt.md",
                  "filePath": "docs/data-tables/spellbook/contributing/Adding A Spell/1-do-some-prerequisites and-set-up-Spellbook-dbt.md",
                  "url": "https://dune.com/docs/data-tables/spellbook/contributing/Adding A Spell/1-do-some-prerequisites and-set-up-Spellbook-dbt.md",
                  "summary": "This technical guide provides instructions on how to set up Spellbook dbt on a local computer. The guide is divided into two main sections: prerequisites and setting up Spellbook dbt. \n\nThe prerequisites section outlines the software and tools required to set up Spellbook dbt. These include VSCode, Python 3.9, pip, pipenv, git, and GitHub. The guide provides links to download and install each of these tools. Additionally, the guide instructs users to fork the Spellbook repository, clone it locally, and add an upstream. The guide also includes a video tutorial on how to fork the Spellbook repo.\n\nThe second section of the guide focuses on setting up Spellbook dbt. Once the user has a local copy of their Spellbook fork, they need to install the necessary packages by running `pipenv install` in the terminal. The guide then instructs users to activate their virtual environment by running `pipenv shell` and initialize dbt by running `dbt init`. The guide provides a list of prompts that users should enter when initializing dbt. The guide also instructs users to run `dbt deps` to install dependencies and `dbt compile` to compile the project. Finally, the guide instructs users to create a new branch called \"workshop\" and push it to their remote GitHub repository.\n\nOverall, this guide provides detailed instructions on how to set up Spellbook dbt on a local computer. The guide is well-structured and includes links to relevant resources and a video tutorial. The guide is intended for users who are new to Spellbook dbt and provides step-by-step instructions to ensure that users can set up Spellbook dbt without any issues.",
                  "questions": "1. What is the purpose of Spellbook and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of Spellbook or its relation to blockchain technology.\n\n2. Are there any specific SQL databases that Spellbook dbt is compatible with?\n- The app technical guide does not provide information on the specific SQL databases that Spellbook dbt is compatible with.\n\n3. Is there any guidance on how to integrate Spellbook with a blockchain network or smart contract?\n- The app technical guide does not provide information on how to integrate Spellbook with a blockchain network or smart contract."
                },
                {
                  "fileName": "2-decide-on-a-Spell-to-cast.md",
                  "filePath": "docs/data-tables/spellbook/contributing/Adding A Spell/2-decide-on-a-Spell-to-cast.md",
                  "url": "https://dune.com/docs/data-tables/spellbook/contributing/Adding A Spell/2-decide-on-a-Spell-to-cast.md",
                  "summary": "This app technical guide covers the process of deciding on a Spell to cast in the Dune app. The guide provides three ways to decide on a Spell, including having an idea based on previous experience with Dune, checking out Spellbook bounties in Dework, or asking for suggestions in the #spellbook Discord channel. \n\nThe guide then provides an example of creating a migration Spell, specifically translating the Keep3r network `view_job_log` abstraction from Dune's v1 database into a V2 Spell. The guide directs the user to find the `view_job_log.sql` file in the `deprecated-dune-v1-abstractions` folder within VSCode. \n\nThe guide also includes a note that Dune V1 Abstractions have been moved to a new repository and provides a link to access the code for migrating a V1 Abstraction to a Spell. The guide concludes by instructing the user to set up the file structure for the Spell's SQL schema and source files.\n\nOverall, this guide provides a clear and concise explanation of how to decide on a Spell and create a migration Spell in the Dune app. The example provided helps to illustrate the process and make it more accessible to users.",
                  "questions": "1. What is the purpose of the Dune Docs app and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the Dune Docs app or its relation to blockchain technology.\n\n2. What is the significance of the migration Spell mentioned in the guide?\n- The migration Spell mentioned in the guide is for translating the Keep3r network `view_job_log` abstraction from Dune’s v1 database into a V2 Spell.\n\n3. How does the Spellbook bounties in Dework relate to blockchain SQL analysis?\n- The Spellbook bounties in Dework provide a way for users to suggest and work on Spells, which may involve SQL analysis related to blockchain technology."
                },
                {
                  "fileName": "3-set-up-your-file-structure-for-SQL-schema-and-source-files.md",
                  "filePath": "docs/data-tables/spellbook/contributing/Adding A Spell/3-set-up-your-file-structure-for-SQL-schema-and-source-files.md",
                  "url": "https://dune.com/docs/data-tables/spellbook/contributing/Adding A Spell/3-set-up-your-file-structure-for-SQL-schema-and-source-files.md",
                  "summary": "This app technical guide provides instructions on how to set up the file structure for SQL, schema, and source files in the Dune Docs project. The guide explains that all Spells are stored in the `/spellbook/models` directory by project name, then blockchain network. The folder names are all lowercase, and words are separated by underscores. The guide provides an example of the folder structure for the Keep3r network, where the folder is `/spellbook/models/keep3r_network/ethereum`. \n\nThe guide explains that if the project folder exists but a Spell is being created for a new blockchain, a folder for the new blockchain should be created. The guide then explains that three files need to be created: a `.sql` file for the Spell's logic, a `_schema.yml` file to define the Spell's purpose and add generic tests, descriptions, metadata, etc., and a `_sources.yml` file with any project-specific table dependencies. The guide provides an example of the file structure for a Spell folder.\n\nThe guide also explains the naming convention for Spell files. Schema files are named `[project_name]_[blockchain]_schema.yml`, sources files are named `[project_name]_[blockchain]_sources.yml`, and SQL files for Spells are named `[project_name]_[blockchain]_[spell_name].sql`. \n\nThe guide then provides an example of a specific v1 migration example where three additional `.sql` files are needed for a Spell called `keep3r_network_ethereum_view_job_log.sql`. The guide explains that these files are needed because the original `view_job_log.sql` V1 Abstraction has two `FROM` statements that reference two other files that are also abstractions that need to be converted into Spells. The guide also explains that a recursive check needs to be done to see if those abstractions depend on any other abstractions that have yet to be migrated to Spells. \n\nOverall, this app technical guide provides a detailed explanation of how to set up the file structure for Spells in the Dune Docs project and provides examples to help users understand the process.",
                  "questions": "1. What is the purpose of the dune docs app and how does it relate to blockchain SQL analysis?\n- The app technical guide does not provide information on the purpose of the dune docs app or its relation to blockchain SQL analysis.\n\n2. What is the file structure for storing Spells in the dune docs app?\n- Spells are stored in the `/spellbook/models` directory by project name, then blockchain network. Names are all lower case and words are separated by `_`. The app requires the creation of three files: a `.sql` file for the Spell's logic, a `_schema.yml` file for defining the spell's purpose and adding metadata, and a `_sources.yml` file for project-specific table dependencies.\n\n3. How does the app handle dependencies between Spells and abstractions in the migration process?\n- The app requires a recursive check to see if abstractions depend on any other abstractions that have yet to be migrated to Spells. The app also requires the creation of additional `.sql` files for Spells that depend on other abstractions, and these dependencies are identified by searching for `FROM` statements in the original abstractions."
                },
                {
                  "fileName": "4-identify-and-define-sources.md",
                  "filePath": "docs/data-tables/spellbook/contributing/Adding A Spell/4-identify-and-define-sources.md",
                  "url": "https://dune.com/docs/data-tables/spellbook/contributing/Adding A Spell/4-identify-and-define-sources.md",
                  "summary": "# App Technical Guide: Identify and Define Sources\n\nThis guide is focused on the `app` folder of the Dune Docs project and covers the process of identifying and defining sources in the `_sources.yml` file. The purpose of this file is to provide a structured way of defining the sources of data that will be used in the project. \n\nThe guide provides an example of how to format the `_sources.yml` file, which includes a version number and a list of sources. Each source is defined by a name, a one-line description, and a list of tables. The guide also explains how to identify the sources that need to be named by searching for `FROM` statements in the V1 abstractions that are being migrated. \n\nThe example provided in the guide is for the Keep3r Network Ethereum sources. The name of the source is `keep3r_network_ethereum`, and the description provides an overview of the Keep3r Network and its purpose. The list of tables includes the names of the tables that will be used as sources of data for the project. \n\nOverall, this guide is a useful resource for developers who are working on the Dune Docs project and need to identify and define sources of data. By following the guidelines provided in this guide, developers can ensure that the sources of data are properly defined and structured, which will make it easier to work with the data in the project.",
                  "questions": "1. What is the purpose of the `_sources.yml` file in the Dune Docs project?\n    \n    The `_sources.yml` file in the Dune Docs project is used to define sources, including their names, descriptions, and tables.\n\n2. How are the sources formatted in the `_sources.yml` file?\n    \n    The sources in the `_sources.yml` file are formatted using YAML syntax, with a version number and a list of sources that include a name, description, and tables.\n\n3. How does one determine which tables to include in the `_sources.yml` file?\n    \n    To determine which tables to include in the `_sources.yml` file, one should search for `FROM` statements in the V1 abstractions being migrated and include all tables mentioned that are not abstractions."
                },
                {
                  "fileName": "6-write-your-spell-as-SELECT-statement.md",
                  "filePath": "docs/data-tables/spellbook/contributing/Adding A Spell/6-write-your-spell-as-SELECT-statement.md",
                  "url": "https://dune.com/docs/data-tables/spellbook/contributing/Adding A Spell/6-write-your-spell-as-SELECT-statement.md",
                  "summary": "This technical guide covers the process of writing a Spell as a SELECT statement in the Dune Docs project. The guide is focused on the app folder of the project. The guide starts by explaining that the endpoint is `_view_job_log.sql`, but the process should start with `_view_job_migrations.sql` because it is the lowest-level dependency. The guide then explains how to migrate from V1 abstraction to V2 Spell by copying the contents of the V1 file to the `keep3r_network_ethereum_view_job_migrations.sql` file. The guide explains that the `CREATE` or `REPLACE` definition statement is not needed, and everything from the first `SELECT` to the last `TRUE` is required. The guide then explains how to replace hard-coded references with JINJA templating. \n\nThe guide provides examples of SQL code and explains how to modify the syntax to V2/Spark SQL. The guide also explains how to replace hard-coded references with JINJA templating. The guide provides examples of how to format references to sources and models using JINJA. The guide emphasizes the need to test the SQL code in dune.com and fix any errors. The guide also provides tips on how to fix errors by googling or asking for help in the community's Discord channel. \n\nIn summary, this technical guide provides a step-by-step process of writing a Spell as a SELECT statement in the Dune Docs project. The guide covers how to migrate from V1 abstraction to V2 Spell, how to replace hard-coded references with JINJA templating, and how to test the SQL code and fix errors.",
                  "questions": "1. What is the purpose of the dune docs app?\n- The app technical guide does not provide information on the purpose of the dune docs app.\n\n2. What programming languages or technologies are used in this app?\n- The app technical guide mentions the use of SQL, PostgreSQL, Spark SQL, and JINJA templating.\n\n3. What is the process for migrating from V1 abstraction to V2 Spell style?\n- The app technical guide provides a detailed process for migrating from V1 abstraction to V2 Spell style, including modifying syntax to Spark SQL, replacing hard-coded references with JINJA templating, and testing individual SQL files in dune.com."
                },
                {
                  "fileName": "7-configure-alias-and-materialization-strategy.md",
                  "filePath": "docs/data-tables/spellbook/contributing/Adding A Spell/7-configure-alias-and-materialization-strategy.md",
                  "url": "https://dune.com/docs/data-tables/spellbook/contributing/Adding A Spell/7-configure-alias-and-materialization-strategy.md",
                  "summary": "This app technical guide covers the configuration of aliases and materialization strategies in the Spellbook project. The guide explains that materialization strategies are used to persist data in the data lake house and there are four materialization strategies in dbt: table, ephemeral, view, and incremental. Spellbook uses view and incremental strategies. \n\nThe guide explains that view Spells are rebuilt each time they are run, meaning every time someone queries a view Spell, the SQL is run, and fresh data is gathered according to the Spell’s SQL logic. On the other hand, incremental Spells allow dbt to insert or update records in a table according to the logic defined. The guide provides an example of how to create an incremental Spell by including a statement of which column to join new data to the existing data each time the Spell is incremented.\n\nThe guide also explains how to configure aliases and materialization. To configure a Spell’s alias and materialization, the configuration is added to the top of each SQL file. The configuration includes creating an alias for the Spell file that will appear in the dune.com UI, defining how the file is stored and categorized in the UI, and naming the contributors. The guide provides an example of how to configure a Spell’s alias and materialization using a view materialization strategy.\n\nFinally, the guide explains how to add new models to the dbt_project.yml file in the Spellbook root folder. The guide provides an example of how to specify the project name, schema, and materialization strategy for the project as a whole as well as the specific blockchain(s) that Spells have been created for. \n\nOverall, this guide provides a detailed explanation of how to configure aliases and materialization strategies in the Spellbook project. It is a useful resource for developers working on the project who need to configure aliases and materialization strategies for their Spells.",
                  "questions": "1. What are the available materialization strategies in dbt and which ones does Spellbook use?\n- The available materialization strategies in dbt are `table`, `ephemeral`, `view`, and `incremental`. Spellbook uses `view` and `incremental`.\n\n2. How does the `incremental` materialization strategy work and what configuration is needed to implement it?\n- The `incremental` materialization strategy allows dbt to insert or update records in a table according to the logic defined. To implement it, the configuration section of the file needs to include a statement of which column to join new data to existing data, specify that it is an incremental Spell, and provide an instruction for how dbt should combine new/old data using `merge`. Additionally, `if` statements need to be added to any `FROM` for which data needs to be incremented.\n\n3. How do you configure a Spell's alias and materialization and where is this configuration added?\n- To configure a Spell's alias and materialization, the configuration is added to the top of each SQL file. The configuration includes creating an alias for the Spell file that will appear in the UI, defining how the file is stored and categorized in the UI, and specifying whether it is a Spell for a specific project or a whole sector. This configuration assumes the use of a `view` materialization strategy."
                },
                {
                  "fileName": "8-make-a-pull-request-get-merged-become-an-archwizard.md",
                  "filePath": "docs/data-tables/spellbook/contributing/Adding A Spell/8-make-a-pull-request-get-merged-become-an-archwizard.md",
                  "url": "https://dune.com/docs/data-tables/spellbook/contributing/Adding A Spell/8-make-a-pull-request-get-merged-become-an-archwizard.md",
                  "summary": "This section of the app technical guide covers the process of making a pull request to the official Spellbook in the Dune Docs project. The guide provides step-by-step instructions on how to submit a pull request after committing local changes to the Spellbook GitHub fork. The guide also emphasizes the importance of giving an appropriate message when submitting a pull request and waiting for comments from the team. \n\nThe guide includes an example of the \"Open pull request button\" and encourages users to address any comments from the team before their Spell is approved. The ultimate goal of this section is to guide users towards becoming a Dune Archwizard by having their Spell approved. \n\nOverall, this section of the guide is focused on the app feature of contributing to the official Spellbook and becoming a part of the select few Dune Archwizards. It provides clear instructions and encourages users to take the necessary steps to ensure their pull request is approved.",
                  "questions": "1. What is the purpose of the Dune Docs project and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the Dune Docs project or its relation to blockchain technology.\n\n2. What programming languages or frameworks are used in the development of this app?\n- The app technical guide does not provide information on the programming languages or frameworks used in the development of this app.\n\n3. Are there any security measures in place to protect user data or prevent unauthorized access?\n- The app technical guide does not provide information on any security measures in place to protect user data or prevent unauthorized access."
                },
                {
                  "fileName": "index.md",
                  "filePath": "docs/data-tables/spellbook/contributing/Adding A Spell/index.md",
                  "url": "https://dune.com/docs/data-tables/spellbook/contributing/Adding A Spell/index.md",
                  "summary": "The app technical guide provides a comprehensive explanation of Spellbook, an open-source dbt repository for creating and maintaining high-level blockchain data tables using SQL and Jinja templating. The guide explains how Spellbook enables the community to build towards a standardized way to transform data into meaningful abstraction layers. The guide also highlights the importance of Spellbook in making blockchain data more transparent, accessible, and meaningful together. \n\nThe guide provides a step-by-step process of how to cast a Spell, which includes setting up Spellbook dbt, deciding on a Spell to cast, setting up a file structure for SQL, schema, and source files, identifying and defining sources, defining expectations with schema and tests, writing a Spell as a SELECT statement, configuring alias and materialization strategy, and making a pull request to become an Archwizard. \n\nThe guide also provides examples of how to use Spellbook to aggregate and organize raw data from multiple sources to make it much easier to query. For instance, the nft.trades Spell enables users to see industry-wide stats like total volume by # of txs and $USD, 24-hr volume, 24-hour and 7-day growth, market share by marketplace, volume by marketplace, and transaction count by marketplace. \n\nOverall, the app technical guide provides a detailed explanation of Spellbook and how to cast a Spell, making it easier for users to create and maintain high-level blockchain data tables using SQL and Jinja templating.",
                  "questions": "1. What is Spellbook and how does it relate to blockchain data analytics?\n- Spellbook is an open-source dbt repository for creating and maintaining high-level blockchain data tables using SQL and Jinja templating. It enables the community to build toward a standardized way to transform data into meaningful abstraction layers, making it much easier to query blockchain data.\n\n2. How does Spellbook save time and effort in blockchain data analysis?\n- Spellbook allows users to create abstracted data sets, like dex.trades and nft.trades, which aggregate and organize raw data from multiple sources. This saves time and effort in data analysis as users can skip the manual abstraction work and get straight to the insights.\n\n3. How can a blockchain SQL analyst contribute to Spellbook?\n- A blockchain SQL analyst can contribute to Spellbook by doing the data engineering for a new marketplace, submitting a Pull Request to Spellbook, and having the entire community benefit from their work. They can also follow the 8 steps outlined in the app technical guide to create and maintain high-level blockchain data tables using SQL and Jinja templating."
                }
              ],
              "folders": [],
              "summary": "This folder in the Dune Docs project focuses on the process of contributing a new Spell to the Spellbook, which is an open-source dbt repository for creating and maintaining high-level blockchain data tables using SQL and Jinja templating. The guides in this folder provide detailed instructions on how to set up Spellbook dbt, decide on a Spell to cast, set up a file structure for SQL, schema, and source files, identify and define sources, define expectations with schema and tests, write a Spell as a SELECT statement, configure alias and materialization strategy, and make a pull request to become an Archwizard.\n\nFor example, the guide \"2-decide-on-a-Spell-to-cast.md\" helps users decide on a Spell to cast by providing three ways to decide on a Spell, including having an idea based on previous experience with Dune, checking out Spellbook bounties in Dework, or asking for suggestions in the #spellbook Discord channel. The guide also provides an example of creating a migration Spell, specifically translating the Keep3r network `view_job_log` abstraction from Dune's v1 database into a V2 Spell.\n\nAnother example is the guide \"6-write-your-spell-as-SELECT-statement.md\", which covers the process of writing a Spell as a SELECT statement in the Dune Docs project. The guide provides a step-by-step process of migrating from V1 abstraction to V2 Spell, replacing hard-coded references with JINJA templating, and testing the SQL code and fixing errors.\n\nThese guides are useful for analysts and developers who want to contribute to the Spellbook project by creating and maintaining high-level blockchain data tables. By following the instructions provided in these guides, users can ensure that their Spells are properly structured, tested, and integrated into the Spellbook project. This will ultimately help make blockchain data more transparent, accessible, and meaningful for the entire community.\n\nOverall, the guides in this folder provide a comprehensive explanation of how to contribute a new Spell to the Spellbook project, making it easier for users to create and maintain high-level blockchain data tables using SQL and Jinja templating. The guides are well-structured and include examples to help users understand the process and contribute effectively to the project.",
              "questions": ""
            },
            {
              "folderName": "examples",
              "folderPath": "docs/data-tables/spellbook/contributing/examples",
              "url": "https://dune.com/docs/data-tables/spellbook/contributing/examples",
              "files": [
                {
                  "fileName": "daily-aggregation.md",
                  "filePath": "docs/data-tables/spellbook/contributing/examples/daily-aggregation.md",
                  "url": "https://dune.com/docs/data-tables/spellbook/contributing/examples/daily-aggregation.md",
                  "summary": "# Daily Aggregation\n\nThis section of the app technical guide covers the daily aggregation feature of the Dune Docs project. The purpose of this feature is to sum all transfers for the day. The table is materialized as an incrementally loaded table updated every 15 minutes because the next step includes a slower `[window](https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-window.html)` function to capture a rolling sum.\n\nThe guide explains the novel components that make this Spell incremental. The `<div data-gb-custom-block data-tag=\"if\"> </div>` JINJA block allows the addition of an arbitrary filter when running in “incremental” mode. Incremental mode is default and a full refresh is denoted by a command line arg to completely recreate the table. The block is used to filter for all data timestamped in the last two days. The model runs every fifteen minutes, but a look back of 2 days is allowed to account for data arriving late from the blockchain.\n\nTo avoid duplicates, a “`merge`” incremental\\_strategy is used. Merge strategies require a unique key and deduplicate the table upon each update. The guide shows that a unique key is created by coalescing several transfer features together that are utilized here.\n\nThe guide also introduces the first use of “refs” in this spellset. A ref, like `{{ ref('tokens_ethereum_erc20') }}` is simply a reference to another model in the DBT project. The ref references the name of the file itself. That means, duplicate file names cannot exist.\n\nThe guide provides an example of the `transfers_ethereum_erc20_agg_day.sql` file, which contains the SQL code for the daily aggregation feature. The code includes a configuration block that specifies the alias, materialized, file format, incremental strategy, and unique key. The SQL code also includes a select statement that retrieves the required data and a group by statement that groups the data by the required fields.\n\nThe guide also provides an example of the `transfers_ethereum_schema.yml` file, which contains the schema for the Ethereum transfers. The schema includes the name of the transfer, the blockchain, the sector, the project, the contributors, the tags, and the columns. The columns include the blockchain, the hour, the wallet address, the token address, the symbol, the amount raw, and the amount USD.\n\nIn summary, this section of the app technical guide provides a detailed explanation of the daily aggregation feature of the Dune Docs project. It explains the novel components that make this Spell incremental, provides examples of the SQL code and schema files, and introduces the concept of refs.",
                  "questions": "1. What is the purpose of the Daily Aggregation table in the Dune Docs app?\n- The Daily Aggregation table sums all transfers for the day and is materialized as an incrementally loaded table updated every 15 minutes.\n\n2. How does the app handle duplicates in the Daily Aggregation table?\n- The app uses a \"merge\" incremental strategy that requires a unique key and deduplicates the table upon each update.\n\n3. What is a ref in the Dune Docs app and how is it used?\n- A ref is a reference to another model in the DBT project and is used to reference the name of the file itself. It cannot have duplicate file names."
                },
                {
                  "fileName": "final-day-balance.md",
                  "filePath": "docs/data-tables/spellbook/contributing/examples/final-day-balance.md",
                  "url": "https://dune.com/docs/data-tables/spellbook/contributing/examples/final-day-balance.md",
                  "summary": "# Final Daily Balance\n\nThis technical guide covers the Final Daily Balance feature of the Dune Docs project. The feature is located in the `app` folder of the project. \n\nThe Final Daily Balance feature is an Ethereum ERC20 token balances spell that expands the Spell to cover all days, not just the days with transfer activity. The feature adds price data, removes known rebase tokens, and any tokens that resulted in large negative balances. \n\nThe `balances_ethereum_erc20_day.sql` file contains the SQL code for the feature. It uses the `transfers_ethereum_erc20_rolling_day` table to derive the `balances_ethereum_erc20_noncompliant` table, which looks for unique token addresses with larger negative balances that indicate the contract may not be compliant with ERC20. The `balances_ethereum_erc20_day` table then removes rebase tokens from balances and likely non-compliant tokens due to negative balances. \n\nThe `transfers_ethereum_schema.yml` file contains the schema for the `balances_ethereum_erc20_day` table. The table provides daily token balances of ERC20 Ethereum tokens per wallet and contract address pair. The table depends on `erc20_ethereum_transfers`. \n\nOverall, the Final Daily Balance feature provides a comprehensive view of daily Ethereum ERC20 token balances, including price data and compliance checks.",
                  "questions": "1. What is the purpose of the `transfers_ethereum_erc20_rolling_day` table and how is it used in the `balances_ethereum_erc20_day` SQL query?\n   \n   The blockchain SQL analyst might want to know more about the `transfers_ethereum_erc20_rolling_day` table and how it is used in the `balances_ethereum_erc20_day` SQL query to understand how the daily token balances are calculated.\n\n2. How are rebase tokens and non-compliant tokens identified and removed from the final daily balances?\n\n   The blockchain SQL analyst might want to know more about how rebase tokens and non-compliant tokens are identified and removed from the final daily balances to understand the accuracy and reliability of the data.\n\n3. What is the significance of the `prices` table and how is it used in the `balances_ethereum_erc20_day` SQL query?\n\n   The blockchain SQL analyst might want to know more about the `prices` table and how it is used in the `balances_ethereum_erc20_day` SQL query to understand how the daily token balances are converted to USD."
                },
                {
                  "fileName": "index.md",
                  "filePath": "docs/data-tables/spellbook/contributing/examples/index.md",
                  "url": "https://dune.com/docs/data-tables/spellbook/contributing/examples/index.md",
                  "summary": "The app technical guide titled \"Spellbook Examples\" provides an overview of how to track daily balances for ERC-20 tokens using the Dune app. The guide starts by introducing ERC-20 tokens and their contract standard set by the Ethereum Foundation. The main focus of the guide is to identify transfers and track daily balances using the Dune app.\n\nThe guide provides a modular series of spells that can be used to track daily balances. The first spell is \"Reformatted transfers\" which reformats the data from the `erc20_ethereum.evt_Transfer` table. The second spell is \"Daily aggregation\" which aggregates the daily transfers. The third spell is \"Rolling sum\" which calculates the rolling sum of daily transfers. The final spell is \"Final daily balances\" which calculates the final daily balances for Ethereum ERC20 tokens.\n\nThe guide also includes a video that demonstrates how to find the `erc20_ethereum.evt_Transfer` table using the data explorer. The guide is focused on the app folder of the Dune app and provides examples of how to use the app to track daily balances for ERC-20 tokens.",
                  "questions": "1. What is the purpose of the Dune table `erc20_ethereum.evt_Transfer` and how does it relate to blockchain data analysis?\n   \n   A blockchain SQL analyst might want to know more about the structure and contents of the `erc20_ethereum.evt_Transfer` table, as well as how it can be used to track daily balances of ERC-20 tokens. They may also want to know how this table is populated and updated over time.\n\n2. How do the modular spells in this app technical guide work together to provide a comprehensive analysis of ERC-20 token transfers?\n\n   A blockchain SQL analyst might be interested in understanding how the different spells in this guide fit together to provide a complete picture of daily balances for ERC-20 tokens. They may also want to know how these spells can be customized or adapted for different use cases.\n\n3. Are there any limitations or potential issues with using this app technical guide for blockchain data analysis?\n\n   A blockchain SQL analyst might want to know about any potential limitations or issues with using this app technical guide, such as data quality or accuracy concerns, or any assumptions or simplifications made in the analysis. They may also want to know about any potential performance or scalability issues when working with large datasets."
                },
                {
                  "fileName": "reformatted.md",
                  "filePath": "docs/data-tables/spellbook/contributing/examples/reformatted.md",
                  "url": "https://dune.com/docs/data-tables/spellbook/contributing/examples/reformatted.md",
                  "summary": "# Reformatted Transfers\n\nThis technical guide is focused on the `app` folder of the Dune Docs project and covers the reformatted transfers feature. The purpose of this feature is to make it easier to sum up transfers by munging the base table into a union of sent transactions and received transactions. \n\nThe guide explains that WETH requires special handling due to the additional functions of deposit and withdrawal. Therefore, `zeroex_ethereum.weth9_evt_deposit` is added as a source. The model is defined in a YAML file where the description, tests, and metadata are defined. Contributors are also tracked in this file. \n\nThe JINJA config block is used to define the alias for this view as `erc20`. Without this alias, the table name would default to the file name. The schema name for this view is defined in the `dbt_project.yml` file in the root of the Spellbook project. Schema’s are defined there by the directory structure. The name of this view would be `transfers_ethereum.erc20` given the current structure.\n\nThe guide provides an SQL example of the `transfers_ethereum_erc20.sql` file, which includes four CTEs: `sent_transfers`, `received_transfers`, `deposited_weth`, and `withdrawn_weth`. These CTEs are used to select unique transaction IDs, wallet addresses, token addresses, event block times, and raw amounts for each transfer type. The `unique_tx_id`, `blockchain`, `wallet_address`, `token_address`, `evt_block_time`, and `amount_raw` columns are then selected from each CTE and unioned together to create the final table.\n\nThe `transfers_ethereum_schema.yml` file is also provided as an example. This file includes metadata such as the blockchain, sector, project, contributors, tags, and description for the `transfers_ethereum_erc20` model. The `dbt_project.yml` file is also included as an example, which defines the schema and materialized view for the `transfers` and `ethereum` folders.\n\nOverall, this technical guide provides a detailed explanation of the reformatted transfers feature in the Dune Docs app. It covers the purpose of the feature, how it works, and provides examples of the SQL, YAML, and `dbt_project.yml` files used to implement it.",
                  "questions": "1. What is the purpose of the dune docs app and how does it relate to blockchain SQL analysis?\n   \n   The app is a documentation platform for spells used in Dune Analytics, which is a platform for blockchain SQL analysis. Blockchain SQL analysts may use this app to understand the data models and schemas used in Dune Analytics.\n\n2. What is the purpose of the `transfers_ethereum_erc20` model and how is it defined?\n   \n   The `transfers_ethereum_erc20` model is used to track ERC20 token transfers on the Ethereum blockchain. It is defined in a YAML file and a SQL file, where the SQL file defines the logic for the model and the YAML file defines metadata such as the description, tests, and contributors.\n\n3. How does the app handle WETH deposits and withdrawals?\n   \n   The app handles WETH deposits and withdrawals by adding `zeroex_ethereum.weth9_evt_deposit` as a source and defining two SQL queries to handle deposited and withdrawn WETH. These queries are then combined with queries for sent and received transfers to create a union of all transfer types."
                },
                {
                  "fileName": "rolling-sum.md",
                  "filePath": "docs/data-tables/spellbook/contributing/examples/rolling-sum.md",
                  "url": "https://dune.com/docs/data-tables/spellbook/contributing/examples/rolling-sum.md",
                  "summary": "# Rolling Sum of Daily Transfers\n\nThis section of the app technical guide covers the rolling sum window function applied to each daily transfer sum. The purpose of this query is to calculate the rolling sum of raw amounts of ERC20 tokens held after taking into account token decimals. The query is contained in the `transfers_ethereum_erc20_rolling_day.sql` file located in the `app` folder of the project. \n\nThe query selects the blockchain, day, wallet address, token address, symbol, last updated timestamp, recency index, and the rolling sum of the raw amount of ERC20 tokens held. The `transfers_ethereum_erc20_agg_day` reference is used to partition the data by token address and wallet address and order it by day. \n\nThe `transfers_ethereum_erc20_schema.yml` file in the `app` folder of the project contains the schema for the `transfers_ethereum_erc20_rolling_hour` table. The table includes columns for blockchain, hour, wallet address, token address, symbol, amount raw, amount, amount USD, updated at, and recency index. \n\nOverall, this section of the app technical guide provides information on how to calculate the rolling sum of raw amounts of ERC20 tokens held using a window function. It also includes the schema for the table that stores the results of this calculation.",
                  "questions": "1. What is the purpose of the `rolling sum window function` in this app technical guide?\n    \n    The purpose of the `rolling sum window function` is to apply it to each daily transfer sum in order to calculate the rolling sum of raw amount of ERC20 token held.\n\n2. What is the significance of the `recency_index` column in the `transfers_ethereum_erc20_schema.yml` file?\n    \n    The `recency_index` column is an index of the most recent balance ascending, where `recency_index=1` is the wallet/contract pair's most recent balance.\n\n3. How does the `transfers_ethereum_erc20_rolling_hour` table differ from the `transfers_ethereum_erc20_agg_day` table?\n    \n    The `transfers_ethereum_erc20_rolling_hour` table calculates the rolling sum of raw amount of ERC20 token held after taking into account token decimals, while the `transfers_ethereum_erc20_agg_day` table does not."
                }
              ],
              "folders": [],
              "summary": "This folder contains a series of technical guides focused on the `app` folder of the Dune Docs project, specifically covering the process of tracking daily balances for Ethereum ERC-20 tokens. The guides provide detailed explanations of various features and functionalities, including reformatted transfers, daily aggregation, rolling sum, and final daily balances. These guides are essential for analysts who want to understand the inner workings of the Dune Docs project and how to use it effectively.\n\nThe `reformatted.md` guide explains the reformatted transfers feature, which simplifies the process of summing up transfers by creating a union of sent and received transactions. It covers the handling of WETH, the use of JINJA config blocks, and provides examples of the `transfers_ethereum_erc20.sql` and `transfers_ethereum_schema.yml` files.\n\nThe `daily-aggregation.md` guide covers the daily aggregation feature, which sums all transfers for the day. It explains the incremental nature of the feature, the use of merge strategies, and the concept of refs. The guide also provides examples of the `transfers_ethereum_erc20_agg_day.sql` file and the `transfers_ethereum_schema.yml` file.\n\nThe `rolling-sum.md` guide focuses on the rolling sum window function applied to each daily transfer sum. It explains how to calculate the rolling sum of raw amounts of ERC20 tokens held, using the `transfers_ethereum_erc20_rolling_day.sql` file. The guide also includes the schema for the `transfers_ethereum_erc20_rolling_hour` table, as found in the `transfers_ethereum_erc20_schema.yml` file.\n\nThe `final-day-balance.md` guide covers the Final Daily Balance feature, which provides a comprehensive view of daily Ethereum ERC20 token balances, including price data and compliance checks. It explains the use of the `balances_ethereum_erc20_day.sql` file and the schema for the `balances_ethereum_erc20_day` table, as found in the `transfers_ethereum_schema.yml` file.\n\nLastly, the `index.md` guide provides an overview of the entire process of tracking daily balances for ERC-20 tokens using the Dune app. It introduces the concept of ERC-20 tokens and their contract standard, as well as the modular series of spells used to track daily balances.\n\nThese guides are useful for analysts who want to gain a deeper understanding of the Dune Docs project and its features. By following the examples provided in the guides, analysts can effectively track daily balances for ERC-20 tokens and make informed decisions based on the data.",
              "questions": ""
            }
          ],
          "summary": "The `contributing` folder in the Dune Docs project focuses on the process of contributing a new Spell to the Spellbook, which is an open-source dbt repository for creating and maintaining high-level blockchain data tables using SQL and Jinja templating. The guides in this folder provide detailed instructions on how to set up Spellbook dbt, decide on a Spell to cast, set up a file structure for SQL, schema, and source files, identify and define sources, define expectations with schema and tests, write a Spell as a SELECT statement, configure alias and materialization strategy, and make a pull request to become an Archwizard.\n\nFor example, the guide \"2-decide-on-a-Spell-to-cast.md\" helps users decide on a Spell to cast by providing three ways to decide on a Spell, including having an idea based on previous experience with Dune, checking out Spellbook bounties in Dework, or asking for suggestions in the #spellbook Discord channel. The guide also provides an example of creating a migration Spell, specifically translating the Keep3r network `view_job_log` abstraction from Dune's v1 database into a V2 Spell.\n\nAnother example is the guide \"6-write-your-spell-as-SELECT-statement.md\", which covers the process of writing a Spell as a SELECT statement in the Dune Docs project. The guide provides a step-by-step process of migrating from V1 abstraction to V2 Spell, replacing hard-coded references with JINJA templating, and testing the SQL code and fixing errors.\n\nThese guides are useful for analysts and developers who want to contribute to the Spellbook project by creating and maintaining high-level blockchain data tables. By following the instructions provided in these guides, users can ensure that their Spells are properly structured, tested, and integrated into the Spellbook project. This will ultimately help make blockchain data more transparent, accessible, and meaningful for the entire community.\n\nOverall, the guides in this folder provide a comprehensive explanation of how to contribute a new Spell to the Spellbook project, making it easier for users to create and maintain high-level blockchain data tables using SQL and Jinja templating. The guides are well-structured and include examples to help users understand the process and contribute effectively to the project.",
          "questions": ""
        },
        {
          "folderName": "top tables",
          "folderPath": "docs/data-tables/spellbook/top tables",
          "url": "https://dune.com/docs/data-tables/spellbook/top tables",
          "files": [
            {
              "fileName": "dex.trades.md",
              "filePath": "docs/data-tables/spellbook/top tables/dex.trades.md",
              "url": "https://dune.com/docs/data-tables/spellbook/top tables/dex.trades.md",
              "summary": "# Dex.Trades App Technical Guide\n\nThe Dex.Trades app is a decentralized exchange aggregator that collects data from multiple DEX platforms into one simple table. This guide provides an overview of the app and its features.\n\n## Overview\n\nDecentralized exchanges are the backbone of the DeFi industry, allowing users to swap any native (ETH) or ERC-20 token for any ERC-20 token through smart contracts. However, with so many decentralized exchanges available, it can be challenging to work with the smart contract data for all of them. Dex.Trades solves this problem by standardizing and normalizing trading data across virtually all relevant decentralized exchanges.\n\n## Column Data\n\nThe Dex.Trades table contains the following columns:\n\n- `block_time`: The timestamp of the block that included this transaction.\n- `token_a_symbol`: The symbol of one of the two tokens that got traded.\n- `token_b_symbol`: The symbol of one of the two tokens that got traded.\n- `token_a_amount`: The amount of token A that got traded.\n- `token_b_amount`: The amount of token B that got traded.\n- `project`: The DEX on which this trade was executed.\n- `version`: Which version of the DEX got used?\n- `blockchain`: Which blockchain did this occur on?\n- `taker`: Which contract called the DEX contract?\n- `maker`: In some special cases, there actually is a counterparty to transactions, and this party will get displayed here if applicable.\n- `token_a_amount_raw`: The raw amount of token A that got traded.\n- `token_b_amount_raw`: The raw amount of token B that got traded.\n- `usd_amount`: The USD value of this trade.\n- `token_a_address`: The ERC-20 token contract address of token A.\n- `token_b_address`: The ERC-20 token contract address of token B.\n- `exchange_contract_address`: The address of the decentralized exchange contract that made this trade possible.\n- `tx_hash`: The hash of the transaction that contained this trade.\n- `tx_from`: Which address initiated this transaction?\n- `tx_to`: What was the first smart contract that got called during this tx?\n- `trace_address`: Which position in the graph tree does the execution of the trade have?\n- `evt_index`: This logs index position in the block (cumulative amount of logs ordered by execution).\n- `trade_id`: Just for database magic.\n\n## Conclusion\n\nThe Dex.Trades app is an essential tool for anyone looking to work with decentralized exchanges. By aggregating data across multiple DEX platforms into one simple table, Dex.Trades makes it easy to query for trading data for your favorite tokens without having to deal with all of the different DEX smart contracts yourself. The scripts that generate the table can be found in the public Github repo.",
              "questions": "1. What is the purpose of dex.trades and how does it work?\n- Answer: dex.trades is a table that standardizes and normalizes trading data across multiple decentralized exchanges, making it easier to query for trading data for different tokens without having to deal with different DEX smart contracts. It works by aggregating data from various DEX platforms into one simple table.\n\n2. What specific data is included in the dex.trades table?\n- Answer: The dex.trades table includes data such as the timestamp of the block that included the transaction, the symbols and amounts of the tokens traded, the DEX on which the trade was executed, the blockchain on which it occurred, the contract addresses involved, and the USD value of the trade.\n\n3. Where can the scripts that generate the dex.trades table be found?\n- Answer: The scripts that generate the dex.trades table can be found in the public github repo at https://github.com/duneanalytics/spellbook/tree/master/ethereum/dex."
            },
            {
              "fileName": "labels.md",
              "filePath": "docs/data-tables/spellbook/top tables/labels.md",
              "url": "https://dune.com/docs/data-tables/spellbook/top tables/labels.md",
              "summary": "# Labels\n\nThe Labels technical guide is a feature on Dune that allows users to add, update, and query labels for any address. The guide explains what labels are, how to add them, and how to use them. \n\nA label is a piece of metadata about an address, a tag, or metadata. It comes in the form of a key-value pair. The key is the label type, and the value is the label name. Users can browse addresses and labels on the labels page. Labels on Dune are open-ended and crowd-sourced, meaning users are free to come up with new types and label names. \n\nThe guide provides examples of what users can do with labels, such as labeling all addresses that used a certain dapp, labeling all addresses that hold a certain amount of a token, labeling all addresses that use a dapp more than X times per month, and labeling all addresses that sent money to Binance. Users can also do more novel and involved things around user patterns like who did arbitrage trades or profited from flash loans and so much more.\n\nThe Labels table stores labels in the new `labels.labels` table, which has the following schema: `id`, `address`, `name`, `blockchain`, `author`, `source`, `updated_at`, `label_type`, and `model_name`. \n\nThe guide also provides a warning that the Using Labels section is currently under construction. \n\nOverall, the Labels technical guide provides a comprehensive overview of the Labels feature on Dune, including what labels are, how to add them, and how to use them. It also provides examples of what users can do with labels and explains how labels are stored in the Labels table.",
              "questions": "1. What is the purpose of the Labels feature on Dune?\n- The Labels feature on Dune allows users to add, update, and query labels for any address, providing metadata about an address in the form of a key-value pair.\n\n2. How are labels created on Dune?\n- Labels on Dune are open-ended and crowd-sourced, meaning users are free to come up with both new types and label names. Labels can be added using Dune queries, which can be used to label addresses based on various criteria such as dapp usage, token holdings, and more.\n\n3. What is the schema of the `labels.labels` table?\n- The `labels.labels` table stores labels and has columns for the label ID, address, name, blockchain, author, source, updated_at, label_type, and model_name."
            },
            {
              "fileName": "nft.trades.md",
              "filePath": "docs/data-tables/spellbook/top tables/nft.trades.md",
              "url": "https://dune.com/docs/data-tables/spellbook/top tables/nft.trades.md",
              "summary": "The `nft.trades` technical guide is a documentation of the effort to make NFT trading data easily available to everyone on Dune. The guide provides an overview of the `nft.trades` table, which aggregates and standardizes the data between different data platforms and provides auxiliary information and metadata all in one table. The guide explains how the dataset makes it extremely easy to query for any NFT related trading data across all indexed platforms. \n\nThe guide provides information on how the `nft.trades` table works, including Single Item Trade, Bundle Trade, and Aggregator Trade. The Single Item Trade occurs between a buyer and a seller, and they exchange an item that is uniquely identified by the combination of `nft_contract_address` and `token_id`. The Bundle Trade contains multiple items, and each of these items is uniquely identified through a combination of `nft_contract_address` and `token_id`. The Aggregator Trade is a trade in which a single trade transaction contains multiple items, and the approach is to unravel aggregator trades so that each row corresponds to a unique item that was traded, with its associated ID, price, collection, etc.\n\nThe guide also provides information on Platform and Royalty Fees. In the most recent version of `nft.trades`, information about the amount and percent of royalty fees in the original amount and in USD is available when this information was able to be retrieved. Royalty fees are going to the creator, and Platform fees are collected by the NFT platform. \n\nThe guide provides examples of queries that can be run on the `nft.trades` table, including All trades for a given NFT, Trades in the last 24 hour on a given platform, and Platform volumes in the last year. The guide also provides examples of dashboards that utilize parameters and look across the entire ecosystem.\n\nFinally, the guide provides a column data table that lists the column name, data type, and description of the `nft.trades` table. The guide also explains that the SQL code that processes the data for every marketplace is open source and available in their GitHub repository. Everyone can review the code, make pull requests, and submit code to add more marketplaces.",
              "questions": "1. What platforms are currently indexed by nft.trades?\n- OpenSea, Rarible, SuperRare, CryptoPunks, Foundation, and LooksRare are currently indexed by nft.trades.\n\n2. What metadata is provided about the traded NFT?\n- The metadata provided about the traded NFT includes nft_project_name and erc_standard.\n\n3. Can a blockchain SQL analyst add their own aggregator platform to the nft.trades table?\n- Yes, a blockchain SQL analyst can make a pull request to add their own aggregator platform to the nft.trades table."
            },
            {
              "fileName": "prices.md",
              "filePath": "docs/data-tables/spellbook/top tables/prices.md",
              "url": "https://dune.com/docs/data-tables/spellbook/top tables/prices.md",
              "summary": "# Prices\n\nThis technical guide covers the `Prices` feature of the Dune Docs project. The `Prices` feature allows users to get the price of almost all relevant ERC20 tokens. The data is pulled from the Coinpaprika API and the price is the volume-weighted price based on real-time market data, translated to USD.\n\nThe guide provides two tables for getting prices: `prices.usd` and `prices_from_dex_data`. The `prices.usd` table supports a range of ERC20 tokens. If the token you desire is not listed in this table, you can make a pull request to the GitHub repository. The `prices_from_dex_data` table creates price feeds based on decentralized exchange trading data. This table covers much more assets than `prices.usd`, since it covers all assets that are traded on any of the decentralized exchanges that are indexed in `dex.trades`. However, this table is very resource-intensive and can only be updated every few hours. Also, the resolution is only hourly, so if you need minutely prices, you should refer to `prices.usd`.\n\nThe guide provides a detailed explanation of how the `prices_from_dex_data` table works. The script generates median hourly prices based on data from decentralized exchanges found in `dex.trades`. It assigns asset prices based on a trading pair which has a price feed in `prices.usd`. For example, if the $SPELL/ETH pool is used, the $ETH price is contained in `prices.usd`, but the $SPELL price is not. In order to get the $SPELL price, the script will dynamically calculate the price of $SPELL based on the price of $ETH that was exchanged for it. The guide provides an example of how this calculation is done.\n\nThe guide also highlights known issues with the `prices_from_dex_data` table. In rare cases, the script will generate price feeds that are based on illiquid pairs and therefore report wrong data. This happens when all liquid trading pools of this token do not have a price feed in `prices.usd`. The guide provides an example of how this issue can occur and how to manually construct a price feed in such cases.\n\nOverall, this technical guide provides a comprehensive explanation of the `Prices` feature of the Dune Docs project, including how to use the `prices.usd` and `prices_from_dex_data` tables, how the `prices_from_dex_data` table works, and known issues with the table.",
              "questions": "1. What is the source of the price data for the decentralized exchange trading data table?\n- The source of the price data for the decentralized exchange trading data table is the trading data from decentralized exchanges found in `dex.trades`.\n\n2. What is the resolution for the `prices.usd` table?\n- The resolution for the `prices.usd` table is by minute.\n\n3. What are the known issues with the script that generates median hourly prices based on data from decentralized exchanges found in `dex.trades`?\n- In rare cases, the script will generate price feeds that are based on illiquid pairs and therefore report wrong data. This happens when all liquid trading pools of a token do not have a price feed in `prices.usd`. In cases like this, a manual price feed construction is required."
            },
            {
              "fileName": "tokens.md",
              "filePath": "docs/data-tables/spellbook/top tables/tokens.md",
              "url": "https://dune.com/docs/data-tables/spellbook/top tables/tokens.md",
              "summary": "# Tokens\n\nThis section of the app technical guide for the Dune Docs project covers token transfers and metadata. The guide is aimed at individuals who will be working with fungible (ERC20) and non-fungible (ERC721 and ERC1155) tokens in their analysis. The guide provides information on two metadata tables and two transfer tables that are essential for working with tokens.\n\nThe metadata tables include:\n\n1. `tokens.erc20`: This table contains useful information such as the token `symbol` and the `decimals` for any given `contract_address`. The `decimals` information is needed to get the actual amount from raw amounts in on-chain data.\n\n2. `tokens.nft`: This table contains the collection `name` and `symbol` for any given `contract_address`.\n\nThese tables are usually joined on `contract_address` at the end of a query to make everything more human-readable.\n\nThe transfer tables include:\n\n1. `erc20_ethereum.evt_Transfer`: This table contains all transfer events for every ERC20 token. The guide provides a link to a video guide that explains how to get ERC20 balances, mints, and burns.\n\n2. `nft.transfers`: This table contains all transfer events for every ERC721 or ERC1155 token. The guide provides a link to a guide that explains how to leverage this table to find NFT balances, transfers, and mints.\n\nIf you're looking for information on how to calculate native token balances like Ethereum (ETH) balances, the guide provides a link to another guide that covers this topic.\n\nOverall, this section of the app technical guide provides essential information for individuals working with tokens in their analysis. The metadata and transfer tables are crucial for understanding token transfers and metadata, and the guide provides links to additional resources for further learning.",
              "questions": "1. What types of tokens does this app support?\n- The app supports both fungible (erc20) and nonfungible (erc721 and erc1155) tokens.\n\n2. What information can be found in the metadata tables?\n- The metadata tables contain information such as the token symbol, decimals, collection name, and symbol for a given contract address.\n\n3. What transfer events can be found in the transfer tables?\n- The transfer tables contain all transfer events for erc20, erc721, and erc1155 tokens, and can be used to find balances, transfers, mints, and burns."
            }
          ],
          "folders": [],
          "summary": "This folder contains technical guides for various features and tables related to the Dune Docs project, specifically focusing on data tables and their usage. These guides provide detailed explanations, examples, and use cases for working with different aspects of the project, such as decentralized exchange trades, labels, NFT trades, token prices, and token metadata.\n\nFor example, the `dex.trades.md` guide covers the Dex.Trades app, which is a decentralized exchange aggregator that collects data from multiple DEX platforms into one simple table. This guide provides an overview of the app, its features, and the columns in the Dex.Trades table. This guide is useful for anyone looking to work with decentralized exchanges and aggregate data across multiple DEX platforms.\n\nThe `labels.md` guide focuses on the Labels feature, which allows users to add, update, and query labels for any address. This guide explains what labels are, how to add them, and how to use them. It also provides examples of what users can do with labels and explains how labels are stored in the Labels table.\n\nThe `nft.trades.md` guide documents the effort to make NFT trading data easily available on Dune. It provides an overview of the `nft.trades` table, which aggregates and standardizes the data between different data platforms and provides auxiliary information and metadata all in one table. This guide is useful for anyone looking to query NFT related trading data across all indexed platforms.\n\nThe `prices.md` guide covers the Prices feature,",
          "questions": ""
        }
      ],
      "summary": "The `spellbook` folder in the Dune Docs project focuses on the concept of Spells, which are custom tables constructed and maintained by Dune and the community. These tables are designed to make it easier for users to query and analyze blockchain data. The folder contains a main guide, `index.md`, which provides a comprehensive overview of Spells, the Spellbook, and how to contribute to the project. Additionally, there are two subfolders, `contributing` and `top tables`, which contain more specific guides on contributing new Spells and working with various data tables.\n\nThe `index.md` guide introduces Spells and the Spellbook, explaining their benefits and how they can be used with Dune V2 and Spark SQL. It also covers Sector Spells and Project Spells, which standardize data across multiple contracts and projects, making it easier to compare metrics and assemble data into one neat table. This guide is useful for anyone looking to understand how to use Spells and contribute to the Spellbook project.\n\nThe `contributing` subfolder contains guides that focus on the process of contributing a new Spell to the Spellbook. These guides provide detailed instructions on setting up Spellbook dbt, deciding on a Spell to cast, setting up a file structure, defining sources and expectations, writing a Spell as a SELECT statement, and making a pull request. For example, the guide \"6-write-your-spell-as-SELECT-statement.md\" covers the process of writing a Spell as a SELECT statement, migrating from V1 abstraction to V2 Spell, and testing the SQL code. These guides are useful for analysts and developers who want to contribute to the Spellbook project by creating and maintaining high-level blockchain data tables.\n\nThe `top tables` subfolder contains technical guides for various features and tables related to the Dune Docs project. These guides provide detailed explanations and examples for working with different aspects of the project, such as decentralized exchange trades, labels, NFT trades, token prices, and token metadata. For instance, the `dex.trades.md` guide covers the Dex.Trades app, which is a decentralized exchange aggregator that collects data from multiple DEX platforms into one simple table. This guide is useful for anyone looking to work with decentralized exchanges and aggregate data across multiple DEX platforms.\n\nOverall, the `spellbook` folder in the Dune Docs project provides a comprehensive explanation of Spells, the Spellbook, and how to contribute to the project. It is a valuable resource for analysts and developers who want to create and maintain high-level blockchain data tables using SQL and Jinja templating, making blockchain data more transparent, accessible, and meaningful for the entire community.",
      "questions": ""
    }
  ],
  "summary": "The Decoded Tables guide in the `docs/data-tables/decoded` folder focuses on decoding smart contract activity into human-readable tables on the Dune platform. This guide is essential for analysts and developers who want to understand and access the decoded data of smart contracts, events, and function calls on the Dune platform.\n\nThe guide covers the following topics:\n\n1. **Call Tables**: This section explains how Dune parses all message calls and transactions made to smart contracts in their own tables. It provides information on how the tables are named and how they are created on an individual contract level or a class of contracts. It also highlights a common misconception about `pure`, `read`, or `constant` functions not being recorded in Dune.\n\n2. **Event Logs**: This section covers the concept of event logs in smart contracts and how they are decoded into tables named according to a specific schema. It provides examples of how to name tables for the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL) and how to look at event logs of a transaction in Etherscan.\n\n3. **Decoding Process**: This section explains how Dune uses the ABI (Application Binary Interface) for smart contracts and the interface standard for standardized token smart contracts (ERC20, ERC721, etc.) to create tables for each event and function defined in the smart contract's ABI. It provides an example of decoding an ERC20 transfer event log and how to understand decoded data.\n\n4. **Accessing Decoded Data**: This section provides examples of how to access decoded data for specific events and function calls using the V2 Engine (Spark SQL) and V1 Engine (PostgreSQL). It also explains how to check if contracts are already decoded by querying the `[blockchain].contracts` tables or using a dashboard.\n\n5. **Which Tables to Use**: This section discusses which tables to use (events or calls) and provides queries to explore decoded contracts, such as seeing all projects with decoded data or checking for multiple instances of a contract.\n\nThis guide is useful for analysts who want to access and analyze decoded data from smart contracts, events, and function calls on the Dune platform. For example, an analyst might use this guide to understand how to access decoded data for a specific ERC20 token transfer event or how to explore all projects with decoded data on the platform. By understanding the decoding process and how to access the decoded data, analysts can gain valuable insights into smart contract activity and interactions on the Dune platform.",
  "questions": ""
}
