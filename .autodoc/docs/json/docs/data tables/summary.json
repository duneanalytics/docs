{
  "folderName": "data tables",
  "folderPath": ".autodoc\\docs\\json\\docs\\data tables",
  "url": "https://dune.com/tree/master/doc\\docs\\json\\docs\\data tables",
  "files": [
    {
      "fileName": "index.md",
      "filePath": "docs\\data tables\\index.md",
      "url": "https://dune.com/blob/master/data tables\\index.md",
      "summary": "# Tables and Chains Overview\n\nThis technical guide provides an overview of the tables and chains available in the Dune Analytics platform. The guide is divided into two main sections: the four kinds of tables and available chains. \n\nThe first section explains the process of ingesting data from node providers to create raw tables, which are then decoded using contract ABIs to provide easier to work with decoded tables. The abstracted tables are then created to standardize and aggregate the data from all other tables, giving users the easiest to work with spell tables. The community providers like Reservoir and Flashbots are also explained, which can be thought of as spell level abstractions. \n\nThe second section provides a list of available chains that can be queried in Dune Analytics. Each chain is explained in detail, including Ethereum, Gnosis Chain, Polygon POS, Optimism, BNB Chain, Arbitrum, Avalanche (C-Chain), Ethereum's Goerli Testnet, Fantom, Solana, and Bitcoin. \n\nThe guide also includes links to relevant documentation for each chain, such as Ethereum.org for Ethereum, and the Binance Smart Chain documentation for BNB Chain. Additionally, the guide provides a brief history of Ethereum and its updates, as well as a deep dive into Optimism's Layer 2 Optimistic Rollup network. \n\nThe guide also includes a suggestion to look in spellbook and community datasets first, and then if users can't find what they want, they can try decoded and raw tables. \n\nOverall, this technical guide provides a comprehensive overview of the tables and chains available in Dune Analytics, making it easier for users to navigate and query the platform. \n\nExample: \n\nIf a user wants to query data from the Ethereum Mainnet, they can read the section on Ethereum, which explains the history of Ethereum, its updates, and provides a link to Ethereum.org for further documentation. The guide also explains that querying on Dune works exactly the same as querying on Ethereum Mainnet.",
      "questions": "1. What kind of data is included in the raw and decoded tables for each chain?\n- The raw tables contain unedited, raw, and encoded blockchain data, while the decoded tables provide decoded calls and events made to smart contracts.\n\n2. How does querying data from Gnosis Chain (xDai) differ from querying data from Ethereum Mainnet?\n- Gnosis Chain follows all standards and upgrades of Ethereum Mainnet, so querying on Dune works exactly the same.\n\n3. What is the difference between Solana and EVM chains in terms of data?\n- Solana is a non-EVM blockchain that employs a \"proof of history\" mechanism, so its data is quite different from EVM chains."
    }
  ],
  "folders": [
    {
      "folderName": "community",
      "folderPath": ".autodoc\\docs\\json\\docs\\data tables\\community",
      "url": "https://dune.com/tree/master/doc\\docs\\json\\docs\\data tables\\community",
      "files": [
        {
          "fileName": "index.md",
          "filePath": "docs\\data tables\\community\\index.md",
          "url": "https://dune.com/blob/master/data tables\\community\\index.md",
          "summary": "# Community\n\nThis section of the Dune Docs project contains data that has been submitted and hosted on Dune by third-party data providers. The purpose of this section is to provide off-chain data or augmented on-chain data that may be needed in addition to blockchain data. \n\nThe section is only available on V2 Engine. The guide notes that the infrastructure for this endeavor is still being built, and therefore, the support for more datasets is not available at the moment. \n\nThe section contains two datasets, Flashbots and Reservoir, which are listed as cards in a grid format. The purpose of these datasets is not explained in this guide, but they are linked to their respective index pages where more information about them can be found. \n\nThe guide is short and straightforward, providing a brief overview of the Community section and its purpose. It also notes that the section is only available on V2 Engine and that more datasets will be added in the future. \n\nExample:\n\nIf a user needs off-chain data or augmented on-chain data in addition to blockchain data, they can visit the Community section of the Dune Docs project. They will find two datasets, Flashbots and Reservoir, which they can explore further by clicking on the links to their respective index pages. However, they should note that the section is only available on V2 Engine and that more datasets will be added in the future.",
          "questions": "1. What is the V2 Engine mentioned in the note at the beginning of the technical guide?\n- The V2 Engine is required to access the Community section of Dune Docs.\n\n2. What kind of off-chain or augmented on-chain data is provided by the selected organizations mentioned in the guide?\n- The guide does not provide specific information on the type of data provided by the selected organizations.\n\n3. Is there any timeline or plan for when Dune Docs will be able to support more datasets for the Community section?\n- The guide does not provide any information on a timeline or plan for supporting more datasets in the Community section."
        }
      ],
      "folders": [
        {
          "folderName": "flashbots",
          "folderPath": ".autodoc\\docs\\json\\docs\\data tables\\community\\flashbots",
          "url": "https://dune.com/tree/master/doc\\docs\\json\\docs\\data tables\\community\\flashbots",
          "files": [
            {
              "fileName": "arbitrages.md",
              "filePath": "docs\\data tables\\community\\flashbots\\arbitrages.md",
              "url": "https://dune.com/blob/master/data tables\\community\\flashbots\\arbitrages.md",
              "summary": "# Arbitrages\n\nThis section of the app technical guide covers the `flashbots.arbitrages` table, which contains records with additional information about each arbitrage trade. The table includes various columns such as `block_number`, `account_address`, `created_at`, `end_amount`, `error`, `id`, `profit_amount`, `profit_token_address`, `protocols`, `start_amount`, `transaction_hash`, and `timestamp`. Each column is described in detail in the table.\n\nThe purpose of this section is to provide information on how to query the `flashbots.arbitrages` table and understand the data contained within it. The guide includes a query example that can be found at [Total Arb Protocols](https://dune.com/queries/626076/1167481), which demonstrates how to use the table to retrieve information on arbitrage trades.\n\nOverall, this section of the app technical guide is useful for developers who are working with the `flashbots.arbitrages` table and need to understand its structure and how to query it effectively.",
              "questions": "1. What is the purpose of the `flashbots.arbitrages` table in the Dune Docs app?\n- The `flashbots.arbitrages` table contains records with additional information about each arbitrage trade.\n\n2. What type of data is stored in the `profit_amount` column?\n- The `profit_amount` column stores the profit amount after the arbitrage.\n\n3. Is there a link to query examples for the `flashbots.arbitrages` table?\n- Yes, query examples for the `flashbots.arbitrages` table can be found at [Total Arb Protocols](https://dune.com/queries/626076/1167481)."
            },
            {
              "fileName": "index.md",
              "filePath": "docs\\data tables\\community\\flashbots\\index.md",
              "url": "https://dune.com/blob/master/data tables\\community\\flashbots\\index.md",
              "summary": "# Flashbots\n\nThis section of the app technical guide covers the Flashbots project, which is a research and development organization aimed at ensuring that MEV (Miner Extractable Value) incentives do not become opaque and undemocratic. MEV refers to the profit that miners can make by reordering, censoring, or including transactions in a block. \n\nThe guide notes that mev-inspect-py, which is Flashbots' open-source engine for generating MEV data, powers dashboards such as mev-explore and Dune's Flashbots integration. The guide encourages researchers and developers to report any bugs they find or implement new features to improve the engine. \n\nThe guide provides links to the Flashbots documentation and Discord channel for more information and updates on their data and mev-inspect. \n\nExample: If a developer is working on integrating Flashbots into their project, they can consult the Flashbots documentation to understand how to use mev-inspect-py to generate MEV data and how to integrate it into their project. They can also join the Flashbots Discord channel to ask questions and get updates on any new features or bug fixes.",
              "questions": "1. What is the purpose of Flashbots and how does it relate to blockchain technology?\n- Flashbots is a research and development organization that aims to prevent MEV incentives from becoming opaque and undemocratic in blockchain technology.\n\n2. What is mev-inspect-py and how is it used in the app?\n- mev-inspect-py is an open source engine used to generate MEV data and is used to power dashboards such as mev-explore and Dune's Flashbots integration.\n\n3. How can researchers and developers contribute to the improvement of the app?\n- Researchers and developers can report and help correct any found bugs or implement new features by consulting the documentation and joining the Flashbots discord for more information and updates on their data and mev-inspect."
            },
            {
              "fileName": "liquidations.md",
              "filePath": "docs\\data tables\\community\\flashbots\\liquidations.md",
              "url": "https://dune.com/blob/master/data tables\\community\\flashbots\\liquidations.md",
              "summary": "# Liquidations\n\nThis section of the app technical guide covers the `flashbots.liquidations` table, which contains details related to executed liquidations. Liquidation is a Miner Extractable Value (MEV) strategy. MEV refers to the value that miners can extract from the blockchain by reordering, censoring, or including transactions in blocks. \n\nThe table contains the following columns:\n\n- `created_at`: Time of the record's creation.\n- `transaction_hash`: Transaction hash.\n- `trace_address`: Trace pattern related to the position of the transaction in the chain of all transactions related to the MEV trade.\n- `debt_token_address`: Underlying token address of the debt to pay.\n- `received_amount`: Amount received from the liquidation.\n- `protocol`: Protocol name.\n- `liquidated_user`: Address of the liquidated user.\n- `liquidator_user`: Address of the liquidator user.\n- `received_token_address`: Address of the received asset.\n- `block_number`: Block number.\n- `debt_purchase_amount`: Amount of purchased debt.\n- `timestamp`: Timestamp of the latest update of the file.\n\nThe guide provides a query example for the `flashbots.liquidations` table. The query is called \"Liquidations by Protocol\" and can be found at [https://dune.com/queries/625715/1166880](https://dune.com/queries/625715/1166880). \n\nThis section of the app technical guide is relevant to the `app` folder of the project, as it provides information on the `flashbots.liquidations` table, which is likely used in the app's interface to display liquidation data to users.",
              "questions": "1. What is the purpose of the liquidations table in the context of blockchain and how is it related to MEV (Miner Extractable Value)? \n- The liquidations table contains details related to executed liquidations, which is another MEV strategy. It shows the underlying token address of the debt to pay, amount received from the liquidation, and other relevant information.\n\n2. Are there any specific protocols or blockchain networks that this app technical guide is designed for? \n- The app technical guide does not specify any particular protocols or blockchain networks. However, it does provide a query example for liquidations by protocol using Dune Analytics.\n\n3. How frequently is the liquidations table updated and what triggers the updates? \n- The app technical guide states that the timestamp column shows the latest update of the file, but it does not provide information on how frequently the table is updated or what triggers the updates."
            },
            {
              "fileName": "mev_summary.md",
              "filePath": "docs\\data tables\\community\\flashbots\\mev_summary.md",
              "url": "https://dune.com/blob/master/data tables\\community\\flashbots\\mev_summary.md",
              "summary": "# `mev_summary` Table\n\nThe `mev_summary` table is a part of the Dune Docs project and contains a summary of all the classified transactions. This table is located in the `app` folder of the project. The purpose of this table is to provide a summary of all the transactions that have been classified. \n\nThe table contains several columns such as `block_timestamp`, `block_number`, `base_fee_per_gas`, `coinbase_transfer`, `error`, `gas_price`, `gas_price_with_coinbase_transfer`, `gas_used`, `gross_profit_usd`, `miner_address`, `miner_payment_usd`, `protocol`, `protocols`, `transaction_hash`, `type`, and `timestamp`. Each column has a specific type and description. \n\nFor example, the `block_timestamp` column is of type `timestamp` and contains the block timestamp. The `block_number` column is of type `bigint` and contains the block number. The `type` column is of type `string` and contains the type of the MEV (e.g. arbitrage). \n\nQuery examples for this table can be found on the Dune website. One such example is the \"Miner Revenue from Liquidations and Arbitrages\" query, which can be found at [https://dune.com/queries/625974/1167301](https://dune.com/queries/625974/1167301). \n\nOverall, the `mev_summary` table is an important part of the Dune Docs project as it provides a summary of all the classified transactions. This information can be used to analyze and understand the MEV ecosystem.",
              "questions": "1. What is the purpose of the `mev_summary` table in the context of blockchain and SQL analysis?\n- The `mev_summary` table contains a summary of all classified transactions, which can be useful for analyzing miner revenue and profit in the context of MEV (miner-extractable value) strategies.\n\n2. Can this table be joined with other tables in the dune docs database, and if so, which ones?\n- It is unclear from the provided technical guide whether this table can be joined with other tables in the dune docs database. Further exploration of the database schema and documentation may be necessary to determine this.\n\n3. Are there any limitations or caveats to be aware of when using this table for analysis?\n- The technical guide does not provide information on any limitations or caveats to be aware of when using this table for analysis. It may be necessary to consult additional documentation or conduct further testing to identify any potential issues."
            },
            {
              "fileName": "sandwiched-swaps.md",
              "filePath": "docs\\data tables\\community\\flashbots\\sandwiched-swaps.md",
              "url": "https://dune.com/blob/master/data tables\\community\\flashbots\\sandwiched-swaps.md",
              "summary": "# Sandwiched Swaps\n\nThis section of the app technical guide covers the `flashbots.sandwiched_swaps` table, which contains additional data about one or more swaps that were sandwiched with a corresponding sandwich in the database. The table includes columns such as `created_at`, `block_number`, `sandwich_id`, `trace_address`, `transaction_hash`, and `timestamp`.\n\nThe `created_at` column indicates the time of the record's creation, while the `block_number` column shows the block number of the swap. The `sandwich_id` column contains the internal ID of the sandwiched swap, and the `trace_address` column shows the trace pattern related to the position of the swap in the chain of all swaps related to the arbitrage trade. The `transaction_hash` column contains the transaction hash, and the `timestamp` column shows the timestamp of the latest update of the file.\n\nQuery examples for this table can be found in the file located at `dune docs/app/query/sandwiched_swaps.sql`. These examples demonstrate how to retrieve data from the `flashbots.sandwiched_swaps` table using SQL queries.\n\nOverall, this section of the app technical guide provides information on how to work with the `flashbots.sandwiched_swaps` table in the Dune Docs app. It covers the purpose of the table and the columns it contains, as well as providing examples of how to query the table.",
              "questions": "1. What is the purpose of the sandwiched_swaps table in the context of blockchain and SQL analysis?\n- A blockchain SQL analyst might want to know how the sandwiched_swaps table fits into the overall data analysis process and what insights it can provide about swaps and arbitrage trades.\n\n2. Are there any limitations or potential issues with the data in the sandwiched_swaps table?\n- A blockchain SQL analyst might want to know if there are any data quality issues or limitations that could affect the accuracy of their analysis.\n\n3. How frequently is the sandwiched_swaps table updated and what is the source of the data?\n- A blockchain SQL analyst might want to know how often they can expect new data to be added to the table and where that data is coming from in order to better understand the timeliness and reliability of the information."
            },
            {
              "fileName": "sandwiches.md",
              "filePath": "docs\\data tables\\community\\flashbots\\sandwiches.md",
              "url": "https://dune.com/blob/master/data tables\\community\\flashbots\\sandwiches.md",
              "summary": "# Sandwiches Table\n\nThe `sandwiches` table is a part of the Dune Docs project and contains detailed information about executed sandwiches. The table has ten columns, each with a specific purpose. \n\n- `created_at`: This column stores the time of the record's creation.\n- `block_number`: This column stores the block number.\n- `backrun_swap_trace_address`: This column stores the address of the swap in the backrun transaction.\n- `backrun_swap_transaction_hash`: This column stores the transaction hash of the backrun transaction of the specified sandwich.\n- `frontrun_swap_trace_address`: This column stores the address of the swap in the frontrun transaction.\n- `frontrun_swap_transaction_hash`: This column stores the transaction hash of the frontrun transaction of the specified sandwich.\n- `id`: This column stores the internal ID of the sandwich.\n- `profit_amount`: This column stores the profit amount after the arbitrage.\n- `profit_token_address`: This column stores the address of the profit asset.\n- `sandwicher_address`: This column stores the address of the sandwicher.\n- `timestamp`: This column stores the timestamp of the latest update of the file.\n\nThis table is useful for analyzing the performance of executed sandwiches and identifying any issues that may arise during the execution process. For example, if a sandwicher consistently experiences low profits, they may need to adjust their strategy or look for new opportunities. \n\nHere is an example of how to query the `sandwiches` table:\n\n```\nSELECT *\nFROM sandwiches\nWHERE sandwicher_address = '0x123abc'\n```\n\nThis query will return all sandwiches executed by the sandwicher with the address `0x123abc`.",
              "questions": "1. What is the purpose of the \"sandwiches\" table in the Dune Docs app?\n- The \"sandwiches\" table contains detailed information about executed sandwiches, including block number, transaction hashes, profit amount, and addresses of the sandwicher and profit asset.\n\n2. How is the data in the \"sandwiches\" table updated?\n- The \"timestamp\" column indicates the latest update of the file, but it is unclear how the data in the table is updated or if it is updated automatically.\n\n3. Is there any connection between the Dune Docs app and blockchain technology?\n- The table includes columns for block number and transaction hashes, suggesting that the app may be connected to a blockchain network. However, without further information it is unclear what type of blockchain or how it is being used."
            }
          ],
          "folders": [],
          "summary": "The `.autodoc\\docs\\json\\docs\\data tables\\community\\flashbots` folder contains documentation for the Flashbots project, which focuses on Miner Extractable Value (MEV) and its impact on the Ethereum ecosystem. The folder includes guides for various data tables related to MEV strategies, such as arbitrages, liquidations, and sandwiched swaps. These guides are essential for developers and analysts working with Flashbots data and aim to provide a better understanding of the structure and usage of these tables.\n\nFor instance, the `arbitrages.md` guide covers the `flashbots.arbitrages` table, which contains information about arbitrage trades. It explains the purpose of the table, its columns, and provides a query example to retrieve information on arbitrage trades. This guide is useful for developers who need to understand the structure of the table and how to query it effectively.\n\nSimilarly, the `liquidations.md` guide focuses on the `flashbots.liquidations` table, which contains details related to executed liquidations. It provides a query example called \"Liquidations by Protocol\" that demonstrates how to use the table to analyze liquidation data.\n\nThe `mev_summary.md` guide covers the `mev_summary` table, which provides a summary of all classified transactions. This table is crucial for analyzing and understanding the MEV ecosystem. The guide includes a query example called \"Miner Revenue from Liquidations and Arbitrages\" that demonstrates how to use the table to analyze miner revenue.\n\nThe `sandwiched-swaps.md` guide explains the `flashbots.sandwiched_swaps` table, which contains data about sandwiched swaps. It provides query examples for retrieving data from the table using SQL queries. This guide is helpful for developers working with sandwiched swap data in the Dune Docs app.\n\nLastly, the `sandwiches.md` guide covers the `sandwiches` table, which contains detailed information about executed sandwiches. It provides an example of how to query the table to retrieve all sandwiches executed by a specific sandwicher.\n\nOverall, the guides in this folder are essential for developers and analysts working with Flashbots data and aim to provide a better understanding of the structure and usage of the various data tables related to MEV strategies. By following these guides, users can effectively analyze and understand the impact of MEV on the Ethereum ecosystem.",
          "questions": ""
        },
        {
          "folderName": "reservoir",
          "folderPath": ".autodoc\\docs\\json\\docs\\data tables\\community\\reservoir",
          "url": "https://dune.com/tree/master/doc\\docs\\json\\docs\\data tables\\community\\reservoir",
          "files": [
            {
              "fileName": "ask-events.md",
              "filePath": "docs\\data tables\\community\\reservoir\\ask-events.md",
              "url": "https://dune.com/blob/master/data tables\\community\\reservoir\\ask-events.md",
              "summary": "# Ask Events\n\nThis section of the app technical guide covers the `reservoir.ask_events` table, which contains records with information about each ask change. The table includes columns such as `id`, `kind`, `contract`, `token_id`, `order_id`, `maker`, `price`, `quantity_remaining`, `valid_from`, `valid_until`, `source`, `tx_hash`, `tx_timestamp`, and `created_at`. \n\nThe `id` column is an internal event ID, while the `kind` column specifies the type of event (e.g. new-order, expiry, sale, cancel, balance-change, approval-change, bootstrap, revalidation, reprice). The `contract` column contains the contract address, and the `token_id` column contains the ID of the token in the collection. The `order_id` column is the associated ask ID, and the `maker` column contains the associated ask maker wallet address. The `price` column contains the associated ask price in native currency, and the `quantity_remaining` column contains the associated ask tokens remaining. The `valid_from` and `valid_until` columns contain the associated ask validity start and expiration, respectively. The `source` column specifies the source of the order (e.g. opensea.io), while the `tx_hash` and `tx_timestamp` columns contain the associated transaction hash and timestamp, respectively. Finally, the `created_at` column contains the timestamp the event was recorded.\n\nThis section also includes links to query examples for the `reservoir.ask_events` table, which can be found at [https://dune.com/queries/1302858/2232178](https://dune.com/queries/1302858/2232178) and [https://dune.com/queries/1302863/2232189](https://dune.com/queries/1302863/2232189).\n\nOverall, this section of the app technical guide provides a detailed overview of the `reservoir.ask_events` table and its various columns, as well as links to query examples for further exploration. It is relevant to the data tables section of the project app.",
              "questions": "1. What is the purpose of the `reservoir.ask_events` table in the context of blockchain and SQL analysis?\n- The `reservoir.ask_events` table contains records with information about each ask change, which could be useful for analyzing the behavior of buyers and sellers in a blockchain marketplace.\n\n2. Are there any limitations or constraints on the data that can be queried from this table?\n- The app technical guide does not provide information on any limitations or constraints on the data that can be queried from this table.\n\n3. Are there any other tables or data sources that are related to the `reservoir.ask_events` table and could be used for more comprehensive analysis?\n- The app technical guide does not provide information on any other related tables or data sources, but a blockchain SQL analyst may want to explore other tables or data sources to gain a more comprehensive understanding of the marketplace behavior."
            },
            {
              "fileName": "asks.md",
              "filePath": "docs\\data tables\\community\\reservoir\\asks.md",
              "url": "https://dune.com/blob/master/data tables\\community\\reservoir\\asks.md",
              "summary": "# Reservoir.asks Table\n\nThe `reservoir.asks` table is a part of the Dune Docs project and contains records with information about each listing. The table has various columns such as `id`, `kind`, `status`, `contract`, `token_id`, `maker`, `taker`, `price`, `start_price`, `end_price`, `currency_address`, `currency_symbol`, `currency_price`, `dynamic`, `quantity`, `quantity_filled`, `quantity_remaining`, `valid_from`, `valid_until`, `nonce`, `source`, `fee_bps`, `expiration`, `raw_data`, `created_at`, and `updated_at`. Each column has a specific data type and description.\n\nThe purpose of this table is to provide information about each listing, including the listing's status, price, quantity, and other relevant details. The table can be queried using various query examples, which are provided in the documentation. \n\nFor example, to query all active listings, one can use the following SQL query:\n\n```\nSELECT * FROM reservoir.asks WHERE status = 'active';\n```\n\nThis will return all records from the `reservoir.asks` table where the `status` column is set to 'active'.\n\nOverall, the `reservoir.asks` table is an essential part of the Dune Docs project, providing valuable information about each listing. The documentation provides a detailed description of each column in the table, along with query examples to help users retrieve the data they need.",
              "questions": "1. What is the purpose of the `reservoir.asks` table in the Dune Docs app?\n- The `reservoir.asks` table contains records with information about each listing in the app.\n\n2. What type of data is stored in the `price` column of the `reservoir.asks` table?\n- The `price` column in the `reservoir.asks` table stores the current price in native currency.\n\n3. Is there any information in the `reservoir.asks` table about the buyer of a listing?\n- No, there is no information in the `reservoir.asks` table about the buyer of a listing. The table only contains information about the maker and taker wallet addresses."
            },
            {
              "fileName": "attribute-keys.md",
              "filePath": "docs\\data tables\\community\\reservoir\\attribute-keys.md",
              "url": "https://dune.com/blob/master/data tables\\community\\reservoir\\attribute-keys.md",
              "summary": "# Attribute Keys\n\nThis section of the app technical guide covers the `reservoir.attribute_keys` table, which contains records with information about each attribute key. The table has seven columns, including `id`, `collection_id`, `key`, `kind`, `rank`, `created_at`, and `updated_at`. \n\n- `id`: This column contains the internal attribute key id.\n- `collection_id`: This column contains the associated collection id.\n- `key`: This column contains the name of the attribute.\n- `kind`: This column contains the value type, which can be string, number, date, or range.\n- `rank`: This column contains the sort order.\n- `created_at`: This column contains the timestamp the attribute key was created.\n- `updated_at`: This column contains the timestamp the attribute key was updated.\n\nThe purpose of this section is to provide developers with an understanding of the structure and content of the `reservoir.attribute_keys` table. It also includes a link to query examples that can be used to retrieve data from the table.\n\nFor example, if a developer wants to retrieve all the attribute keys associated with a specific collection, they can use the following query:\n\n```\nSELECT *\nFROM reservoir.attribute_keys\nWHERE collection_id = 'collection_id_value';\n```\n\nOverall, this section of the app technical guide is essential for developers who are working with the `reservoir.attribute_keys` table and need to understand its structure and contents.",
              "questions": "1. What is the purpose of the `reservoir.attribute_keys` table in the context of the Dune Docs project?\n- The `reservoir.attribute_keys` table contains information about each attribute key in the project, including its name, value type, and sort order.\n\n2. How does the `reservoir.attribute_keys` table relate to blockchain technology?\n- It is unclear from the provided information how the `reservoir.attribute_keys` table specifically relates to blockchain technology.\n\n3. Are there any security considerations or best practices that should be followed when working with the `reservoir.attribute_keys` table?\n- It is unclear from the provided information whether there are any security considerations or best practices that should be followed when working with the `reservoir.attribute_keys` table."
            },
            {
              "fileName": "attributes.md",
              "filePath": "docs\\data tables\\community\\reservoir\\attributes.md",
              "url": "https://dune.com/blob/master/data tables\\community\\reservoir\\attributes.md",
              "summary": "# Dune Docs App Technical Guide: Attributes\n\n## Reservoir Attributes\n\nThis section of the guide covers the `reservoir.attributes` table, which contains records with information about each attribute. The table includes columns such as `id`, `value`, `token_count`, `on_sale_count`, `floor_sell_value`, `sell_updated_at`, `collection_id`, `kind`, `key`, `created_at`, and `updated_at`. \n\nThe `id` column represents the internal attribute ID, while the `attribute_key_id` column represents the internal attribute key ID. The `value` column contains the attribute value, and the `token_count` column represents the amount of tokens that have the attribute. The `on_sale_count` column represents the amount of tokens that have the attribute and are on sale. The `floor_sell_value` column represents the current floor ask price, and the `sell_updated_at` column represents the timestamp the floor sale was last updated. The `collection_id` column represents the associated collection ID, and the `kind` column represents the value type (string, number, date, range). The `key` column represents the associated key name, and the `created_at` and `updated_at` columns represent the timestamps the attribute was created and updated, respectively.\n\nThis section also provides query examples that can be found at `https://dune.com/queries/1302927/2232298` and `https://dune.com/queries/1302966/2232361`.\n\nOverall, this section of the guide is useful for developers working on the Dune Docs app who need to understand the structure and contents of the `reservoir.attributes` table. It provides a clear overview of the table's columns and their meanings, as well as examples of queries that can be used to retrieve data from the table.",
              "questions": "1. What is the purpose of the `reservoir.attributes` table in the context of blockchain? \n- The `reservoir.attributes` table contains information about each attribute, including the associated collection ID and the amount of tokens that have the attribute. \n\n2. How are the `floor_sell_value` and `sell_updated_at` columns relevant to blockchain analysis? \n- The `floor_sell_value` column contains the current floor ask price, which could be useful for analyzing token sales and market trends. The `sell_updated_at` column provides a timestamp for when the floor sale was last updated, which could also be relevant for market analysis. \n\n3. Are there any limitations or considerations to keep in mind when using the query examples provided in the technical guide? \n- The technical guide does not provide any information on limitations or considerations for the query examples, so it may be necessary to test and validate the queries before relying on them for analysis."
            },
            {
              "fileName": "bid-events.md",
              "filePath": "docs\\data tables\\community\\reservoir\\bid-events.md",
              "url": "https://dune.com/blob/master/data tables\\community\\reservoir\\bid-events.md",
              "summary": "# Bid Events\n\nThis section of the app technical guide covers the `reservoir.bid_events` table, which contains records with information about each bid change. The table includes various columns such as `id`, `kind`, `status`, `contract`, `token_set_id`, `order_id`, `maker`, `price`, `value`, `quantity_remaining`, `valid_from`, `valid_until`, `source`, `tx_hash`, `tx_timestamp`, and `created_at`. \n\nThe `id` column represents the internal event ID, while the `kind` column represents the type of event, such as `new-order`, `expiry`, `sale`, `cancel`, `balance-change`, `approval-change`, `bootstrap`, `revalidation`, and `reprice`. The `status` column represents the status of the event, which can be either `active` or `expired`. The `contract` column represents the contract address, while the `token_set_id` column represents the ID of the token set. The `order_id` column represents the associated bid ID, while the `maker` column represents the associated bid maker wallet address. The `price` column represents the associated bid price in native currency, while the `value` column represents the associated bid value in native currency. The `quantity_remaining` column represents the associated bid tokens remaining, while the `valid_from` column represents the associated bid validity start. The `valid_until` column represents the associated bid validity expiration, while the `source` column represents the source of the order, such as `opensea.io`. The `tx_hash` column represents the associated transaction hash, while the `tx_timestamp` column represents the associated transaction timestamp. Finally, the `created_at` column represents the timestamp the event was recorded.\n\nThis section also includes a link to query examples, which are currently TBD. The query examples will likely demonstrate how to retrieve specific information from the `reservoir.bid_events` table, such as bids of a certain type or bids associated with a specific contract or token set. Overall, this section of the app technical guide provides a detailed overview of the `reservoir.bid_events` table and its various columns, which will be useful for developers working on the bidding functionality of the Dune Docs app.",
              "questions": "1. What is the purpose of the dune docs project and how does it relate to blockchain technology?\n- The app technical guide provided does not give any information about the purpose of the dune docs project or its relation to blockchain technology.\n\n2. How is the data in the bid events table being stored and accessed?\n- The app technical guide does not provide information on how the data in the bid events table is being stored and accessed.\n\n3. Are there any security measures in place to protect the bid events data?\n- The app technical guide does not mention any security measures in place to protect the bid events data."
            },
            {
              "fileName": "bids.md",
              "filePath": "docs\\data tables\\community\\reservoir\\bids.md",
              "url": "https://dune.com/blob/master/data tables\\community\\reservoir\\bids.md",
              "summary": "# Dune Docs App Technical Guide: Bids\n\n## Reservoir.bids\n\nThis section of the guide covers the `reservoir.bids` table, which contains records with information about each bid. The table includes columns such as `id`, `kind`, `status`, `contract`, `maker`, `taker`, `price`, `value`, `currency_address`, `currency_symbol`, `currency_price`, `quantity`, `quantity_filled`, `quantity_remaining`, `valid_from`, `valid_until`, `nonce`, `source`, `fee_bps`, `expiration`, `raw_data`, `created_at`, and `updated_at`. \n\nThe purpose of this section is to provide a detailed description of each column in the `reservoir.bids` table, including the column name, type, and description. For example, the `id` column is a string that represents the internal order id, while the `kind` column is a string that represents the protocol name (e.g. seaport). \n\nAdditionally, this section provides a link to query examples for the `reservoir.bids` table, which can be found at [TBD](TBD). \n\nOverall, this section of the guide is useful for developers who are working with the `reservoir.bids` table and need to understand the purpose and structure of each column. \n\nExample: If a developer needs to retrieve the `maker` and `price` columns from the `reservoir.bids` table, they can use the following SQL query: \n\n```\nSELECT maker, price\nFROM reservoir.bids;\n```",
              "questions": "1. What is the purpose of the dune docs app and how does it relate to blockchain technology?\n- The app technical guide only provides information about a specific table called \"reservoir.bids\" and does not give an overview of the entire app. Therefore, a blockchain SQL analyst might have questions about the overall purpose of the app and how it utilizes blockchain technology.\n\n2. How is the data in the \"reservoir.bids\" table being collected and stored?\n- The app technical guide does not provide information on how the data is being collected and stored, which might be important for a blockchain SQL analyst to understand in order to properly analyze the data.\n\n3. Are there any security measures in place to protect the data in the \"reservoir.bids\" table?\n- The app technical guide does not mention any security measures, such as encryption or access controls, which might be a concern for a blockchain SQL analyst working with sensitive data."
            },
            {
              "fileName": "collection-floor-ask-events.md",
              "filePath": "docs\\data tables\\community\\reservoir\\collection-floor-ask-events.md",
              "url": "https://dune.com/blob/master/data tables\\community\\reservoir\\collection-floor-ask-events.md",
              "summary": "# Collection Floor Ask Events\n\nThis section of the app technical guide covers the `reservoir.collection_floor_ask_events` table, which contains records with information about each collection floor ask change. The table has several columns, including `id`, `kind`, `collection_id`, `contract`, `token_id`, `order_id`, `maker`, `price`, `previous_price`, `valid_until`, `source`, `tx_hash`, `tx_timestamp`, and `created_at`. \n\nThe `kind` column specifies the type of event, which can be `new-order`, `expiry`, `sale`, `cancel`, `balance-change`, `approval-change`, `bootstrap`, `revalidation`, or `reprice`. The `collection_id` column contains the ID of the collection, while the `contract` column contains the address of the contract. The `token_id` column contains the ID of the token in the collection, and the `order_id` column contains the ID of the associated ask. The `maker` column contains the wallet address of the associated ask maker, and the `price` column contains the associated ask price in native currency. The `previous_price` column contains the previous floor ask price in native currency, and the `valid_until` column contains the expiration time of the associated ask. The `source` column specifies the source of the order, such as `opensea.io`. The `tx_hash` column contains the associated transaction hash, and the `tx_timestamp` column contains the associated transaction timestamp. The `created_at` column contains the timestamp when the event was recorded.\n\nThe guide also provides two query examples that can be used to retrieve information from the `reservoir.collection_floor_ask_events` table. The first query example can be found at [https://dune.com/queries/1302799/2232083](https://dune.com/queries/1302799/2232083), while the second query example can be found at [https://dune.com/queries/1302841/2232151](https://dune.com/queries/1302841/2232151).\n\nOverall, this section of the app technical guide provides a detailed explanation of the `reservoir.collection_floor_ask_events` table and its columns, as well as query examples that can be used to retrieve information from the table.",
              "questions": "1. What is the purpose of the `reservoir.collection_floor_ask_events` table in the context of blockchain and SQL analysis?\n- A blockchain SQL analyst might want to know how this table fits into the overall data schema and what insights it can provide about collection floor ask changes in a blockchain ecosystem.\n\n2. Are there any limitations or constraints to consider when querying this table?\n- A blockchain SQL analyst might want to know if there are any specific query requirements or limitations, such as query speed or data volume, that could impact their analysis.\n\n3. How frequently is this table updated and what is the data retention policy?\n- A blockchain SQL analyst might want to know how frequently new records are added to this table and how long the data is retained, in order to understand the freshness and reliability of the data for their analysis."
            },
            {
              "fileName": "collection-top-bid-events.md",
              "filePath": "docs\\data tables\\community\\reservoir\\collection-top-bid-events.md",
              "url": "https://dune.com/blob/master/data tables\\community\\reservoir\\collection-top-bid-events.md",
              "summary": "# Collection Top Bid Events\n\nThis section of the app technical guide covers the `reservoir.collection_top_bid_events` table. This table contains records with information about each collection top bid change. The table has several columns, including `id`, `kind`, `collection_id`, `contract`, `token_id`, `order_id`, `maker`, `price`, `previous_price`, `valid_until`, `source`, `tx_hash`, `tx_timestamp`, and `created_at`. \n\nThe `id` column contains the internal event ID, while the `kind` column specifies the type of event, such as `new-order`, `expiry`, `sale`, `cancel`, `balance-change`, `approval-change`, `bootstrap`, `revalidation`, or `reprice`. The `collection_id` column contains the ID of the collection, and the `contract` column contains the contract address. The `token_id` column contains the ID of the token in the collection, and the `order_id` column contains the associated bid ID. The `maker` column contains the associated bid maker wallet address, and the `price` column contains the associated bid price in native currency. The `previous_price` column contains the previous top bid price in native currency, and the `valid_until` column contains the associated bid validity expiration. The `source` column contains the source of the order, such as `opensea.io`. The `tx_hash` column contains the associated transaction hash, and the `tx_timestamp` column contains the associated transaction timestamp. Finally, the `created_at` column contains the timestamp the event was recorded.\n\nThis section also provides a link to query examples, which are currently TBD. \n\nOverall, this section of the app technical guide provides a detailed overview of the `reservoir.collection_top_bid_events` table and its various columns. It is useful for developers who need to work with this table and understand the information it contains.",
              "questions": "1. What is the purpose of the \"reservoir.collection_top_bid_events\" table in the context of blockchain and SQL? \n- The table contains records with information about each collection top bid change, which could be useful for analyzing bidding behavior and trends within a collection.\n\n2. Are there any limitations or constraints on the data types used in the table columns? \n- The table lists the data types for each column, but it does not specify any limitations or constraints on those data types. A blockchain SQL analyst may need to investigate further to determine if there are any restrictions on the data that can be stored in the table.\n\n3. Is there any additional documentation or context available for the \"kind\" column, which lists different event types? \n- The table provides a list of possible values for the \"kind\" column, but it does not explain what each of those event types represents. A blockchain SQL analyst may need to consult other documentation or resources to gain a better understanding of the different event types and their significance."
            },
            {
              "fileName": "collections.md",
              "filePath": "docs\\data tables\\community\\reservoir\\collections.md",
              "url": "https://dune.com/blob/master/data tables\\community\\reservoir\\collections.md",
              "summary": "# Collections\n\nThis section of the app technical guide covers the `reservoir.collections` table, which contains records with information about each NFT collection. The table includes columns such as `id`, `slug`, `name`, `description`, `token_count`, `contract`, `day1_rank`, `day7_rank`, `day30_rank`, `all_time_rank`, `day1_volume`, `day7_volume`, `day30_volume`, `all_time_volume`, `day1_volume_change`, `day7_volume_change`, `day30_volume_change`, `floor_ask_value`, `day1_floor_sale_value`, `day7_floor_sale_value`, `day30_floor_sale_value`, `day1_floor_sale_change`, `day7_floor_sale_change`, `day30_floor_sale_change`, `created_at`, and `updated_at`. \n\nThe purpose of this guide is to provide developers with an understanding of the structure and contents of the `reservoir.collections` table, as well as examples of queries that can be used to retrieve data from the table. The guide includes a detailed description of each column in the table, including the data type and a brief explanation of its purpose. \n\nThe query examples provided in the guide demonstrate how to retrieve specific data from the `reservoir.collections` table using Dune's query language. For example, the first query example retrieves the `id`, `name`, `description`, and `contract` columns for all records in the table. The second query example retrieves the `id`, `name`, `day1_rank`, `day7_rank`, and `day30_rank` columns for all records in the table. \n\nOverall, this section of the app technical guide is essential for developers who need to work with NFT collections in the Dune app. It provides a clear understanding of the structure and contents of the `reservoir.collections` table, as well as examples of queries that can be used to retrieve data from the table.",
              "questions": "1. What is the purpose of the dune docs app and how does it relate to blockchain technology?\n   \n   Answer: The app technical guide for dune docs does not provide information on the purpose of the app or its relation to blockchain technology. Further documentation or context would be needed to answer this question.\n\n2. What is the significance of the \"contract\" column in the \"reservoir.collections\" table?\n   \n   Answer: The \"contract\" column in the \"reservoir.collections\" table contains the contract address for each NFT collection. This information could be useful for a blockchain SQL analyst who is interested in tracking NFT collections on a specific blockchain network.\n\n3. How are the \"day1_rank\", \"day7_rank\", \"day30_rank\", and \"all_time_rank\" columns calculated in the \"reservoir.collections\" table?\n   \n   Answer: The app technical guide for dune docs does not provide information on how the \"day1_rank\", \"day7_rank\", \"day30_rank\", and \"all_time_rank\" columns are calculated in the \"reservoir.collections\" table. Further documentation or context would be needed to answer this question."
            },
            {
              "fileName": "index.md",
              "filePath": "docs\\data tables\\community\\reservoir\\index.md",
              "url": "https://dune.com/blob/master/data tables\\community\\reservoir\\index.md",
              "summary": "The Reservoir section of the app technical guide covers the Reservoir feature of the Dune Docs project. Reservoir is an open-source, on-chain NFT order aggregation tool that enables the next generation of NFT products and liquidity sources. The guide provides links to the Reservoir dashboard, documentation, and Discord channel for further information and support.\n\nThe Reservoir section of the app technical guide is divided into three subsections: Dashboard, Docs, and Discord. The Dashboard subsection provides a link to the Reservoir dashboard, which is a web-based interface for managing and monitoring Reservoir orders. The Docs subsection provides a link to the Reservoir documentation, which contains detailed information on how to use Reservoir, including installation instructions, API documentation, and examples. The Discord subsection provides a link to the Reservoir Discord channel, which is a community forum for discussing Reservoir and getting help from other users.\n\nOverall, the Reservoir section of the app technical guide is a useful resource for anyone looking to use Reservoir in their NFT project. The guide provides links to all the necessary resources for getting started with Reservoir, including the dashboard, documentation, and community forum. By following the instructions in the guide and using the resources provided, users can easily integrate Reservoir into their NFT project and take advantage of its powerful features.",
              "questions": "1. What is the purpose of Reservoir in the context of blockchain technology?\n- Reservoir is enabling the next generation of NFT products and liquidity sources through open-source, on-chain NFT order aggregation.\n\n2. What are the available resources for developers to learn about Reservoir?\n- Developers can access the Reservoir dashboard, documentation, and Discord channel for learning about the app.\n\n3. Is Reservoir built on a blockchain or using SQL technology?\n- The app technical guide does not provide information on whether Reservoir is built on a blockchain or using SQL technology."
            },
            {
              "fileName": "sales.md",
              "filePath": "docs\\data tables\\community\\reservoir\\sales.md",
              "url": "https://dune.com/blob/master/data tables\\community\\reservoir\\sales.md",
              "summary": "# Sales\n\nThis section of the app technical guide covers the `reservoir.sales` table, which contains records with information about each sale. The table includes various columns such as `id`, `contract`, `token_id`, `order_id`, `order_kind`, `order_side`, `order_source`, `from`, `to`, `price`, `usd_price`, `currency_address`, `currency_symbol`, `currency_price`, `amount`, `fill_source`, `aggregator_source`, `wash_trading_score`, `is_primary`, `tx_hash`, `tx_log_index`, `tx_batch_index`, `tx_timestamp`, `created_at`, and `updated_at`. Each column is described in detail, including its data type and a brief description of its purpose.\n\nThe guide also provides two query examples that can be used to retrieve data from the `reservoir.sales` table. These queries can be accessed via the links provided in the guide.\n\nOverall, this section of the app technical guide is useful for developers who need to work with sales data in the Dune Docs project. It provides a clear understanding of the structure and contents of the `reservoir.sales` table, as well as examples of how to query the data.",
              "questions": "1. What is the purpose of the `reservoir.sales` table in the context of blockchain technology? \n- The `reservoir.sales` table contains records with information about each sale, likely related to transactions on a blockchain.\n\n2. How is the `usd_price` column calculated and what currency is it based on? \n- The `usd_price` column represents the sale price in USD, but it is unclear how this value is calculated or what currency exchange rate is used.\n\n3. What is the significance of the `is_primary` column and how does it relate to blockchain technology? \n- The `is_primary` column indicates whether the sale is a paid mint, but it is unclear how this relates to blockchain technology or what a paid mint refers to in this context."
            },
            {
              "fileName": "token-attributes.md",
              "filePath": "docs\\data tables\\community\\reservoir\\token-attributes.md",
              "url": "https://dune.com/blob/master/data tables\\community\\reservoir\\token-attributes.md",
              "summary": "# Token Attributes\n\nThis section of the app technical guide covers the `reservoir.token_attributes` table, which contains records with information about each NFT token attribute. The table has several columns, including `id`, `contract`, `token_id`, `attribute_id`, `collection_id`, `key`, `value`, `created_at`, and `updated_at`. \n\nThe `id` column is an internal token attribute ID, while the `contract` column contains the contract address. The `token_id` column contains the ID of the token in the collection, and the `attribute_id` column is an internal attribute ID. The `collection_id` column contains the internal collection ID, while the `key` column contains the attribute name. The `value` column contains the attribute value, and the `created_at` and `updated_at` columns contain timestamps for when the token attribute was created and updated, respectively.\n\nThe guide provides a query example for this table, which can be found at [https://dune.com/queries/1302940/2232326](https://dune.com/queries/1302940/2232326). This query can be used to retrieve information from the `reservoir.token_attributes` table.\n\nOverall, this section of the app technical guide provides information about the `reservoir.token_attributes` table and its columns. It is useful for developers who are working on the app's NFT token attributes functionality.",
              "questions": "1. What is the purpose of the dune docs app and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the dune docs app or its relation to blockchain technology.\n\n2. Can this app be used to query token attributes on any blockchain platform or is it specific to a certain blockchain?\n- The app technical guide does not provide information on whether this app can be used to query token attributes on any blockchain platform or if it is specific to a certain blockchain.\n\n3. Are there any limitations or restrictions on the types of token attributes that can be queried using this app?\n- The app technical guide does not provide information on any limitations or restrictions on the types of token attributes that can be queried using this app."
            },
            {
              "fileName": "token-floor-ask-events.md",
              "filePath": "docs\\data tables\\community\\reservoir\\token-floor-ask-events.md",
              "url": "https://dune.com/blob/master/data tables\\community\\reservoir\\token-floor-ask-events.md",
              "summary": "# Token Floor Ask Events\n\nThis section of the app technical guide covers the `reservoir.token_floor_ask_events` table, which contains records with information about each NFT token floor ask change. The table includes columns such as `id`, `kind`, `contract`, `token_id`, `order_id`, `maker`, `price`, `previous_price`, `nonce`, `valid_from`, `valid_until`, `source`, `tx_hash`, `tx_timestamp`, and `created_at`.\n\nThe `id` column represents the internal token attribute id, while the `kind` column represents the event type, such as `new-order`, `expiry`, `sale`, `cancel`, `balance-change`, `approval-change`, `bootstrap`, `revalidation`, or `reprice`. The `contract` column contains the contract address, and the `token_id` column contains the id of the token in the collection. The `order_id` column represents the associated Ask id, and the `maker` column represents the associated Ask maker wallet address. The `price` column contains the associated ask price in native currency, while the `previous_price` column contains the previous ask price in native currency. The `nonce` column represents the order nonce of the maker, and the `valid_from` and `valid_until` columns represent the associated ask validity start and expiration, respectively. The `source` column contains the source of the order, such as `opensea.io`, while the `tx_hash` column contains the associated transaction hash, and the `tx_timestamp` column contains the associated transaction timestamp. Finally, the `created_at` column represents the timestamp the event was recorded.\n\nThis section also includes two query examples that can be found at the specified URLs. These queries can be used to retrieve information from the `reservoir.token_floor_ask_events` table.\n\nOverall, this section of the app technical guide provides a detailed explanation of the `reservoir.token_floor_ask_events` table and its columns, as well as query examples that can be used to retrieve information from the table.",
              "questions": "1. What is the purpose of this table in the context of a blockchain application?\n- This table contains records of NFT token floor ask changes, which could be useful for analyzing market trends and pricing behavior.\n\n2. Are there any limitations or constraints on the data stored in this table?\n- The technical guide does not mention any specific limitations or constraints on the data stored in this table, but it may be important to check the underlying database schema for any such restrictions.\n\n3. How frequently is this table updated and what triggers those updates?\n- The technical guide does not provide information on the frequency or triggers for updates to this table, which could be important for understanding the timeliness and accuracy of the data."
            },
            {
              "fileName": "tokens.md",
              "filePath": "docs\\data tables\\community\\reservoir\\tokens.md",
              "url": "https://dune.com/blob/master/data tables\\community\\reservoir\\tokens.md",
              "summary": "# Tokens\n\nThis section of the app technical guide covers the `reservoir.tokens` table, which contains records with information about each NFT token. The table includes columns such as `id`, `contract`, `token_id`, `name`, `description`, `collection_id`, `owner`, `floor_ask_id`, `floor_ask_value`, `floor_ask_maker`, `floor_ask_valid_from`, `floor_ask_valid_to`, `floor_ask_source`, `last_sale_value`, `last_sale_timestamp`, `created_at`, and `updated_at`. \n\nThe `id` column represents the internal token id, while the `contract` column contains the contract address. The `token_id` column represents the id of the token in the collection, and the `name` and `description` columns contain the name and description of the NFT. The `collection_id` column represents the associated collection id, and the `owner` column contains the wallet address of the owner. \n\nThe `floor_ask_id`, `floor_ask_value`, `floor_ask_maker`, `floor_ask_valid_from`, `floor_ask_valid_to`, and `floor_ask_source` columns represent information about the floor ask, such as the id, value, maker wallet address, listing start and end times, and source. The `last_sale_value` and `last_sale_timestamp` columns represent the associated transaction timestamp. Finally, the `created_at` and `updated_at` columns contain timestamps for when the token was created and updated, respectively.\n\nThe guide also provides query examples for the `reservoir.tokens` table, which can be found at the links provided. These examples can be used to retrieve specific information from the table, such as the floor ask value for a particular token.\n\nOverall, this section of the app technical guide provides a detailed overview of the `reservoir.tokens` table and its columns, as well as query examples for retrieving information from the table.",
              "questions": "1. What is the purpose of the dune docs app and how does it relate to blockchain technology?\n- The app technical guide does not provide information on the purpose of the dune docs app or its relation to blockchain technology.\n\n2. Can the reservoir.tokens table be used to track the ownership and transaction history of NFTs on a blockchain?\n- Yes, the reservoir.tokens table contains information about each NFT token, including the owner wallet address and associated transaction timestamps.\n\n3. Are there any limitations or restrictions on the types of NFTs that can be tracked using the reservoir.tokens table?\n- The app technical guide does not provide information on any limitations or restrictions on the types of NFTs that can be tracked using the reservoir.tokens table."
            }
          ],
          "folders": [],
          "summary": "The Reservoir section of the app technical guide focuses on the data tables related to the Reservoir feature of the Dune Docs project. Reservoir is an open-source, on-chain NFT order aggregation tool that enables the next generation of NFT products and liquidity sources. The guide provides detailed explanations of various tables, their columns, and their purposes, as well as query examples for retrieving specific information from these tables.\n\nFor instance, the `reservoir.sales` table contains records with information about each sale, including columns such as `id`, `contract`, `token_id`, `order_id`, and more. The guide provides a clear understanding of the structure and contents of this table, as well as examples of how to query the data. This information is useful for developers who need to work with sales data in the Dune Docs project.\n\nAnother example is the `reservoir.tokens` table, which contains records with information about each NFT token. The guide provides a detailed overview of the table and its columns, such as `id`, `contract`, `token_id`, `name`, `description`, and more. The guide also provides query examples for retrieving information from the table, such as the floor ask value for a particular token.\n\nThe Reservoir section of the app technical guide is essential for developers who need to work with NFT collections, sales, and attributes in the Dune app. It provides a clear understanding of the structure and contents of the various data tables related to the Reservoir feature, as well as examples of queries that can be used to retrieve data from these tables. By following the instructions in the guide and using the resources provided, developers can easily integrate Reservoir into their NFT project and take advantage of its powerful features.\n\nOverall, the Reservoir section of the app technical guide is a valuable resource for anyone looking to use Reservoir in their NFT project. The guide provides links to all the necessary resources for getting started with Reservoir, including the dashboard, documentation, and community forum. By following the instructions in the guide and using the resources provided, users can easily integrate Reservoir into their NFT project and take advantage of its powerful features.",
          "questions": ""
        }
      ],
      "summary": "The `.autodoc\\docs\\json\\docs\\data tables\\community` folder contains documentation for the Community section of the Dune Docs project, which focuses on providing off-chain data or augmented on-chain data submitted by third-party data providers. This section is essential for developers and analysts who need additional data beyond blockchain data for their projects. Currently, the Community section is only available on V2 Engine, and more datasets will be added in the future.\n\nThe folder contains two subfolders, `flashbots` and `reservoir`, which provide documentation for the Flashbots and Reservoir datasets, respectively. The Flashbots project deals with Miner Extractable Value (MEV) and its impact on the Ethereum ecosystem. The `flashbots` folder contains guides for various data tables related to MEV strategies, such as arbitrages, liquidations, and sandwiched swaps. These guides help developers and analysts understand the structure and usage of these tables, enabling them to analyze and understand the impact of MEV on the Ethereum ecosystem effectively.\n\nFor example, the `arbitrages.md` guide in the `flashbots` folder covers the `flashbots.arbitrages` table, which contains information about arbitrage trades. Developers can use this guide to understand the table structure and query it effectively.\n\nThe Reservoir dataset focuses on the Reservoir feature of the Dune Docs project, an open-source, on-chain NFT order aggregation tool. The `reservoir` folder provides detailed explanations of various tables, their columns, and their purposes, as well as query examples for retrieving specific information from these tables. This documentation is essential for developers working with NFT collections, sales, and attributes in the Dune app.\n\nFor instance, the `reservoir.sales` table guide provides a clear understanding of the table structure and contents, as well as examples of how to query the data. Developers can use this guide to work with sales data in the Dune Docs project effectively.\n\nIn summary, the `.autodoc\\docs\\json\\docs\\data tables\\community` folder provides essential documentation for developers and analysts who need additional off-chain or augmented on-chain data for their projects. By following the guides in this folder, users can effectively work with the Flashbots and Reservoir datasets, analyze their data, and integrate them into their projects.",
      "questions": ""
    },
    {
      "folderName": "decoded",
      "folderPath": ".autodoc\\docs\\json\\docs\\data tables\\decoded",
      "url": "https://dune.com/tree/master/doc\\docs\\json\\docs\\data tables\\decoded",
      "files": [
        {
          "fileName": "call-tables.md",
          "filePath": "docs\\data tables\\decoded\\call-tables.md",
          "url": "https://dune.com/blob/master/data tables\\decoded\\call-tables.md",
          "summary": "# Call Tables\n\nThis technical guide covers how Dune parses all message calls and transactions made to smart contracts in their own tables. The guide explains that smart contracts generally have functions that can be called by either an externally owned account (EOA) or other smart contracts. The tables are named according to the project name, contract name, and function name. \n\nThe guide provides examples of how Dune records transactions in the tables, such as when a Uniswap v3 pool gets created via the Uniswap v3 factory function `createPool`. The guide also explains that for a contract where multiple instances exist, Dune will decode all calls to all instances of this smart contract into one table. \n\nThe guide addresses common misconceptions, such as the fact that web3.js, web3.py, and all other methods of locally calling a `pure`, `read`, or `constant` function do not broadcast or publish anything on the blockchain and are therefore not recorded in Dune. However, if one of these functions is invoked by another smart contract in the context of a transaction, this will be broadcast on the chain and therefore accessible in Dune. \n\nThe guide concludes with further reading resources, including links to articles on the difference between a transaction and a call, Soliditylang.org documentation, and how calldata is encoded. \n\nOverall, this technical guide provides a high-level overview of how Dune records transactions in tables and how to access this data. It is useful for developers who want to understand how Dune works and how to use it to analyze smart contract transactions.",
          "questions": "1. What tables are created for smart contract calls and transactions on Dune?\n- On Dune, tables are created for all message calls and transactions made to smart contracts, and they are named according to the contract name and function name.\n\n2. How does Dune handle multiple instances of a smart contract?\n- For a contract with multiple instances, Dune decodes all calls to all instances into one table.\n\n3. What is a common misconception about accessing state data on Dune?\n- Local calls to `pure`, `read`, or `constant` functions using web3.js or web3.py are not recorded on Dune, but if these functions are invoked by another smart contract in the context of a transaction, the message call will be recorded."
        },
        {
          "fileName": "event-logs.md",
          "filePath": "docs\\data tables\\decoded\\event-logs.md",
          "url": "https://dune.com/blob/master/data tables\\decoded\\event-logs.md",
          "summary": "The Event Logs technical guide explains how smart contracts emit event logs when certain predefined actions are completed. The structure of these logs is predefined by the smart contract developer, and the content is dynamically created during the transaction. The guide highlights the usefulness of logs for monitoring, alerting, and keeping track of what happens inside a smart contract. Logs are also useful for data analysis since they present data that can be analyzed post factum. \n\nThe guide provides a schema for decoding all event logs for smart contracts into tables named accordingly. The schema is different for the V2 Engine (Spark SQL) and V1 Engine (PosgreSQL). The guide uses the Uniswap V3 factory as an example and explains how to look at the event logs of a transaction in Etherscan. The guide also provides the table name where the event will be stored in Dune. \n\nThe guide explains that if there are multiple instances of a contract, all event logs across all instances of the smart contract will be collected in one table. The guide provides an example of how all Uniswap V3 pool swap events on Ethereum are stored in a table. The column `contract_address` indicates which smart contract emitted the event. \n\nThe guide concludes by providing further reading resources on understanding event logs on the Ethereum blockchain. Overall, the guide provides a detailed explanation of event logs and how they are used in the Dune Docs project.",
          "questions": "1. What is the format of the tables that will be created for decoding event logs in Dune Docs?\n   \n   The tables for decoding event logs in Dune Docs will be named according to the schema `[projectname_blockchain].[contractName]_evt_[eventName]` for V2 Engine (Spark SQL) and `[projectname].\"[contractName]_evt_[eventName]\"` for V1 Engine (PosgreSQL).\n\n2. How can a blockchain SQL analyst access the event logs of a transaction in Etherscan?\n   \n   A blockchain SQL analyst can access the event logs of a transaction in Etherscan by opening the logs tab of the transaction.\n\n3. How are event logs stored in Dune Docs when there are multiple instances of a contract?\n   \n   When there are multiple instances of a contract, all event logs across all instances of the smart contract are collected in one table, with the `contract_address` column indicating which smart contract emitted the event."
        },
        {
          "fileName": "index.md",
          "filePath": "docs\\data tables\\decoded\\index.md",
          "url": "https://dune.com/blob/master/data tables\\decoded\\index.md",
          "summary": "The Decoded Tables guide covers the process of decoding smart contract activity into human-readable tables using the ABI (Application Binary Interface) for smart contracts and the interface standard for standardized token smart contracts (ERC20, ERC721, etc.). The guide explains how Dune creates tables for each event and function defined in the smart contract's ABI, and how every event, message call, or transaction made to that contract is decoded and inserted as a row into these tables.\n\nThe guide provides examples of table naming conventions for both V2 Engine (Spark SQL) and V1 Engine (PosgreSQL). It also explains how to identify specific smart contracts using the `contract_address` column and how to check if contracts are already decoded by querying the `[blockchain].contracts` tables.\n\nThe guide includes a section on understanding decoded data, which emphasizes the importance of analyzing events and transactions, and provides tips on how to make sense of the data. It also discusses which tables to use, suggesting that events are generally the easiest and most accessible way to analyze blockchain data, but in some cases, it might be necessary to use transaction and message calls (found in call tables).\n\nFinally, the guide provides example queries to explore decoded contracts, such as seeing all projects with decoded data, and checking for multiple instances of a contract.",
          "questions": "1. **How can I check if a specific contract has already been decoded in the Dune database?**\n\n   You can check if a contract has been decoded by querying the `[blockchain].contracts` tables through the Dune database or by using the provided dashboard links for the V2 Engine (Spark SQL) and V1 Engine (PosgreSQL) in the app technical guide.\n\n2. **How long does it take to initially decode a smart contract once it has been submitted?**\n\n   It usually takes about 24 hours to initially decode a smart contract. You can check the status of your contract's decoding process using the \"Is my Contract decoded yet?\" dashboard link provided in the app technical guide.\n\n3. **What is the difference between event tables and call tables in the decoded data?**\n\n   Event tables contain data related to events emitted by smart contracts, while call tables contain data related to transactions and message calls made between smart contracts. In most cases, analyzing events is easier and more accessible, but in some cases, you might need to use call tables for additional information or when events are not emitted."
        }
      ],
      "folders": [],
      "summary": "The Decoded Data Tables folder in the Dune Docs project focuses on providing technical guides for understanding and working with decoded smart contract activity in human-readable tables. These guides are essential for developers and analysts who want to analyze and monitor smart contract transactions and events on the Ethereum blockchain using Dune.\n\nThe folder contains three main guides:\n\n1. **Call Tables**: This guide explains how Dune parses all message calls and transactions made to smart contracts into tables named according to the project name, contract name, and function name. It provides examples of how Dune records transactions, such as when a Uniswap v3 pool gets created via the Uniswap v3 factory function `createPool`. The guide clarifies common misconceptions and highlights that only transactions broadcasted on the blockchain are recorded in Dune. This guide is useful for developers who want to understand how Dune works and how to use it to analyze smart contract transactions.\n\n2. **Event Logs**: This guide focuses on how smart contracts emit event logs when certain predefined actions are completed. It explains the schema for decoding all event logs for smart contracts into tables and provides examples using the Uniswap V3 factory. The guide also covers how event logs across multiple instances of a smart contract are collected in one table. This guide is essential for developers and analysts who want to monitor, alert, and keep track of what happens inside a smart contract, as well as analyze the data post factum.\n\n3. **Decoded Tables**: This guide covers the process of decoding smart contract activity into human-readable tables using the ABI and the interface standard for standardized token smart contracts. It explains how Dune creates tables for each event and function defined in the smart contract's ABI and provides examples of table naming conventions. The guide also includes a section on understanding decoded data and provides example queries to explore decoded contracts. This guide is crucial for analysts who want to make sense of the data and decide which tables to use for their analysis.\n\nOverall, the Decoded Data Tables folder in the Dune Docs project provides comprehensive guides for understanding and working with decoded smart contract activity in human-readable tables. These guides are essential for developers and analysts who want to analyze and monitor smart contract transactions and events on the Ethereum blockchain using Dune.",
      "questions": ""
    },
    {
      "folderName": "raw",
      "folderPath": ".autodoc\\docs\\json\\docs\\data tables\\raw",
      "url": "https://dune.com/tree/master/doc\\docs\\json\\docs\\data tables\\raw",
      "files": [
        {
          "fileName": "blocks.md",
          "filePath": "docs\\data tables\\raw\\blocks.md",
          "url": "https://dune.com/blob/master/data tables\\raw\\blocks.md",
          "summary": "# Blocks\n\nThis section of the app technical guide covers the concept of blocks in blockchains and rollups. A block is a collection of transactions that incrementally alter the state of an EVM system. Transactions within a block can only be executed one after the other, not in parallel. \n\nThe guide provides tables that are useful for identifying block activity and transaction changes over time. These tables are divided into two sections: V2 Engine (Spark SQL) and V1 Engine (PosgreSQL). Each table contains information about different chains, such as Ethereum Mainnet, Gnosis Chain, Polygon, Optimism, BNB Chain, Arbitrum, and Avalanche C-Chain. The tables also provide notes on what information is not included in each chain. \n\nThe guide also includes a section on column data, which provides a description of each column in the tables. The columns include `time`, `number`, `hash`, `parent hash`, `gas_limit`, `gas_used`, `miner`, `difficulty`, `total_difficulty`, `nonce`, `size`, and `base_fee_per_gas`. Each column has a data type and a description of what it represents. \n\nThe guide provides an example of the column data in the form of a video. The video shows how to use the tables to identify block activity and transaction changes over time. \n\nOverall, this section of the app technical guide provides a comprehensive overview of blocks in blockchains and rollups. It also provides useful tables and column data that can be used to analyze block activity and transaction changes over time.",
          "questions": "1. What is the purpose of the Dune Docs app in relation to blockchain SQL analysis?\n- The app technical guide provides information on tables and column data that can be used for identifying block activity and transaction changes over time in various chains.\n\n2. What is the difference between the V2 Engine (Spark SQL) and V1 Engine (PosgreSQL) tables?\n- The V2 Engine tables contain more chains and additional columns such as `miner`, `nonce`, and `base_fee_per_gas`, while the V1 Engine tables have fewer chains and do not contain `nonce` or `base_fee_per_gas`.\n\n3. How can the Dune Docs app be used to analyze blockchains and rollups?\n- The app provides tables and column data that can be queried using Spark SQL or PostgreSQL to analyze block activity and transaction changes over time in various chains."
        },
        {
          "fileName": "event-logs.md",
          "filePath": "docs\\data tables\\raw\\event-logs.md",
          "url": "https://dune.com/blob/master/data tables\\raw\\event-logs.md",
          "summary": "# Event Logs\n\nThis technical guide covers the `Event Logs` tables in the Dune Docs project. These tables store all logs data that gets generated by smart contracts. The purpose of this guide is to provide an understanding of how event logs work and how they can be useful for querying contracts that are not yet decoded or are not able to be decoded since the code of the smart contract is not public.\n\nThe guide explains that logs are an elegant way to store tiny amounts of data on EVM blockchains for a small amount of gas. Specifically, event logs are useful to let other people know something has happened without them having to query contracts individually. The guide also provides a link to an article for more information on this topic.\n\nThe guide then provides two tables that show the different chains and tables that are available in the Dune Docs project. The first table shows the V2 Engine (Spark SQL) and the second table shows the V1 Engine (PosgreSQL). Each table lists the chain, table, and any notes that may be relevant.\n\nFinally, the guide provides a detailed description of the column data that is available in the Event Logs tables. The description includes the column name, data type, and a brief explanation of what the column represents. An example is also provided to help users understand how the data is structured.\n\nOverall, this technical guide provides a comprehensive overview of the Event Logs tables in the Dune Docs project. It explains how event logs work, how they can be useful, and provides detailed information on the available data.",
          "questions": "1. What is the purpose of the Event Logs tables in this app and how are they useful for blockchain analysis?\n   \n   The Event Logs tables store all logs data generated by smart contracts and are useful for querying contracts that are not yet decoded or are not able to be decoded since the code of the smart contract is not public. They are also useful for letting other people know something has happened without them having to query contracts individually.\n\n2. What engines are used for this app and what are the differences between them?\n   \n   The app uses two engines: V2 Engine (Spark SQL) and V1 Engine (PosgreSQL). The main difference between them is the type of SQL used: Spark SQL for V2 and PostgreSQL for V1.\n\n3. What kind of data is stored in the Event Logs tables and what are some examples of the columns?\n   \n   The Event Logs tables store data such as the contract address, keccak256 hash of a flattened event declaration string, indexed topics of the event, unindexed data containing further information on the event, transaction hash, block hash, block number, block time, and index position of the log and transaction in the block. An example of the columns can be found in the table under the \"Column Data\" section of the app technical guide."
        },
        {
          "fileName": "index.md",
          "filePath": "docs\\data tables\\raw\\index.md",
          "url": "https://dune.com/blob/master/data tables\\raw\\index.md",
          "summary": "# Raw Tables\n\nThe Raw Tables section of the Dune Docs project provides raw, unfiltered, and unedited data for querying transactions, blocks, event logs, or traces across the blockchains that Dune supports. This section is useful for obtaining meta information about the blockchain, a transaction, traces, or certain events. However, queries written using raw data tables can be difficult to understand and audit due to the nature of the encoded data commonly found in these tables. Additionally, raw data tables have a large number of rows, which can make querying slow. Therefore, it is often better to submit contracts for decoding and work with decoded data.\n\nThe EVM Raw Table Data section focuses on Ethereum Virtual Machine (EVM), which powers all chains in Dune except Solana and Bitcoin. This section includes the following subtopics:\n\n- Blocks: Blocks are the building blocks of blockchains and rollups.\n- Event Logs: Event Logs are data generated by smart contracts.\n- Traces: Traces contain information about the execution of smaller atomic actions generated by transactions.\n- Transactions: Transactions are cryptographically signed instructions from accounts.\n\nEach subtopic provides detailed information on how to query the specific data type. For example, the Blocks subtopic explains how to query block data, including block number, timestamp, and miner address. The Event Logs subtopic explains how to query event logs, including the event name, contract address, and event parameters.\n\nOverall, the Raw Tables section of the Dune Docs project provides a comprehensive guide for querying raw data tables and understanding the encoded data commonly found in these tables. It also provides guidance on when it is better to work with decoded data and how to query specific data types within the EVM Raw Table Data section.",
          "questions": "1. What types of blockchain data can be queried using raw tables in Dune Docs?\n- Raw tables in Dune Docs allow for querying of any transaction, block, event log, or trace across the blockchains that Dune supports.\n\n2. What are some challenges associated with querying raw data tables?\n- Queries written using raw data tables can be difficult to understand and audit due to the encoded data commonly found in these tables. Additionally, raw data tables have a large number of rows and can be slow to query.\n\n3. Which blockchains in Dune Docs are powered by the Ethereum Virtual Machine (EVM)?\n- All chains in Dune Docs except for Solana and Bitcoin are powered by the Ethereum Virtual Machine (EVM)."
        },
        {
          "fileName": "traces.md",
          "filePath": "docs\\data tables\\raw\\traces.md",
          "url": "https://dune.com/blob/master/data tables\\raw\\traces.md",
          "summary": "# Traces\n\nThis technical guide covers the Traces feature of the Dune Docs project. Traces tables contain information about the execution of smaller atomic actions generated by transactions. Transactions can trigger smaller atomic actions that modify the internal state of an Ethereum Virtual Machine. Information about the execution of these actions is logged and can be found stored as an EVM execution trace, or just a trace. \n\nThe guide provides information on the tables and column data of the Traces feature. The tables are divided into two engines: V2 Engine (Spark SQL) and V1 Engine (PosgreSQL). Each table contains information about the traces of different chains, such as Ethereum Mainnet, Gnosis Chain, Polygon, Optimism, BNB Chain, Arbitrum, and Avalanche C-Chain. The column data provides a detailed description of each column in the tables. \n\nThe guide also explains the gas used in `.traces`. The `gas_used` column in the `.traces` tables is a bit hard to understand, so the guide provides pointers on how to understand it. For example, the `gas_used` of a trace will always include the gas consumed by the trace and all its subtraces. \n\nFinally, the guide provides information on creation traces. One type of trace, `create`, is used to create a smart contract then transfer ether to it. The guide provides tables and column data for creation traces. \n\nOverall, this technical guide provides a comprehensive overview of the Traces feature of the Dune Docs project. \n\nExample queries are also provided in the guide. For instance, there is an example query that shows how to arrive at the \"true\" `gas_used` value. Another example query shows how to create a smart contract then transfer ether to it. \n\nNote that this guide is not a part of the Dune Docs project.",
          "questions": "1. What is the purpose of the `traces` tables in the different chains listed in the guide?\n- The `traces` tables contain information about the execution of smaller atomic actions generated by transactions in different chains.\n\n2. What is the difference between the `gas` and `gas_used` columns in the `.traces` tables?\n- The `gas` column represents the gas provided with the message call, while the `gas_used` column represents the gas consumed by the transaction in `wei`.\n\n3. What is the purpose of the `creation_traces` tables in the different chains listed in the guide?\n- The `creation_traces` tables contain information about the creation of smart contracts and the transfer of ether to them."
        },
        {
          "fileName": "transactions.md",
          "filePath": "docs\\data tables\\raw\\transactions.md",
          "url": "https://dune.com/blob/master/data tables\\raw\\transactions.md",
          "summary": "# Transactions\n\nThis section of the app technical guide covers transactions in the Ethereum network. Transactions are cryptographically signed instructions from accounts that initiate a transaction to update the state of the Ethereum network. Transactions always originate from externally owned accounts, and a smart contract cannot initiate a transaction. Transactions need to be broadcast to the whole network, and any node can broadcast a request for a transaction to be executed on the EVM. After this happens, a miner will execute the transaction and propagate the resulting state change to the rest of the network. \n\nThe section also provides a link to the official Ethereum documentation for more information on transactions.\n\n## Tables\n\nThis section provides a table that lists the different chains and tables that contain transaction data. The tables are divided into two engines: V2 Engine (Spark SQL) and V1 Engine (PosgreSQL). The table lists the chains, tables, and notes for each table. For example, the Ethereum Mainnet chain has a table named `ethereum.transactions`, and the Gnosis Chain has a table named `gnosis.transactions`.\n\n## Column Data\n\nThis section provides a table that lists the different columns and their data types for the transaction data. The table also provides a description of each column. For example, the `block_time` column is of type `_timestamptz_` and represents the time when the block was mined that includes this transaction. The `value` column is of type `_numeric_` and represents the amount of `[chain_gas_token]` sent in this transaction in `wei`. Note that ERC20 tokens do not show up here. \n\nThe section also provides an example of the column data in the form of an embedded video. \n\nOverall, this section of the app technical guide provides a comprehensive overview of transactions in the Ethereum network, including tables and column data.",
          "questions": "1. What is the purpose of the Transactions table in this app and what data does it contain?\n   \n   The Transactions table contains information about transactions on various blockchain networks, including Ethereum Mainnet, Gnosis Chain, Polygon, Optimism, BNB Chain, Arbitrum, and Avalanche C-Chain. It includes data such as the block time, block number, value, gas limit, gas price, gas used, max fee per gas, max priority fee per gas, priority fee per gas, nonce, index, success, from address, to address, block hash, data, hash, type, access list, effective gas price, gas used for L1, L1 gas used, L1 gas price, L1 fee, L1 fee scalar, L1 block number, L1 timestamp, and L1 tx origin.\n   \n2. Does this app support EIP1559 and how is it reflected in the Transactions table?\n   \n   The app supports EIP1559 on some networks, but not on others. The Transactions table includes columns for max fee per gas, max priority fee per gas, and priority fee per gas, which are introduced by EIP1559. However, for networks where EIP1559 is not supported, these columns do not contain data and the type column is always set to Legacy.\n   \n3. How is gas measured in this app and is it consistent across all networks?\n   \n   Gas is measured in wei for most networks, but for Arbitrum it is measured in ArbGas and for Avalanche C-Chain it is measured in nanoavax. Therefore, gas measurement is not consistent across all networks in this app."
        }
      ],
      "folders": [
        {
          "folderName": "bitcoin",
          "folderPath": ".autodoc\\docs\\json\\docs\\data tables\\raw\\bitcoin",
          "url": "https://dune.com/tree/master/doc\\docs\\json\\docs\\data tables\\raw\\bitcoin",
          "files": [
            {
              "fileName": "blocks.md",
              "filePath": "docs\\data tables\\raw\\bitcoin\\blocks.md",
              "url": "https://dune.com/blob/master/data tables\\raw\\bitcoin\\blocks.md",
              "summary": "# Blocks\n\nThis section of the app technical guide covers the `bitcoin.blocks` feature of the project. It provides a detailed description of the columns in the `bitcoin.blocks` table, which contains information about each block in the Bitcoin blockchain. \n\nEach column name is listed along with its corresponding data type and a description of what the column represents. For example, the `time` column represents the time at which the block was mined, while the `height` column represents the block number. \n\nThe guide also includes information about the various rewards associated with mining a block, such as the `mint_reward` and `total_reward`. Additionally, it provides details about the size of the block, the number of transactions it contains, and the difficulty of mining the block. \n\nOverall, this section of the guide is useful for developers who are working with Bitcoin data and need to understand the structure of the `bitcoin.blocks` table. \n\nExample: If a developer wants to retrieve information about the size of a particular block, they can query the `size` column in the `bitcoin.blocks` table.",
              "questions": "1. What is the purpose of the `bitcoin.blocks` table in the Dune Docs app? \n- The `bitcoin.blocks` table in the Dune Docs app contains information about Bitcoin blocks, including their time, height, hash, transaction count, size, and various rewards.\n\n2. How does the app handle updates to the `bitcoin.blocks` table? \n- The app technical guide does not provide information on how updates to the `bitcoin.blocks` table are handled.\n\n3. Can the app be used to analyze blocks from other cryptocurrencies besides Bitcoin? \n- The app technical guide does not provide information on whether the app can be used to analyze blocks from other cryptocurrencies besides Bitcoin."
            },
            {
              "fileName": "index.md",
              "filePath": "docs\\data tables\\raw\\bitcoin\\index.md",
              "url": "https://dune.com/blob/master/data tables\\raw\\bitcoin\\index.md",
              "summary": "# App Technical Guide: Bitcoin\n\nThis guide provides information on how to work with Bitcoin data in the Dune Docs project. As a non-EVM chain, Bitcoin's raw data looks different from other chains, and this guide aims to help users understand and work with this data.\n\nThe guide starts with a brief introduction to Bitcoin and provides a link to a full written guide on getting started. This is useful for users who are new to Bitcoin and want to learn more about it.\n\nThe main section of the guide is \"Data Available,\" which lists the different types of Bitcoin data that are available in the Dune Docs project. These include blocks, transactions, outputs, and inputs. Each of these data types has its own page, which provides more detailed information on how to work with that specific type of data.\n\nFor example, the \"Blocks\" page provides information on how to access and analyze Bitcoin block data, while the \"Transactions\" page provides information on how to work with Bitcoin transaction data. The \"Outputs\" and \"Inputs\" pages provide information on how to work with Bitcoin output and input data, respectively.\n\nOverall, this guide is a useful resource for anyone who wants to work with Bitcoin data in the Dune Docs project. It provides an overview of the different types of data available and links to more detailed information on each type.",
              "questions": "1. What type of data is available for analysis in this app?\n- The app provides data on blocks, transactions, outputs, and inputs for Bitcoin.\n\n2. Is this app compatible with Ethereum Virtual Machine (EVM) chains?\n- No, this app is specifically designed for non-EVM chains like Bitcoin.\n\n3. Are there any additional resources available for getting started with analyzing Bitcoin data?\n- Yes, the app provides a link to a full written guide on getting started with analyzing Bitcoin data."
            },
            {
              "fileName": "inputs.md",
              "filePath": "docs\\data tables\\raw\\bitcoin\\inputs.md",
              "url": "https://dune.com/blob/master/data tables\\raw\\bitcoin\\inputs.md",
              "summary": "The Inputs section of the app technical guide for the Dune Docs project provides a detailed description of the `bitcoin.inputs` table. This table contains information related to the inputs of Bitcoin transactions, including block time, block date, block height, index, transaction ID, spent block height, spent transaction ID, spent output number, value, address, type, coinbase, script ASM, script HEX, script description, script signature ASM, script signature HEX, sequence, and witness data. \n\nThe guide provides a table that lists each column name, data type, and a brief description of what the column represents. For example, the `block_time` column represents the time at which the block containing the input was mined, while the `value` column represents the number of Satoshis attached to the input. \n\nThe guide also provides additional information about certain columns, such as the `sequence` column, which is intended to allow unconfirmed time-locked transactions to be updated before being finalized. The guide notes that this column is not currently used except to disable locktime in a transaction. \n\nOverall, this section of the app technical guide provides developers with a comprehensive understanding of the `bitcoin.inputs` table and the information it contains. By providing detailed descriptions of each column, developers can more easily work with this data and integrate it into their applications.",
              "questions": "1. What is the purpose of this app and how does it relate to blockchain technology?\n- The app is not clearly described in this technical guide, so a blockchain SQL analyst might want to know more about its intended use and how it interacts with blockchain data.\n\n2. Are there any limitations or known issues with the data being collected in the `bitcoin.inputs` table?\n- The technical guide does not provide information on data quality or potential issues with the input data, so an analyst might want to investigate this further before using the data for analysis.\n\n3. Is there any additional documentation or support available for using this app and its associated data tables?\n- The technical guide only provides information on the `bitcoin.inputs` table, so an analyst might want to know if there are other tables or resources available for understanding the app and its data."
            },
            {
              "fileName": "outputs.md",
              "filePath": "docs\\data tables\\raw\\bitcoin\\outputs.md",
              "url": "https://dune.com/blob/master/data tables\\raw\\bitcoin\\outputs.md",
              "summary": "The app technical guide provides documentation for the `dune docs` project, specifically focusing on the `Outputs` feature of the app. The guide contains a table with detailed information on the `bitcoin.outputs` data table, which includes column names, data types, and descriptions of each column. \n\nThe `block_time` column provides the timestamp of the block, while the `block_date` column provides the date of the block. The `block_height` column provides the block number, and the `block_hash` column provides the hash of the block. The `tx_id` column provides the hash of the transaction that the output is from, and the `index` column provides the 0-indexed number of the output within the transaction. \n\nThe `value` column provides the number of Satoshis attached to the output, while the `script_asm` column provides a symbolic representation of the bitcoin's script language op-codes. The `script_hex` column provides a hexadecimal representation of the bitcoin's script language op-codes. The `address` column provides the address that owns the output, and the `type` column provides the address type of the output. \n\nThis guide is useful for developers who are working on the `Outputs` feature of the `dune docs` app. It provides a clear understanding of the data table and its columns, which can be used to build queries and analyze data. For example, a developer could use this guide to understand how to retrieve the block time and date of a specific output, or how to identify the address type of an output. \n\nOverall, the app technical guide provides a comprehensive overview of the `Outputs` feature of the `dune docs` app, making it easier for developers to work with the data and build new features.",
              "questions": "1. What data source does this app technical guide pull from to generate the `bitcoin.outputs` table?\n- This information is not provided in the app technical guide and would require further investigation or documentation.\n\n2. Can this app technical guide be used to analyze outputs from other cryptocurrencies besides Bitcoin?\n- No, this app technical guide is specifically for analyzing Bitcoin outputs and does not provide information on other cryptocurrencies.\n\n3. Is there any information provided in this app technical guide about the inputs that correspond to each output in the `bitcoin.outputs` table?\n- No, this app technical guide only provides information on the outputs themselves and does not include any information on the corresponding inputs."
            },
            {
              "fileName": "transactions.md",
              "filePath": "docs\\data tables\\raw\\bitcoin\\transactions.md",
              "url": "https://dune.com/blob/master/data tables\\raw\\bitcoin\\transactions.md",
              "summary": "The Transactions section of the Dune Docs project provides a detailed guide on the `bitcoin.transactions` feature. This guide covers the various columns that make up the transaction table, including their data types and descriptions. The table columns include block time, block date, block height, block hash, index, ID, input value, output value, fee, input count, output count, size, virtual size, is coinbase, coinbase, input, output, lock time, and hex. \n\nThe guide also provides definitions for the various structures within the input and output columns. The input structure includes fields such as value, height, tx_id, output_number, coinbase, sequence, witness_data, script_signature, and script_pub_key. The output structure includes fields such as index, value, and script_pub_key. \n\nThe guide explains that the STRUCT data type allows for representing nested hierarchical data and has key-value pairs. It is similar to a dictionary in Python and can be used to group fields together to make them more accessible. The guide also provides examples of how to work with these columns using syntax such as `input[1].witness_data[2]` or `input[3].script_pub_key.address`. \n\nOverall, this guide provides a comprehensive overview of the `bitcoin.transactions` feature, including the various columns and structures that make up the transaction table. It is a valuable resource for developers working with this feature in the Dune Docs project.",
              "questions": "1. What is the source of the data in the `bitcoin.transactions` table?\n- The app technical guide does not provide information on the source of the data in the `bitcoin.transactions` table.\n\n2. Can the `input` and `output` fields be joined to other tables in the database?\n- The app technical guide does not provide information on whether the `input` and `output` fields can be joined to other tables in the database.\n\n3. Is there any information on the frequency of updates to the data in the `bitcoin.transactions` table?\n- The app technical guide does not provide information on the frequency of updates to the data in the `bitcoin.transactions` table."
            }
          ],
          "folders": [],
          "summary": "The `.autodoc\\docs\\json\\docs\\data tables\\raw\\bitcoin` folder contains a comprehensive app technical guide for working with Bitcoin data in the Dune Docs project. The guide is divided into several sections, each focusing on a specific aspect of Bitcoin data, such as blocks, transactions, inputs, and outputs.\n\nThe `blocks.md` file provides a detailed description of the `bitcoin.blocks` table, which contains information about each block in the Bitcoin blockchain. This section is useful for developers who need to understand the structure of the `bitcoin.blocks` table and retrieve information about specific blocks, such as their size or the number of transactions they contain.\n\nThe `index.md` file serves as an introduction to the app technical guide, providing an overview of the different types of Bitcoin data available in the Dune Docs project. This file is a useful starting point for users who are new to Bitcoin and want to learn more about the data types and how to work with them.\n\nThe `inputs.md` file focuses on the `bitcoin.inputs` table, which contains information related to the inputs of Bitcoin transactions. This section is valuable for developers who need to understand the structure of the `bitcoin.inputs` table and work with input data, such as the value of an input or the block time of the block containing the input.\n\nThe `outputs.md` file provides a detailed guide on the `bitcoin.outputs` data table, which includes information about the outputs of Bitcoin transactions. This section is helpful for developers working with output data, such as retrieving the block time and date of a specific output or identifying the address type of an output.\n\nFinally, the `transactions.md` file offers a comprehensive overview of the `bitcoin.transactions` feature, including the various columns and structures that make up the transaction table. This guide is a valuable resource for developers working with transaction data, such as analyzing transaction fees or working with nested hierarchical data in the input and output columns.\n\nOverall, the app technical guide in this folder is an essential resource for developers and analysts working with Bitcoin data in the Dune Docs project. It provides a clear understanding of the different data types and structures, making it easier to build queries, analyze data, and integrate the information into various applications.",
          "questions": ""
        },
        {
          "folderName": "solana",
          "folderPath": ".autodoc\\docs\\json\\docs\\data tables\\raw\\solana",
          "url": "https://dune.com/tree/master/doc\\docs\\json\\docs\\data tables\\raw\\solana",
          "files": [
            {
              "fileName": "account-activity.md",
              "filePath": "docs\\data tables\\raw\\solana\\account-activity.md",
              "url": "https://dune.com/blob/master/data tables\\raw\\solana\\account-activity.md",
              "summary": "# Account Activity\n\nThis technical guide covers the `Solana.account_activity` table, which contains information from the transactions table focused on account usage. Each row contains all information about an account's usage in a transaction. The purpose of this guide is to provide a detailed description of the columns in the `Solana.account_activity` table and their corresponding data types.\n\nThe table contains the following columns:\n\n- `block_slot`: a `bigint` representing the slot of the block this transaction was in.\n- `block_hash`: a `string` representing the hash of the block this transaction was in.\n- `block_time`: a `timestamp` representing the timestamp that this account usage occurred.\n- `block_date`: a `date` representing the date this account usage occurred.\n- `address`: a `string` representing the address of the account, also referred to as public key.\n- `tx_index`: an `int` representing the index of this transaction in the block.\n- `tx_id`: a `string` representing the ID of the transaction in which this account usage occurred.\n- `tx_success`: a `boolean` representing whether the transaction succeeded and was committed.\n- `signed`: a `boolean` representing whether this account signed this transaction.\n- `writeable`: a `boolean` representing whether this account was granted read-write access in this transaction.\n- `pre_balance`: a `bigint` representing the balance of this account before the transaction was processed.\n- `pre_token_balance`: a `decimal` representing the token balance before the transaction was processed.\n- `post_balance`: a `bigint` representing the balance of this account after the transaction was processed.\n- `post_token_balance`: a `decimal` representing the token balance after the transaction was processed.\n- `balance_change`: a `bigint` representing the balance change that occurred as part of the transaction.\n- `token_balance_change`: a `decimal` representing the balance change that occurred as part of the transaction.\n- `token_mint_address`: a `string` representing the address the associated token address is minting from (i.e. the actual token address).\n- `token_owner_address`: a `string` representing the address that owns this token address.\n\nThis guide provides a clear understanding of the `Solana.account_activity` table and its columns. For example, if a developer wants to retrieve information about an account's usage in a transaction, they can use this table to get all the necessary information.",
              "questions": "1. What blockchain platform is this app technical guide for?\n- The app technical guide is for the Solana blockchain platform.\n\n2. What specific account information is included in the table?\n- The table contains information about an account's usage in a transaction, including its address, pre- and post-transaction balances, and token balances.\n\n3. What is the purpose of the token\\_mint\\_address and token\\_owner\\_address columns?\n- The token\\_mint\\_address column indicates the address from which the associated token is being minted, while the token\\_owner\\_address column indicates the address that owns the token address."
            },
            {
              "fileName": "blocks.md",
              "filePath": "docs\\data tables\\raw\\solana\\blocks.md",
              "url": "https://dune.com/blob/master/data tables\\raw\\solana\\blocks.md",
              "summary": "# Blocks\n\nThis section of the app technical guide focuses on the `Solana.blocks` table, which contains block data within Solana's blockchain. The purpose of this table is to identify block activity and transaction changes over time. The table includes several columns such as `hash`, `height`, `slot`, `time`, `date`, `parent_slot`, `previous_block___hash`, `total_transactions`, `successful_transactions`, and `failed_transactions`. Each column is described in detail, including the data type and a brief explanation of what it represents.\n\nFor example, the `hash` column is a string that represents the hash of the block, base-58 encoded. The `height` column is a bigint that represents the number of blocks beneath this block. The `time` column is a timestamp that represents the estimated time this block was produced. The `total_transactions` column is a bigint that represents the total number of transactions in this block, while the `successful_transactions` and `failed_transactions` columns represent the number of successful and failed transactions in this block, respectively.\n\nThe guide also includes a video that provides an overview of the `Solana.blocks` table. Additionally, there are two Solana Query examples provided: `Solana blocks over time` and `Transactions per day`. These examples demonstrate how to use the `Solana.blocks` table to analyze block activity and transaction changes over time.\n\nOverall, this section of the app technical guide provides a comprehensive overview of the `Solana.blocks` table and its columns. It also includes examples of how to use the table to analyze block activity and transaction changes over time.",
              "questions": "1. What is the purpose of the Solana.blocks table in the Dune Docs app?\n- The Solana.blocks table contains block data within Solana's blockchain and can be used to identify block activity and transaction changes over time.\n\n2. What data types are used in the Solana.blocks table?\n- The Solana.blocks table uses data types such as string, bigint, timestamp, and date.\n\n3. Are there any sample queries available for analyzing Solana.blocks data in the Dune Docs app?\n- Yes, there are sample queries available for analyzing Solana.blocks data in the Dune Docs app, such as Solana blocks over time and Transactions per day."
            },
            {
              "fileName": "index.md",
              "filePath": "docs\\data tables\\raw\\solana\\index.md",
              "url": "https://dune.com/blob/master/data tables\\raw\\solana\\index.md",
              "summary": "# Solana Technical Guide\n\nThis technical guide provides information on Solana's raw data and how it differs from other chains. It also provides details on the data available in the app and the changelog of the app.\n\n## Data Available\n\nThis section provides a list of the data available in the app. It includes the following:\n\n- Account Activity: This table contains information from the transactions table focused on account usage.\n- Blocks: Blocks are the building blocks of blockchains and rollups.\n- Rewards: This table contains data about rewards paid out on Solana.\n- Transactions: Transactions are cryptographically signed instructions from accounts.\n- Vote Transactions: This table contains the full set of vote transactions that are submitted by validators to vote on a block.\n\n## Changelog\n\nThis section provides a list of changes made to the app. It includes the following:\n\n### 2022-03-25\n\nThe `solana.account_activity` table has been updated to a new version. The new version of the table contains additional information around token activity. The following columns were added to the table:\n\n- `pre_token_balances`: The token balance before the transaction was processed.\n- `post_token_balances`: The token balance after the transaction was processed.\n- `token_balance_changes`: The balance change that occurred as part of the transaction.\n\n### 2022-03-18\n\nThe `solana.account_activity` table has been released. It contains all of the information about an accounts usage in a transaction. The table is optimized to run with WHERE address =  queries.\n\n### 2022-03-01\n\nThe `solana.transactions` table has been upgraded to a new version. The new version of the table uses cleaner array structs to make it easier to extract useful information. The vote transactions have also been split into their own table `solana.vote_transactions`, so queries using `solana.transactions` will have better performance. \n\nThis section also provides information on what the changes mean for existing queries using `solana.transactions`. It includes the following:\n\n- You won't need to check if a transaction is a vote transaction.\n- The `error_index` and `error_message` columns have been removed and merged into the `error` column.\n- Structs containing indexes to `account_keys` now include the account address directly.\n- The `pre_token_balances` and `post_token_balances` columns have changed.\n- The `instructions` column has changed.\n- The `inner_instructions` column is removed, and inner instructions have been moved into the `instructions` column.\n\nOverall, this technical guide provides a comprehensive overview of Solana's raw data and the data available in the app. It also provides information on the changes made to the app and what they mean for existing queries.",
              "questions": "1. What is Solana and how does it differ from other chains?\n- Solana is a non-EVM chain and its raw data looks different from other chains.\n\n2. What data is available in this app and what information does it provide?\n- The app provides information on account activity, blocks, rewards, transactions, and vote transactions.\n\n3. What changes were made to the `solana.transactions` table and how might it affect existing queries?\n- The `solana.transactions` table has been upgraded to a new version, with cleaner array structs and better performance for queries. However, some existing queries may break due to changes in column names and structures."
            },
            {
              "fileName": "rewards.md",
              "filePath": "docs\\data tables\\raw\\solana\\rewards.md",
              "url": "https://dune.com/blob/master/data tables\\raw\\solana\\rewards.md",
              "summary": "# Rewards\n\nThis section of the app technical guide covers the `Solana.rewards` table, which contains data about rewards paid out on Solana. Each row in the table corresponds to one reward, and one block may contain zero or more rewards. The table has several columns, including `block_slot`, which indicates the block's slot index in the ledger, `block_hash`, which is the hash of the block, `block_time`, which is the estimated time the block was produced, and `block_date`, which is the date of the event. Other columns include `commission`, which indicates the vote account commission when the reward was credited (only present for voting and staking rewards), `lamports`, which is the number of reward lamports credited or debited by the account, `pre_balance`, which is the account balance in lamports before the reward was applied, `post_balance`, which is the account balance in lamports after the reward was applied, `recipient`, which is the public key of the account that received the reward, and `reward_type`, which indicates the type of reward (e.g., \"fee\", \"rent\", \"voting\", \"staking\").\n\nAn example query for this table is provided in the guide, which can be found at [Solana rewards fee per day](https://dune.xyz/queries/391421/747012). This query likely retrieves data from the `Solana.rewards` table to calculate the daily rewards paid out on Solana.\n\nOverall, this section of the app technical guide provides information on the `Solana.rewards` table and its columns, which is useful for developers working on the rewards feature of the app.",
              "questions": "1. What is the purpose of the Solana.rewards table?\n    \n    The Solana.rewards table contains data about rewards paid out on Solana, with each row corresponding to one reward.\n\n2. What information does the commission column provide and when is it present?\n    \n    The commission column provides the vote account commission when the reward was credited, and it is only present for voting and staking rewards.\n\n3. What are the different types of rewards listed in the reward_type column?\n    \n    The different types of rewards listed in the reward_type column are \"fee\", \"rent\", \"voting\", and \"staking\"."
            },
            {
              "fileName": "transactions.md",
              "filePath": "docs\\data tables\\raw\\solana\\transactions.md",
              "url": "https://dune.com/blob/master/data tables\\raw\\solana\\transactions.md",
              "summary": "# Transactions\n\nThe Transactions section of the Dune Docs project focuses on the Solana.transactions table, which contains transaction data within Solana's blockchain. This table provides relevant data related to account, protocol, and program activity. The guide provides a detailed description of each column in the table, including the column name, column type, and description. \n\nThe guide also includes query examples that demonstrate how to use the Solana.transactions table to extract data. For example, the guide provides a query that shows the number of Solana instructions by day for DEXes. \n\nThe guide also includes several struct definitions that allow for representing nested hierarchical data and have key-value pairs. These structs can be used to group fields together to make them more accessible. The guide provides a detailed description of each struct, including the field name, data type, and description. \n\nThe token_balance struct, for example, includes the account key of the account that the token balance is provided for, the public key of the token's mint, and the derived amount from the token balance's raw amount and the number of decimals. \n\nThe instructions struct includes an ordered list of accounts to pass to the program, program input data in a base-58 string, and the account key of the program that executed this instruction. \n\nThe inner_instructions struct includes an ordered list of accounts to pass to the program, program input data in a base-58 string, and the account key of the program that executed this instruction. \n\nFinally, the error struct includes the instruction number that failed and the error message. \n\nOverall, the Transactions section of the Dune Docs project provides a comprehensive guide to the Solana.transactions table and the structs used to represent nested hierarchical data. The guide includes detailed descriptions of each column and struct, as well as query examples that demonstrate how to use the data in the table.",
              "questions": "1. What data is available in the Solana.transactions table?\n- The Solana.transactions table contains transaction data within Solana's blockchain, including relevant data related to account, protocol, and program activity.\n\n2. What is the purpose of the STRUCT data type in this app?\n- The STRUCT data type allows for representing nested hierarchical data and has key-value pairs, similar to a dictionary in Python. It can be used to group fields together to make them more accessible.\n\n3. Are there any examples of how to extract data from the token_balance field?\n- Yes, there is an example query provided in the app technical guide that shows how to extract the number of Solana instructions by day for DEXes using the token_balance field."
            },
            {
              "fileName": "vote-transactions.md",
              "filePath": "docs\\data tables\\raw\\solana\\vote-transactions.md",
              "url": "https://dune.com/blob/master/data tables\\raw\\solana\\vote-transactions.md",
              "summary": "# Vote Transactions\n\nThis section of the app technical guide covers the `Solana.vote_transactions` table, which contains the full set of vote transactions that are submitted by validators to vote on a block. This table can be joined with the non-vote transactions table to get a full breakdown of all transactions. The schema of this table is the same as the main transactions table.\n\nThe guide provides a detailed description of each column in the `Solana.vote_transactions` table, including the column name, column type, and description. Some of the key columns include:\n\n- `block_slot`: This column contains the block's slot index in the ledger.\n- `block_time`: This column contains the estimated time the block was produced.\n- `fee`: This column contains the fee charged for the transaction.\n- `success`: This column indicates whether the transaction was valid and committed.\n- `instructions`: This column contains the instructions to execute in order.\n- `signatures`: This column contains a list of base-58 encoded signatures applied to the transaction.\n\nThe guide also provides an example query that demonstrates how to use the `Solana.vote_transactions` table. The query shows how to retrieve Solana transactions from the past 30 days using Dune Analytics.\n\nOverall, this section of the app technical guide provides a comprehensive overview of the `Solana.vote_transactions` table and its columns. It is a useful resource for developers who are working with Solana transactions and need to understand the data contained in this table.",
              "questions": "1. What is the purpose of the dune docs app and how does it relate to blockchain technology?\n- The app technical guide provided does not give information on the overall purpose of the dune docs app, so a blockchain SQL analyst may want to know more about how the app relates to blockchain technology and what specific features it offers for blockchain analysis.\n\n2. How does the Solana.vote_transactions table differ from other transaction tables in the app?\n- The app technical guide provides information on the Solana.vote_transactions table, but it does not explain how it differs from other transaction tables in the app. A blockchain SQL analyst may want to know this information in order to better understand how to use the table for analysis.\n\n3. Are there any limitations or known issues with the app's data collection or analysis capabilities?\n- The app technical guide does not provide any information on limitations or known issues with the app's data collection or analysis capabilities. A blockchain SQL analyst may want to know this information in order to assess the reliability and accuracy of the data provided by the app."
            }
          ],
          "folders": [],
          "summary": "The `.autodoc\\docs\\json\\docs\\data tables\\raw\\solana` folder contains a comprehensive technical guide for various Solana data tables, which are essential for developers and analysts working with Solana blockchain data. These guides provide detailed information on the structure, columns, and data types of the tables, as well as examples of how to use them in queries and analysis.\n\nFor instance, the `account-activity.md` guide focuses on the `Solana.account_activity` table, which contains information about account usage in transactions. This guide is particularly useful for developers who want to retrieve information about an account's usage in a transaction, as it provides a clear understanding of the table and its columns.\n\nSimilarly, the `blocks.md` guide covers the `Solana.blocks` table, which contains block data within Solana's blockchain. This guide is essential for analyzing block activity and transaction changes over time. It also includes examples of Solana Query, such as `Solana blocks over time` and `Transactions per day`, demonstrating how to use the `Solana.blocks` table effectively.\n\nThe `rewards.md` guide focuses on the `Solana.rewards` table, which contains data about rewards paid out on Solana. This guide is useful for developers working on the rewards feature of the app, as it provides information on the table's columns and an example query for calculating daily rewards paid out on Solana.\n\nThe `transactions.md` guide provides a comprehensive overview of the `Solana.transactions` table and the structs used to represent nested hierarchical data. This guide is crucial for developers working with transaction data within Solana's blockchain, as it includes detailed descriptions of each column and struct, as well as query examples that demonstrate how to use the data in the table.\n\nLastly, the `vote-transactions.md` guide covers the `Solana.vote_transactions` table, which contains the full set of vote transactions submitted by validators to vote on a block. This guide is a valuable resource for developers working with Solana transactions and understanding the data contained in this table.\n\nOverall, the guides in the `.autodoc\\docs\\json\\docs\\data tables\\raw\\solana` folder provide a thorough understanding of various Solana data tables and their usage in queries and analysis. These guides are essential for developers and analysts working with Solana blockchain data and contribute significantly to the larger project feature of data tables.",
          "questions": ""
        }
      ],
      "summary": "The `.autodoc\\docs\\json\\docs\\data tables\\raw` folder contains a comprehensive app technical guide for working with raw data tables in the Dune Docs project. These guides provide detailed information on the structure, columns, and data types of the tables, as well as examples of how to use them in queries and analysis. The project feature this folder is focused on is the `data tables`.\n\nFor instance, the `blocks.md` guide covers the concept of blocks in blockchains and rollups, providing useful tables and column data that can be used to analyze block activity and transaction changes over time. This guide might be useful for analysts who want to track the growth of a specific blockchain or identify patterns in block activity.\n\nSimilarly, the `event-logs.md` guide focuses on the `Event Logs` tables, which store all logs data generated by smart contracts. This guide is particularly useful for developers who need to query contracts that are not yet decoded or are not able to be decoded since the code of the smart contract is not public.\n\nThe `traces.md` guide provides a comprehensive overview of the Traces feature, which contains information about the execution of smaller atomic actions generated by transactions. This guide might be useful for analysts who want to understand the gas usage of specific transactions or identify the creation of new smart contracts.\n\nLastly, the `transactions.md` guide offers a detailed explanation of transactions in the Ethereum network, including tables and column data. This guide is crucial for developers working with transaction data, as it includes detailed descriptions of each column and examples of how to use the data in the table.\n\nIn addition to the main folder, there are two subfolders: `bitcoin` and `solana`. The `bitcoin` subfolder contains a comprehensive app technical guide for working with Bitcoin data, covering aspects such as blocks, transactions, inputs, and outputs. The `solana` subfolder provides a thorough understanding of various Solana data tables and their usage in queries and analysis.\n\nOverall, the guides in the `.autodoc\\docs\\json\\docs\\data tables\\raw` folder provide a detailed understanding of various raw data tables and their usage in queries and analysis. These guides are essential for developers and analysts working with blockchain data and contribute significantly to the larger project feature of data tables.",
      "questions": ""
    },
    {
      "folderName": "spellbook",
      "folderPath": ".autodoc\\docs\\json\\docs\\data tables\\spellbook",
      "url": "https://dune.com/tree/master/doc\\docs\\json\\docs\\data tables\\spellbook",
      "files": [
        {
          "fileName": "index.md",
          "filePath": "docs\\data tables\\spellbook\\index.md",
          "url": "https://dune.com/blob/master/data tables\\spellbook\\index.md",
          "summary": "The app technical guide covers the Spells feature of the Dune project. Spells are custom tables that are built and maintained by Dune and the community. The guide explains that Spells are available on Dune V2 and can be queried from both Spark SQL and Dune SQL V2 Query Engines. The guide also provides a link to the Spellbook GitHub repository where the Spells can be found. \n\nThe guide explains that the Spellbook is a retooling of the existing abstractions repository and a first-in-class open-source analytics engineering tool called dbt. Abstractions are some of the most queried tables on Dune, and the Spellbook aims to make the experience of creating them better. The guide explains that dbt allows for the writing and management of unit tests to spot and prevent any issues in the abstractions. \n\nThe guide also explains that there are two types of Spells: Sector Spells and Project Spells. Sector Spells are tables that take in data from multiple contracts and projects, standardize the data across them, and make it easy to query for this data and compare the metrics of different projects with each other. Project Spells allow projects to assemble their data into one neat table that has all the data they need in one place. \n\nThe guide provides information on how to contribute to the Spellbook and how to view available Spells. It also warns that the abstractions for V1 are no longer open for contributions and will be sunsetted with the V1 engine soon. \n\nOverall, the app technical guide provides a detailed explanation of the Spells feature of the Dune project, including how to use it, how to contribute to it, and how it can benefit users.",
          "questions": "1. What is the purpose of Spells in Dune and how are they maintained?\n- Spells are custom tables that cover a type of activity on the blockchain and are built and maintained by Dune and their community.\n\n2. What is the difference between Abstractions and Spells in Dune?\n- Abstractions are snippets of SQL executed on the data platform for the V1 engine, while Spells are models or tables that can be materialized into views and tables using dbt for the V2 engine.\n\n3. How can a blockchain SQL analyst contribute to Spellbook and what are some benefits of using dbt?\n- A blockchain SQL analyst can contribute to Spellbook by creating new Spells and submitting pull requests to the public GitHub repository. Using dbt allows for classical software engineering practices to be injected into writing SQL, including managing dependencies, writing and managing unit tests, and adding data integrity tests with minimal effort."
        }
      ],
      "folders": [
        {
          "folderName": "contributing",
          "folderPath": ".autodoc\\docs\\json\\docs\\data tables\\spellbook\\contributing",
          "url": "https://dune.com/tree/master/doc\\docs\\json\\docs\\data tables\\spellbook\\contributing",
          "files": [
            {
              "fileName": "index.md",
              "filePath": "docs\\data tables\\spellbook\\contributing\\index.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\index.md",
              "summary": "The Spellbook technical guide is focused on providing information on how to cast a spell from scratch using the Spellbook app. The guide is divided into two main sections: Casting a Spell from Scratch and Video Guides. \n\nThe Casting a Spell from Scratch section provides a link to a guide on how to add a spell to the Spellbook app. This section is aimed at users who prefer to learn by doing and want to get started with the app. Additionally, the section provides a link to the Spellbook GitHub repository for users who want to take a look under the hood and understand the app's infrastructure.\n\nThe Video Guides section contains two video tutorials on how to use the Spellbook app. The first video is a DuneCon workshop by Megan Heintz, a Dune Team member, who walks users through Spellbook's infrastructure and how to migrate data to a spell. The second video tutorial is by Andrew Hong, who shows users the main protocol interactions and how to pull and transform data on Ethereum using the app. \n\nOverall, the Spellbook technical guide provides users with a comprehensive understanding of how to use the Spellbook app. The guide is aimed at users who want to learn by doing and those who want to understand the app's infrastructure. The video tutorials provide a step-by-step guide on how to use the app, making it easy for users to get started.",
              "questions": "1. What is the purpose of Spellbook and how does it relate to blockchain technology?\n   \n   The app technical guide does not provide clear information on the purpose of Spellbook or its relation to blockchain technology, so a blockchain SQL analyst might have to do further research or analysis to understand its relevance to their work.\n\n2. Are there any security considerations or vulnerabilities that need to be addressed when using Spellbook?\n\n   The app technical guide does not mention any security considerations or vulnerabilities related to Spellbook, so a blockchain SQL analyst might need to investigate further or consult with security experts to ensure the safety of their data.\n\n3. What programming languages or frameworks are used to develop Spellbook?\n\n   The app technical guide does not provide information on the programming languages or frameworks used to develop Spellbook, so a blockchain SQL analyst might need to examine the source code on GitHub or consult with the development team to understand the technical details of the app."
            }
          ],
          "folders": [
            {
              "folderName": "Adding A Spell",
              "folderPath": ".autodoc\\docs\\json\\docs\\data tables\\spellbook\\contributing\\Adding A Spell",
              "url": "https://dune.com/tree/master/doc\\docs\\json\\docs\\data tables\\spellbook\\contributing\\Adding A Spell",
              "files": [
                {
                  "fileName": "1-do-some-prerequisites and-set-up-Spellbook-dbt.md",
                  "filePath": "docs\\data tables\\spellbook\\contributing\\Adding A Spell\\1-do-some-prerequisites and-set-up-Spellbook-dbt.md",
                  "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\Adding A Spell\\1-do-some-prerequisites and-set-up-Spellbook-dbt.md",
                  "summary": "This app technical guide provides a step-by-step guide on how to set up Spellbook dbt on a local computer. The guide is divided into two main sections: prerequisites and setting up Spellbook dbt. The prerequisites section outlines the software and tools required to set up Spellbook dbt, including VSCode, Python 3.9, pip, pipenv, and git and GitHub. The section also provides links to resources for installing these tools and troubleshooting any issues that may arise.\n\nThe second section of the guide focuses on setting up Spellbook dbt. It provides instructions on how to clone the Spellbook repository, install the necessary packages, and initialize dbt. The guide also includes a sample configuration file with prompts that users can enter to configure dbt. The section concludes with instructions on how to create a new branch and push it to a remote GitHub repository.\n\nThe guide includes screenshots and a video tutorial to help users visualize the steps involved in setting up Spellbook dbt. The guide is intended for users who are new to Spellbook dbt and provides a comprehensive overview of the steps involved in setting up the tool. Overall, the guide is well-organized and easy to follow, making it an excellent resource for users who are new to Spellbook dbt.",
                  "questions": "1. What is the purpose of Spellbook and how does it relate to blockchain technology?\n   - The app technical guide does not provide information on the purpose of Spellbook or its relation to blockchain technology.\n2. Are there any specific database management systems that Spellbook dbt is compatible with?\n   - The app technical guide mentions that during the setup process, users will be prompted to choose a database management system, with Databricks being one of the options.\n3. Are there any security considerations that need to be taken into account when setting up Spellbook?\n   - The app technical guide does not provide information on any security considerations that need to be taken into account when setting up Spellbook."
                },
                {
                  "fileName": "2-decide-on-a-Spell-to-cast.md",
                  "filePath": "docs\\data tables\\spellbook\\contributing\\Adding A Spell\\2-decide-on-a-Spell-to-cast.md",
                  "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\Adding A Spell\\2-decide-on-a-Spell-to-cast.md",
                  "summary": "This app technical guide covers the process of deciding on a Spell to cast in the Dune app. The guide provides three ways to decide on a Spell, including having an idea of what abstract data is needed, looking at Spellbook bounties in Dework, or asking for suggestions in the #spellbook Discord channel. The guide then provides an example of creating a migration Spell for translating the Keep3r network view_job_log abstraction from Dune's v1 database into a V2 Spell.\n\nThe guide also includes a note that Dune V1 Abstractions have been moved to a new repository, which needs to be cloned to access the code for migrating a V1 Abstraction to a Spell. The guide provides the full path to the view_job_log.sql file, which is needed to set up the file structure for the Spell's SQL schema and source files.\n\nOverall, this guide provides a step-by-step process for deciding on a Spell to cast and creating a migration Spell in the Dune app. It also includes helpful links and examples to guide users through the process.",
                  "questions": "1. What is the purpose of the Dune Docs app and how does it relate to blockchain technology? \n   - The app technical guide does not provide information on the purpose of the Dune Docs app or its relation to blockchain technology.\n2. How does the migration Spell mentioned in the guide interact with blockchain data? \n   - The app technical guide does not provide information on how the migration Spell interacts with blockchain data.\n3. Are there any security considerations or best practices that should be followed when creating Spells in Dune? \n   - The app technical guide does not provide information on security considerations or best practices for creating Spells in Dune."
                },
                {
                  "fileName": "3-set-up-your-file-structure-for-SQL-schema-and-source-files.md",
                  "filePath": "docs\\data tables\\spellbook\\contributing\\Adding A Spell\\3-set-up-your-file-structure-for-SQL-schema-and-source-files.md",
                  "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\Adding A Spell\\3-set-up-your-file-structure-for-SQL-schema-and-source-files.md",
                  "summary": "This technical guide provides instructions on how to set up the file structure for SQL, schema, and source files in the Dune Docs project. The guide explains that all Spells are stored in the `/spellbook/models` directory by project name and blockchain network. The folder names are all lowercase, and words are separated by underscores. The guide provides an example of the folder structure for the Keep3r network, where the folder is `/spellbook/models/keep3r_network/ethereum`. \n\nThe guide explains that if the project folder exists but a Spell is being created for a new blockchain, a folder for the new blockchain should be created. The guide then explains that three files need to be created: a `.sql` file for the Spell's logic, a `_schema.yml` file to define the Spell's purpose and add generic tests, descriptions, metadata, etc., and a `_sources.yml` file with any project-specific table dependencies. The guide provides an example of the file structure for a Spell folder. \n\nThe guide also explains the naming convention for Spell files. Schema files are named `[project_name]_[blockchain]_schema.yml`, sources files are named `[project_name]_[blockchain]_sources.yml`, and SQL files for Spells are named `[project_name]_[blockchain]_[spell_name].sql`. \n\nThe guide then provides an example of a specific v1 migration example where three additional `.sql` files are needed for a Spell called `keep3r_network_ethereum_view_job_log.sql`. The guide explains that these files are needed because the original `view_job_log.sql` V1 Abstraction has two `FROM` statements that reference two other files that are also abstractions that need to be converted into Spells. The guide also explains that a recursive check needs to be done to see if those abstractions depend on any other abstractions that have yet to be migrated to Spells. \n\nOverall, this technical guide provides a clear and detailed explanation of how to set up the file structure for Spells in the Dune Docs project. It provides examples and naming conventions for the different types of files needed for Spells and explains how to handle dependencies between Spells.",
                  "questions": "1. What is the purpose of the app and how does it relate to blockchain technology?\n   Answer: The app technical guide is focused on setting up a file structure for SQL, schema, and source files for a project that involves blockchain networks. A blockchain SQL analyst might want to know more about the specific use case of the project and how it utilizes blockchain technology.\n\n2. What are the naming conventions for the files and folders in the app?\n   Answer: The app technical guide provides specific naming conventions for the files and folders used in the project. A blockchain SQL analyst might want to know more about these conventions to ensure consistency and organization in their work.\n\n3. How does the app handle dependencies between different files and abstractions?\n   Answer: The app technical guide explains how to identify and handle dependencies between different files and abstractions in the project. A blockchain SQL analyst might want to know more about this process to ensure that all necessary files and abstractions are properly migrated to Spells."
                },
                {
                  "fileName": "4-identify-and-define-sources.md",
                  "filePath": "docs\\data tables\\spellbook\\contributing\\Adding A Spell\\4-identify-and-define-sources.md",
                  "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\Adding A Spell\\4-identify-and-define-sources.md",
                  "summary": "This app technical guide covers the process of identifying and defining sources in the Dune Docs project. The guide provides instructions on how to complete the `_sources.yml` file, which is used to specify the sources of data for the project. The file is formatted using YAML syntax, and it contains information about the version of the engine used, the name and description of the source, and the tables associated with the source.\n\nThe guide explains how to identify the sources that need to be named by searching for `FROM` statements in the V1 abstractions that are being migrated. The tables mentioned in these statements that are not abstractions are the ones that need to be included in the `_sources.yml` file. The guide provides an example of how to create a `keep3r_network_ethereum_sources.yml` file, which includes a description of the Keep3r Network, a marketplace for posting and accepting jobs to help run decentralized infrastructure. The file lists the tables associated with the source, such as `Keep3r_evt_LiquidityAddition` and `Keep3r_evt_KeeperWork`.\n\nOverall, this guide is essential for developers working on the Dune Docs project, as it provides clear instructions on how to identify and define sources of data. By following the steps outlined in the guide, developers can ensure that the project is properly structured and that the data is accurately represented.",
                  "questions": "1. What is the purpose of the `_sources.yml` file in the Dune Docs project?\n    \n    The `_sources.yml` file in the Dune Docs project is used to identify and define sources for the project's data.\n\n2. How are the sources formatted in the `_sources.yml` file?\n    \n    The sources in the `_sources.yml` file are formatted with a name, a one-line description, and a list of tables.\n\n3. How can a blockchain SQL analyst determine which sources to name in the `_sources.yml` file?\n    \n    A blockchain SQL analyst can determine which sources to name in the `_sources.yml` file by searching for `FROM` statements in the V1 abstractions being migrated and looking for all tables mentioned that are not abstractions."
                },
                {
                  "fileName": "6-write-your-spell-as-SELECT-statement.md",
                  "filePath": "docs\\data tables\\spellbook\\contributing\\Adding A Spell\\6-write-your-spell-as-SELECT-statement.md",
                  "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\Adding A Spell\\6-write-your-spell-as-SELECT-statement.md",
                  "summary": "This technical guide is focused on the app feature of the Dune Docs project. The guide provides a step-by-step process for writing a Spell as a SELECT statement. The guide starts by explaining that the endpoint is `_view_job_log.sql`, but the lowest-level dependency is `_view_job_migrations.sql`. The guide then explains that the process of migrating from V1 abstraction to V2 Spell starts by copying the contents of the V1 file to the `keep3r_network_ethereum_view_job_migrations.sql` file. The guide then explains how to modify the syntax from V1 abstraction style to V2 Spell style. \n\nThe guide also explains how to replace hard-coded references with JINJA templating. The guide clarifies that sources are data that have been added by the Dune team, while models are the `SELECT` statements defined in the `.sql` files stored inside the `spellbook/models` directory. The guide provides examples of how to format references to sources and models using JINJA templating. \n\nThe guide emphasizes the importance of testing each SQL file individually and fixing any errors before adding JINJA templating. The guide also provides tips on how to fix errors, including googling the error message or asking for help in the community Discord channel. \n\nOverall, this technical guide provides a detailed explanation of how to write a Spell as a SELECT statement and how to replace hard-coded references with JINJA templating. The guide is well-organized and easy to follow, making it a useful resource for developers working on the Dune Docs app.",
                  "questions": "1. What is the purpose of the dune docs app?\n- The app technical guide does not provide information on the purpose of the dune docs app.\n\n2. What programming languages or technologies are used in this app?\n- The app technical guide mentions the use of SQL, PostgreSQL, Spark SQL, and JINJA templating.\n\n3. What is the process for migrating from V1 abstraction to V2 Spell style?\n- The app technical guide provides a detailed process for migrating from V1 abstraction to V2 Spell style, which involves modifying the syntax to Spark SQL, replacing hard-coded references with JINJA templating, and testing the SQL code in dune.com."
                },
                {
                  "fileName": "7-configure-alias-and-materialization-strategy.md",
                  "filePath": "docs\\data tables\\spellbook\\contributing\\Adding A Spell\\7-configure-alias-and-materialization-strategy.md",
                  "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\Adding A Spell\\7-configure-alias-and-materialization-strategy.md",
                  "summary": "This technical guide covers the configuration of aliases and materialization strategies in the dune docs project. The guide explains how to configure aliases for Spells, which are SQL files that contain logic for data transformation, and how to specify the materialization strategy for each Spell. The guide also provides an overview of the four materialization strategies available in dbt, which are table, ephemeral, view, and incremental. \n\nThe `view` materialization strategy is the default in Spellbook, and it is used to store SQL logic without additional data. The `incremental` materialization strategy, on the other hand, allows dbt to insert or update records in a table according to the defined logic. The guide provides an example of how to create an incremental Spell by specifying the partition column, materialization type, and incremental strategy. \n\nTo configure aliases and materialization, the guide explains how to add configuration to the top of each SQL file. The configuration includes an alias for the Spell file that appears in the dune.com UI, as well as how the file is stored and categorized in the UI. The guide provides an example of how to configure aliases for a `view` materialization strategy. \n\nFinally, the guide explains how to add new models to the `dbt_project.yml` file in the Spellbook root folder. The models section specifies the project name, schema, and materialization strategy for the project as a whole, as well as the specific blockchain(s) that the Spells are created for. \n\nOverall, this guide provides a comprehensive overview of how to configure aliases and materialization strategies in the dune docs project. It is a useful resource for developers who are working on the app, API, data tables, or query features of the project.",
                  "questions": "1. What are the available materialization strategies in dbt and which ones does Spellbook use?\n   \n   Answer: There are 4 materialization strategies in dbt: `table`, `ephemeral`, `view`, and `incremental`. Spellbook uses `view` and `incremental`.\n   \n2. How can an `incremental` Spell be created and what are the benefits of using it?\n\n   Answer: An `incremental` Spell can be created by including specific configuration statements in the Config section of the SQL file. The benefits of using it are faster run times, though the data won't be as fresh as `view` Spells.\n   \n3. How can aliases and materialization be configured for a Spell and where should this configuration be added?\n\n   Answer: Aliases and materialization can be configured for a Spell by adding configuration statements to the top of each SQL file. This configuration assumes a `view` materialization strategy. It should be added to the top of each SQL file."
                },
                {
                  "fileName": "8-make-a-pull-request-get-merged-become-an-archwizard.md",
                  "filePath": "docs\\data tables\\spellbook\\contributing\\Adding A Spell\\8-make-a-pull-request-get-merged-become-an-archwizard.md",
                  "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\Adding A Spell\\8-make-a-pull-request-get-merged-become-an-archwizard.md",
                  "summary": "This section of the app technical guide covers the process of submitting a pull request to the official Spellbook in the Dune Docs project. The guide provides step-by-step instructions on how to commit local changes to a GitHub fork of the Spellbook and then submit a pull request. \n\nThe guide also includes a screenshot of the \"Open pull request\" button on the GitHub page and advises users to give their pull request an appropriate message. It also notes that comments from the team may be received and that improvements may need to be made before the pull request is approved. \n\nThe purpose of this guide is to help users contribute to the Spellbook and become Dune Archwizards. It is relevant to the app folder of the project as it pertains to the process of submitting changes to the app's codebase. \n\nAn example of how this guide could be useful is if a user has made changes to the Spellbook and wants to contribute those changes to the official version. By following the steps outlined in the guide, the user can ensure that their changes are properly submitted and reviewed by the team before being merged into the official Spellbook.",
                  "questions": "1. What is the purpose of the Spellbook and how does it relate to blockchain technology?\n   \n   The app technical guide does not provide information on the purpose of the Spellbook or its relation to blockchain technology.\n\n2. Are there any specific coding languages or frameworks required to contribute to the Spellbook?\n\n   The app technical guide does not provide information on any specific coding languages or frameworks required to contribute to the Spellbook.\n\n3. Is there a review process for pull requests and who is responsible for reviewing them?\n\n   The app technical guide mentions that there is a review process for pull requests and that the Team provides comments for improvements, but it does not provide information on who is responsible for reviewing the pull requests."
                },
                {
                  "fileName": "index.md",
                  "filePath": "docs\\data tables\\spellbook\\contributing\\Adding A Spell\\index.md",
                  "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\Adding A Spell\\index.md",
                  "summary": "This technical guide is titled \"How to Cast a Spell\" and is focused on the Spellbook feature of the Dune Docs project. The guide explains what Spellbook is, why it is used, and how to use it. Spellbook is an open-source dbt repository that allows users to create and maintain high-level blockchain data tables using SQL and Jinja templating. It enables the community to build towards a standardized way to transform data into meaningful abstraction layers. \n\nThe guide explains that blockchain data is packaged in blocks, which is one form of data we call \"Raw\" in Dune. Spellbook lets users create abstracted data sets, like dex.trades and nft.trades, which aggregate and organize raw data from multiple sources to make it much easier to query. The guide provides examples of how to use Spellbook to analyze blockchain data and how it can save time and effort.\n\nThe guide also provides an overview of the nft.trades Spell, which allows users to see industry-wide stats like total volume by # of txs and $USD, 24-hr volume, 24-hour and 7-day growth, market share by marketplace, volume by marketplace, and transaction count by marketplace. The guide explains how Spellbook can be used to make data more transparent, accessible, and meaningful together.\n\nThe guide provides 8 steps to casting a Spell, which includes doing some prerequisites and setting up Spellbook dbt, deciding on a Spell to cast, setting up the file structure for SQL, schema, and source files, identifying and defining sources, defining expectations with schema and tests, writing the Spell as a SELECT statement, configuring alias and materialization strategy, and making a pull request, getting merged, and becoming an Archwizard. \n\nOverall, this technical guide provides a comprehensive overview of Spellbook and how to use it to analyze blockchain data. It is a useful resource for anyone looking to work with blockchain data and wants to learn how to use Spellbook to make the process easier and more efficient.",
                  "questions": "1. What is Spellbook and how does it relate to blockchain data analytics?\n   \n   Spellbook is an open-source dbt repository that allows for the creation and maintenance of high-level blockchain data tables using SQL and Jinja templating. It enables the community to build towards a standardized way to transform data into meaningful abstraction layers, making it much easier to query and analyze blockchain data.\n\n2. How does the nft.trades Spell work and what insights can it provide for blockchain data analysts?\n   \n   The nft.trades Spell allows for the querying of industry-wide stats such as total volume by number of transactions and USD, 24-hour volume, 24-hour and 7-day growth, market share by marketplace, volume by marketplace, and transaction count by marketplace. It provides insights into the performance of NFT marketplaces and can be used to create dashboards and visualizations for analysis.\n\n3. What are the steps to casting a Spell and how can it benefit the web3 data community?\n   \n   The 8 steps to casting a Spell include prerequisites and setting up Spellbook dbt, deciding on a Spell to cast, setting up file structure for SQL, schema, and source files, identifying and defining sources, defining expectations with schema and tests, writing the Spell as a SELECT statement, configuring alias and materialization strategy, and making a pull request to become an Archwizard. Casting a Spell can benefit the web3 data community by allowing for the creation of standardized abstraction layers and making blockchain data more transparent, accessible, and meaningful for analysis."
                }
              ],
              "folders": [],
              "summary": "The \"Adding A Spell\" folder in the Dune Docs project is focused on guiding users through the process of creating and contributing a new Spell to the Spellbook feature. The Spellbook is an open-source dbt repository that allows users to create and maintain high-level blockchain data tables using SQL and Jinja templating. It enables the community to build towards a standardized way to transform data into meaningful abstraction layers.\n\nThe guide in this folder covers various aspects of creating a new Spell, including setting up prerequisites and the Spellbook dbt environment, deciding on a Spell to cast, setting up the file structure for SQL, schema, and source files, identifying and defining sources, defining expectations with schema and tests, writing the Spell as a SELECT statement, configuring alias and materialization strategy, and making a pull request to contribute the Spell to the official Spellbook.\n\nThis guide is particularly useful for developers and analysts who want to contribute to the Dune Docs project by creating new Spells or migrating existing V1 abstractions to V2 Spells. By following the steps outlined in the guide, users can ensure that their Spells are properly structured, tested, and submitted for review by the Dune Docs team.\n\nFor example, a user might want to create a new Spell that aggregates data from multiple sources to analyze the performance of a specific decentralized finance (DeFi) protocol. By following the guide, the user can set up the necessary environment, create the required files, write the SQL logic, and submit their Spell for review and potential inclusion in the official Spellbook.\n\nOverall, the \"Adding A Spell\" folder provides a comprehensive and detailed guide for users who want to contribute to the Dune Docs project by creating and submitting new Spells. The guide is well-organized and easy to follow, making it an excellent resource for users who are new to the Spellbook feature or the Dune Docs project as a whole.",
              "questions": ""
            },
            {
              "folderName": "examples",
              "folderPath": ".autodoc\\docs\\json\\docs\\data tables\\spellbook\\contributing\\examples",
              "url": "https://dune.com/tree/master/doc\\docs\\json\\docs\\data tables\\spellbook\\contributing\\examples",
              "files": [
                {
                  "fileName": "daily-aggregation.md",
                  "filePath": "docs\\data tables\\spellbook\\contributing\\examples\\daily-aggregation.md",
                  "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\examples\\daily-aggregation.md",
                  "summary": "# Daily Aggregation\n\nThis technical guide covers the Daily Aggregation feature of the Dune Docs project. The Daily Aggregation feature sums all transfers for the day. The table is materialized as an incrementally loaded table updated every 15 minutes because the next step includes a slower `window` function to capture a rolling sum.\n\nThe guide explains the novel components that make this Spell incremental. The `<div data-gb-custom-block data-tag=\"if\"> </div>` JINJA block allows the addition of an arbitrary filter when running in incremental mode. Incremental mode is default, and a full refresh is denoted by a command-line argument to completely recreate the table. The block is used to filter for all data timestamped in the last two days. The model runs every fifteen minutes, but a look back of 2 days is allowed to account for data arriving late from the blockchain.\n\nThe guide also explains the use of refs in this spellset. A ref, like `{{ ref('tokens_ethereum_erc20') }}` is a reference to another model in the DBT project. The ref references the name of the file itself. That means, duplicate file names are not allowed.\n\nThe guide provides an example of the `transfers_ethereum_erc20_agg_day.sql` file, which contains the SQL code for the Daily Aggregation feature. The file uses the `config` function to set the alias, materialized, file format, incremental strategy, and unique key. The SQL code selects the blockchain, date truncated to the day, wallet address, token address, symbol, sum of the amount_raw, sum of the amount_raw divided by power(10, t.decimals), and unique_transfer_id. The file also uses the `left join` function to join the `transfers_ethereum_erc20` and `tokens_ethereum_erc20` tables. The `where` function is used to filter the data timestamped in the last two days. The `group by` function is used to group the data by date truncated to the day, wallet address, token address, t.symbol, and unique_tx_id.\n\nThe guide also provides an example of the `transfers_ethereum_schema.yml` file, which contains the schema for the Daily Aggregation feature. The file includes the name, meta, config, and columns of the table. The columns include blockchain, hour, wallet_address, token_address, symbol, amount_raw, amount, and amount_usd.\n\nIn summary, the Daily Aggregation feature of the Dune Docs project is an incrementally loaded table updated every 15 minutes that sums all transfers for the day. The feature uses a JINJA block to add an arbitrary filter when running in incremental mode and refs to reference another model in the DBT project. The `transfers_ethereum_erc20_agg_day.sql` file contains the SQL code for the feature, while the `transfers_ethereum_schema.yml` file contains the schema for the feature.",
                  "questions": "1. What is the purpose of the \"incremental\" mode and how does it work?\n    \n    The \"incremental\" mode is used to update the table every 15 minutes with new data. It is the default mode and allows for a look back of 2 days to account for late data from the blockchain. A full refresh is denoted by a command line arg to completely recreate the table.\n    \n2. How does the app handle duplicates in the table and what is the unique key used for deduplication?\n    \n    The app uses a \"merge\" incremental strategy to handle duplicates in the table. The unique key used for deduplication is the `'unique_transfer_id'` which is created by coalescing several transfer features together.\n    \n3. What is a \"ref\" in this app and how is it used?\n    \n    A \"ref\" is a reference to another model in the DBT project. It references the name of the file itself and is used to avoid duplicate file names. In this app, it is used to reference the transfers and tokens models in the Ethereum ERC20 project."
                },
                {
                  "fileName": "final-day-balance.md",
                  "filePath": "docs\\data tables\\spellbook\\contributing\\examples\\final-day-balance.md",
                  "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\examples\\final-day-balance.md",
                  "summary": "# Final Daily Balance\n\nThis technical guide is focused on the `app` folder of the Dune Docs project. The guide explains the final daily Ethereum ERC20 token balances spell. The spell is expanded to cover all days, not just the days with transfer activity. The guide also explains how price data is added, known rebase tokens are removed, and any tokens that resulted in large negative balances are removed.\n\nThe `balances_ethereum_erc20_day.sql` file contains the SQL code for the spell. The code uses the `transfers_ethereum_erc20_rolling_day` table to derive the `balances_ethereum_erc20_noncompliant` table. The `balances_ethereum_erc20_noncompliant` table looks for unique token addresses with larger negative balances, which indicate the contract may not be compliant with ERC20. The `tokens_ethereum_rebase` table is a static list of known rebase tokens that are managed.\n\nThe SQL code in `balances_ethereum_erc20_day.sql` calculates the daily token balances of ERC20 Ethereum tokens per wallet and contract address pair. The code uses the `prices` table to calculate the amount in USD. The code also removes rebase tokens from balances and likely non-compliant tokens due to negative balances.\n\nThe `transfers_ethereum_schema.yml` file contains the schema for the `balances_ethereum_erc20_day` table. The table has columns for the blockchain, day, wallet address, token address, amount raw, amount, amount USD, and symbol.\n\nOverall, this technical guide provides a detailed explanation of the final daily Ethereum ERC20 token balances spell and how it works. It also explains the tables used and how they are derived. The guide is useful for developers who want to understand how the spell works and how to use it in their projects.",
                  "questions": "1. What is the purpose of the `transfers_ethereum_erc20_rolling_day` table and how is it used in the `balances_ethereum_erc20_day` query?\n   \n   The blockchain SQL analyst might want to know more about the `transfers_ethereum_erc20_rolling_day` table and how it is used in the `balances_ethereum_erc20_day` query to understand how daily token balances are calculated.\n\n2. How are rebase tokens identified and removed from the final daily Ethereum ERC20 token balances spell?\n   \n   The blockchain SQL analyst might want to know more about how rebase tokens are identified and removed from the final daily Ethereum ERC20 token balances spell to understand how the spell handles these types of tokens.\n\n3. What is the significance of the `balances_ethereum_erc20_noncompliant` table and how is it derived?\n   \n   The blockchain SQL analyst might want to know more about the `balances_ethereum_erc20_noncompliant` table and how it is derived to understand how the spell identifies non-compliant ERC20 tokens."
                },
                {
                  "fileName": "index.md",
                  "filePath": "docs\\data tables\\spellbook\\contributing\\examples\\index.md",
                  "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\examples\\index.md",
                  "summary": "This app technical guide covers the Spellbook Examples for the Dune Docs project. The Spellbook Examples are a series of modular spells that demonstrate how to track daily balances for ERC-20 tokens that follow a contract standard set by the Ethereum Foundation. The guide begins by introducing ERC-20 tokens and the need to identify transfers to track daily balances. The main base Dune table used for this purpose is `erc20_ethereum.evt_Transfer`, which can be found via the data explorer.\n\nThe guide then goes on to describe the modular spells that make up the Spellbook Examples. The first spell is the Reformatted transfers spell, which reformats the data from the `evt_Transfer` table to make it easier to work with. The second spell is the Daily aggregation of transfers spell, which aggregates the transfers on a daily basis. The third spell is the Rolling sum of daily transfers spell, which calculates the rolling sum of daily transfers. The final spell is the Final daily balances for Ethereum ERC20 tokens spell, which calculates the final daily balances for the ERC-20 tokens.\n\nEach spell is described in detail, with examples and screenshots where appropriate. The guide is focused on the app folder of the project and provides a high-level overview of the purpose of each spell and how it applies to the app. Overall, this guide serves as a useful resource for developers looking to track daily balances for ERC-20 tokens using the Dune Docs app.",
                  "questions": "1. What is the purpose of the Dune table `erc20_ethereum.evt_Transfer` and how does it relate to blockchain data analysis? \n   - The Dune table `erc20_ethereum.evt_Transfer` is used to track daily balances of ERC-20 tokens and is a key component in analyzing blockchain data related to token transfers.\n2. How does the Spellbook Examples module break down the analysis of ERC-20 tokens? \n   - The Spellbook Examples module breaks down the analysis of ERC-20 tokens into a series of modular spells, including reformatted transfers, daily aggregation, rolling sum, and final daily balances.\n3. Is this app technical guide specific to Ethereum or can it be applied to other blockchain platforms? \n   - The app technical guide specifically references ERC-20 tokens and the Ethereum Foundation, so a blockchain SQL analyst may wonder if the techniques and tools described can be applied to other blockchain platforms and token standards."
                },
                {
                  "fileName": "reformatted.md",
                  "filePath": "docs\\data tables\\spellbook\\contributing\\examples\\reformatted.md",
                  "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\examples\\reformatted.md",
                  "summary": "The app technical guide is focused on the Reformatted Transfers feature of the Dune Docs project. The guide explains how the base table records the transfer amount to and from an account, and how it is munged into a union of sent transactions and received transactions to make it easier to sum up transfers. The guide also explains how WETH requires special handling, and how `zeroex_ethereum.weth9_evt_deposit` is added as a source to the model. \n\nThe guide further explains that the model is defined in a YAML file, where things like the description, tests, and metadata are defined. The guide also highlights that the JINJA config block defines that the alias for this view is `erc20`, and without this alias, the table name would default to the file name. The schema name for this view is defined in the `dbt_project.yml` file in the root of the Spellbook project. \n\nThe guide provides examples of the SQL code for the `transfers_ethereum_erc20` model, the YAML file for the model, and the `dbt_project.yml` file. The SQL code shows how the sent transfers, received transfers, deposited WETH, and withdrawn WETH are selected and unioned to create the `transfers_ethereum_erc20` model. The YAML file shows the metadata, description, and columns for the `transfers_ethereum_erc20` model. The `dbt_project.yml` file shows the schema and materialized view for the `transfers` and `ethereum` models. \n\nOverall, the app technical guide provides a detailed explanation of the Reformatted Transfers feature of the Dune Docs project, including how it works, how it is defined, and how it is implemented. The guide is useful for developers who want to understand how the feature works and how to use it in their own projects.",
                  "questions": "1. What is the purpose of the `unique_tx_id` field in the SQL query?\n   \n   The `unique_tx_id` field is used to identify unique transactions and avoid duplicates in the table.\n\n2. How are contributors tracked in the YAML file?\n   \n   Contributors are tracked in the YAML file using the `contributors` field, where they can add their handle when writing or editing a spell.\n\n3. How is the schema name for this view defined in the project?\n   \n   The schema name for this view is defined in the `dbt_project.yml` file in the root of the Spellbook project, where schemas are defined by the directory structure."
                },
                {
                  "fileName": "rolling-sum.md",
                  "filePath": "docs\\data tables\\spellbook\\contributing\\examples\\rolling-sum.md",
                  "url": "https://dune.com/blob/master/data tables\\spellbook\\contributing\\examples\\rolling-sum.md",
                  "summary": "# Rolling Sum of Daily Transfers\n\nThis section of the app technical guide covers the rolling sum of daily transfers feature of the Dune Docs project. The purpose of this feature is to apply a rolling sum window function to each daily transfer sum. The query for this feature is provided in the `transfers_ethereum_erc20_rolling_day.sql` file. The query selects the blockchain, day, wallet address, token address, symbol, last updated timestamp, recency index, and the sum of the raw amount and amount of the ERC20 token held. \n\nThe `transfers_ethereum_schema.yml` file contains the schema for the `transfers_ethereum_erc20_rolling_hour` table. This table includes columns for the blockchain, hour, wallet address, token address, symbol, amount raw, amount, amount in USD, updated at timestamp, and recency index. \n\nThe purpose of these files is to provide the necessary code and schema for the rolling sum of daily transfers feature. The `transfers_ethereum_erc20_rolling_day.sql` file provides the query for the feature, while the `transfers_ethereum_schema.yml` file provides the schema for the table that stores the results of the query. \n\nOverall, this section of the app technical guide provides developers with the necessary information to implement the rolling sum of daily transfers feature in the Dune Docs project.",
                  "questions": "1. What is the purpose of the Rolling Sum of Daily Transfers query in the context of blockchain SQL analysis?\n- The Rolling Sum of Daily Transfers query is used to apply a rolling sum window function to each daily transfer sum in order to calculate the amount of ERC20 tokens held by each wallet/contract pair.\n\n2. How does the Rolling Sum of Daily Transfers query handle missing data?\n- The Rolling Sum of Daily Transfers query fills in all the missing days and does a few more clean up steps in order to ensure accurate calculations.\n\n3. What information is included in the transfers_ethereum_erc20_rolling_hour schema?\n- The transfers_ethereum_erc20_rolling_hour schema includes information such as the blockchain, hour, wallet address, token address, ERC20 token symbol, rolling sum of raw amount of ERC20 token held, rolling sum of amount of ERC20 token held in USD, UTC timestamp when table was last updated, and recency index."
                }
              ],
              "folders": [],
              "summary": "This section of the app technical guide focuses on the Spellbook Examples for the Dune Docs project, specifically covering the daily aggregation of transfers, final daily balances, reformatted transfers, and rolling sum of daily transfers features. These modular spells demonstrate how to track daily balances for ERC-20 tokens that follow a contract standard set by the Ethereum Foundation. The guide is particularly useful for developers looking to track daily balances for ERC-20 tokens using the Dune Docs app.\n\nThe **Daily Aggregation** feature sums all transfers for the day and is incrementally loaded every 15 minutes. The guide explains the use of JINJA blocks and refs in this spellset, as well as providing examples of the `transfers_ethereum_erc20_agg_day.sql` file and the `transfers_ethereum_schema.yml` file.\n\nThe **Final Daily Balance** feature calculates the final daily Ethereum ERC20 token balances per wallet and contract address pair. The guide explains how price data is added, known rebase tokens are removed, and any tokens that resulted in large negative balances are removed. Examples of the `balances_ethereum_erc20_day.sql` file and the `transfers_ethereum_schema.yml` file are provided.\n\nThe **Reformatted Transfers** feature reformats the data from the `evt_Transfer` table to make it easier to work with. The guide explains how WETH requires special handling and how `zeroex_ethereum.weth9_evt_deposit` is added as a source to the model. Examples of the SQL code for the `transfers_ethereum_erc20` model, the YAML file for the model, and the `dbt_project.yml` file are provided.\n\nThe **Rolling Sum of Daily Transfers** feature applies a rolling sum window function to each daily transfer sum. The guide provides examples of the `transfers_ethereum_erc20_rolling_day.sql` file and the `transfers_ethereum_schema.yml` file.\n\nIn summary, this section of the app technical guide offers a comprehensive understanding of the Spellbook Examples for the Dune Docs project, focusing on the daily aggregation of transfers, final daily balances, reformatted transfers, and rolling sum of daily transfers features. The guide is beneficial for developers who want to implement these features in their own projects and gain a deeper understanding of how they work within the Dune Docs app.",
              "questions": ""
            }
          ],
          "summary": "The guide in the `Adding A Spell` folder is focused on guiding users through the process of creating and contributing a new Spell to the Spellbook feature within the Dune Docs project. The Spellbook is an open-source dbt repository that allows users to create and maintain high-level blockchain data tables using SQL and Jinja templating. It enables the community to build towards a standardized way to transform data into meaningful abstraction layers.\n\nThe guide covers various aspects of creating a new Spell, including setting up prerequisites and the Spellbook dbt environment, deciding on a Spell to cast, setting up the file structure for SQL, schema, and source files, identifying and defining sources, defining expectations with schema and tests, writing the Spell as a SELECT statement, configuring alias and materialization strategy, and making a pull request to contribute the Spell to the official Spellbook.\n\nThis guide is particularly useful for developers and analysts who want to contribute to the Dune Docs project by creating new Spells or migrating existing V1 abstractions to V2 Spells. By following the steps outlined in the guide, users can ensure that their Spells are properly structured, tested, and submitted for review by the Dune Docs team.\n\nFor example, a user might want to create a new Spell that aggregates data from multiple sources to analyze the performance of a specific decentralized finance (DeFi) protocol. By following the guide, the user can set up the necessary environment, create the required files, write the SQL logic, and submit their Spell for review and potential inclusion in the official Spellbook.\n\nOverall, the \"Adding A Spell\" folder provides a comprehensive and detailed guide for users who want to contribute to the Dune Docs project by creating and submitting new Spells. The guide is well-organized and easy to follow, making it an excellent resource for users who are new to the Spellbook feature or the Dune Docs project as a whole.",
          "questions": ""
        },
        {
          "folderName": "top tables",
          "folderPath": ".autodoc\\docs\\json\\docs\\data tables\\spellbook\\top tables",
          "url": "https://dune.com/tree/master/doc\\docs\\json\\docs\\data tables\\spellbook\\top tables",
          "files": [
            {
              "fileName": "dex.trades.md",
              "filePath": "docs\\data tables\\spellbook\\top tables\\dex.trades.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\top tables\\dex.trades.md",
              "summary": "# Dex.Trades App Technical Guide\n\nThis technical guide provides an overview of the dex.trades feature of the Dune Docs project. Dex.trades is a table that aggregates data across multiple decentralized exchange (DEX) platforms into one simple table. The purpose of this table is to standardize and normalize trading data across virtually all relevant DEXs, making it easier for users to query trading data for their favorite tokens without having to deal with all of the different DEX smart contracts themselves.\n\n## Column Data\n\nThe guide provides a detailed breakdown of the column data contained in the dex.trades table. The column names, data types, and descriptions are all listed in a table format. Some of the key columns include:\n\n- `block_time`: The timestamp of the block that included the transaction\n- `token_a_symbol` and `token_b_symbol`: The symbols of the two tokens that were traded\n- `token_a_amount` and `token_b_amount`: The amounts of token A and token B that were traded\n- `project`: The DEX on which the trade was executed\n- `usd_amount`: The USD value of the trade\n\n## Github Repo\n\nThe guide also provides a link to the public Github repo where the scripts that generate the dex.trades table can be found. The repo is located in the `ethereum/dex` folder of the Dune Analytics Spellbook.\n\nOverall, this technical guide provides a high-level overview of the dex.trades feature of the Dune Docs project, including its purpose, column data, and Github repo.",
              "questions": "1. What blockchains does dex.trades support?\n- The `blockchain` column in the table provides information on which blockchain the trade occurred on.\n\n2. Can dex.trades handle trades from all decentralized exchanges?\n- The app technical guide states that dex.trades standardizes and normalizes trading data across \"virtually all relevant decentralized exchanges,\" but it is unclear if there are any exchanges that are not supported.\n\n3. How is the USD value of a trade calculated?\n- The `usd_amount` column in the table provides the USD value of a trade, but it is unclear how this value is calculated."
            },
            {
              "fileName": "labels.md",
              "filePath": "docs\\data tables\\spellbook\\top tables\\labels.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\top tables\\labels.md",
              "summary": "The Labels technical guide is a documentation for the Address Labels feature on Dune. The guide explains what labels are, how to add them, and how to use them. Labels are metadata about an address, in the form of a key-value pair, where the key is the label type and the value is the label name. The Labels feature allows users to add, update, and query labels for any address. \n\nThe guide provides examples of what can be created with labels, such as labeling all addresses that used a certain dapp, all addresses that hold a certain amount of a token, or all addresses that use a dapp more than X times per month. Users can also come up with their own label types and names, as labels on Dune are open-ended and crowd-sourced. \n\nThe Labels table stores labels in the `labels.labels` table, which has a schema that includes columns such as `id`, `address`, `name`, `blockchain`, `author`, `source`, `updated_at`, `label_type`, and `model_name`. \n\nThe guide also provides a warning that the Using Labels section is currently under construction. \n\nOverall, the Labels technical guide provides a comprehensive explanation of the Address Labels feature on Dune, including what labels are, how to add them, and how to use them. It also provides examples of what can be done with labels and information on how labels are stored in the Labels table.",
              "questions": "1. What is the purpose of the labels.labels table and what data is stored in it?\n   \n   The labels.labels table stores metadata about labeled addresses, including the label name, type, author, source, and last update time, as well as the address and blockchain it describes. It also includes the label model name.\n\n2. How are labels added to addresses and what are some examples of labels that can be added?\n   \n   Labels can be added to addresses using Dune queries, which can be used to label addresses based on various criteria such as dapp usage, token holdings, and transaction history. Examples of labels that can be added include addresses that used a certain dapp, hold a certain amount of a token, or sent money to a specific address.\n\n3. Are there any limitations or delays when querying labels in SQL on dune.com?\n   \n   There might be a few minutes delay from adding the label on dune.com until it can be queried in SQL."
            },
            {
              "fileName": "nft.trades.md",
              "filePath": "docs\\data tables\\spellbook\\top tables\\nft.trades.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\top tables\\nft.trades.md",
              "summary": "The `nft.trades` technical guide provides an overview of the effort to make NFT trading data easily available to everyone on Dune. The guide explains that the table aggregates and standardizes data between different data platforms and provides auxiliary information and metadata all in one table. The guide also lists the platforms that have been indexed so far, including OpenSea, Rarible, SuperRare, CryptoPunks, Foundation, and LooksRare.\n\nThe guide explains how single item trades work, including the exchange of an item between a buyer and a seller, the identification of the item through a combination of `nft_contract_address` and `token_id`, and the metadata associated with the trade. The guide also explains how bundle trades and aggregator trades work and provides recommendations for working with these types of trades.\n\nThe guide includes examples of SQL queries that can be used to retrieve data from the `nft.trades` table, including all trades for a given NFT, trades in the last 24 hours on a given platform, and platform volumes in the last year. The guide also includes examples of dashboards that utilize parameters and look across the entire ecosystem.\n\nThe guide provides a detailed list of column data, including the data type and description of each column. The guide also explains that the SQL code that processes the data for every marketplace is open source and available in the Dune Analytics GitHub repository, allowing anyone to review the code, make pull requests, and submit code to add more marketplaces.\n\nOverall, the `nft.trades` technical guide provides a comprehensive overview of the effort to make NFT trading data easily available to everyone on Dune, including how the table works, how different types of trades work, examples of SQL queries and dashboards, and a detailed list of column data.",
              "questions": "1. What platforms are currently indexed by nft.trades?\n- OpenSea, Rarible, SuperRare, CryptoPunks, Foundation, and LooksRare are currently indexed by nft.trades.\n\n2. What metadata is provided about the traded NFT?\n- The metadata provided about the traded NFT includes nft_project_name and erc_standard.\n\n3. What should be done if a platform is not indexed by nft.trades?\n- If a platform is not indexed by nft.trades, the SQL code that processes the data for every marketplace is open source and available in their GitHub repository. Anyone can review the code, make pull requests, and submit code to add more marketplaces."
            },
            {
              "fileName": "prices.md",
              "filePath": "docs\\data tables\\spellbook\\top tables\\prices.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\top tables\\prices.md",
              "summary": "# Prices\n\nThis technical guide covers the `Prices` feature of the Dune Docs project. The `Prices` feature allows users to get the price of almost all relevant ERC20 tokens. The price data is pulled from the Coinpaprika API and is volume-weighted based on real-time market data, translated to USD.\n\nThe guide provides two tables for getting prices: `prices.usd` and `prices_from_dex_data`. The `prices.usd` table supports a range of ERC20 tokens. If the token you desire is not listed in this table, you can make a pull request to the GitHub repository or use the decentralized price feed `dex.view_token_prices` for V1 Engine.\n\nThe `prices_from_dex_data` table creates price feeds based on decentralized exchange trading data. This table covers much more assets than `prices.usd` since it covers all assets that are traded on any of the decentralized exchanges that are indexed in `dex.trades`. However, this table is very resource-intensive and can only be updated every few hours. The resolution is only hourly, so if you need minutely prices, you should refer to `prices.usd`.\n\nThe guide also explains how the `prices_from_dex_data` table works. The script generates median hourly prices based on data from decentralized exchanges found in `dex.trades`. It assigns asset prices based on a trading pair that has a price feed in `prices.usd`. For example, if the $SPELL/ETH pool is used, the script will dynamically calculate the price of $SPELL based on the price of $ETH that was exchanged for it.\n\nThe guide also highlights known issues with the `prices_from_dex_data` table. In rare cases, the script will generate price feeds that are based on illiquid pairs and therefore report wrong data. This happens when all liquid trading pools of this token do not have a price feed in `prices.usd`. In such cases, you have to manually construct a price feed.\n\nOverall, this technical guide provides a comprehensive explanation of the `Prices` feature of the Dune Docs project. It explains how to use the two tables provided to get prices and highlights known issues with the `prices_from_dex_data` table.",
              "questions": "1. What is the source of price data for this app?\n- The price data is pulled from the coinpaprika API.\n\n2. What is the difference between the `prices.usd` table and the table that creates price feeds based on decentralized exchange trading data?\n- The `prices.usd` table supports a range of erc20.tokens and has a resolution by minute, while the table that creates price feeds based on decentralized exchange trading data covers much more assets than `prices.usd` and has a resolution only by hour.\n\n3. What are the known issues with the script that generates median hourly prices based on data from decentralized exchanges found in `dex.trades`?\n- In rare cases, the script will generate price feeds that are based on illiquid pairs and therefore report wrong data. This happens when all liquid trading pools of a token do not have a price feed in `prices.usd`. In cases like this, a manual price feed must be constructed."
            },
            {
              "fileName": "tokens.md",
              "filePath": "docs\\data tables\\spellbook\\top tables\\tokens.md",
              "url": "https://dune.com/blob/master/data tables\\spellbook\\top tables\\tokens.md",
              "summary": "The Tokens section of the app technical guide for the Dune Docs project covers token transfers and metadata. The guide is aimed at analysts who will be working with both fungible (erc20) and non-fungible (erc721 and erc1155) tokens. The guide provides information on several tables that are essential for working with tokens.\n\nThe Metadata tables section of the guide covers two tables: tokens.erc20 and tokens.nft. The tokens.erc20 table contains useful information such as the token symbol and the decimals for any given contract_address. The latter is needed to get the actual amount from raw amounts in on-chain data. The tokens.nft table contains the collection name and symbol for any given contract_address. These tables are usually joined on contract_address at the end of a query to make everything more human-readable.\n\nThe Transfer tables section of the guide covers two tables: erc20_ethereum.evt_Transfer and nft.transfers. The erc20_ethereum.evt_Transfer table contains all transfer events for every erc20 token. Analysts can find how to get erc20 balances, mints, and burns using a provided guide. The nft.transfers table contains all transfer events for every erc721 or erc1155 token. Analysts can learn how to leverage this to find nft balances, transfers, and mints in a provided guide.\n\nFinally, the guide provides a link to a guide on how to calculate native token balances like ethereum (ETH) balances. This guide is useful for analysts who need to calculate balances for native tokens.\n\nOverall, the Tokens section of the app technical guide provides essential information for analysts working with tokens. The guide covers metadata and transfer tables for both fungible and non-fungible tokens, as well as a guide on how to calculate native token balances.",
              "questions": "1. What types of tokens does this app support?\n   - The app supports both fungible (erc20) and nonfungible (erc721 and erc1155) tokens.\n2. What information can be found in the metadata tables?\n   - The metadata tables contain information such as the token symbol, decimals, collection name, and symbol for a given contract address.\n3. What transfer events can be found in the transfer tables?\n   - The transfer tables contain all transfer events for erc20, erc721, and erc1155 tokens, which can be used to find balances, transfers, mints, and burns."
            }
          ],
          "folders": [],
          "summary": "The `.autodoc\\docs\\json\\docs\\data tables\\spellbook\\top tables` folder contains technical guides for various features of the Dune Docs project, specifically focusing on data tables and their usage. These guides are essential for analysts working with different aspects of the project, such as token transfers, metadata, prices, address labels, and NFT trades.\n\nFor example, the `dex.trades.md` guide provides an overview of the dex.trades feature, which aggregates data across multiple decentralized exchange (DEX) platforms into one simple table. This guide is useful for users who want to query trading data for their favorite tokens without dealing with different DEX smart contracts.\n\nThe `labels.md` guide covers the Address Labels feature on Dune, explaining what labels are, how to add them, and how to use them. This guide is helpful for users who want to label addresses based on specific criteria, such as usage of a certain dapp or holding a certain amount of a token.\n\nThe `nft.trades.md` guide provides a comprehensive overview of the effort to make NFT trading data easily available on Dune. This guide is useful for users who want to retrieve data from the `nft.trades` table, such as all trades for a given NFT or platform volumes in the last year.\n\nThe `prices.md` guide covers the `Prices` feature, which allows users to get the price of almost all relevant ERC20 tokens. This guide is helpful for users who want to use the `prices.usd` and `prices_from_dex_data` tables to get token prices and understand the limitations of each table.\n\nLastly, the `tokens.md` guide focuses on token transfers and metadata for both fungible (erc20) and non-fungible (erc721 and erc1155) tokens. This guide is essential for analysts working with tokens, as it covers metadata and transfer tables, as well as a guide on how to calculate native token balances.\n\nOverall, the guides in this folder provide valuable information for analysts working with various aspects of the Dune Docs project. They offer detailed explanations, examples, and insights into how these features fit into the larger project and how they can be used effectively.",
          "questions": ""
        }
      ],
      "summary": "The `.autodoc\\docs\\json\\docs\\data tables\\spellbook` folder contains technical guides and resources for the Spells feature of the Dune project. Spells are custom tables that are built and maintained by Dune and the community, aiming to standardize and simplify data querying across multiple contracts and projects. The folder is divided into two subfolders: `contributing` and `top tables`.\n\nThe `contributing` subfolder provides a comprehensive guide on how to create and contribute a new Spell to the Spellbook. This guide is particularly useful for developers and analysts who want to contribute to the Dune Docs project by creating new Spells or migrating existing V1 abstractions to V2 Spells. For example, a user might want to create a new Spell that aggregates data from multiple sources to analyze the performance of a specific decentralized finance (DeFi) protocol. By following the guide, the user can set up the necessary environment, create the required files, write the SQL logic, and submit their Spell for review and potential inclusion in the official Spellbook.\n\nThe `top tables` subfolder contains technical guides for various features of the Dune Docs project, specifically focusing on data tables and their usage. These guides are essential for analysts working with different aspects of the project, such as token transfers, metadata, prices, address labels, and NFT trades. For instance, the `dex.trades.md` guide provides an overview of the dex.trades feature, which aggregates data across multiple decentralized exchange (DEX) platforms into one simple table. This guide is useful for users who want to query trading data for their favorite tokens without dealing with different DEX smart contracts.\n\nOverall, the guides in the `.autodoc\\docs\\json\\docs\\data tables\\spellbook` folder provide valuable information for analysts working with various aspects of the Dune Docs project. They offer detailed explanations, examples, and insights into how these features fit into the larger project and how they can be used effectively. By following these guides, users can ensure that their Spells are properly structured, tested, and submitted for review by the Dune Docs team, ultimately contributing to the standardization and simplification of data querying across the Dune ecosystem.",
      "questions": ""
    }
  ],
  "summary": "The `index.md` file in the `.autodoc\\docs\\json\\docs\\data tables` folder provides a comprehensive overview of the tables and chains available in the Dune Analytics platform. This guide is essential for users who want to navigate and query the platform effectively. The guide is divided into two main sections: the four kinds of tables and available chains.\n\nThe first section explains the process of ingesting data from node providers to create raw tables, which are then decoded using contract ABIs to provide easier to work with decoded tables. The abstracted tables are then created to standardize and aggregate the data from all other tables, giving users the easiest to work with spell tables. The community providers like Reservoir and Flashbots are also explained, which can be thought of as spell level abstractions.\n\nThe second section provides a list of available chains that can be queried in Dune Analytics. Each chain is explained in detail, including Ethereum, Gnosis Chain, Polygon POS, Optimism, BNB Chain, Arbitrum, Avalanche (C-Chain), Ethereum's Goerli Testnet, Fantom, Solana, and Bitcoin. The guide also includes links to relevant documentation for each chain, such as Ethereum.org for Ethereum, and the Binance Smart Chain documentation for BNB Chain.\n\nFor example, if a user wants to query data from the Ethereum Mainnet, they can read the section on Ethereum, which explains the history of Ethereum, its updates, and provides a link to Ethereum.org for further documentation. The guide also explains that querying on Dune works exactly the same as querying on Ethereum Mainnet.\n\nThe guide also includes a suggestion to look in spellbook and community datasets first, and then if users can't find what they want, they can try decoded and raw tables.\n\nOverall, this technical guide provides a comprehensive overview of the tables and chains available in Dune Analytics, making it easier for users to navigate and query the platform. By following this guide, analysts can effectively work with various data tables and chains, analyze their data, and integrate them into their projects.",
  "questions": ""
}